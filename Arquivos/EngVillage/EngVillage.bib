Results 988


@inproceedings{20082711344142 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A multi-stage approach for reliable dynamic reconfigurations of component-based systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {David, Pierre-Charles and Leger, Marc and Grall, Herve and Ledoux, Thomas and Coupaye, Thierry},
volume = {5053 LNCS},
year = {2008},
pages = {106 - 111},
issn = {03029743},
address = {Oslo, Norway},
abstract = {In this paper we present an end-to-end solution to define and execute reliable dynamic reconfigurations of open component-based systems while guaranteeing their continuity of service. It uses a multi-stage approach in order to deal with the different kinds of possible errors in the most appropriate way; in particular, the goal is to detect errors as early as possible to minimize their impact on the target system. Reconfigurations are expressed in a restricted, domain-specific language in order to allow different levels of static and dynamic validation, thus detecting errors before executing the reconfiguration where possible. For errors that can not be detected early (including software and hardware faults), a runtime environment provides transactional semantics to the reconfigurations. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Dynamical systems},
keywords = {Computer networks;Dynamic models;Dynamics;Error analysis;Errors;Information theory;Mechanics;Object recognition;},
note = {Component-based systems;Distributed applications (DA);Domain specific language (DSL);Dynamic reconfigurations;End to end (ETE);hardware faults;Heidelberg (CO);In order;international conferences;Interoperable systems;Multi-stage approach;runtime environments;Springer (CO);Static and dynamic;Target systems;},
URL = {http://dx.doi.org/10.1007/978-3-540-68642-2_9},
} 


@inproceedings{20081411178683 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A DSL approach for object memory management of small devices},
journal = {ACM International Conference Proceeding Series},
author = {Marquet, Kevin and Grimaud, Gilles},
volume = {272},
year = {2007},
pages = {155 - 164},
address = {Lisboa, Portugal},
abstract = {Small devices have a specific hardware configuration. In particular, they usually include several types of memories (typically ROM, internal and external RAM, Flash memory) different in quantities and properties. We propose an object memory management where the placement of an object in a given generation is based on different properties. This approach is supported by a domain specific language allowing to write powerful and flexible placement policies. These placement policies completely describe the placement, in the different memories, of the objects handled by the virtual machine. Copyright 2007 ACM.},
key = {DSL},
keywords = {Computer programming languages;Data storage equipment;Flash memory;Random access storage;ROM;},
note = {Domain specific language;Object memory management;Placement policies;Virtual machines;},
URL = {http://dx.doi.org/10.1145/1294325.1294346},
} 


@inproceedings{20074110855805 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {AVal: An extensible attribute-oriented programming validator for Java},
journal = {Proceedings - Sixth IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2006},
author = {Noguera, Carlos and Pawlak, Renaud},
year = {2006},
pages = {175 - 183},
address = {Philadelphia, PA, United states},
abstract = {Attribute Oriented Programming (@OP) permits programmers to extend the semantics of a base program by annotating it with attributes that are related to a set of concerns. Examples of this are applications that rely on XDoclet (such as Hibernate) or, with the release of Java5's annotations, EJB3. The set of attributes that implements a concern defines a Domain Specific Language, and as such, imposes syntactic and semantic rules on the way attributes are included in the program or even on the program itself. We propose a framework for the definition and checking of these rules for @OP that uses Java5 annotations. We define an extensible set of meta-annotations to allow the validation of @OP programs, as well as the means to extend them using a compile-time model of the program's source code. We show the usefulness of the approach by presenting two examples of its use: an @OP extension for the Fractal component model called Fraclet, and the JSR 181 for web services definition. &copy; 2006 IEEE.},
key = {Java programming language},
keywords = {Mathematical models;Object oriented programming;Semantics;Web services;},
note = {Attribute Oriented Programming;Compile-time model;Domain Specific Language;},
URL = {http://dx.doi.org/10.1109/SCAM.2006.5},
} 


@inproceedings{20080311037270 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Encodings of problems in effectively propositional logic},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Navarro-Perez, Juan Antonio and Voronkov, Andrei},
volume = {4501 LNCS},
year = {2007},
pages = {3 - },
issn = {03029743},
address = {Lisbon, Portugal},
abstract = {Solving various combinatorial problems by their translation to the propositional satisfiability problem has become commonly accepted. By optimising such translations and using efficient SAT solvers one can often solve hard problems in various domains, such as formal verification and planning. This approach to solving combinatorial problems is usually implemented by a translation procedure turning a formal description of the problem written in a domain-specific language L (for example, SMV for model checking problems [3] or STRIPS [2] for planning problems) into a SAT problem. Such translation procedures share the following common features: 1. They contain many isomorphic or nearly isomorphic subsets of clauses obtained by the translation of the same expression of L. 2. The size of the resulting SAT problem is dominated by these copies. In this talk the second author will present encodings able to specify some combinatorial problems, namely LTL bounded model checking [1] and planning within the Bernays-Scho&die;nfinkel fragment of first-order logic. This fragment, which also corresponds to the category of effectively propositional problems (EPR) of the CASC system competitions [4], allows a natural and succinct representation of both the transition systems corresponding to the problems and the property that one wants to verify, while avoiding the problem of creating isomorphic copies. Our technique provides a rich collection of benchmarks with close links to real-life applications for the automated reasoning community and may boost development of new translation techniques and solvers for effectively propositional problems. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Formal logic},
keywords = {Combinatorial mathematics;Computer programming languages;Problem solving;Verification;},
note = {Combinatorial problems;Domain specific language;Effectively propositional problems (EPR);Transition systems;},
} 


@article{20073110710386 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The case for frame-based software engineering},
journal = {IEEE Software},
author = {Bassett, Paul G.},
volume = {24},
number = {4},
year = {2007},
pages = {90 - 99},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {A frame is an archetype - a model from which all similar things are made. Frame technology can synthesize any information structure (such as a program) from machine-adaptable frames. The author contrasts FT with object-oriented classes. By canonically defining each information structure in terms of its unique properties, frames avoid the complexities induced by code-level redundancies. Frames also solve the problem of how to regenerate domain-specific-language programs without destroying prior customizations. The article includes evidence of FT's efficacy, its impact on software's life cycle, elements of frame design, and an easy way to get started. &copy; 2007 IEEE.},
key = {Software engineering},
keywords = {Automatic programming;Computer programming languages;Evolutionary algorithms;Object oriented programming;},
note = {Domain-specific-language programs;Frame-based software engineering;Information structure;Reuse models;Software engineering process;},
URL = {http://dx.doi.org/10.1109/MS.2007.119},
} 


@article{2005329284347 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {PyNSoL: Objects as scaffolding},
journal = {Computing in Science and Engineering},
author = {Tobis, Michael},
volume = {7},
number = {4},
year = {2005},
pages = {84 - 91},
issn = {15219615},
abstract = {PyNSol, the Pythonic Numeric Solver, an application development environment for finite difference and finite volume numerical methods is discussed. PyNSol is targeted to support researchers in the environmental sciences, but it could also be useful in other settings. PyNSol is discussed as an alternative approach to scientific computing. PyNSol's initial release supports only regular grids. PyNSol doesn't support adaptive mesh refinement, nested grids, or finite elements. PyNSol endevors to expose the domain-specific language at the Python interactive prompt. PyNSol's design disentangles the differencing and optimization methods from the physical model as far as the end user is concerned.},
key = {Software engineering},
keywords = {Climatology;Computer software;Finite difference method;Finite volume method;Mathematical models;Natural sciences computing;Object oriented programming;Optimization;},
note = {Domain-specific language;Environmental sciences;Pythonic Numeric Solver (PyNSol);Scaffolding;},
URL = {http://dx.doi.org/10.1109/MCSE.2005.78},
} 


@inproceedings{20080311018966 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a rule-based approach for context-aware applications},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Daniele, Laura and Costa, Patricia Dockhorn and Pires, Luis Ferreira},
volume = {4606 LNCS},
year = {2007},
pages = {33 - 43},
issn = {03029743},
address = {Enschede, Netherlands},
abstract = {Context-aware applications can sense and explore the users' context in order to provide proper and useful services to these users. These applications can react intelligently upon changes in the user's context, performing actions relevant to the user, the application itself, and the interaction between user and application. Context-aware reactive behaviors can be expressed by using rules written in a Domain-specific Language, coined ECA-DL, specially developed for context-aware applications. This paper proposes support for the development of a generic component capable of executing rules written using ECA-DL. This component executes these rules by using Jess, which is a well-known tool for developing rule-based systems. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Learning systems},
keywords = {Formal languages;Human computer interaction;Systems engineering;User interfaces;},
note = {Domain-specific Language;Rule-based systems;},
} 


@inproceedings{2001246536388 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Functional reactive programming from first principles},
journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
author = {Wan, Z. and Hudak, P.},
year = {2000},
pages = {242 - 252},
address = {Vancouver, BC, Canada},
abstract = {Functional Reactive Programming, or FRP, is a general framework for programming hybrid systems in a high-level, declarative manner. The key ideas in FRP are its notions of behaviors and events. Behaviors are time-varying, reactive values, while events are time-ordered sequences of discrete-time event occurrences. FRP is the essence of Fran, a domain-specific language embedded in Haskell for programming reactive animations, but FRP is now also being used in vision, robotics and other control systems applications. In this paper we explore the formal semantics of FRP and how it relates to an implementation based on streams that represent (and therefore only approximate) continuous behaviors. We show that, in the limit as the sampling interval goes to zero, the implementation is faithful to the formal, continuous semantics, but only when certain constraints on behaviors are observed. We explore the nature of these constraints, which vary amongst the FRP primitives. Our results show both the power and limitations of this approach to language design and implementation. As an example of a limitation, we show that streams are incapable of representing instantaneous predicate events over behaviors.},
key = {High level languages},
keywords = {Animation;Computer hardware description languages;Computer vision;Constraint theory;Embedded systems;Formal languages;Robotics;Semantics;Time sharing systems;Time varying systems;},
note = {Domain specific language;Formal semantics;Functional reactive programming;},
} 


@inproceedings{20081711212285 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {OOPSLA: 22nd International Conference on Object-Oriented Programming, Systems, Languages, and Applications - Proceedings},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
year = {2007},
pages = {ACM Special Interest Group on Programming Languages, SIGPLAN - },
address = {Montreal, QC, Canada},
abstract = {The proceedings contain 39 papers. The topics discussed include: variant path types for scalable extensibility; dependent classes; component nextgen: a sound and expressive component framework for Java; user-changeable visibility resolving unanticipated name clashes in traits; tractions with isolation and cooperation; granting Java interface developers their wishes; the justadd extensible Java compiler; streamflex: high-throughput stream programming in Java; the causes of bloat, the limits of health; notation and representation in collaborative object-oriented design: an observational study; WebRB: evaluating a visual domain-specific language for building relational web-application; modular typestate checking of aliased objects; and modular verification of higher-order methods with mandatory calls specified by model programs.},
key = {Object oriented programming},
keywords = {Computer hardware description languages;Computer programming languages;Computer software selection and evaluation;Computer systems programming;Java programming language;Linguistics;Model checking;Neodymium;Query languages;},
note = {(SPM) classes;Aliased;component frameworks;Domain specific language (DSL);High-throughput (HT);Higher order methods;international conferences;Java compilers;Java interfaces;Languages (traditional);Model programs;Modular verification;Object-oriented design (OOD);Object-oriented programming;Observational studies;stream programming;type states;},
} 


@article{20080611080300 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Integration of RE and MDE paradigms: The ProjectIT approach and tools},
journal = {IET Software},
author = {Da Silva, A.R. and Saraiva, J. and Ferreira, D. and Silva, R. and Videira, C.},
volume = {1},
number = {6},
year = {2007},
pages = {294 - 314},
issn = {17518806},
address = {Six Hills Way, Stevenage, SG1 2AY, United Kingdom},
abstract = {The suggestion that in software development projects the emphasis must be on the project management (RE), requirements engineering, and design activities, and consequently efforts in production activities - such as traditional software programming and testing - should be minimised and performed as automatically as possible is discussed. The ProjectIT approach that integrates contributions from the RE and model-driven engineering communities is also discussed. The goal with requirement specification is not just in managing textual specifications, but also to obtain a consistent requirements document that is in conformance with a domain-specific language, and that can be re-used to increase the design and development activities in the context of model driven and code generation techniques. Furthermore, the feasibility and benefits of this approach by presenting a proof-of-concept case study are discussed, in which the orchestration of the concepts and concrete components related with the ProjectIT approach, the PIT-RSL, XIS and PIT-TSL languages and the ProjectIT-Studio CASE tool is emphasised. A practical demonstration of the approach including the description of the system requirements, the design of the system, the use of code generation techniques, and how they integrate to improve and accelerate the software engineering lifecycle is presented. &copy; The Institution of Engineering and Technology 2007.},
key = {Project management},
keywords = {Computer programming;Formal languages;Information technology;Software engineering;Systems analysis;},
note = {Domain-specific language;Software engineering lifecycles;Software programming;},
URL = {http://dx.doi.org/10.1049/iet-sen:20070012},
} 


@inproceedings{20085111787542 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Self-sustained routing for event Diffusion in wireless sensor networks},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Terfloth, Kirsten and Schiller, Jochen},
volume = {5321 LNCS},
year = {2008},
pages = {236 - 241},
issn = {03029743},
address = {Orlando, FL, United states},
abstract = {Wireless sensor networks have the potential to become a scalable, low-cost and highly flexible tool for distributed monitoring and/or event recognition: Embedded devices that coordinate themselves via wireless communication to implement a common, distributed application are already seeing first industrial adaption in e.g. home automation, personal health or environmental monitoring. Despite of their valuable properties they put a high burden upon application development since critical issues such as a general resource scarcity, the unreliable communication medium and the management of distribution are often visible throughout the protocol stack to ensure efficient utilization. In the demo, we will show how our middleware framework FACTS helps to alleviate problems in implementation of both system- and application-level code. Providing a rule-based, domain-specific language, FACTS is especially suited to express event-driven tasks. Therefore, we will showcase how to efficiently program a self-sustained routing protocol forwarding relevant events to dedicated sink nodes with only a handful of rules. &copy; 2008 Springer Berlin Heidelberg.},
key = {Wireless sensor networks},
keywords = {Applications;Computer networks;Computer software;Hybrid sensors;Interchanges;Internet protocols;Intersections;Linguistics;Middleware;Routing protocols;Sensor networks;Sensors;Wireless telecommunication systems;},
note = {Application developments;Communication mediums;Critical issues;Distributed applications;Distributed monitoring;Do-mains;Domain-specific language;Embedded devices;Environmental monitoring;Event recognitions;Event-driven;FACTS;Flexible tools;Home automations;Middleware frameworks;Personal healths;Protocol stacks;Resource scarcities;Routing;Rules;Sink nodes;Specific languages;Wireless communications;},
URL = {http://dx.doi.org/10.1007/978-3-540-88808-6-25},
} 


@article{20084111629309 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Schema driven assignment and implementation of life science identifiers (LSIDs)},
journal = {Journal of Biomedical Informatics},
author = {Bafna, Sapna and Humphries, Julian and Miranker, Daniel P.},
volume = {41},
number = {5},
year = {2008},
pages = {730 - 738},
issn = {15320464},
address = {6277 Sea Harbor Drive, Orlando, FL 32887-4900, United States},
abstract = {Life science identifier (LSID) is a global unique identifier standard intended to help rationalize the unique archival requirements of biological data. We describe LSID implementation architecture such that data managed by a relational database management system may be integrated with the LSID protocol as an add-on layer. The approach requires a database administrator (DBA) to specify an export schema detailing the content and structure of the archived data, and a mapping of the existing database to that schema. This specification can be expressed using SQL view syntax. In effect, we define a SQL-like language for implementing LSIDs. We describe the mapping of the view definition to an implementation as a set of databases triggers and a fixed runtime library. Thus a compiler for a domain-specific language could be written that would reduce the implementation of LSIDs to the task of writing SQL view-like definitions. &copy; 2008 Elsevier Inc.},
key = {Database systems},
keywords = {Administrative data processing;Conformal mapping;Linguistics;Management information systems;Network architecture;Query languages;Semiconductor quantum dots;Standards;},
note = {Archived data;Biological data;Biology;Content and structure;Database administrator;Domain-Specific Language;Export schema;Implementation architecture;Life sciences;LSID;Metadata;RDF;Relational database management system;Resolution;Run-time libraries;Systematics;Trigger;View;},
URL = {http://dx.doi.org/10.1016/j.jbi.2008.05.014},
} 


@inproceedings{1999140005619 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Safe and efficient active network programming},
journal = {Proceedings of the IEEE Symposium on Reliable Distributed Systems},
author = {Thibault, Scott and Consel, Charles and Muller, Gilles},
year = {1998},
pages = {135 - 143},
issn = {10609857},
address = {West Lafayette, IN, USA},
abstract = {Active networks are aimed at incorporating programmability into the network to achieve extensibility. One approach to obtaining extensibility is to download router programs into network nodes. This programmability is critical to allow multipoint distributed systems to adapt to network conditions and individual clients' needs. Although promising, this approach raises critical issues such as safety to achieve reliability despite the complexity of a distributed system, security to protect shared resources, and efficiency to maximize usage of bandwidth. This paper proposes the use of a domain-specific language, PLAN-P, to address all of the above issues. To address safety and security, we give examples of properties of PLAN-P programs that can be automatically checked due to the use of a restricted language. For efficiency, we show that an automatically generated run-time compiler for PLAN-P produces code which outperforms an equivalent compiled Java program. Additionally, we present performance results on a real application (learning bridge) where we obtain 100% of the maximum possible throughput.},
key = {Computer programming},
keywords = {Client server computer systems;Computational complexity;Computer networks;Computer programming languages;Program compilers;Response time (computer systems);Security of data;},
note = {Active network programming;Domain specific language;Software Package PLAN P;},
} 


@inproceedings{20083411477081 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using DSL for automatic generation of software connectors},
journal = {Proceedings - 7th International Conference on Composition-Based Software Systems, ICCBSS 2008},
author = {Bure, Toma and Malohlava, Michal and Hnetynka, Petr},
year = {2008},
pages = {138 - 147},
address = {Madrid, Spain},
abstract = {Component-based engineering is a recognized paradigm, which models an application as a collection of reusable components. The key idea behind components is that they contain only the business logic and communicate with one another only via well-defined interfaces. The communication paths among components (so called bindings) are in modern component systems realized by software connectors, which allow explicit modeling of communication and also its implementation at runtime. An important aspect of using connectors is the possibility of their automatic generation, which saves a significant amount of development work. However, the generation itself is not a trivial task, since there is a big semantic gap between the abstract specification of a connector at design time and its implementation at runtime. In this paper, we present an approach to generating implementations of software connectors. The approach is based on a new domain specific language for describing templates of connector implementations and a transformation framework using the Strate-go/XT term rewriting system for generating source code of connectors. &copy; 2008 IEEE.},
key = {Connectors (structural)},
keywords = {Abstracting;Computer software;Computer software reusability;Information theory;Models;Technology;},
note = {Abstract specifications;Automatic generation;Business logics;Communication paths;Component systems;Component-based engineering;Design time;Domain-Specific Language;Explicit modeling;International conferences;Reusable components;Run-time;Semantic gaps;Software connectors;Software systems;Source coding;Term rewriting system;},
URL = {http://dx.doi.org/10.1109/ICCBSS.2008.17},
} 


@inproceedings{2001446711934 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Recent advances in process systems engineering},
journal = {Conference Record - IEEE Instrumentation and Measurement Technology Conference},
author = {Linninger, A.A.},
volume = {3},
year = {2001},
pages = {1665 - 1670},
address = {Budapest, Hungary},
abstract = {A crucial success factor in a technology driven market is coupled with the ability to understand and interpret new technologies expeditiously and convert this knowledge into a competitive advantage. In search for procedures to advance corporate know-how faster, mathematical modeling is becoming an indispensable tool. The new challenge for systems research is to create a new breed of computer-based technologies for assistance and/or partial automation of the creative modeling process. Meta-modeling is a modeling paradigm for rapid computer-aided model generation of large multi-scale systems in the industrial practice. It proposes model building by means of phenomena-oriented modeling languages. Using the domain-specific language concepts, users compose process models by specifying the physical and chemical phenomena in a fully declarative fashion. Automatic interpretation of the high-level concepts of the model application leads to an equivalent set of system equations. Computer-aided model generation enables engineering teams of formulate highly structured process models in short amount of time. It also focuses the modeling effort onto the fundamental principles governing a process model without the need for explicit coding of all constitutive and balance equations. This article discusses recent advances and open challenges for computer-aided model generation.},
key = {Systems engineering},
keywords = {Computer aided engineering;Computer hardware description languages;Computer simulation;Computer simulation languages;Computer supported cooperative work;Differential equations;Distributed computer systems;Encoding (symbols);High level languages;Large scale systems;Mathematical models;Runge Kutta methods;},
note = {Computer aided model generation;Domain specific language;Phenomena oriented modeling languages;Process systems engineering;},
URL = {http://dx.doi.org/10.1109/IMTC.2001.929486},
} 


@inproceedings{20083511479656 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Visualizing the analysis of dynamically adaptive systems using i* and DSLs},
journal = {2nd International Workshop on Requirements Engineering Visualization, REV 2007},
author = {Sawyer, Pete and Bencomo, Nelly and Hughes, Danny and Grace, Paul and Goldsby, Heather J. and Cheng, Betty H. C.},
year = {2007},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {Self-adaptation is emerging as a crucial enabling capability for many applications, particularly those deployed in dynamically changing environments. One key challenge posed by Dynamically Adaptive Systems (DASs) is the need to handle changes to the requirements und corresponding behavior of a DAS in response to varying environmental conditions. In this paper we propose a visual model-driven approach that uses the i* modeling language to represent goal models for the DAS requirements. Our approach applies a rigorous separation of concerns between the requirements for the DAS to operate in stable conditions and those that enable it to adapt at run-time to enable it to cope with changes in its environment. We further show how requirements derived from the i* modeling can be used by a domain-specific language to achieve requirements model-driven development. We describe our experiences with applying this approach to GridStix, an adaptive flood warning system, deployed on the River Ribble in North Yorkshire, England. &copy; 2007 IEEE.},
key = {Adaptive systems},
keywords = {Electronic warfare;Embedded systems;Intelligent vehicle highway systems;Linguistics;Military electronic countermeasures;Military operations;Requirements engineering;Separation;Systems analysis;Technology;Visualization;},
note = {Changing environments;Domain-Specific Language;England;Environmental conditioning;Flood warning systems;Goal modeling;Model-driven approach;Modeling languages;North Yorkshire;Requirements modeling;Run-time;Self-adaptation;Separation of concerns;},
URL = {http://dx.doi.org/10.1109/REV.2007.10},
} 


@article{1995142560600 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Theory and practice of middle-out programming to support program understanding},
journal = {Program Comprehension, Workshop Proceedings},
author = {Bennett, K.H. and Ward, M.P.},
year = {1994},
pages = {168 - 175},
address = {Washington, DC, USA},
abstract = {The paper describes recent work and results at Durham on what is termed as middle-out programming. The objective is to avoid the problems of top-down and bottom-up approaches by designing a high-level language specific to the application domain. An example of using this approach in the design of a large software system is presented. The main gain achieved in comprehension is through the large reduction in system size, and through a domain specific language. Other novel features of the approach are: the ability to provide a theoretical basis for user-enhanceable systems; the simplification of the capture of domain knowledge; and the concurrent engineering of the development and requirement stages.},
key = {High level languages},
keywords = {Computer aided design;Computer aided software engineering;Computer programming;Computer simulation;Computer software;Concurrent engineering;Graph theory;Hierarchical systems;Large scale systems;User interfaces;},
note = {Domain knowledge;Domain specific language;Generic approach;Hierarchical structures;Large software system;Middle out programming;Program comprehension;Program understanding;User enhanceable systems;},
} 


@inproceedings{20080411044487 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A transformation-driven approach to the verification of security policies in web designs},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Guerra, Esther and Sanz, Daniel and Diaz, Paloma and Aedo, Ignacio},
volume = {4607 LNCS},
year = {2007},
pages = {269 - 284},
issn = {03029743},
address = {Como, Italy},
abstract = {In this paper, we present a verification framework for security policies of Web designs. The framework is based on the transformation of the models that conform the system design into a formalism where further analysis can be performed. The transformation is specified as a triple graph transformation system, which in addition creates mappings between the elements in the source and target models. This allows the back-annotation of the analysis results to the original model by means of triple graphical patterns. The verification mechanisms are provided by the designer of the Web design language, together with the language specification. However, the complexities of the formalisms are hidden to the developer who uses the language. As case study, we apply these ideas to Labyrinth, a domain specific language oriented to the design of Web applications. The analysis is done by a transformation into the Petri nets formalism, and then performing model checking on the coverability graph. The framework is supported by the meta-modelling tool AToM<sup>3</sup>. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {World Wide Web},
keywords = {Computer programming languages;Mathematical models;Pattern recognition;Petri nets;Systems analysis;},
note = {Domain specific language;Security policies;Web applications;Web design language;},
} 


@inproceedings{20082811368021 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Composing SIC: A lightweight service model for wireless sensor networks},
journal = {2007 International Conference on Sensor Technologies and Applications, SENSORCOMM 2007, Proceedings},
author = {Bergstrom, Eric and Pandey, Raju},
year = {2007},
pages = {475 - 483},
address = {Valencia, Spain},
abstract = {Although Wireless Sensor Network applications share a common set of limitations (e.g. resource scarcity and lossy radio communication models) a basic set of runtime services (e.g. routing, time synchronization, and code dissemination), applications are often designed in an adhoc fashion, reducing the amount of code reuse, making a component-based software engineering approach desirable. We present a micro service component model, entitled &mu;SIC, that abstracts a sensor node as an entity that provides and uses services. This model is realized through the use of the &mu;SIC runtime, a small and efficient Message-Oriented Middleware (MOM) tailored for resource-constrained devices. The &mu;SIC runtime can perform service-paging, a method of storing a service's state to flash memory and restoring it whenever the service is needed. Secondly, we provide a domain-specific language allowing applications to be expressed as a collection of services that run on top of the &mu;SIC runtime and enables a multi-threaded programming model. &copy; 2007 IEEE.},
key = {Wireless sensor networks},
keywords = {Applications;BASIC (programming language);Codes (standards);Codes (symbols);Computer programming languages;Computer software;Computer software reusability;Data storage equipment;Detectors;Flash memory;Hybrid sensors;Information theory;Middleware;Models;Network architecture;Radio communication;Routing protocols;Sensor networks;Sensors;Software engineering;Telecommunication equipment;Wireless telecommunication systems;},
note = {code dissemination;Code Reuse (CR);Communication models;Component-based software engineering (CBSE);Domain specific language (DSL);international conferences;Message-Oriented Middleware (MOM);Multithreaded programming (MTP);Resource constrained devices;resource scarcity;Run time;Run time services;Sensor node (SN);Sensor technologies;Service components;service modeling;Time synchronization;Wireless sensors;},
URL = {http://dx.doi.org/10.1109/SENSORCOMM.2007.4394966},
} 


@inproceedings{20073510786314 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Benchmark generation using domain specific modeling},
journal = {Proceedings of the Australian Software Engineering Conference, ASWEC},
author = {Bui, Ngoc Bao and Zhu, Liming and Gorton, Ian and Liu, Yan},
year = {2007},
pages = {169 - 178},
address = {Melbourne, Australia},
abstract = {Performance benchmarks are domain specific applications that are specialized to a certain set of technologies and platforms. The development of a benchmark application requires mapping the performance specific domain concepts to an implementation and producing complex technology and platform specific code. Domain Specific Modeling (DSM) promises to bridge the gap between application domains and implementations by allowing designers to specify solutions in domain-specific abstractions and semantics through Domain Specific Languages (DSL). This allows generation of a final implementation automatically from high level models. The modeling and task automation benefits obtained from this approach usually justify the upfront cost involved. This paper employs a DSM based approach to invent a new DSL, DSLBench, for benchmark generation. DSLBench and its associated code generation facilities allow the design and generation of a completely deployable benchmark application for performance testing from a high level model. DSLBench is implemented using Microsoft Domain Specific Language toolkit. It is integrated with the Visual Studio 2005 Team Suite as a plug-in to provide extra modeling capabilities for performance testing. We illustrate the approach using a case study based on .Net and C#. &copy; 2007 IEEE.},
key = {Software engineering},
keywords = {Automatic programming;Codes (symbols);Computer programming languages;Mathematical models;Program compilers;Semantics;},
note = {Benchmark application;Benchmark generation;Domain specific modeling;Microsoft Domain Specific Language toolkit;},
URL = {http://dx.doi.org/10.1109/ASWEC.2007.13},
} 


@inproceedings{20083211435121 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Behavioral fault modeling for model-based safety analysis},
journal = {Proceedings of IEEE International Symposium on High Assurance Systems Engineering},
author = {Joshi, Anjali and Heimdahl, Mats P.E.},
year = {2007},
pages = {199 - 208},
issn = {15302059},
address = {Dallas, TX, United states},
abstract = {Recent work in the area of Model-based Safety Analysis has demonstrated key advantages of this methodology over traditional approaches, for example, the capability of automatic generation of safety artifacts. Since safety analysis requires knowledge of the component faults and failure modes, one also needs to formalize and incorporate the system fault behavior into the nominal system model. Fault behaviors typically tend to be quite varied and complex, and incorporating them directly into the nominal system model can clutter it severely. This manual process is error-prone and also makes model evolution difficult. These issues can be resolved by separating the fault behavior from the nominal system model in the form of a "fault model", and providing a mechanism for automatically combining the two for analysis. Towards implementing this approach we identify key requirements for a flexible behavioral fault modeling notation. We formalize it as a domain-specific language based on Lustre, a textual synchronous dataflow language. The fault modeling extensions are designed to be amenable for automatic composition into the nominal system model. &copy; 2007 IEEE.},
key = {Modal analysis},
keywords = {Chlorine compounds;Dynamic programming;Failure analysis;Industrial engineering;Linguistics;Model structures;Quality assurance;Reliability;Safety engineering;Security systems;Systems engineering;Technical presentations;Technology;},
note = {Automatic composition;Automatic generation;Component faults;Domain-Specific Language;Error-prone;Fault modeling;High assurance systems;International symposium;Model evolution;Model-based;Nominal systems;Safety analysis;Synchronous data flow;System faults;},
URL = {http://dx.doi.org/10.1109/HASE.2007.25},
} 


@inproceedings{20083111409905 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific model editors with model completion},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Sen, Sagar and Baudry, Benoit and Vangheluwe, Hans},
volume = {5002 LNCS},
year = {2008},
pages = {259 - 270},
issn = {03029743},
address = {Nashville, TN, United states},
abstract = {Today, integrated development environments such as Eclipse allow users to write programs quickly by presenting a set of recommendations for code completion. Similarly, word processing tools such as Microsoft Word present corrections for grammatical errors in sentences. Both of these existing systems use a set of constraints expressed in the form of a grammar to restrict/correct the user. Taking this idea further, in this paper we present an integrated software system capable of generating recommendations for model completion of partial models built in arbitrary domain specific model editors. We synthesize the model editor equipped with automatic completion from a modelling language's declarative specification consisting of a meta-model and constraints on it along with a visual syntax. The automatic completion feature is powered by a Prolog engine whose input is a constraint logic program derived from some models. The input logic program is obtained by a model transformation from models in multiple languages: the meta-model (as a class diagram), constraints on it (as constraint logic clauses), and a partial model (in the domain specific language). The Prolog engine solves the generated logic program and the solution(if there is one) is returned to the model editor as a set of recommendations for properties of the partial model. We incorporate automatic completion in the generative tool AToM <sup>3</sup> and use SWI-Prolog for constraint representation and satisfaction. We present examples using an illustrative visual language of Finite State Machines. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Artificial intelligence},
keywords = {Bioinformatics;Computational linguistics;Computer science;Computer simulation languages;Computer software;Fuzzy logic;Linguistics;Logic programming;Models;PROLOG (programming language);Query languages;Software engineering;Word processing;},
note = {Automatic completion;Class diagram (CD);Constraint logic program (CLP);Declarative specification;Domain specific;Domain specific language (DSL);Eclipse (CO);Existing systems;Grammatical errors;Integrated Development Environments (IDE);Integrated software systems;Lecture Notes;Logic programs;Meta modelling;Microsoft Word;Model transformations;Multiple languages;Processing tools;},
URL = {http://dx.doi.org/10.1007/978-3-540-69073-3_27},
} 


@inproceedings{20074010847549 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automating the generation, deployment and application of charging schemes for composed IMS services},
journal = {10th IFIP/IEEE International Symposium on Integrated Network Management 2007, IM '07},
author = {Xu, Lei and Jennings, Brendan},
year = {2007},
pages = {856 - 859},
address = {Munich, Germany},
abstract = {Providers of communications services aim to specify, realise and deploy services as quickly as possible in order to gain a competitive edge in meeting evolving consumer demands. One means of creating new service offerings is the composition of pre-existing services which, when orchestrated in a particular manner, provide novel functionality. Indeed, many industry analysts predict the emergence of virtual services providers, who do not themselves deploy and offer individual services, but instead orchestrate services offered by other providers. Crucial to the success of providers offering composed services is an efficient, automated process by which such services are charged and billed for. In this paper we present a process for automated generation of charging schemes for composed IMS services, based on analysis of the charging schemes associated with services comprising those composed services. Charging schemes are specified using a Domain Specific Language (DSL), so that they can then be mapped to platform specific representations that can be deployed onto one or more rating engines. Semiautomated configuration of charging schemes in this manner obviates the need for expensive manual configuration of accounting components every time a new composed services is specified and activated. &copy; 2007 IEEE.},
key = {Telecommunication services},
keywords = {Information services;Internet service providers;Quality of service;Telecommunication industry;Virtual reality;},
note = {Charging schemes;Domain specific language;IMS services;Multi provider composed services;Service composition;},
URL = {http://dx.doi.org/10.1109/INM.2007.374728},
} 


@article{20073110714094 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {DSLBench: Applying DSL in benchmark generation},
journal = {ACM International Conference Proceeding Series},
author = {Bui, Ngoc Bao and Jeffery, Ross},
volume = {183},
year = {2006},
address = {Melbourne, Australia},
abstract = {Meeting performance requirements is a challenging software engineering problem in designing and constructing middleware based applications. Considerable efforts have been spent to build performance analysis models from the application architectural models that can be applied before the implementation phase. Accurate analysis models require realistic performance data to be populated into the performance models, which represents the performance characteristics of the middleware and the application hosted by the middleware runtime environment. Benchmark applications are usually developed to collect these performance data. However, benchmark generation for middleware-based systems is a costly and time consuming process because of the complexity of programming models and technology specific features of different types of middleware. The paper proposes an approach to automate benchmark generation processes following Model Driven Development methodology, which aims to construct deployable benchmark applications from the high-level design models. A modelling language is designed specifically for performance testing domain by using the recently released Microsoft Domain Specific Language toolkit. This approach can be integrated into Visual Studio 2005 Team System as a "plug in " to model and generate load testing suites. Copyright 2006 ACM.},
key = {DSL},
keywords = {Computer programming languages;Mathematical models;Middleware;Problem solving;Software architecture;Software testing;},
note = {Domain specific language;Domain specific modeling;Language toolkit;Model driven development;},
URL = {http://dx.doi.org/10.1145/1169086.1169087},
} 


@inproceedings{20073910826323 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Revel8or: Model driven capacity planning tool suite},
journal = {Proceedings - International Conference on Software Engineering},
author = {Zhu, Liming and Liu, Yan and Bui, Ngoc Bao and Gorton, Ian},
year = {2007},
pages = {797 - 800},
issn = {02705257},
address = {Minneapolis, MN, United states},
abstract = {Designing complex multi-tier applications that must meet strict performance requirements is a challenging software engineering problem. Ideally, the application architect could derive accurate performance predictions early in the project life-cycle, leveraging initial application design-level models and a description of the target software and hardware platforms. To this end, we have developed a capacity planning tool suite for component-based applications, called Revel8tor. The tool adheres to the model driven development paradigm and supports benchmarking and performance prediction for J2EE, .Net and Web services platforms. The suite is composed of three different tools: MDAPerf MDABench and DSLBench. MDAPerf allows annotation of design diagrams and derives performance analysis models. MDABench allows a customized benchmark application to be modeled in the UML 2.0 Testing Profile and automatically generates a deployable application, with measurement automatically conducted. DSLBench allows the same benchmark modeling and generation to be conducted using a simple performance engineering Domain Specific Language (DSL) in Microsoft Visual Studio. DSLBench integrates with Visual Studio and reuses its load testing infrastructure. Together, the tool suite can assist capacity planning across platforms in an automated fashion. &copy; 2007 IEEE.},
key = {Software design},
keywords = {Automation;Formal languages;Life cycle;Mathematical models;Problem solving;Web services;},
note = {Domain Specific Language (DSL);Project life-cycle;},
URL = {http://dx.doi.org/10.1109/ICSE.2007.73},
} 


@inproceedings{20073110742060 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A verified staged interpreter is a verified compiler},
journal = {Proceedings of the 5th International Conference on Generative Programming and Component Engineering, GPCE'06},
author = {Brady, Edwin and Hammond, Kevin},
year = {2006},
pages = {111 - 120},
address = {Portland, OR, United states},
abstract = {Dependent types and multi-stage programming have both been used, separately, in programming language design and implementation. Each technique has its own advantages - - with dependent types, we can verify aspects of interpreters and compilers such as type safety and stack invariants. Multi-stage programming, on the other hand, can give the implementor access to underlying compiler technology; a staged interpreter is a translator. In this paper, we investigate the combination of these techniques. We implement an interpreter for a simply typed lambda calculus, using dependent types to guarantee correctness properties by construction. We give explicit proofs of these correctness properties, then add staging annotations to generate a translator from the interpreter. In this way, we have constructed a verified compiler from a verified staged interpreter. We illustrate the application of the technique by considering a simple staged interpreter that provides guarantees for some simple resource bound properties, as might be found in a domain specific language for real-time embedded systems. Copyright &copy; 2006 ACM.},
key = {Program interpreters},
keywords = {Computer aided design;Embedded systems;Functional programming;Multi agent systems;Program compilers;Real time systems;Resource allocation;},
note = {Dependent types;Domain specific language implementation;Multi-stage programming;Partial evaluation;Resource aware programming;},
URL = {http://dx.doi.org/10.1145/1173706.1173724},
} 


@article{20080911116284 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {NOAH: A CSP-based language for describing the behaviour of coupled models},
journal = {Software - Practice and Experience},
author = {Armstrong, C.W. and Ford, R.W. and Freeman, T.L. and Riley, G.D.},
volume = {38},
number = {2},
year = {2008},
pages = {135 - 159},
issn = {00380644},
address = {Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom},
abstract = {Scientists in many fields rely on computational simulations that are built from a collection of separate, inter-communicating single models (e.g. Earth System Models often consist of single models of the ocean, atmosphere and land processes); these simulations are called coupled models. Coupled models allow scientists to simulate richer scientific phenomena than is possible by running single models alone. Scientific interest is typically focused on the investigation served by a coupled model, rather than the complex and inadequately supported software engineering activity of constructing it. In response to this lack of support, a coupling methodology called the Flexible Coupling Approach (FCA) has been developed at the University of Manchester together with a tool that implements this approach, the Bespoke Framework Generator (BFG). Whilst being adequate for a large class of coupled models (e.g., many Earth System Models), the BFG is unable to handle coupled models with complex behavioural requirements (in terms of the scheduling and inter-communication of single models). To capture these more complex expressions of behaviour, this paper introduces NOAH, a domain-specific language that is implemented in the formalism Communicating Sequential Processes (CSP), and which is used by a new implementation of the FCA, called the CSP-based Framework Generator (CFG). NOAH is introduced through two example coupled models which have complex behavioural requirements. NOAH represents the first attempt to bring the advantages of using formal descriptions of coupled models to application scientists, providing a language in which to specify coupled model behaviour precisely and the ability to check that a coupled model is deadlock free using tools such as the Failures-Divergence Refinement (FDR) model checker. Copyright &copy; 2007 John Wiley &amp; Sons, Ltd.},
key = {Computer simulation languages},
keywords = {Automatic programming;Computer aided software engineering;Computer system recovery;Mathematical models;Problem solving;},
note = {Automatic code generation;Coupled modeling;Domain specific language;},
URL = {http://dx.doi.org/10.1002/spe.822},
} 


@inproceedings{2001496752890 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Developing a stage lighting system for scratch},
journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
author = {Sperber, M.},
year = {2001},
pages = {122 - 133},
address = {Florence, Italy},
abstract = {Lula is a system for computer-assisted stage lighting design and control. Whereas other systems for the same purpose are usually the results of long chains of incremental improvements of historic concepts. Lula represents a complete redesign. Whereas other systems focus on control aspects of lighting. Lula focuses on design and generates control information from it. This approach gives significantly more flexibility to the lighting designer and shortens the design process itself. Lula's design and implementation draw from a number of disciplines in advanced programming. It is written in Scheme and runs atop PLT Scheme, and benefits from its high-level GUI library. Lula uses an algebraic model for lighting looks based on just three combinators. It employs Functional Reactive Programming for all dynamic aspects of lighting, and is programmable via a functional-reactive domain-specific language. Lula is an actual product and has users who have neither interest in nor knowledge of functional programming.},
key = {Computer programming},
keywords = {Animation;Computational methods;Computer aided design;Computer programming languages;Computer software;Graphical user interfaces;Lighting;Semantics;},
note = {Computer-assisted stage lighting design;Functional reactive domain specific language;Functional reactive programming;},
URL = {http://dx.doi.org/10.1145/507635.507652},
} 


@inproceedings{20073110742063 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Gaigen 2: A geometric algebra implementation generator},
journal = {Proceedings of the 5th International Conference on Generative Programming and Component Engineering, GPCE'06},
author = {Fontijne, Daniel},
year = {2006},
pages = {141 - 150},
address = {Portland, OR, United states},
abstract = {Geometric Algebra (GA) is an algebra that encodes geometry much better than standard techniques, which are mainly based on linear algebra with various extensions. Compared to standard techniques, GA has clearer semantics and a richer, more consistent language. This expresses itself, among others, in a much greater genericity of functions over the algebra. Exploiting this genericity efficiently is a problem that can be solved through generative programming.This paper describes our Geometric Algebra Implementation Generator Gaigen 2. Gaigen 2 synthesizes highly efficient GA implementations from the specification of the algebra. Functions over such algebras can be defined in a high-level coordinate-free domain-specific language, and Gaigen 2 transforms these functions into low-level coordinate-based code. This code can be emitted in any target language through a custom back-end. Benchmarks of our implementation show that the combination of GA and Gaigen 2 can rival the performance of standard geometry techniques, despite the greater abstraction and genericity of GA.To obtain this high performance, Gaigen 2 must adapt the generated code to the program that links to it. This is done via a profiling feedback loop. While running, the generated code makes a connection to the code generator. The generated code sends information about functions that should be optimized. The code generator registers this information and sends back new type information. After the program terminates, the code is regenerated according to the recorded profile. This profiling feedback technique may also be useful to implement other types of algebras. Copyright &copy; 2006 ACM.},
key = {Automatic programming},
keywords = {Computational geometry;Conformal mapping;Linear algebra;Mathematical models;Object oriented programming;Program compilers;},
note = {Conformal model;Geometric Algebra (GA);Profiling program transformations;},
URL = {http://dx.doi.org/10.1145/1173706.1173728},
} 


@inproceedings{2006199863663 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling Turnpike frontend system: A model-driven development framework leveraging UML metamodeling and attribute-oriented programming},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Wada, Hiroshi and Suzuki, Junichi},
volume = {3713 LNCS},
year = {2005},
pages = {584 - 600},
issn = {03029743},
address = {Montego Bay, Jamaica},
abstract = {This paper describes and empirically evaluates a new model-driven development framework, called Modeling Turnpike (or mTurnpike). It allows developers to model and program domain-specific concepts (ideas and mechanisms specific to a particular business or technology domain) and to transform them to the final (compilable) source code. By leveraging UML metamodeling and attribute-oriented programming, mTurnpike provides an abstraction to represent domain-specific concepts at the modeling and programming layers simultaneously. The mTurnpike frontend system transforms domain-specific concepts from the modeling layer to programming layer, and vise versa, in a seamless manner. Its backend system combines domain-specific models and programs, and transforms them to the final (compilable) source code. This paper focuses on the frontend system of mTurnpike, and describes its design, implementation and performance implications. In order to demonstrate how to exploit mTurnpike in application development, this paper also shows a development process using an example DSL (domain specific language) to specify service-oriented distributed systems. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Object oriented programming},
keywords = {Codes (symbols);Computer programming languages;Computer simulation;Performance;},
note = {Attribute-oriented programming;Domain specific language;Domain-specific concepts;Modeling Turnpike;Modeling Turnpike frontend system;UML metamodeling;},
URL = {http://dx.doi.org/10.1007/11557432_44},
} 


@inproceedings{20082711353451 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A software factory for air traffic data},
journal = {AIAA/IEEE Digital Avionics Systems Conference - Proceedings},
author = {Comitz, Paul H. and Pinto, Avinash},
year = {2006},
address = {Portland, OR, United states},
abstract = {Modern Enterprise Architecture requires a flexible, scalable and upgradeable infrastructure that allows communication, and subsequently collaboration, between heterogeneous information processing and computing environments. Heterogeneous systems often use different data representations for the same data items, limiting collaboration. Although this problem is conceptually straightforward, the process of data conversion is error prone, often dramatically underestimated, and surprisingly complex. The complexity is often the result of the non-standard data representations that are used by computing systems in the aviation domain. This paper describes some of the work that is being done by Boeing Advanced Air Traffic Management to address this challenge. A prototype software factory for air traffic data management is being built and evaluated. The software factory provides the capability for a user such as a Systems Engineer or an Air Traffic Domain Expert to create an interface model. The model will allow the user to specify entities such as data items, scaling, units, headers and footers, representation, and coding. The factory automatically creates a machine usable interface. A prototype for a Domain Specific Language to assist in this task is being developed.},
key = {Avionics},
keywords = {Air traffic control;Aircraft instruments;Computer systems;Data processing;Digital arithmetic;Information management;Management information systems;Network architecture;Programming theory;Software prototyping;Standards;Systems engineering;},
note = {(algorithmic) complexity;(e ,3e) process;Air Traffic (CO);Air traffic management (ATM);aviation domain;Computing environments;Computing systems;Data conversion;Data items;Data representations;Digital avionics;domain experts;Domain specific language (DSL);Enterprise architecture (EA);Error prone;Heterogeneous (hybrid) systems;Heterogeneous information;interface modeling;Prototype software;software factories;},
URL = {http://dx.doi.org/10.1109/DASC.2006.313758},
} 


@article{1996283192247 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Concurrent, asynchronous search for the availability of knowledge},
journal = {Applied Artificial Intelligence},
author = {Fabiano, Antonio S. and Cerri, Stefano A.},
volume = {10},
number = {2},
year = {1996},
pages = {145 - 161},
issn = {08839514},
address = {Basingstoke, United Kingdom},
abstract = {We describe how a common conceptual model of the application domain can be used to support a cooperative and concurrent search among loosely coupled knowledge sources distributed over a network with unknown topology. The introduction of a conceptual level, shared among all the knowledge sources in the net, allows us to obtain independence from the logical data organization of each node, not only from the physical, as is the case in distributed database management systems (DDBMS). The navigation process is based on the conceptual model and has been designed and developed by means of a set of cooperative agents, with specific knowledge and abilities, that reason about the local data and exchange information to ensure both the communication through the net and the information processing at each net node. In order to ensure the comprehension of the architecture, we include a worked-out example in the domain of pharmacology, where such a model and its associated domain-specific language have been realized.},
key = {Knowledge based systems},
keywords = {Computer programming languages;Computer simulation;Concurrency control;Data communication systems;Data processing;Data structures;Distributed database systems;Information retrieval systems;},
note = {Concurrent search;Domain specific language;Knowledge availability;Logical data organization;},
URL = {http://dx.doi.org/10.1080/088395196118632},
} 


@inproceedings{20092912196076 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A practical high volume software product line},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Bell, Peter},
year = {2007},
pages = {994 - 1003},
address = {Montreal, QC, Canada},
abstract = {Many Software Product Line case studies focus on the fact that an ROI can be achieved in 3-5 projects. This paper asks the question "what has to be done differently to be able to generate 10,000 custom applications a year?" As wholesalers of custom web applications for Small to Medium Sized Businesses, we have to create highly customizable web applications in minutes - not months. After 18 months of research and experimentation we have developed a layered system that focuses on the reuse of declarative executable specifications rather than the reuse of imperative code, allowing us to blend speed of development with flexibility of the generated solutions. The system uses a feature modeler to select common functionality and a decision support system to de-skill the customization process. It has a collection of domain specific languages for describing the vast majority of custom functionality required by our clients and an extensible framework allowing any system functionality to be overloaded/extended using custom code if necessary. In this paper we provide an introduction to the key theoretical concepts required to understand the system. We then introduce our domain specific languages for describing web applications. We then look at the process of building applications using SystemsForge and then we highlight our conclusions to date and document some of the outstanding issues that we are still investigating relating to managing domain specific language evolution and interactions.},
key = {Object oriented programming},
keywords = {Artificial intelligence;Computer software;Computer systems programming;Decision support systems;Decision theory;Linguistics;Query languages;Software architecture;World Wide Web;XML;},
note = {Configuration management;Domain specific language;Experience;Feature modeling;Language oriented programming;Practitioner report;Software product line;},
} 


@inproceedings{20081711212457 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A practical high volume software product line},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Bell, Peter},
year = {2007},
pages = {994 - 1003},
address = {Montreal, QC, Canada},
abstract = {Many Software Product Line case studies focus on the fact that an ROI can be achieved in 3-5 projects. This paper asks the question "what has to be done differently to be able to generate 10,000 custom applications a year?" As wholesalers of custom web applications for Small to Medium Sized Businesses, we have to create highly customizable web applications in minutes - not months. After 18 months of research and experimentation we have developed a layered system that focuses on the reuse of declarative executable specifications rather than the reuse of imperative code, allowing us to blend speed of development with flexibility of the generated solutions. The system uses a feature modeler to select common functionality and a decision support system to de-skill the customization process. It has a collection of domain specific languages for describing the vast majority of custom functionality required by our clients and an extensible framework allowing any system functionality to be overloaded/extended using custom code if necessary. In this paper we provide an introduction to the key theoretical concepts required to understand the system. We then introduce our domain specific languages for describing web applications. We then look at the process of building applications using SystemsForge and then we highlight our conclusions to date and document some of the outstanding issues that we are still investigating relating to managing domain specific language evolution and interactions.},
key = {Object oriented programming},
keywords = {Administrative data processing;Artificial intelligence;Codes (standards);Codes (symbols);Computer systems programming;Decision making;Decision support systems;Decision theory;Linguistics;Management information systems;Neodymium;Query languages;Specifications;World Wide Web;XML;},
note = {(e ,3e) process;building applications;case studies;Customizable;Decision supports;Domain specific language (DSL);Executable specifications;Extensible framework;international conferences;Languages (traditional);Layered systems;Medium sized businesses;Object-oriented programming;Software product line (SPL);System functionalities;Volume Software (CO);WEB applications;},
URL = {http://dx.doi.org/10.1145/1297846.1297968},
} 


@article{1997133511552 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Why explore object methods, patterns, and architectures?},
journal = {IEEE Software},
author = {Mellor, Stephen J. and Johnson, Ralph},
volume = {14},
number = {1},
year = {1997},
pages = {27 - 29},
issn = {07407459},
address = {Los Alamitos, CA, United States},
abstract = {Objects, patterns, and architectures each holds the promise of solving chronic software development problems. However, each camp advocates quite different means for achieving that solution. Resolving the conflicting views requires a re-examination of core assumptions.},
key = {Software engineering},
keywords = {Computer architecture;Computer programming languages;Computer simulation;Computer software;Encoding (symbols);Object oriented programming;},
note = {Domain specific language;Generic patterns;Reference models;},
} 


@article{20093012205020 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A pedagogical framework for domain-specific languages},
journal = {IEEE Software},
author = {Fowler, Martin},
volume = {26},
number = {4},
year = {2009},
pages = {13 - 14},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {A framework for thinking about domain-specific languages (DSLs) divides them into internal DSLs, external DSLs, and language workbenches. In all cases, it's important to have an explicit semantic model so that they form a veneer over an underlying library. DSLs are valuable for increasing programmer productivity and improving communication with domain experts. &copy; 2009 IEEE.},
key = {Probability density function},
keywords = {Computer software;DSL;Graphical user interfaces;Libraries;Linguistics;Markup languages;Mining;Modems;Query languages;Telecommunication lines;XML;},
note = {Domain experts;Domain specific languages;Domain-specific language;Explicit semantics;Language workbench;Language workbenches;Programmer productivity;Programming;Software;},
URL = {http://dx.doi.org/10.1109/MS.2009.85},
} 


@inproceedings{2002066855325 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Bossa: A DSL framework for application-specific scheduling policies},
journal = {Proceedings of the Workshop on Hot Topics in Operating Systems - HOTOS},
author = {Barreto, Luciano Porto and Muller, Gilles},
year = {2001},
pages = {161 - },
address = {Elmau, Germany},
abstract = {A framework for easing the development of adaptable process scheduling infrastructures is presented. This framework permits the development and installation of basic scheduling policies. The framework architecture relies on two basic components: Virtual Schedulers (VSs) and Application-Specific Policies (ASPs).},
key = {High level languages},
keywords = {Computer operating systems;Computer software maintenance;Interfaces (computer);Program compilers;Program translators;Real time systems;Recursive functions;Scheduling;Software engineering;},
note = {Application specific policies;Central processing unit;Domain specific language;Software package Bossa;Virtual schedulers;},
} 


@inproceedings{20091412016893 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Raising the level of abstraction of application-level Checkpointing},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Arora, Ritu},
year = {2008},
pages = {919 - 920},
address = {Nashville, TN, United states},
abstract = {Checkpointing is one of the key ingredients required for writing fault-tolerant applications for dynamic and distributed computing environments. Manual reengineering of large legacy applications to insert checkpointing mechanisms is a daunting task, mainly due to the time and cost overheads. This poster describes an approach for nonintrusive reengineering of existing applications to insert a Checkpointing and Restart (CaR) mechanism. The user describes the CaR specifications at a high-level and the required code is semi-automatically generated and inserted in the application.},
key = {Object oriented programming},
keywords = {Applications;Computer systems programming;Linguistics;Query languages;Reengineering;},
note = {Automatically generated;Checkpointing;Distributed computing environments;Domain-specific language;Fault-tolerant applications;Legacy applications;Level of abstractions;Non-intrusive;},
URL = {http://dx.doi.org/10.1145/1449814.1449908},
} 


@inproceedings{20103213132849 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Formal approach use to choose a software manufactoring cell's SDLC},
journal = {ITNG2010 - 7th International Conference on Information Technology: New Generations},
author = {Montini, Denis Avila and Fernandes, Danilo Douradinho and Marcondes, Francisco Supino and Tasinaffo, Paulo Marcelo and Vega, Italo Santiago and Dias, Luiz Alberto Vieira},
year = {2010},
pages = {1304 - 1305},
address = {Las Vegas, NV, United states},
abstract = {This paper shows how to use state machines and systematic approaches to software modeling to help modeler to improve, verify and validate a Domain Analysis and also refine and improve enterprise business processes. The main objective of this approach is how to systematic got a DSL from a Domain Analysis which can be used code system respecting, all business rules without complex definitions or documents. Many problems of Computer Software Systems (CSS) are derived from a lack of its behavior specification in order to solve that problem, but even with a well defined system behavior, many business rules are not properly treated since formalization becomes on the design phase. This paper shows an approach on how to systematically refine domain analysis to consider all business rules. It considers a state machine which represent all aspects of the domain choice. The state machines use is based on user friendliness and formality. &copy; 2010 IEEE.},
key = {Formal methods},
keywords = {Computer software;Contour followers;Information technology;Linguistics;Refining;},
note = {Behavior specifications;Business rules;Code system;Design phase;Domain analysis;Domain specific language;Domain specific languages;Enterprise business process;Formal approach;Manufactoring;Software modeling;State machine;System behaviors;User friendliness;},
URL = {http://dx.doi.org/10.1109/ITNG.2010.81},
} 


@inproceedings{20080411042117 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model based HMI specification in an automotive context},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Fleischmann, Thomas},
volume = {4557 LNCS},
number = {PART 1},
year = {2007},
pages = {31 - 39},
issn = {03029743},
address = {Beijing, China},
abstract = {An overview of how a model based specification approach can be used in the domain of automotive human machine interface (HMI) development is presented. The common paper based specification approach is compared to a model based, tool supported process. Requirements from different stakeholders for such an approach are outlined. Intended audiences are all stakeholders involved in the creation of graphical user interfaces ranging from design, usability engineering, and prototyping to specification and final product realization. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Man machine systems},
keywords = {Automatic programming;Program compilers;Specifications;Usability engineering;},
note = {Domain specific language;HMI specification;Human machine interface (HMI);Stakeholders;},
} 


@article{20073910835729 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Abstraction and variation},
journal = {IEEE Software},
author = {Spinellis, Diomidis},
volume = {24},
number = {5},
year = {2007},
pages = {24 - 25},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {Copy-pasting code is a source of bugs. By employing in our programs abstraction mechanisms such as functions, classes, types, decision tables, domain-specific languages, and databases, we can abstract common elements into parameterized reusable functionality. However, abstraction has its cost. Its early gains are large, but eventually the benefits turn negative and the code becomes less comprehensible and maintainable. Deciding when abstracting is appropriate is what makes programming an art. &copy; 2007 IEEE.},
key = {Software engineering},
keywords = {Computer programming languages;Computer software reusability;Database systems;Decision tables;Functional programming;Program debugging;},
note = {Copy-pasting code;Domain-specific language;},
URL = {http://dx.doi.org/10.1109/MS.2007.127},
} 


@article{20073910835734 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Building domain-specific languages for model-driven development},
journal = {IEEE Software},
author = {Cuadrado, Jesus Sanchez and Molina, Jesus Garcia},
volume = {24},
number = {5},
year = {2007},
pages = {48 - 55},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {The emergence of the model-driven development paradigm has revitalized interest in domain-specific languages. Embedding a DSL in a dynamic language facilitates rapid development. This article illustrates dynamic-language features and techniques that the authors found useful while developing embedded DSLs in Ruby for a model-driven development tool. For this domain, it's possible to achieve a runtime performance comparable to existing tools while shortening development time. This article is part of a special issue on dynamically typed languages. &copy; 2007 IEEE.},
key = {Computer programming languages},
keywords = {Computer aided software engineering;Software design;Spreadsheets;},
note = {Domain-specific language;Dynamically typed language;Specialized application language;},
URL = {http://dx.doi.org/10.1109/MS.2007.135},
} 


@article{1997293661916 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Integrating legacy systems with modern corporate applications},
journal = {Communications of the ACM},
author = {Robertson, Paul},
volume = {40},
number = {5},
year = {1997},
pages = {39 - 46},
issn = {00010782},
address = {New York, NY, United States},
abstract = {Legacy software systems evolve at a very rapid pace against modern software systems which evolve at a pace which challenges corporate efforts to introduce new products. A good example of this rapid change is the replacement of client-server applications with intranet-based solutions. This change can be effectively addressed by using dynamic object oriented programming to build key pieces of rapidly-changing information processing infrastructure.},
key = {Computer aided software engineering},
keywords = {Computer architecture;Computer systems programming;Database systems;Object oriented programming;},
note = {Data conversion model;Domain specific language;Legacy systems;},
URL = {http://dx.doi.org/10.1145/253769.253785},
} 


@inproceedings{2004148099428 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Developing agents for bioinformatics applications: A preliminary design},
journal = {Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications},
author = {Pontelli, E. and Son, T.C. and Pan, Y. and Phan, T.},
volume = {3},
year = {2003},
pages = {1005 - 1011},
address = {Las Vegas, NV, United states},
abstract = {A brief overview of the &phi;LOG project, aimed at the development of a domain specific framework for the rapid prototyping of applications in evolutionary biology. The framework is based on a DSL, whose execution model relies on the automatic combination of existing bioinformatics services. Moreover, the framework is under development as a collaboration between researchers in Computer Science and Biology at NMSU.},
key = {Software agents},
keywords = {Computational linguistics;Context free grammars;Logic programming;Molecular biology;Program compilers;Software engineering;},
note = {Bioinformatics;Domain Specific language;Semantic web;},
} 


@article{20092712169555 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Code Generation with the Exemplar Flexibilization Language},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Heradio, R. and Cerrada, J.A. and Lopez, J.C. and Coz, J.R.},
volume = {238},
number = {2},
year = {2009},
pages = {25 - 34},
issn = {15710661},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Code Generation is an increasing popular technique for implementing Software Product Lines that produces code from abstract specifications written in Domain Specific Languages (DSLs). This paper proposes to take advantage of the similitude among the products in a domain to generate them by analogy. That is, instead of synthesizing the final code from scratch or transforming the DSL specifications, the final products are obtained by adapting a previously developed domain product. The paper also discusses the capabilities and limitations of several currently available tools and languages to implement this kind of generators and introduce a new language to overcome the limitations. &copy; 2009 Elsevier B.V. All rights reserved.},
key = {Linguistics},
keywords = {Abstracting;Computer software;Network architecture;Network components;Query languages;Specifications;},
note = {Abstract specifications;Code Generation;Domain Specific Language;Domain specific languages;Software Product Line;},
URL = {http://dx.doi.org/10.1016/j.entcs.2009.05.004},
} 


@article{20084611711697 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A Rule-based Method to Match Software Patterns Against UML Models},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Ballis, D. and Baruzzo, A. and Comini, M.},
volume = {219},
number = {C},
year = {2008},
pages = {51 - 66},
issn = {15710661},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {In a UML model, different aspects of a system are covered by different types of diagrams and this bears the risk that an overall system specification becomes barely tractable by the designer. When the model grows, it is likely that the architectural integrity will be compromised by extensions and bug-fixing operations. Hence, it is important to provide means to help designers to search in big models for particular instances of some variable schema of UML models (design patterns) they construct. This can help them both to find potential problems in the architecture design and to ensure that intended architectural choices had not been broken by mistake. In this paper we propose a rule-based method to find matches of design patterns into a UML model. The method is general enough to tackle most patterns and antipatterns. &copy; 2008 Elsevier B.V. All rights reserved.},
key = {Architectural design},
keywords = {Design;Pattern matching;Risk management;Specifications;Unified Modeling Language;},
note = {Anti patterns;Architectural choices;Architecture designs;Design patterns;Overall systems;Potential problems;Rule-based domain specific language;Software patterns;UML Design Patterns;UML formal specification;UML models;},
URL = {http://dx.doi.org/10.1016/j.entcs.2008.10.034},
} 


@article{20082711347975 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Extending grammars and metamodels for reuse: The Reuseware approach},
journal = {IET Software},
author = {Henriksson, J. and Heidenreich, F. and Johannes, J. and Zschaler, S. and Amann, U.},
volume = {2},
number = {3},
year = {2008},
pages = {165 - 184},
issn = {17518806},
address = {Six Hills Way, Stevenage, SG1 2AY, United Kingdom},
abstract = {The trend towards domain-specific languages leads to an ever-growing plethora of highly specialised languages. Developers of such languages focus on their specific domains rather than on the technical challenges of language design. The generic features of languages are rarely included in special-purpose languages. One very important feature is the ability to formulate partial programs in separate encapsulated entities, which can be composed into complete programs in a well-defined manner. A language-independent approach is presented that adds useful constructs for defining components. The authors discuss the underlying concepts and describe a composition environment and tool supporting these ideas-the Reuseware Composition Framework. To evaluate this approach, the authors enrich the (Semantic) Web query language Xcerpt with an additional useful reuse concept - modules. &copy; 2008 The Institution of Engineering and Technology.},
key = {Query languages},
keywords = {Information theory;Linguistics;Structure (composition);},
note = {(OTDR) technology;Domain specific language (DSL);Generic features;language designs;Languages (traditional);Meta-models;Technical challenges;},
URL = {http://dx.doi.org/10.1049/iet-sen:20070060},
} 


@inproceedings{20082611338338 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Multiparadigm programming in object-oriented languages},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Davis, Kei and Striegnitz, Jorg},
volume = {4906 LNCS},
year = {2008},
pages = {13 - 26},
issn = {03029743},
address = {Berlin, Germany},
abstract = {While OO has become ubiquitously employed for design, implementation, and even conceptualization, many practitioners recognize the concomitant need for other programming paradigms according to problem domain. Nevertheless, the choice of a programming paradigm is strongly influenced by the supporting programming language facilities. In turn, choice of programming language is usually highly constrained by practical considerations. We seek answers to the question of how to address the need for other programming paradigms, or even domain specific languages, in the general context of OO languages. It is clear that this field is yet nascent: novel, disparate approaches and techniques are still being discovered or invented, and this very novelty adds a significant element of intellectual entertainment. This article describes the cross section of research efforts reported at the workshop on Multiparadigm Programming in Object-Oriented Languages held at the 2007 European Conference on Object-Oriented Programming. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Object oriented programming},
keywords = {Architectural design;C (programming language);Computer networks;Computer programming languages;Computer software;Computers;Linguistics;Problem oriented languages;Query languages;Technology;},
note = {cross sectioning;Domain specific language (DSL);European;General (CO);Heidelberg (CO);Languages (traditional);Multi paradigm programming;Object oriented technology (OOT);Object-oriented languages;Object-oriented programming;problem domains;Programming language;programming paradigms;Research efforts;Springer (CO);},
URL = {http://dx.doi.org/10.1007/978-3-540-78195-0_3},
} 


@inproceedings{20091412003905 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MDE for SoC design},
journal = {Innovations in Systems and Software Engineering},
author = {Truscan, Dragos and Lundkvist, Torbjorn and Alanen, Marcus and Sandstrom, Kim and Porres, Ivan and Lilius, Johan},
volume = {5},
number = {1},
year = {2009},
pages = {49 - 64},
issn = {16145046},
address = {The Guildway, Old Portsmouth Road, Artington, Guildford, GU3 1LP, United Kingdom},
abstract = {We employ the principles of model-driven engineering to assist the design of system-on-chip (SoC) architectures. As a concrete example, we look at the MICAS architecture, for which we propose a graphical specification language, defined via metamodeling techniques, that models the architecture at different abstraction levels. Model transformations are defined to support the refinement of MICAS specification towards implementation. In addition, several libraries are put in place, to enable reuse and automation throughout the design process. Tool support for editing the specifications, enforcing their consistency, and for running the transformations is provided via the Coral modeling framework. The approach shows that model-driven engineering can be seen as an enabler in providing computer-aided software engineering (CASE) tool support and automation for the development of SoC architectures. &copy; Springer-Verlag London Limited 2009.},
key = {Computer aided software engineering},
keywords = {Application specific integrated circuits;Computer architecture;Integrated circuits;Linguistics;Mica;Microprocessor chips;Programmable logic controllers;Silicate minerals;Specification languages;Specifications;Systems analysis;},
note = {Domain-specific language;Metamodel;Model transformation;Model-driven engineering;Systemon chip;},
URL = {http://dx.doi.org/10.1007/s11334-009-0077-4},
} 


@inproceedings{20082411316459 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Increasing innovation: A trilogy of experiments towards a design-by-analogy method},
journal = {2007 Proceedings of the ASME International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, DETC2007},
author = {Linsey, J.S. and Clauss, E. and Wood, K.L. and Laux, J.P. and Markman, A.B.},
volume = {3 PART A},
year = {2008},
pages = {145 - 159},
address = {Las Vegas, NV, United states},
abstract = {Design by analogy is a noted approach for conceptual design. This paper seeks to develop a robust design-by-analogy method. This endeavor is sought through a series of three experiments focusing on understanding the influence of representation on the design-by-analogy process. The first two experiments evaluate the effects of analogous product description-presented in either domain-general or domainspecific language-on a designer's ability to later use the product to solve a novel design problem. Six different design problems with corresponding analogous products are evaluated. The third experiment in the series uses a factorial design to explore the effects of the representation (domain specific or general sentinel descriptions) for both the design problem and the analogous product on the designer's ability to develop solutions to novel design problems. Results show that a more general representation of the analogous products facilitates later use for a novel design problem. The highest rates of success occur when design problems are presented in domain specific representations and the analogous product is in a domain general representation. Other insights for the development of design by analogy methods and tools are also discussed. Copyright &copy; 2007 by ASME.},
key = {Design of experiments},
keywords = {Architectural design;Computer networks;Computers;Conceptual design;Design;Engineering;Experiments;Information systems;Microfluidics;Microsensors;Multi agent systems;Nanosystems;Photoacoustic effect;Process design;Process engineering;Product design;Technology;},
note = {analogy method;analogy process;Design problems;Design theory and methodology;Domain specific;Domain specific language (DSL);Factorial designs;General (CO);international conferences;International designs;Micro and nano systems;novel design;Product descriptions;Robust designs;Technical conferences;},
} 


@inproceedings{20090611892081 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Train control language - Teaching computers interlocking},
journal = {WIT Transactions on the Built Environment},
author = {Endresen, J. and Carlson, E. and Moen, T. and Alme, K.J. and Haugen, O?. and Olsen, G.K. and Svendsen, A.},
volume = {103},
year = {2008},
pages = {651 - 660},
issn = {17433509},
address = {Toledo, Spain},
abstract = {Computer specialists are rarely trained in the world of tracks and trains, while signaling experts are rarely computer specialists. This paper is about bridging the gap between trains and computers with a specially designed language that enables the signaling experts to create consistent train interlocking systems. The language is supported by tailored tools created with open source technology on the development platform Eclipse. From the formal definition of the language in the form of a metamodel, a graphical editor is generated. The systems created with that graphic editor are then transformed for several purposes that are internally consistent. The editor makes sure that the systems conform to the language, and the language makes sure that the systems conform to the way interlockings are designed. The transformations then produce interlocking tables and even actual code automatically from the graphically created model.},
key = {Interlocking signals},
keywords = {Computer science;DSL;Fourier transforms;Linguistics;Locomotives;Modems;Network components;Railroad cars;Railroads;Signaling;Systems analysis;Telecommunication lines;},
note = {Code generation;Computer Based Interlocking (CBI);Domain Specific Language (DSL);Eclipse;Interlocking;},
URL = {http://dx.doi.org/10.2495/CR080631},
} 


@inproceedings{20084811751581 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards interoperability in component based development with a family of DSLs},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Ober, Ileana and Abou Dib, Ali and Feraud, Louis and Percebois, Christian},
volume = {5292 LNCS},
year = {2008},
pages = {148 - 163},
issn = {03029743},
address = {Paphos, Cyprus},
abstract = {In this paper we address interoperability between components specified using various languages within a same family of DSLs. Our approach consists in applying results of the category theory in order to merge the languages into a unification one, automatically obtained. For this, we use the category of formal specifications of each DSL in the family. Using colimits on the category of algebraic specifications that implements the semantics of the DSLs in the family, we construct a language that unifies the family. Additionally we obtain translation morphisms from individual DSLs to the resulting unified one. By application of the translation morphisms, one can translate each component specifications into a specification written in the unification language. Moreover, properties established in the context of a DSL are transferred to the unifying language. In this paper, we illustrate the unification and the preservation of a property on an example. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Interoperability},
keywords = {DSL;Formal methods;Information theory;Linguistics;Modems;Query languages;Semantics;Software architecture;Specifications;Telecommunication lines;Translation (languages);},
note = {Category theory;Domain specific language (DSL);Formal semantics;Heterogeneous components;Specware;},
URL = {http://dx.doi.org/10.1007/978-3-540-88030-1_12},
} 


@inproceedings{20090611900638 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Design and development of a context oriented language for middleware based applications},
journal = {Next Generation Aspect Oriented Middleware Workshop, NOMI 2008 - AOSD Conference 2008 Brussels, 7th International Conference on Aspect-Oriented Software Development},
author = {Sindico, Andrea and Bartolomeo, Giovanni and Grassi, Vincenzo and Salsano, Stefano},
year = {2008},
pages = {1 - 5},
address = {Brussels, Belgium},
abstract = {Nowadays context-aware adaptation is becoming an important feature for pervasive computing applications. In this paper we present JCOOL, a COntext Oriented Language tailored to handle context awareness in Java applications. JCOOL exploits Aspect Oriented techniques so that context changes detection and related adaptations can be considered as two separated crosscutting concerns with respect to the core 'business logic' of new or legacy Java applications. Moreover, mobile and pervasive applications generally rely on middlewares that hide the complexity of the underlying environment. In order to show how JCOOL support can be introduced into middleware based application, in the second part of the paper we also describe JCOOL integration in SMILE [1], a Middleware Independent Layer developed in the scope of the SMS project [2]. &copy; 2008 ACM.},
key = {Java programming language},
keywords = {Applications;Computer software;Linguistics;Middleware;Programming theory;Software design;},
note = {Aspect oriented programming;Business-logic;Context awareness;Context-aware adaptations;Crosscutting concerns;Design and Development;Domain specific language;Java applications;Middleware based applications;Pervasive applications;Pervasive computing applications;},
URL = {http://dx.doi.org/10.1145/1408620.1408621},
} 


@inproceedings{20091311990267 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Requirements for digital forensics investigation domain-specific languages},
journal = {Proceedings of the 2008 International Conference on Security and Management, SAM 2008},
author = {Bradford, Phillip G. and Ray, Daniel A.},
year = {2008},
pages = {428 - 434},
address = {Las Vegas, NV, United states},
abstract = {This paper gives an analysis of the digital forensics problem domain to enable the design of effective and practical domain specific languages for digital forensics investigations. The focus is on design and implementation using standard components. The paper first addresses domain specific languages in general terms and then addresses the steps necessary to create them. The paper looks at domain analysis for our particular digital investigation domain. To address domain analysis the paper reviews several key domain models that have been created in the field of digital forensics. The paper also examines DSL design and answers questions about the nature of our particular DSL. These concern relations to previous DSLs, what goals and principles will be supported by our DSL, and the particular structure of our DSL. The paper also briefly touches on DSL implementation issues, although the details of these are left for a later paper.},
key = {Query languages},
keywords = {Computer applications;DSL;Electronic crime countermeasures;Graphical user interfaces;Industrial management;Linguistics;Modems;Security systems;Telecommunication lines;},
note = {Application generator;Computer security;Digital investigations;Domain-specific language;System security management;},
} 


@inproceedings{20080511065126 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Constraint based role based access control in the SECTET-framework: A model-driven approach},
journal = {Journal of Computer Security},
author = {Alam, Muhammad and Hafner, Michael and Breu, Ruth},
volume = {16},
number = {2},
year = {2008},
pages = {223 - 260},
issn = {0926227X},
address = {Nieuwe Hemweg 6B, Amsterdam, 1013 BG, Netherlands},
abstract = {With respect to Service Oriented Architectures (SOA's) paradigm, the core Role Based Access Control (RBAC) has several limitations. In SOA, permissions to execute web services are not assigned statically to roles but are associated with a set of Permission Assignment Constraints (PAC) upon the fulfilment of which a role is assigned a permission to execute a web service. Further, the RBAC does not support partial inheritance which is an integral requirement in SOA. A major challenge in SOA is the inheritance of permissions associated with PAC in the presence of role hierarchies. This contribution has three objectives. First we propose an extension to Role Based Access Control (available at csrc.nist.gov/rbac/), which we call Constraint based RBAC (CRBAC), in order to make RBAC applicable to the dynamic environment of SOA. Within CRBAC, a high-level language - called SECTET-PL (available at http:// qe-informatik.uibk.ac.at/~muhammad/TechnicalReportSECTETPL.pdf) is used for the specification of PAC. Being part of the SECTET-framework for model-driven security for B2B-workflows, SECTET-PL is a policy language influenced by OCL (available at http://www.omg.org/docs/ptc/03-10-14.pdf) and interpreted in the context of UML models. Using the Model Driven Architecture (MDA) (available at http://www.omg.org/mda) paradigm, we then describe the transformation of high-level security models to low-level web services standard artefacts with the help of the Eclipse Modelling Framework and OpenArchitectureWare. Finally, we present the target architecture of the SECTET-framework used to realize the security artefacts generated from the transformations and thus completes the cycle of MDA. &copy; 2008 - IOS Press and the authors. All rights reserved.},
key = {Access control},
keywords = {Computer architecture;Computer programming languages;Computer simulation;Constraint theory;Hierarchical systems;Web services;},
note = {Domain specific language;Model driven architecture;Model driven engineering;Service oriented architecture;},
} 


@article{20075110987437 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A language-driven approach for the design of interactive applications},
journal = {Interacting with Computers},
author = {Sierra, Jose-Luis and Fernandez-Manjon, Baltasar and Fernandez-Valmayor, Alfredo},
volume = {20},
number = {1},
year = {2008},
pages = {112 - 127},
issn = {09535438},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {In this paper we propose a language-driven approach for the high-level design of interactive applications architected according to the model-view-controller pattern. The approach is especially well-suited for applications that incorporate contents with sophisticated structures, and whose interactive behavior is driven by these structures. In our approach we characterize the structure of the contents stored in the applications' models with suitable domain-specific languages. Then we characterize the interactive behavior of these applications by assigning suitable operational semantics to these languages. The resulting designs are amenable to support rapid prototyping, exploration and early discovery of application features, systematic implementation using standard web-based technologies, and rational collaboration processes between domain experts and developers during production and maintenance. We exemplify the approach in the e-learning domain with a system for the production of Socratic tutors. &copy; 2007 Elsevier B.V. All rights reserved.},
key = {Computer programming languages},
keywords = {E-learning;Interactive computer systems;Mathematical models;User interfaces;Websites;},
note = {Document oriented approach;Domain specific language;Language driven development;Model view controller;},
URL = {http://dx.doi.org/10.1016/j.intcom.2007.09.001},
} 


@inproceedings{20094712457555 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MBT4Chor: A model-based testing approach for service choreographies},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Stefanescu, Alin and Wieczorek, Sebastian and Kirshin, Andrei},
volume = {5562 LNCS},
year = {2009},
pages = {313 - 324},
issn = {03029743},
address = {Enschede, Netherlands},
abstract = {Service choreographies describe the global communication protocols between services and testing these choreographies is an important task in the context of service-oriented architectures (SOA). Formal modeling of service choreographies makes a model-based testing (MBT) approach feasible. In this paper we present an MBT approach for SOA integration testing based on SAP proprietary choreography models called Message Choreography Models (MCM). In our approach, MCMs are translated into executable UML models using Java as action language. These UML models are used by a UML model execution engine developed by IBM for test generation and model debugging. We describe the achievements and challenges of our approach based on first experimental evaluation conducted at SAP. &copy; 2009 Springer Berlin Heidelberg.},
key = {Java programming language},
keywords = {Communication;Formal logic;Information services;Linguistics;Network architecture;Semantic Web;Service oriented architecture (SOA);Software testing;},
note = {Choreography Modeling;Domain Specific Language;Model Transformation;Model-Based Testing;Service Integration;SOA;},
URL = {http://dx.doi.org/10.1007/978-3-642-02674-4_23},
} 


@inproceedings{20085011773762 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Software support for building end-user programming environments in the automation domain},
journal = {Proceedings - International Conference on Software Engineering},
author = {Prahofer, Herbert and Hurnaus, Dominik and Schatz, Roland and Wirth, Christian and Mossenbock, Hanspeter},
year = {2008},
pages = {76 - 80},
issn = {02705257},
address = {Leipzig, Germany},
abstract = {Projects in the automation domain often require that end users, who are the machine operators, have means to change control software to make adaptations and optimizations for the machining task at hand. Although they usually do not have any software development expertise, they intervene in safety-critical software systems. This results in high demands on end-user programming environments with respect to supporting, guiding, and supervising end users. In this paper we present a software framework which is intended to serve as a basis for developing end-user programming environments. The main parts of this framework are a domainspecific language for programming automation solutions at a high level of abstraction, different visual editors for supporting end users, an approach for checking program changes against formal specifications, a variability modeling approach for representing high-level user decisions, and an approach for setting up customized end-user environments from models. Copyright 2008 ACM.},
key = {Computer programming languages},
keywords = {Automation;Cobalt;Computer programming;Concurrency control;High level languages;Linguistics;Model checking;Software engineering;Technical presentations;},
note = {Domain-specific language;End-user programming;Industrial automation;Visual language;Visual programming;},
URL = {http://dx.doi.org/10.1145/1370847.1370864},
} 


@inproceedings{20083711537146 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {System demonstration of spiral: Generator for high-performance linear transform libraries},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Voronenko, Yevgen and Franchetti, Franz and De Mesmay, Frederic and Puschel, Markus},
volume = {5140 LNCS},
year = {2008},
pages = {407 - 412},
issn = {03029743},
address = {Urbana, IL, United states},
abstract = {We demonstrate Spiral, a domain-specific library generation system. Spiral generates high performance source code for linear transforms (such as the discrete Fourier transform and many others) directly from a problem specification. The key idea underlying Spiral is to perform automatic reasoning and optimizations at a high abstraction level using the mathematical, declarative domain-specific languages SPL and &sum;-SPL and a rigorous rewriting framework. Optimization includes various forms of parallelization. Even though Spiral provides complete automation, its generated libraries often run faster than any existing hand-written code. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Fourier transforms},
keywords = {Codes (symbols);Computer networks;Computer programming languages;Discrete Fourier transforms;Libraries;Mathematical transformations;Matrix algebra;Optimization;Technology;XML;},
note = {Automatic performance tuni;Discrete Fourier transform;Domain-specific language;FFT;Linear transform;Multithreading;Program generation;Rewriting;SIMD vector instructions;},
URL = {http://dx.doi.org/10.1007/978-3-540-79980-1_30},
} 


@inproceedings{20083111409885 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A comparison of standard compliant ways to define domain specific languages},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Weisemoller, Ingo and Schurr, Andy},
volume = {5002 LNCS},
year = {2008},
pages = {47 - 58},
issn = {03029743},
address = {Nashville, TN, United states},
abstract = {Domain specific languages are of increasing importance for today's software development processes. Their area of application ranges from process modeling over architecture description and system design to behavioral specification and simulation. There are numerous approaches for the definition and implementation of DSLs. Among others, the OMG offers UML profiles as a lightweight extension of a predefined multi-purpose language and MOF as a metamodeling language, which can be used to define DSLs from scratch. This contribution investigates various approaches to define DSLs, focusing on architectural description languages as an example. Besides the usage of UML profiles and the definition of an entirely new language with MOF, the adaption of the UML based on a metamodel extension is also considered. As a consequence of the shortcomings depicted for the different approaches, we suggest to combine UML profiles and metamodeling in order to compensate their weaknesses and take advantage of their benefits. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Linguistics},
keywords = {Arsenic compounds;Artificial intelligence;Bioinformatics;Computer science;Computer simulation;Computer simulation languages;Computer software;Models;Process engineering;Query languages;Software engineering;Standards;Unified Modeling Language;},
note = {Architectural description language (ADL);Architecture description (AD);Behavioral specification;Domain specific language (DSL);Heidelberg (CO);Lecture Notes;Meta modelling;Meta-modeling;Multi purpose;Process Modeling;Software development processes;System designs;Uml profiles;},
URL = {http://dx.doi.org/10.1007/978-3-540-69073-3_6},
} 


@inproceedings{20083111409912 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Models in Software Engineering - Workshops and Symposia at MoDELS 2007, Reports and Revised Selected Papers},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {5002 LNCS},
year = {2008},
pages = {ACM Special Interest Group on Software Engineering; IEEE Computer Society - },
issn = {03029743},
address = {Nashville, TN, United states},
abstract = {The proceedings contain 32 papers. The topics discussed include: a generic approach for automatic model composition; designing syntax embeddings and assimilations for language libraries; a comparison of standard compliant ways to define domain specific languages; domain-specific methods and tools for the design of advanced interactive techniques; transforming discourse models to structural user interface models; deriving input partitions from UML models for automatic test generations; putting performance engineering into model-driven engineering: model-driven performance engineering; model-level integration of the OCL standard library using a pivot model with generics support; domain-specific model editors with model completion; third international workshop on quality in modeling; and developing a quality framework for model-driven engineering.},
key = {Models},
keywords = {Artificial intelligence;Bioinformatics;Computer science;Engineering;Linguistics;Query languages;Software engineering;Standardization;Standards;Systems analysis;Unified Modeling Language;User interfaces;},
note = {Automatic modeling;Domain specific;Domain specific language (DSL);Embeddings;Generic approaches;Interactive techniques;Interface modeling;International (CO);Lecture Notes;Model driven engineering (MDE);Model-driven;OCL standard library;Performance engineering;Test generations;UML (unified modeling language)model;},
} 


@inproceedings{20090611900717 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Documenting and automating collateral evolutions in linux device drivers},
journal = {EuroSys'08 - Proceedings of the EuroSys 2008 Conference},
author = {Padioleau, Yoann and Lawall, Julia and Hansen, Rene Rydhof and Muller, Gilles},
year = {2008},
pages = {247 - 260},
address = {Glasgow, United kingdom},
abstract = {The internal libraries of Linux are evolving rapidly, to address new requirements and improve performance. These evolutions, however, entail a massive problem of collateral evolution in Linux device drivers: for every change that affects an API, all dependent drivers must be updated accordingly. Manually performing such collateral evolutions is time-consuming and unreliable, and has lead to errors when modifications have not been done consistently. In this paper, we present an automatic program transformation tool Coccinelle, for documenting and automating device driver collateral evolutions. Because Linux programmers are accustomed to manipulating program modifications in terms of patch files, this tool uses a language based on the patch syntax to express transformations, extending patches to semantic patches. Coccinelle preserves the coding style of the original driver, as would a human programmer. We have evaluated our approach on 62 representative collateral evolutions that were previously performed manually in Linux 2.5 and 2.6. On a test suite of over 5800 relevant driver files, the semantic patches for these collateral evolutions update over 93% of the files completely. In the remaining cases, the user is typically alerted to a partial match against the driver code, identifying the files that must be considered manually. We have additionally identified over 150 driver files where the maintainer made an error in performing the collateral evolution, but Coccinelle transforms the code correctly. Finally, several patches derived from the use of Coccinelle have been accepted into the Linux kernel. Copyright 2008 ACM.},
key = {Automobile drivers},
keywords = {Application programming interfaces (API);Codes (symbols);Computer operating systems;Fourier transforms;Information theory;Linguistics;Semantics;Systems analysis;},
note = {Collateral evolutions;Device drivers;Domain-specific language;Linux;Program transformation;Software evolution;},
URL = {http://dx.doi.org/10.1145/1352592.1352618},
} 


@inproceedings{20081711212448 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {SmartEMF guidance in modeling tools},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Hessellund, Anders},
year = {2007},
pages = {945 - 946},
address = {Montreal, QC, Canada},
abstract = {The advent of domain-specific modeling in enterprise systems development has given rise to new tool requirements. Existing tools do not offer sufficient modeling guidance or inconsistency management for the multitude of new metamodels and models. Specifically, there is a need to offer guidance on 1) valid editing operations, 2) ensuring consistency among models, 3) bridging the gap between models and custom code, and 4) managing the evolution of domain-specific languages. Based on two empirical case studies, we propose a new unirepresentational modeling tool - SmartEMF - which provides guidance and inconsistency management when developing enterprise systems with multiple domain-specific languages.},
key = {Object oriented programming},
keywords = {Computer systems programming;Linguistics;Neodymium;Tools;},
note = {Domain specific language (DSL);Domain specific modeling (DSM);Editing operations;Empirical case studies;Enterprise system (ES);Evolution (CO);Inconsistency management;international conferences;Languages (traditional);Meta-models;Modeling tools;Object-oriented programming;Tool requirements;},
URL = {http://dx.doi.org/10.1145/1297846.1297958},
} 


@inproceedings{20094112367626 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Concepts of model driven software development in practice-Generic model representation and DSL interpretation},
journal = {ICEIS 2007 - 9th International Conference on Enterprise Information Systems, Proceedings},
author = {Erfurth, Christian and Rossak, Wilhelm and Schachtzabe, Christian and Hornbostel, Detlef and Skatulla, Steffen},
volume = {ISAS},
year = {2007},
pages = {278 - 286},
address = {Funchal, Madeira, Portugal},
abstract = {This paper discusses possibilities to realize constructs of a domain specific model (DSL) on the concrete development and runtime platform Ibykus AP. Here software engineering takes advantage of a combination of generative techniques and stable so-called DSL interpreters. These techniques to implement model driven software development (MDSD) concepts can improve the flexibility, the quality and the performance of the development of large application systems. Presenting the DSL interpreter approach underlying techniques of generic repository structures to hold the software model as well as runtime configuration information are discussed. The importance of an associated clear and well structured interface and tuning alternatives for the repository are pointed out. Finally the paper concludes with an outlook to future research work.},
key = {Modems},
keywords = {Computer software;DSL;Information systems;Linguistics;Software design;Telecommunication lines;},
note = {Application systems;Domain specific;Domain specific language (DSL);Generic models;Model driven software development (MDSD);Model-Driven Software Development;Run-time configuration;Runtimes;Software model;Structured interfaces;},
} 


@inproceedings{2004408389463 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Code generation for WSLAs using AXpect},
journal = {Proceedings - IEEE International Conference on Web Services},
author = {Swint, Galen S. and Pu, Calton},
year = {2004},
pages = {134 - 141},
address = {San Diego, CA, United states},
abstract = {WSLAs can be viewed as describing the service aspect of web services. By their nature, web services are distributed. Therefore, integrating support code into a web service application is potentially costly and error prone. Viewed from this AOP perspective, then, we present a method for integrating WSLAs into code generation using the AXpect weaver, the AOP technology for Infopipes. This helps to localize the code physically and therefore increase the eventual maintainability and enhance the reuse of the WSLA code. We then illustrate the weavers capability by using a WSLA document to codify constraints and metrics for a streaming image application that requires CPU resource monitoring.},
key = {World Wide Web},
keywords = {Codes (symbols);Computer aided software engineering;Computer programming languages;Computer software maintenance;Information technology;Semantics;XML;},
note = {Domain specific language (DSL);IBM (CO);Software quality;System software;Web services;},
URL = {http://dx.doi.org/10.1109/ICWS.2004.1314732},
} 


@article{2006269963268 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Programming by sketching for bit-streaming programs},
journal = {ACM SIGPLAN Notices},
author = {Solar-Lezama, Armando and Rabbah, Rodric and Bodik, Rastislav and Ebcioglu, Kemal},
volume = {40},
number = {6},
year = {2005},
pages = {281 - 294},
issn = {03621340},
abstract = {This paper introduces the concept of programming with sketches, an approach for the rapid development of high-performance applications. This approach allows a programmer to write clean and portable reference code, and then obtain a high-quality implementation by simply sketching the outlines of the desired implementation. Subsequently, a compiler automatically fills in the missing details while also ensuring that a completed sketch is faithful to the input reference code. In this paper, we develop StreamBit as a sketching methodology for the important class of bit-streaming programs (e.g., coding and cryptography). A sketch is a partial specification of the implementation, and as such, it affords several benefits to programmer in terms of productivity and code robustness. First, a sketch is easier to write compared to a complete implementation. Second, sketching allows the programmer to focus on exploiting algorithmic properties rather than on orchestrating low-level details. Third, a sketch-aware compiler rejects "buggy" sketches, thus improving reliability while allowing the programmer to quickly evaluate sophisticated implementation ideas. We evaluated the productivity and performance benefits of our programming methodology in a user-study, where a group of novice StreamBit programmers competed with a group of experienced C programmers on implementing a cipher. We learned that, given the same time budget, the ciphers developed in StreamBit ran 2.5&times; faster than ciphers coded in C. We also produced implementations of DES and Serpent that were competitive with hand optimized implementations available in the public domain. Copyright 2005 ACM.},
key = {Computer programming},
keywords = {Algorithms;Computer programming languages;Cryptography;Optimization;Program compilers;Specifications;},
note = {Domain Specific Compiler];Domain Specific Language;Sketching;Stream Programming;Streamit;Synchronous Dataflow;},
URL = {http://dx.doi.org/10.1145/1064978.1065045},
} 


@inproceedings{20080711091761 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Can we teach computers to write fast libraries?},
journal = {GPCE'07 - Proceedings of the Sixth International Conference on Generative Programming and Component Engineering},
author = {Puschel, Markus},
year = {2007},
pages = {1 - 2},
address = {Salzburg, Australia},
abstract = {As the computing world "goes multicore", high performance library development finally becomes a nightmare. Optimal programs, and their underlying algorithms, have to be adapted to take full advantage of the platform's parallelism, memory hierarchy, and available instruction set. To make things worse, the best implementations are often platform-dependent and platforms are constantly evolving, which quickly renders libraries obsolete. As a consequence, developers are forced to permanently re-implement and re-optimize the same functionality and often even revert to assembly coding just as 50 years ago. A number of research efforts have started to address this problem in a new area called Automatic Performance Tuning with the common goal to rethink the way libraries are created. In this talk we present Spiral (www.spiral.net), a program generation system for linear transforms. Spiral generates highly optimized, platform-tuned implementations of transforms directly from a problem specification. For a user-specified transform, Spiral generates alternative algorithms, optimizes them, compiles them into programs, and "intelligently" searches for the best match to the computing platform. The main idea behind Spiral is a mathematical, declarative framework to represent algorithms and the use of rewriting systems to generate and optimize algorithms at a high level of abstraction. Optimization includes parallelization for vector architectures, shared and distributed memory platforms, GPUs, and even FPGAs. Experimental results show that the code generated by Spiral competes with, and sometimes outperforms, the best available human-written library code. Further, recent research shows that it may be possible to extend Spiral into other domains such as coding or linear algebra. As for the question in the title: Spiral shows that, at least for well-understood problem domains, a positive answer may be in reach.},
key = {Digital libraries},
keywords = {Automation;Fourier transforms;Linear algebra;Optimization;Parallel algorithms;Problem solving;Teaching;},
note = {Domain-specific language;High performance library;Parallelization;Program generation;},
URL = {http://dx.doi.org/10.1145/1289971.1289973},
} 


@article{2006259954601 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {When and how to develop domain-specific languages},
journal = {ACM Computing Surveys},
author = {Mernik, Marjan and Heering, Jan and Sloane, Anthony M.},
volume = {37},
number = {4},
year = {2005},
pages = {316 - 344},
issn = {03600300},
abstract = {Domain-specific languages (DSLs) are languages tailored to a specific application domain. They offer substantial gains in expressiveness and ease of use compared with general-purpose programming languages in their domain of application. DSL development is hard, requiring both domain knowledge and language development expertise. Few people have both. Not surprisingly, the decision to develop a DSL is often postponed indefinitely, if considered at all, and most DSLs never get beyond the application library stage. Although many articles have been written on the development of particular DSLs, there is very limited literature on DSL development methodologies and many questions remain regarding when and how to develop a DSL. To aid the DSL developer, we identify patterns in the decision, analysis, design, and implementation phases of DSL development. Our patterns improve and extend earlier work on DSL design patterns. We also discuss domain analysis tools and language development systems that may help to speed up DSL development. Finally, we present a number of open problems. &copy; 2005 ACM.},
key = {Computer programming languages},
keywords = {Decision theory;Knowledge acquisition;Logic design;Pattern recognition;},
note = {Application language;Domain analysis;Domain-specific language (DSL);Language development system;},
} 


@article{2004138089513 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {SPIRAL: A generator for platform-adapted libraries of signal processing algorithms},
journal = {International Journal of High Performance Computing Applications},
author = {Puschel, Markus and Moura, Jose M. F. and Singer, Bryan and Xiong, Jianxin and Johnson, Jeremy and Padua, David and Veloso, Manuela and Johnson, Robert W.},
volume = {18},
number = {1},
year = {2004},
pages = {21 - 45},
issn = {10943420},
abstract = {SPIRAL is a generator for libraries of fast software implementations of linear signal processing transforms. These libraries are adapted to the computing platform and can be re-optimized as the hardware is upgraded or replaced. This paper describes the main components of SPIRAL: the mathematical framework that concisely describes signal transforms and their fast algorithms; the formula generator that captures at the algorithmic level the degrees of freedom in expressing a particular signal processing transform; the formula translator that encapsulates the compilation degrees of freedom when translating a specific algorithm into an actual code implementation; and, finally, an intelligent search engine that finds within the large space of alternative formulas and implementations the "best" match to the given computing platform. We present empirical data that demonstrate the high performance of SPIRAL generated code.},
key = {Software engineering},
keywords = {Algorithms;Computer hardware;Digital signal processing;Discrete Fourier transforms;Fast Fourier transforms;Optimization;Program compilers;Program translators;},
note = {Automatic performance tuning;Domain specific language;Program generation;Signal transform;Software package SPIRAL;},
URL = {http://dx.doi.org/10.1177/1094342004041291},
} 


@article{20073110710374 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The tools we use},
journal = {IEEE Software},
author = {Spinellis, Diomidis},
volume = {24},
number = {4},
year = {2007},
pages = {20 - 21},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {If we look at the tools we use to convert source code into executable format, we can get an accurate picture of the abstraction level that programmers face during construction and maintenance (where the largest chunk of software development effort takes place). Collecting data from the building of 7,000 application programs showed that most CPU time is spent compiling C and C++ code using tools with roots in the 1970s and 1980s. To see order-of-magnitude productivity improvements, we must raise our code's level of abstraction by adopting more modern technologies such as domain-specific languages, general purpose declarative languages, and executable UML. &copy; 2007 IEEE.},
key = {Computer aided software engineering},
keywords = {C (programming language);Codes (symbols);Computer programming;Computer programming languages;Unified Modeling Language;},
note = {Abstraction;Declarative language;Domain-specific language;Executable unified modeling language;},
URL = {http://dx.doi.org/10.1109/MS.2007.121},
} 


@inproceedings{20063110042224 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Programming for artists: A visual language for expressive lighting design},
journal = {Proceedings - 2005 IEEE Symposium on Visual Languages and Human-Centric Computing},
author = {Gross, Joshua B.},
volume = {2005},
year = {2005},
pages = {331 - 332},
address = {Dallas, TX, United states},
abstract = {Programming is a process of formalizing and codifying knowledge, and, as a result, programming languages are designed for generalists trained in this process of formalization. Artists, whose training focuses on skill and tacit knowledge, are marginalized by existing tools. By designing visual languages that take advantage of an artist's skills in visual perception and expression, we can allow that artist to take advantage of the expressive potential that modern computing offers. In particular, this paper will look at lighting design for interactive, virtual environments, and augmenting an existing programming language to allow artists to leverage their skills in the pragmatics of that medium. &copy; 2005 IEEE.},
key = {Computer programming},
keywords = {Computer aided design;Computer programming languages;Human computer interaction;Knowledge acquisition;Semiotics;Virtual reality;},
note = {Domain specific language;Pragmatics;Virtual environments;Visual perception;},
URL = {http://dx.doi.org/10.1109/VLHCC.2005.54},
} 


@inproceedings{2005219111564 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic generation of language-based tools using the LISA system},
journal = {IEE Proceedings: Software},
author = {Henriques, P.R. and Pereira, M.J.V. and Mernik, M. and Lenic, M. and Gray, J. and Wu, H.},
volume = {152},
number = {2},
year = {2005},
pages = {54 - 69},
issn = {14625970},
abstract = {Many tools have been constructed using different formal methods to process various parts of a language specification (e.g. scanner generators, parser generators and compiler generators). The automatic generation of a complete compiler was the primary goal of such systems, but researchers recognised the possibility that many other language-based tools could be generated from formal language specifications. Such tools can be generated automatically whenever they can be described by a generic fixed part that traverses the appropriate data structures generated by a specific variable part, which can be systematically derivable from the language specifications. The paper identifies generic and specific parts for various language-based tools. Several language-based tools are presented in the paper, which are automatically generated using an attribute grammar-based compiler generator called LISA. The generated tools that are described in the paper include editors, inspectors, debuggers and visualisers/animators. Because of their complexity of construction, special emphasis is given to visualisers/animators, and the unique contribution of our approach toward generating such tools. &copy; IEE, 2005.},
key = {Computer programming languages},
keywords = {Algorithms;Animation;Computational complexity;Computer programming;Data structures;Program compilers;Program debugging;},
note = {Animators;Domain-specific language (DSL);Language-based tools;LISA systems;},
URL = {http://dx.doi.org/10.1049/ip-sen:20041317},
} 


@article{2006269963271 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Formal loop merging for signal transforms},
journal = {ACM SIGPLAN Notices},
author = {Franchetti, Franz and Voronenko, Yevgen and Puschel, Markus},
volume = {40},
number = {6},
year = {2005},
pages = {315 - 326},
issn = {03621340},
abstract = {A critical optimization in the domain of linear signal transforms, such as the discrete Fourier transform (DFT), is loop merging, which increases data locality and reuse and thus performance. In particular, this includes the conversion of shuffle operations into array reindexings. To date, loop merging is well understood only for the DFT, and only for Cooley-Tukey FFT based algorithms, which excludes DFT sizes divisible by large primes. In this paper, we present a formal loop merging framework for general signal transforms and its implementation within the SPIRAL code generator. The framework consists of &Sigma;-SPL, a mathematical language to express loops and index mappings; a rewriting system to merge loops in &Sigma;-SPL; and a compiler that translates &Sigma;-SPL into code. We apply the framework to DFT sizes that cannot be handled using only the Cooley-Tukey FFT and compare our method to FFTW 3.0.1 and the vendor library Intel MKL 7.2.1. Compared to FFTW our generated code is a factor of 2-4 faster under equal implementation conditions (same algorithms, same unrolling threshold). For some sizes we show a speed-up of a factor of 9 using Bluestein's algorithm. Further, we give a detailed comparison against the Intel vendor library MKL; our generated code is between 2 times faster and 4.5 times slower. Copyright 2005 ACM.},
key = {Computer programming},
keywords = {Algorithms;Discrete Fourier transforms;Indexing (of information);Optimization;Program compilers;},
note = {Automatic performance tuning;Domain-specific language;Linear signal transform;Loop optimization;},
URL = {http://dx.doi.org/10.1145/1064978.1065048},
} 


@inproceedings{20083011396530 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A model based approach for policy tool generation and policy analysis},
journal = {2007 1st International Global Information Infrastructure Symposium, GIIS 2007 - "Closing the Digital Divide"},
author = {Barrett, Keara and Davy, Steven and Strassner, John and Jennings, Brendan and Van Der Meer, Sven and Donnelly, William},
year = {2007},
pages = {99 - 105},
address = {Marrakech, Morocco},
abstract = {We outline an approach to policy specification and analysis in which an information model is used as the starling point for semi-automated generation of an integrated suite of languages, tools and an ontology. The suite includes separate domain-specific languages for the specification of systems structure and policies respectively, editors and checkers for these languages, and a baseline ontology that can be augmented with semantic information to support policy analyses processes. We describe a prototypical realisation of the approach, showing how the languages, tools and ontology are used to support policy transformation and conflict detection processes. &copy; 2007 IEEE.},
key = {Ontology},
keywords = {Information theory;Linguistics;Specification languages;},
note = {Conflict detection (CD);Digital divides;Domain specific language (DSL);Global informations;Information modelling;International (CO);Languages (traditional);Model based approaches;Policy analysis;Policy specification;Semantic information;Semi-automated;Support policy;Systems Structure;},
URL = {http://dx.doi.org/10.1109/GIIS.2007.4404174},
} 


@inproceedings{20082811360063 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A framework for business model driven development},
journal = {STEP 2004 Proceedings - The 12th International Workshop on Software Technology and Engineering Practice},
author = {Liew, Philip and Kontogiannis, Kostas and Tong, Tack},
year = {2005},
pages = {47 - 54},
address = {Chicago, IL, United states},
abstract = {Typically, large companies in an effort to increase efficiency specify business processes using workflow languages, while software designers specify the systems that implement these processes with the use of languages like UML. This separation of domain expertise allows for software engineers from each individual area to work more efficiently using domain specific languages and tools. However, models in these two domains evolve independently and inconsistencies may occur when two models become unsynchronized due to constant revision or evolution of processes and design artifacts. In this paper, we present a set of transformations to automatically generate a specific set of UML artifacts from the business process specifications. In particular, we examine and investigate a preliminary framework for the necessary annotations that need be applied to a Business Process Model so that the generation of UML use cases, activity diagrams, collaboration diagrams and deployment diagrams could be feasible. The objective of this work is to be able to generate rich Platform Independent UML models that can be used for automating the generation of design artifacts and source code by using a Model Driven Architecture approach. By doing so, we aim to decrease software design time, reduce maintenance costs and better support system evolution. &copy; 2004 IEEE.},
key = {Software design},
keywords = {Computer simulation languages;Computer software maintenance;Graphic methods;Industry;Information management;Linguistics;Maintenance;Management;Management science;Markup languages;Process engineering;Separation;Specifications;Technology;Unified Modeling Language;},
note = {Activity diagram (AD);Applied (CO);Business model (BM);Business Process modeling;Business processes (BP);Business processing;Collaboration diagrams;Deployment diagrams;design artifacts;design time;Domain expertise;Domain specific language (DSL);Engineering practices;Evolution (CO);Individual (PSS 544-7);International (CO);Languages (traditional);maintenance costs;Model-driven architecture approach (MDA);Platform independent;Software designers;Software Engineers;software technologies;Source coding;support systems;Two domains;UML (unified modeling language)model;Use cases;Workflow languages;},
URL = {http://dx.doi.org/10.1109/STEP.2004.5},
} 


@inproceedings{20083011394900 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Tracing model elements},
journal = {IEEE International Conference on Software Maintenance, ICSM},
author = {Wenzel, Sven and Hutter, Hermann and Kelter, Udo},
year = {2007},
pages = {104 - 113},
address = {Paris, France},
abstract = {In model-driven engineering developers work mainly or only with models, which exist in many versions. This paper presents an approach to trace single model elements or groups of elements within a version history of a model. It also offers analysis capabilities such as detection of logical coupling between model elements. The approach uses a differencing algorithm known as SiDiff to identify similar elements in different versions of a model. SiDiff is highly configurable and thus our tracing approach can be adapted to all diagram types of the UML and to a large set of domain specific languages. The approach has been implemented as an Eclipse plug-in that visualizes all relevant information about the traces and it allows developers to interactively explore details. It has been evaluated by several groups of test persons; they considered most of the functions of the tool to be very useful. &copy; 2007 IEEE.},
key = {Trace elements},
keywords = {Computer software maintenance;Maintenance;Models;Unified Modeling Language;},
note = {Analysis capabilities;Configurable;Differencing algorithm;Domain specific language (DSL);Eclipse plug ins;International conferences;Model driven engineering (MDE);Model elements;Relevant information;},
URL = {http://dx.doi.org/10.1109/ICSM.2007.4362623},
} 


@article{20080711095467 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A framework for modelling restricted delegation of rights in the SECTET},
journal = {Computer Systems Science and Engineering},
author = {Alam, Muhammad and Hafner, Michael and Breu, Ruth and Unterthiner, Stefan},
volume = {22},
number = {5},
year = {2007},
pages = {289 - 305},
issn = {02676192},
address = {9 De Montfort Mews, Leicestershire, LE1 7FW, United Kingdom},
abstract = {We present a novel approach for modelling restricted delegation of rights in a distributed environment based on web services. In existing delegation models, delegated permissions are statically assigned to a role which is not the case in Service Oriented Architecture's (SOA). In SOA, permissions to execute web services are delegated to roles with a set of dynamic constraints. These constraints play a key role in the assignment of permissions to roles. This paper presents an extension to our model Constraint based Role Based Access Control (CRBAC), CRBAC1, in order to support permission-level delegation based on dynamic constraints. Our approach integrates SECTET-PL [1], a predicative language for modelling access rights based on the concept of Role Based Access Control (RBAC). SECTET-PL is part of the SECTET framework for model-driven security for B2B workflows. Our Rights Delegation Model combines the concept of roles from RBAC with the predicative specification of SECTET-PL. The Rights Delegation Model is translated into XACML Delegation Policies, which are interpreted by a security gateway. &copy; 2007 CRL Publishing Ltd.},
key = {Web services},
keywords = {Access control;Dynamic models;Model predictive control;Public policy;},
note = {Delegation of rights;Domain specific language;Model driven architecture;Model driven engineering;Service oriented architecture;},
} 


@article{20063110047018 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using source transformation to test and model check implicit-invocation systems},
journal = {Science of Computer Programming},
author = {Zhang, Hongyu and Bradbury, Jeremy S. and Cordy, James R. and Dingel, Juergen},
volume = {62},
number = {3},
year = {2006},
pages = {209 - 227},
issn = {01676423},
abstract = {In this paper we present a source transformation-based framework to support uniform testing and model checking of implicit-invocation software systems. The framework includes a new domain-specific programming language, the Implicit-Invocation Language (IIL), explicitly designed for directly expressing implicit-invocation software systems, and a set of formal rule-based source transformation tools that allow automatic generation of both executable and formal verification artifacts. We provide details of these transformation tools, evaluate the framework in practice, and discuss the benefits of formal automatic transformation in this context. Our approach is designed not only to advance the state-of-the-art in validating implicit-invocation systems, but also to further explore the use of automated source transformation as a uniform vehicle to assist in the implementation, validation and verification of programming languages and software systems in general. &copy; 2006.},
key = {Computer science},
keywords = {Computer programming languages;Computer software;Logic programming;Set theory;Testing;},
note = {Domain-specific language;Implicit invocation;Model checking;Source transformation;Verifications;},
URL = {http://dx.doi.org/10.1016/j.scico.2006.04.008},
} 


@inproceedings{2005229130895 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Composing programming languages by combining action-semantics modules},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Doh, Kyung-Goo and Mosses, Peter D.},
volume = {44},
number = {2},
year = {2001},
pages = {91 - 113},
issn = {15710661},
address = {Genova, Italy},
abstract = {This article demonstrates a method for composing a programming language by combining action-semantics modules. Each module is defined separately, and then a new module is defined by either extending or combining existing modules. This method enables the language designer to gradually develop a language by selecting, extending and combining suitable language modules. The resulting modular structure is substantially different from that previously employed in action-semantic descriptions. We also discuss how to resolve the conflicts that may arise when combining modules, and indicate some advantages that action semantics has over other approaches in this respect. &copy;2001 Published by Elsevier Science B.V.},
key = {Computer programming languages},
keywords = {Combinatorial mathematics;Context free grammars;Data storage equipment;Problem solving;Rapid prototyping;Semantics;},
note = {Action-semantic modules;Domain-specific language;Landin-Tennent principles;Language-design principles;},
URL = {http://dx.doi.org/10.1016/S1571-0661(04)80922-8},
} 


@inproceedings{2002367067420 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Specifying behavior in C++},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
author = {Dai, Xiangtian and Hager, Gregory and Peterson, John},
volume = {1},
year = {2002},
pages = {153 - 160},
issn = {10504729},
address = {Washington, DC, United states},
abstract = {Most robot programming takes place in the "time domain". That is, the goal is to specify the behavior of a system that is acquiring a continual temporal stream of inputs, and is required to provide a continual, temporal stream of outputs. We present a reactive programming language, based on the Functional Reactive Programming paradigm, for specifying such behavior. The major attributes of this language are: 1) it provides for both synchronous and asynchronous definitions of behavior, 2) specification is equational in nature, 3) it is type safe, and 4) it is embedded in C++. In particular the latter makes it simple to "lift" existing C++ libraries into the language.},
key = {Robot programming},
keywords = {Algorithms;C (programming language);Computational complexity;Data acquisition;Database systems;Robotics;Software engineering;Time domain analysis;},
note = {Domain specific language;Functional reactive programming;},
URL = {http://dx.doi.org/10.1109/ROBOT.2002.1013354},
} 


@inproceedings{2003307555852 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A tutorial on feature oriented programming and product-lines},
journal = {Proceedings - International Conference on Software Engineering},
author = {Batory, Don},
year = {2003},
pages = {753 - 754},
issn = {02705257},
address = {Portland, OR, United states},
abstract = {Feature Oriented Programming (FOP) is a design methodology and tools for program synthesis. The goal is to specify a target program in terms of the features that it offers, and to synthesize an efficient program that meets these specifications. FOP has been used to develop product-lines in disparate domains, including compilers for extensible Java dialects [3], fire support simulators for the U.S. Army [5], high-performance network protocols [1], and program verification tools [14].},
key = {Software engineering},
keywords = {Computer hardware description languages;Computer simulation;Computer software selection and evaluation;HTML;Java programming language;Network protocols;Object oriented programming;Program compilers;Program diagnostics;Websites;},
note = {Aspect oriented programming;Domain specific language;Feature oriented programming;Product lines;},
URL = {http://dx.doi.org/10.1109/ICSE.2003.1201271},
} 


@article{2003237494897 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {One giant step backward},
journal = {Communications of the ACM},
author = {Glass, Robert L.},
volume = {46},
number = {5},
year = {2003},
pages = {21 - 23},
issn = {00010782},
abstract = {To date, a number of things have come along to help software developers. However, a close look at the current scenario reveals that not much have been attained. Taking programming languages as a case in point, it is shown that the programming language community has taken several steps backward. For the most part, today's programming languages are significant improvements over those of yester-decade and yester-millenium. Nonetheless, there is one important way in which programming languages have fallen backward - that way is application domain focus.},
key = {Software engineering},
keywords = {Ada (programming language);ALGOL (programming language);COBOL (programming language);Computer operating systems;Computer programming;Computer science;Computer software reusability;FORTRAN (programming language);Interfaces (computer);Real time systems;},
note = {Domain specific language;Real time program;},
URL = {http://dx.doi.org/10.1145/769800.769817},
} 


@inproceedings{2005229138960 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Fusing logic and control with local transformations: An example optimization},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Johann, Patricia and Visser, Eelco},
volume = {57},
year = {2001},
pages = {144 - 162},
issn = {15710661},
address = {Utrecht, Netherlands},
abstract = {Abstract programming supports the separation of logical concerns from issues of control in program construction. While this separation of concerns leads to reduced code size and increased reusability of code, its main disadvantage is the computational overhead it incurs. Fusion techniques can be used to combine the reusability of abstract programs with the efficiency of specialized programs. In this paper we illustrate some of the ways in which rewriting strategies can be used to separate the definition of program transformation rules from the strategies under which they are applied. Doing so supports the generic definition of program transformation components. Fusion techniques for strategies can then be used to specialize such generic components. We show how the generic innermost rewriting strategy can be optimized by fusing it with the rules to which it is applied. Both the optimization and the programs to which the optimization applies are specified in the strategy language Stratego. The optimization is based on small transformation rules that are applied locally under the control of strategies, using special knowledge about the contexts in which the rules are applied. &copy; 2001 Published by Elsevier Science B. V.},
key = {Logic programming},
keywords = {Algorithms;Computer hardware description languages;Data structures;Matrix algebra;Optimization;Semantics;},
note = {Abstract programming techniques;Domain-specific language;Fusion techniques;Program transformation systems;},
URL = {http://dx.doi.org/10.1016/S1571-0661(04)00271-3},
} 


@inproceedings{2005229132284 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A proof dedicated meta-language},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Delahaye, David},
volume = {70},
number = {2},
year = {2002},
pages = {89 - 102},
issn = {15710661},
address = {Copenhagen, Denmark},
abstract = {We describe a proof dedicated meta-language, called &Lscr;<inf>tac</inf>, in the context of the Coq proof assistant. This new layer of meta-language is quite appropriate to write small and local automations. &Lscr;<inf>tac</inf>, is essentially a small functional core with recursors and powerful pattern-matching operators for Coq terms but also for proof contexts. As &Lscr;<inf>tac</inf>, is not complete, we describe an interface between &Lscr;<inf>tac</inf>, and the full programmable meta-language of the system (Objective CAML), which is also the implementation language. This interface is based on a quotation system where we can use &Lscr;<inf>tac</inf>,'s syntax in ML files, and where it is possible to insert ML code in &Lscr;<inf>tac</inf>, scripts by means of antiquotations. In that way, the two meta-languages are not opposed and we give an example where they fairly cooperate. Thus, this shows that a LCF-like system with a two-level meta-language is completely realistic. &copy; 2002 Published by Elsevier Science B. V.},
key = {Computer programming languages},
keywords = {Abstracting;Computer programming;Computer simulation;Data acquisition;Error detection;Pattern matching;Program debugging;},
note = {Curry-Howard isomorphism;Domain-Specific Language (DSL);Meta-language;Prestburger's arithmetic;},
URL = {http://dx.doi.org/10.1016/S1571-0661(04)80508-5},
} 


@inproceedings{20104313333137 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain Specific modeling languages to support model-driven engineering of aircraft systems},
journal = {8th AIAA Aviation Technology, Integration and Operations (ATIO) Conference},
author = {Van Der Elst, S.W.G. and Van Tooren, M.J.L.},
year = {2008},
address = {Anchorage, AK, United states},
abstract = {Knowledge is a vital component of engineering design. Computer systems enriched with logic and engineering knowledge can support engineering design by automating repetitive and time-consuming processes. This automation is best structured in the framework concept of a Design and Engineering Engine, applying Knowledge Based Engineering techniques. The lack of recognized methodologies implies significant investments for the development and maintenance of Design and Engineering Engines. To alleviate the required effort a Domain Specific modeling Language is developed, enabling the representation of conceptual classes of the problem domain and is considered a visual dictionary of noteworthy abstractions, domain vocabulary and knowledge content. A Domain Specific modeling Language provides an intuitive environment to model domain specific engineering knowledge and enables a tight coupling between modeled knowledge and software program code. The Domain Specific modeling Language is used to develop a Knowledge Based Engineering application dedicated to aircraft wiring harness design processes. Copyright &copy; 2008 by the American Institute of Aeronautics and Astronautics, Inc. All rights reserved.},
key = {Knowledge representation},
keywords = {Aviation;Computer simulation languages;Design;Embedded systems;Knowledge based systems;Query languages;},
note = {Design and engineering engines;Domain model;Domain specific modeling languages;Knowledge-based engineering;Model-driven design;},
} 


@inproceedings{20112914155100 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific metamodel for semantic web enabled multi-agent systems},
journal = {Lecture Notes in Business Information Processing},
author = {Challenger, Moharram and Getir, Sinem and Demirkol, Sebla and Kardas, Geylani},
volume = {83 LNBIP},
year = {2011},
pages = {177 - 186},
issn = {18651348},
address = {London, United kingdom},
abstract = {Autonomous, responsive and proactive nature of agents makes development of agent-based software systems more complex than other software systems. A Domain Specific Modeling Language (DSML) may provide the required abstraction and hence support a more fruitful methodology for the development of MASs especially working on the new challenging environments such as the Semantic Web. In this paper, we introduce a domain specific metamodel for MASs working on the Semantic Web. This new metamodel paves the way for definition of an abstract syntax and a concrete syntax for a future DSML of agent systems. Achieved DSML syntax is supported with a graphical modeling toolkit. &copy; 2011 Springer-Verlag.},
key = {Multi agent systems},
keywords = {Abstracting;Autonomous agents;Information systems;Intelligent agents;Semantic Web;Semantics;Syntactics;Systems engineering;User interfaces;},
note = {Abstract syntax;Agent systems;Agent-based softwares;Concrete syntax;Domain specific;Domain specific modeling languages;Graphical modeling;Meta model;Software systems;},
URL = {http://dx.doi.org/10.1007/978-3-642-22056-2_19},
} 


@inproceedings{20084811751697 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A model-driven measurement approach},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Monperrus, Martin and Jezequel, Jean-Marc and Champeau, Joel and Hoeltzener, Brigitte},
volume = {5301 LNCS},
year = {2008},
pages = {505 - 519},
issn = {03029743},
address = {Toulouse, France},
abstract = {Companies using domain specific languages in a model-driven development process need to measure their models. However, developing and maintaining a measurement software for each domain specific modeling language is costly. Our contribution is a model-driven measurement approach. This measurement approach is model-driven from two viewpoints: 1) it measures models of a model-driven development process; 2) it uses models as unique and consistent metric specifications, w.r.t a metric specification metamodel. This declarative specification of metrics is then used to generate a fully fledged implementation. The benefit from applying the approach is evaluated by two applications. They indicate that this approach reduces the domain-specific measurement software development cost. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Models},
keywords = {Embedded systems;Linguistics;Query languages;Specifications;Systems analysis;XML;},
note = {Applications.;Declarative specifications;Development processes;Do-mains;Domain specific modeling languages;Domain specifics;Measurement softwares;},
URL = {http://dx.doi.org/10.1007/978-3-540-87875-9_36},
} 


@inproceedings{20072010600762 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Round-trip engineering of eclipse plug-ins using eclipse workbench part interaction FSML},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Antkiewicz, Micha and Czarnecki, Krzysztof},
volume = {2006},
year = {2006},
pages = {738 - 739},
address = {Portland, OR, United states},
abstract = {A Framework-Specific Modeling Language (FSML) is a kind of Domain-Specific Modeling Language that is used for modeling framework-based software. FSMLs enable automated round-trip engineering over non-trivial model-to-code mappings and thereby simplify the task of creating and evolving framework-based applications. In this demonstration, we present a prototype implementation of Eclipse Workbench Part Interaction, a FSML capturing an aspect of Eclipse plug-in development. We walk through an example Eclipse plug-in development scenario and demonstrate the round-trip engineering capabilities of the prototype.},
key = {Computer programming languages},
keywords = {Codes (symbols);Computer simulation;Computer software;Conformal mapping;Object oriented programming;},
note = {Domain specific modeling;Eclipse;Framework Specific Modeling Language (FSML);Roundtrip engineering;Workbench Part Interaction;WPI;},
URL = {http://dx.doi.org/10.1145/1176617.1176701},
} 


@inproceedings{20094612442308 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model driven development of context aware software systems},
journal = {International Workshop on Context-Oriented Programming, COP '09},
author = {Sindico, Andrea and Grassi, Vincenzo},
year = {2009},
pages = {a7 - a7},
address = {Genova, Italy},
abstract = {This paper presents the first results of an ongoing work towards the realization of a model driven development framework for context awareness. Its core element consists of a domain specific modeling language called CAMEL (Context Awareness ModEling Language), and defined as a UML extension. CAMEL can be used to enrich a UML model of an application with elements related to contexts and context dependent behaviors. The resulting UML+CAMEL model is the starting point for model transformation aimed at generating executable code or other artifacts. CAMEL is implemented by an Eclipse plugin. &copy; 2009 ACM.},
key = {Embedded systems},
keywords = {Linguistics;},
note = {Context Awareness;Context Oriented Modeling;Context Oriented Programming;MDA;Modeling;UML;},
URL = {http://dx.doi.org/10.1145/1562112.1562119},
} 


@inproceedings{20110913701948 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings - 2010 IEEE 12th International Symposium on High Assurance Systems Engineering, HASE 2010},
journal = {Proceedings of IEEE International Symposium on High Assurance Systems Engineering},
year = {2010},
issn = {15302059},
address = {San Jose, CA, United states},
abstract = {The proceedings contain 22 papers. The topics discussed include: low-cost secret-sharing in sensor networks; predicting faults in high assurance software; a UML-based domain specific modeling language for the availability management framework; symbolic representation techniques in dynamic reliability evaluation; a stateful approach to testing monitors in multithreaded programs; a dataflow testing approach for aspect-oriented programs; paths to property violation: a structural approach for analyzing counter-examples; hybrid Petri nets with general one-shot transitions for dependability evaluation of fluid critical infrastructures; formal analysis of the Kaminsky DNS cache-poisoning attack using probabilistic model checking; experience with model-based user-centered risk assessment for service robots; proved metamodels as backbone for software adaptation; and reverse engineering abstract components for model-based development and verification of embedded software.},
} 


@inproceedings{20064710248016 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling the Railway Control Domain rigorously with a UML 2.0 profile},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Berkenkotter, Kirsten and Hannemann, Ulrich},
volume = {4166 LNCS},
year = {2006},
pages = {398 - 411},
issn = {03029743},
address = {Gdansk, Poland},
abstract = {We introduce the Railway Control Systems Domain (RCSD) profile of the Unified Modeling Language UML 2.0 as a domain specific modeling language for railway and tramway control systems. The RCSD profile covers the segments of the rail network, sensors, and control elements like signals and switches. Using these terms of the railway domain, it facilitates the communication between domain experts and specialists for embedded control system development. Defined as a profile for UML 2.0, the development of precise RCSD descriptions is supported by standard UML tools, visualizing railway networks in the same way as domain experts are used to. The static description of networks is complemented by the characterization of the dynamics within the network with trains running on predefined routes. This behaviour is provided by the semantics of a state transition system derived from the object diagram of a particular network model. This rigorous semantic approach constitutes a prerequisite for further tool-supported analysis of safety requirements, and generation of the actual control system. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Automatic train control},
keywords = {Computer programming languages;Computer simulation;Control systems;Embedded systems;Mathematical models;Railroad signal systems;Railroad track switches;Railroad tracks;Semantics;},
note = {Network models;Railway Control Systems;Tramway control systems;Unified Modeling Language (UML);},
} 


@article{20063410082488 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {End-user specification for diagrammatic model languages},
journal = {Beijing Hangkong Hangtian Daxue Xuebao/Journal of Beijing University of Aeronautics and Astronautics},
author = {Xu, Hongxia and Zhang, Li},
volume = {32},
number = {6},
year = {2006},
pages = {704 - 708},
issn = {10015965},
abstract = {Formal specification of diagrammatic languages is not applicable to end users because of the requisition of computer theory. In order to satisfy the requirement of end users to define their own domain-specific modeling language, a language named EUVDL (end-user visual definition language), was proposed, which could be used to specify the 2-dimensional syntactic structure of diagrammatic model in software engineering. The specification technique of EUVDL combined the object-oriented methods and the rule-based approaches rather than formal specification. The support to end users was provided from following aspects: paradigm, abstract syntax, and concrete syntax. In order to make EUVDL available, the practical strategies for end users were presented and a framework for diagrammatic modeling environment generator was designed. Through comparison to other specification methods and demonstration of an example of visual process model, the conclusion can be drawn out that the specification method has the feature of simple structure, expressive power and reusable ability, and is adapted to end-users.},
key = {Software engineering},
keywords = {Computer simulation;Computer software;Demonstrations;Formal languages;Specifications;Syntactics;Two dimensional;},
note = {Diagram editor generator;Diagrammatic model languages;End user specification (EUVDL);Two dimensional syntactic structure;},
URL = {http://dx.doi.org/10.1016/j.lfs.2005.05.080},
} 


@inproceedings{20113514267967 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Message modeling for the Joint Architecture for Unmanned Systems (JAUS)},
journal = {Proceedings - 18th IEEE International Conference and Workshops on Engineering of Computer-Based Systems, ECBS 2011},
author = {Whitsitt, Sean and Sprinkle, Jonathan},
year = {2011},
pages = {251 - 259},
address = {Las Vegas, NV, United states},
abstract = {The Joint Architecture for Unmanned Systems (JAUS) is a standard for sensing, control, and computational communication of components for unmanned systems. This paper presents a modeling environment capable of producing a domain-specific prototype of the software necessary for intercomputer communications. A metamodel is used to provide the domain-specific modeling language to model both the messages used in JAUS, and the shell interfaces for components that transmit and receive those messages. The produced artifacts are C and C++ code that can be used in unmanned systems and simulations of such systems, including tests that validate the structure and behavior of the generated code. The generated code is compatible with standard JAUS implementations, and is validated using the OpenJAUS open source API and framework. Future work describes the second spiral of features and behaviors (currently in the design phase). The case study and test environment for the software generated by this project is an autonomous ground vehicle, modeled on a Ford Escape Hybrid that is used in laboratory experiments. &copy; 2011 IEEE.},
key = {Open systems},
keywords = {Computer architecture;Computer control systems;Software prototyping;Software testing;Technical presentations;Unmanned vehicles;},
note = {Autonomous Vehicles;Code Generation;JAUS;Metamodeling;Model-based design;Unmanned system;},
URL = {http://dx.doi.org/10.1109/ECBS.2011.17},
} 


@inproceedings{20090911935182 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the 2005 International Conference on Software Engineering Research and Practice, SERP'05},
journal = {Proceedings of the 2005 International Conference on Software Engineering Research and Practice, SERP'05},
volume = {1},
year = {2005},
address = {Las Vegas, NV, United states},
abstract = {The proceedings contain 134 papers. The topics discussed include: progressive autonomy - an incremental agent-based approach; specification and implementation of autonomic large-scale system behaviors using domain specific modeling language tools; experimenting with an evolving ground/space-based software architecture to enable sensor webs; performance assessment of architectural options on intelligent distributed systems; a software architecture intended to design quality groupware applications; scope equivalence of concurrent systems based on bipartite directed acyclic graph; interface descriptions for enterprise architecture; detection of anomalies in a software architectural style with connectors: position paper; predicting maintainability using object oriented system decomposition metrics; and the workshop - implementing well structured enterprise applications.},
} 


@inproceedings{20090911936941 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the 2005 International Conference on Software Engineering Research and Practice, SERP'05},
journal = {Proceedings of the 2005 International Conference on Software Engineering Research and Practice, SERP'05},
volume = {2},
year = {2005},
address = {Las Vegas, NV, United states},
abstract = {The proceedings contain 134 papers. The topics discussed include: progressive autonomy - an incremental agent-based approach; specification and implementation of autonomic large-scale system behaviors using domain specific modeling language tools; experimenting with an evolving ground/space-based software architecture to enable sensor webs; performance assessment of architectural options on intelligent distributed systems; a software architecture intended to design quality groupware applications; scope equivalence of concurrent systems based on bipartite directed acyclic graph; interface descriptions for enterprise architecture; detection of anomalies in a software architectural style with connectors: position paper; predicting maintainability using object oriented system decomposition metrics; and the workshop - implementing well structured enterprise applications.},
} 


@inproceedings{20100512683706 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A model integrated development of embedded software for manufacturing equipment control},
journal = {Lecture Notes in Electrical Engineering},
author = {Song, Zhumei and Li, Di},
volume = {56 LNEE},
year = {2010},
pages = {55 - 61},
issn = {18761100},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {The state-of-art approaches for embedded control software development are costly. It is difficult for manufacturing domain engineers to develop equipment control software in general development environment. Therefore, we propose domain-extending technology of embedded software for equipment control. Model-integrated computing approach is introduced to build meta-model for manufacturing equipment control. Graphical domain specific modeling language is interpreted from the meta-model. Engineers in equipment control domain can use this modeling language to rapidly build application model for different embedded control system. A simple example, signal process, indicates that this technology can reduce development and maintenance costs significantly. Domain engineers can develop their own embedded system with facility. The architecture for embedded control system is explored in design space. It is viable to built modeling language for equipment control software. &copy; 2010 Springer-Verlag Berlin Heidelberg.},
key = {Embedded software},
keywords = {Computer control;Computer software maintenance;Cost reduction;Embedded systems;Equipment;Linguistics;Signal processing;Software design;},
note = {Application models;Design spaces;Development environment;Domain specific modeling languages;Embedded control software;Embedded control systems;Equipment control;Integrated development;Maintenance cost;Manufacturing domains;Manufacturing equipment;Meta model;Model Integrated Computing;Modeling languages;Signal process;},
URL = {http://dx.doi.org/10.1007/978-3-642-05173-9_8},
} 


@inproceedings{20112514077201 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Incremental evaluation of model queries over EMF models: A tutorial on EMF-IncQuery},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Bergmann, Gabor and Horvath, Akos and Rath, Istvan and Varro, Daniel},
volume = {6698 LNCS},
year = {2011},
pages = {389 - 390},
issn = {03029743},
address = {Birmingham, United kingdom},
abstract = {Model driven development platforms such as the industry leader Eclipse Modeling Framework (EMF) greatly benefit from pattern matching, as it supports various usecases including model validation, model transformation, code generation and domain specific behaviour simulation. Pattern matching is a search for model elements conforming to a given pattern that describes their arrangement and properties, e.g. finding a violation of a complex well-formedness constraint of a domain specific modeling language. &copy; 2011 Springer-Verlag.},
key = {Computer simulation},
keywords = {Embedded systems;Pattern matching;},
note = {Code Generation;Domain specific;Domain specific modeling languages;Eclipse modeling framework;Incremental evaluation;incremental pattern matching;Model driven development;Model elements;Model transformation;Model validation;},
URL = {http://dx.doi.org/10.1007/978-3-642-21470-7_32},
} 


@inproceedings{20090911922081 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a component-based model integration approach for embedded computer control system},
journal = {Proceedings - 2008 International Conference on Computational Intelligence and Security, CIS 2008},
author = {Li, Fang and Li, Di and Wan, Jiafu and Huang, Xin},
volume = {1},
year = {2008},
pages = {495 - 499},
address = {Suzhou, China},
abstract = {A component-based model integration approach for the embedded computer control system(ECS) development is proposed in this paper. The three-layer architecture for modeling, verification as well as implementation is described. Model strategies such as multi-aspect &amp; multi-view description method, DSML(Domain Specific Modeling Language) &amp; FML(Formal Modeling Language) description method as well as hierarchical component based modeling method are put forward. The focus of our approach is on creating an integrated embedded computer control system development environment for design, verification as well as implementation. &copy; 2008 IEEE.},
key = {Computer control systems},
keywords = {Artificial intelligence;Computational methods;Computer control;Control system analysis;Control systems;Hierarchical systems;Intelligent control;Linguistics;},
note = {Component-based models;Description methods;Embedded computer control systems;Hierarchical components;Multi views;Three-layer architectures;},
URL = {http://dx.doi.org/10.1109/CIS.2008.218},
} 


@inproceedings{20111213766697 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a DSML for semantic web enabled multi-agent systems},
journal = {ECOOP 2010 Workshop Proceedings - International Workshop on Formalization of Modeling Languages, FML'10},
author = {Kardas, Geylani and Demirezen, Zekai and Challenger, Moharram},
year = {2010},
pages = {Assoc Internationale por les Technologies Objects (AITO); ACM Special Interest Group on Software Engineering (SIGSOFT); University of Maribor; ACM Special Interest Group on Programming Languages (SIGPLAN); CEKTRA - },
address = {Maribor, Slovenia},
abstract = {Software agents are considered as autonomous software components which are capable of acting to meet its design objectives. To perform their tasks and interact with each other, agents constitute systems called Multi-agent systems (MAS). Although agent researchers have a great effort in MAS metamodeling and model-driven MAS development, a significant deficiency exists in current studies when we consider providing a complete Domain Specific Modeling Language (DSML) for MASs. We believe that a DSML increases the descriptive power of a MAS metamodel, defines the system semantics and hence supports a more fruitful methodology for the development of MASs especially working on the new challenging environments such as the Semantic Web. In this paper, we introduce a new DSML for MASs with its abstract syntax, the textual concrete syntax and the interpreter mechanism. The practical use of the DSML is illustrated with a case study which considers the modeling of a multi-agent based e-barter system. Copyright 2010 ACM.},
key = {Multi agent systems},
keywords = {Autonomous agents;Intelligent agents;Object oriented programming;Semantic Web;Semantics;Syntactics;},
note = {Abstract syntax;Autonomous software;Concrete syntax;Design objectives;Domain specific modeling languages;E-barter system;MAS development;Metamodel;Metamodeling;Model-driven;Model-driven engineering;Multi-Agent;Practical use;System semantics;},
URL = {http://dx.doi.org/10.1145/1943397.1943402},
} 


@inproceedings{20094012347990 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {ADELFE design, AMAS-ML in action: A case study},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Rougemaille, Sylvain and Arcangeli, Jean-Paul and Gleizes, Marie-Pierre and Migeon, Frederic},
volume = {5485 LNAI},
year = {2009},
pages = {105 - 120},
issn = {03029743},
address = {Saint-Etienne, France},
abstract = {The complexity of engineers tasks leads us to provide means to bring the Adaptive Multi-Agent Systems (AMAS) design to a higher stage of automation and confidence thanks to Model Driven Development (MDD). This paper focuses on a practical example and illustrates the modifications that have been done to the ADELFE methodology. In the Design phase, we propose to use a Domain Specific Modeling Language (DSML) for the specification of cooperative agents. We also, add a Model Diven Implementation phase using model transformation, DSMLs and code generation. These phases carry out a model centric process to produce and partially generate the system code. We present the use of our MD process applied to a simple, but very illustrative example: the foraging ants simulation. &copy; 2009 Springer Berlin Heidelberg.},
key = {Multi agent systems},
keywords = {Embedded systems;},
note = {Adaptive multiagent systems;ADELFE methodology;Code Generation;Cooperative agents;Design phase;Domain specific modeling languages;Illustrative examples;Model transformation;Model-driven development;System codes;},
URL = {http://dx.doi.org/10.1007/978-3-642-02562-4_6},
} 


@inproceedings{20090211846778 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {DQML: A modeling language for configuring distributed publish/subscribe quality of service policies},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Hoffert, Joe and Schmidt, Douglas and Gokhale, Aniruddha},
volume = {5331 LNCS},
number = {PART 1},
year = {2008},
pages = {515 - 534},
issn = {03029743},
address = {Monterrey, Mexico},
abstract = {Many publish/subscribe (pub/sub) middleware platforms provide flexibility in configuring policies that affect end-to-end quality of service (QoS). While the functionality and tunability of pub/sub middleware has increased, so has the complexity of creating semantically compatible QoS policy configurations. This paper makes two contributions to addressing these challenges. First, it describes how a domain-specific modeling language (DSML) can automate the analysis and synthesis of semantically compatible QoS policy configurations. Second, it empirically evaluates how this DSML increases productivity when generating valid QoS policy configurations. Our experimental results show a 54% reduction in development effort using DQML over manual methods. &copy; 2008 Springer Berlin Heidelberg.},
key = {Quality of service},
keywords = {Computer software;Direction of arrival;High level languages;Linguistics;Middleware;Quality control;Query languages;Radio direction finding systems;},
note = {Configuration Modeling Tools;Data Distribution Service;Domain-Specific Modeling Languages;Modeling Metrics;Pub/Sub Middleware;},
URL = {http://dx.doi.org/10.1007/978-3-540-88871-0_38},
} 


@inproceedings{20094712483756 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {ContractCML - A contract aware component modeling language},
journal = {Proceedings of the 2008 10th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, SYNASC 2008},
author = {Petrascu, Vladiela and Chiorean, Dan and Petrascu, Dragos},
year = {2008},
pages = {273 - 276},
address = {Timisoara, Romania},
abstract = {Providing software components with a four level contract specification - syntax, semantics, synchronization, quality of service - is important to their correct (re)use. The mandatory syntactic level is included by all current component models. Academic models also employ one of the others, but use different formalisms to represent it. Through this paper, we propose an integrated approach for handling component contracts. We focus on introducing ContractCML (Contract Component Modeling Language), a domain specific modeling language that ensures the basis of our proposal. &copy; 2008 IEEE.},
key = {Computation theory},
keywords = {Linguistics;Quality of service;Syntactics;},
note = {Component contracts;Component modeling;Contract specifications;Current component;Domain specific modeling languages;Integrated approach;Software component;},
URL = {http://dx.doi.org/10.1109/SYNASC.2008.35},
} 


@inproceedings{2004478469450 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain independent generative modeling},
journal = {Proceedings - 11th IEEE International Conference and Workshop on the Engineering of Computer-Based Systems, ECBS 2004},
author = {Kusy, Branislav and Ledeczi, Akos and Maroti, Miklos and Volgyesi, Peter},
year = {2004},
pages = {29 - 35},
address = {Brno, Czech republic},
abstract = {Model Integrated Computing employs domain-specific modeling languages for the design of Computer Based Systems and automatically generates their implementation. These system models are declarative in nature. However, for complex systems with regular structure, as well as for adaptive systems, a more algorithmic approach is better suited. Generative modeling employs architectural parameters and generator scripts to specify model structure. This paper describes an approach that enables the addition of generative modeling capabilities to any domain-specific modeling language using metamodel composition. The approach is illustrated through an image processing application using the Generic Modeling Environment (GME).},
key = {Computer systems},
keywords = {Adaptive systems;Computer hardware;Computer programming languages;Computer simulation;Computer software;Interfaces (computer);Systems analysis;},
note = {Computer based systems;Generic modeling environment (GME);Model integrated computing (MIC);Unified modeling language (UML);},
URL = {http://dx.doi.org/10.1109/ECBS.2004.1316679},
} 


@inproceedings{20083611524540 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings - 3rd International Conference on Grid and Pervasive Computing Symposia/Workshops, GPC 2008},
journal = {Proceedings - 3rd International Conference on Grid and Pervasive Computing Symposia/Workshops, GPC 2008},
editor = {},
year = {2008},
address = {Kunming, China},
abstract = {The proceedings contain 63 papers. The topics discussed include: rule-based automatic generation of mediator patterns for service composition mismatches; a fuzzy rule based load balancing model for a distributed service process engine; lambda calculus as a workflow model; a new resource discovery mechanism with negotiate solution based on agent in grid environments; a scientific-workflow- based execution environment for ensemble prediction; research on scheduling algorithm for workflow-based grid resource; job migration and fault tolerance in SLA-aware resource management systems; towards a domain-specific modeling language for customer data integration workflow; textual knowledge flow based intelligent browsing of topics; resource scheduling in desktop grid by grid-JQA; workflow technology for drug discovery; an automatic and scalable testing tool for workflow; and design of a petri net-based workflow engine systems.},
} 


@inproceedings{2005459462385 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Dynamically reconfigurable monitoring in large scale real-time embedded systems},
journal = {Conference Proceedings - IEEE SOUTHEASTCON},
author = {Ahuja, Shikha and Yao, Di and Neema, Sandeep and Bapty, Ted and Shetty, Shweta and Nordstrom, Steven G.},
year = {2005},
pages = {327 - 332},
issn = {07347502},
address = {Ft. Lauderdale, United kingdom},
abstract = {Many large scale real time distributed embedded systems are computation and communication intensive. Some examples of such systems are the data acquisition for high energy experiments performed in Fermi Lab (e.g. the BTeV experiment). This data system contains thousands of processors involved in performing real-time event filtering of particle collisions. A tremendous amount of message passing takes place continuously between these nodes. The physicists need to monitor such a large scale system to ensure its correct operation. Configurable user interfaces will enable the physicist to dynamically view data as well as error conditions in ways that aid analysis as well as enable them to configure and control the state of the system. This paper presents a language that enables the configuration of the user interfaces dynamically, supporting large-scale system monitoring and control. These configurable user interfaces are implemented using Model Integrated Computing [1], The domain specific Modeling language (DSML) and associated tools developed can be used to generate software for a variety of runtime platforms. Currently, the target environment for the user interfaces is Matlab. To transport data from many sources throughout the distributed system to many potential consumers, a publish-subscribe mechanism called Elvin is used in the system and is briefly described in the paper, along with its role in the system monitoring and control. The paper ends with a brief discussion emphasizing the use of this domain specific modeling language in the BTeV system. &copy; 2005 IEEE.},
key = {Embedded systems},
keywords = {Computer programming languages;Data acquisition;Distributed computer systems;Error analysis;Large scale systems;Real time systems;Throughput;User interfaces;},
note = {Distributed embedded systems;Model integrated computing;Real-time embedded system;System monitoring;},
} 


@inproceedings{20093712305491 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Advanced Information Systems Engineering - 21st International Conference, CAiSE 2009, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {5565 LNCS},
year = {2009},
pages = {University of Twente; Centre for Telematics and Information Technology; Netherlands Organisation for Scientific Research; Jacquard; Capgemini - },
issn = {03029743},
address = {Amsterdam, Netherlands},
abstract = {The proceedings contain 38 papers. The topics discussed include: TomTom for business process management (TomTom4BPM); computer-centric business operating models vs. network-centric ones; tutorial: how to value software in a business, and where might the value go?; towards the next generation of service-based systems: the S-Cube research framework; towards the industrialization of data migration: concepts and patterns for standard software implementation projects; defining and using schematic correspondences for automatically generating schema mappings; the problem of transitivity of part-whole relations in conceptual modeling revisited; using UML as a domain-specific modeling language: a proposal for automatic generation of UML profiles; verifying action semantics specifications in UML behavioral models; measuring and comparing effectiveness of data quality techniques; secure information systems engineering: experiences and lessons learned from two health care projects; and development framework for mobile social applications.},
} 


@inproceedings{20113514267938 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling of data adaptable reconfigurable embedded systems},
journal = {Proceedings - 18th IEEE International Conference and Workshops on Engineering of Computer-Based Systems, ECBS 2011},
author = {Gopinath, Vijay Shankar and Sprinkle, Jonathan and Lysecky, Roman},
year = {2011},
pages = {276 - 283},
address = {Las Vegas, NV, United states},
abstract = {Many applications require high flexibility, high configurability and high processing speeds. The physical constraints of a highly flexible system's hardware implementation preclude a hardware solution that satisfies all configuration options. Similarly for pure software implementations, even if configurability is satisfied, process efficiency will be sacrificed. Thus for applications of any significant size, there can be no single hardware or software configuration that can efficiently support all the configurability options of the applications. The Data-Adaptable Reconfigurable Embedded System (DARES) approach tackles this problem through combination of the hardware-software co-design and reconfigurable computing methodologies. Data-adaptability means that as data streams change, the system is reconfigured along the baselines defined within the system's specifications. In this project we use the concepts of Model-Integrated Computing to implement a domain-specific modeling language for the DARES approach. The language captures all the configurability options of the application task(s), performs design-space exploration, and provides a template for source code generation. &copy; 2011 IEEE.},
key = {Embedded systems},
keywords = {Computer hardware;Design;Embedded software;Hardware;Reconfigurable hardware;Space research;Technical presentations;},
note = {DARES;Data adaptability;GME;Model integrated computing;Model-based design;},
URL = {http://dx.doi.org/10.1109/ECBS.2011.31},
} 


@article{20081111147339 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A meta-model of computer numerical control system based on domain-specific modeling},
journal = {Shenzhen Daxue Xuebao (Ligong Ban)/Journal of Shenzhen University Science and Engineering},
author = {Xiao, Su-Hua and Li, Di and Ye, Feng and Shu, Zhao-Gang},
volume = {25},
number = {1},
year = {2008},
pages = {92 - 96},
issn = {10002618},
address = {Shenzhen University, Shenzhen, 518060, China},
abstract = {Computer numerical control (CNC) is a typical embedded real-time system. The traditional development method is the separate development of software and hardware to an application system. To solve problems that exist in current development process of embedded CNC system, this paper presents a development method for embedded CNC system based on Domain-Specific Modeling. The CNC domain meta-model is constructed on feature-based meta-modeling and multi-aspect method, covering both function and non-function, by logical separation and description of every part of the system and relations between them. A domain-specific modeling language is generated from the meta-model by the meta-model interpreter. A user model can be constructed according to CNCML, source code can be generated automatically by the model interpreter and an application system can be compiled. A lathe system is implemented. The result indicates the method can improve development efficiency of CNC system, thus it is a good development method for other embedded systems.},
key = {Numerical control systems},
keywords = {Embedded systems;Mathematical models;Real time systems;},
note = {Domain specific modeling;Lathe system;Meta model;},
} 


@inproceedings{20073410780715 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A QoS policy configuration modeling language for publish/subscribe middleware platforms},
journal = {ACM International Conference Proceeding Series},
author = {Hoffert, Joe and Schmidt, Douglas and Gokhale, Aniruddha},
volume = {233},
year = {2007},
pages = {140 - 145},
address = {Toronto, ON, Canada},
abstract = {Publish/subscribe (pub/sub) middleware platforms for event-based distributed systems often provide many configurable policies that affect end-to-end quality of service (QoS). Although the flexibility and functionality of pub/sub middleware platforms has matured, configuring their QoS policies in semantically compatible ways has become more complex. This paper makes two contributions to reducing the complexity of configuring QoS policies for event-based distributed systems. First, it evaluates various approaches for managing complex QoS policy configurations in pub/sub middleware platforms. Second, it describes a domain-specific modeling language (DSML) that automates the analysis and synthesis of semantically compatible QoS policy configurations. &copy; 2007 ACM.},
key = {Computer programming languages},
keywords = {Computer simulation;Distributed computer systems;Large scale systems;Middleware;Quality of service;},
note = {Data distribution services;Dom-ain-specific modeling languages;Event-based distributed systems;Pub/subMiddleware;},
URL = {http://dx.doi.org/10.1145/1266894.1266922},
} 


@inproceedings{20092912190821 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Agent-Oriented Software Engineering IX - 9th International Workshop, AOSE 2008 Revised Selected Papers},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {5386},
year = {2009},
issn = {03029743},
address = {Estoril, Portugal},
abstract = {The proceedings contain 20 papers. The topics discussed include: model-driven integration of organizational models; MAS modeling based on organizations; a systemic approach to the validation of self-organizing dynamics within MAS; using and extending the SPEM specifications to represent agent oriented methodologies; definition of process models for agent-based development; methodology fragments definition in SPEM for designing adaptive methodology: a first step; a MAS metamodel-driven approach to process fragments selection; an evaluation framework for MAS modeling languages based on metamodel metrics; a unified graphical notation for AOSE; Prometheus and INGENIAS Agent methodologies: a complementary approach; the formal semantics of the domain specific modeling language for multiagent systems; evaluating an agent-oriented approach for change propagation; and experimental evaluation of ontology-based test generation for multi-agent systems.},
} 


@article{2001516768852 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Composing domain-specific design environments},
journal = {Computer},
author = {Ledeczi, A. and Bakay, A. and Maroti, M. and Volgyesi, P. and Nordstrom, G. and Sprinkle, J. and Karsai, G.},
volume = {34},
number = {11},
year = {2001},
pages = {44 - 51+24},
issn = {00189162},
abstract = {Domain-specific integrated development environments can help capture specifications in the form of domain models. These tools support the design process by automating analysis and simulating essential system behavior. In addition, they can automatically generate, configure, and integrate target application components. The high cost of developing domain-specific, integrated modeling, analysis, and application-generation environments prevents their penetration into narrower engineering fields that have limited user bases. Model-integrated computing (MIC), an approach to model-based engineering that helps compose domain-specific design environments rapidly and cost effectively, is particularly relevant for specialized computer-based systems domains-perhaps even single projects. The authors describe how MIC provides a way to compose such environments cost effectively and rapidly by using a metalevel architecture to specify the domain-specific modeling language and integrity constraints. They also discuss the toolset that implements MIC and describe a practical application in which using the technology in a tool environment for the process industry led to significant reductions in development and maintenance costs.},
key = {Computer aided design},
keywords = {Automatic programming;Code converters;Computer aided software engineering;Computer graphics;Computer programming languages;Computer simulation;Computer software reusability;Database systems;Systems analysis;},
note = {Domain specific designs;},
URL = {http://dx.doi.org/10.1109/2.963443},
} 


@inproceedings{2006289990929 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling methodology for application development in petroleum industry},
journal = {Proceedings of the 2005 IEEE International Conference on Information Reuse and Integration, IRI - 2005},
author = {Zhang, Cong and Prasanna, Viktor and Orangi, Abdollah and Da Sie, Will and Kwatra, Aditya},
volume = {2005},
year = {2005},
pages = {445 - 451},
address = {Las Vegas, NV, United states},
abstract = {The development of applications for monitoring, control, simulation and diagnosis in the petroleum industry involves a multitude of complex software tools. These tools have their own formalisms, semantics and use different abstractions to represent the system under development. They use different data formats to represent data in the software tools. Each application requires coupling of two or more different such complex software tools. Providing efficient interaction between these complex software tools using different abstractions, formalisms, data formats, etc. becomes a mammoth task. Thus there is a need to provide a unified environment that allows capturing the desired application and provide a framework for interaction between the necessary software tools. This paper discusses the formal metamodels to describe the individual formalisms in the desired unified environment. These metamodels, created by the Generic Modeling Environment (GME), define the domain-specific modeling language for application development in the petroleum industry. &copy; 2005 IEEE.},
key = {Petroleum industry},
keywords = {Computational complexity;Computer science;Computer simulation;Computer software;Condition monitoring;Data acquisition;Data processing;Mathematical models;Semantics;},
note = {Complex software tools;Formalisms;Generic Modeling Environment (GME);Modeling methodology;},
URL = {http://dx.doi.org/10.1109/IRI-05.2005.1506514},
} 


@article{2003527794198 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling Methodology for Integrated Simulation of Embedded Systems},
journal = {ACM Transactions on Modeling and Computer Simulation},
author = {Ledeczi, Akos and Davis, James and Neema, Sandeep and Agrawal, Aditya},
volume = {13},
number = {1},
year = {2003},
pages = {82 - 103},
issn = {10493301},
abstract = {Developing a single embedded application involves a multitude of different development tools including several different simulators. Most tools use different abstractions, have their own formalisms to represent the system under development, utilize different input and output data formats, and have their own semantics. A unified environment that allows capturing the system in one place and one that drives all necessary simulators and analysis tools from this shared representation needs a common representation technology that must support several different abstractions and formalisms seamlessly. Describing the individual formalisms by metamodels and carefully composing them is the underlying technology behind MILAN, a Model-based Integrated Simulation Framework. MILAN is an extensible framework that supports multigranular simulation of embedded systems by seamlessly integrating existing simulators into a unified environment. Formal metamodels and explicit constraints define the domain-specific modeling language developed for MILAN that combines hierarchical, heterogeneous, parametric dataflow representation with strong data typing. Multiple modeling aspects separate orthogonal concepts. The language also allows the representation of the design space of the application, not just a point solution. Nonfunctional requirements are captured as formal, application-specific constraints. MILAN has integrated tool support for design-space exploration and pruning. The models are used to automatically configure the integrated functional simulators, high-level performance and power estimators, cycle-accurate performance simulators, and power-aware simulators. Simulation results are used to automatically update the system models. The article focuses on the modeling methodology and briefly describes how the integrated models are utilized in the framework.},
key = {Embedded systems},
keywords = {Abstracting;Computer simulation;Metadata;Semantics;},
note = {Domain specific languages;Integrated simulation;Metamodeling;},
URL = {http://dx.doi.org/10.1145/778553.778557},
} 


@inproceedings{20091512018452 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Efficient compilation techniques for large scale feature models},
journal = {GPCE'08: Proceedings of the ACM SIGPLAN 7th International Conference on Generative Programming and Component Engineering},
author = {Mendonca, Marcilio and Wasowski, Andrzej and Czarnecki, Krzysztof and Cowan, Donald},
year = {2008},
pages = {13 - 21},
address = {Nashville, TN, United states},
abstract = {Feature modeling is used in generative programming and software product-line engineering to capture the common and variable properties of programs within an application domain. The translation of feature models to propositional logics enabled the use of reasoning systems, such as BDD engines, for the analysis and transformation of such models and interactive configurations. Unfortunately, the size of a BDD structure is highly sensitive to the variable ordering used in its construction and an inappropriately chosen ordering may prevent the translation of a feature model into a BDD representation of a tractable size. Finding an optimal order is NP-hard and has for long been addressed by using heuristics. We review existing general heuristics and heuristics from the hardware circuits domain and experimentally show that they are not effective in reducing the size of BDDs produced from feature models. Based on that analysis we introduce two new heuristics for compiling feature models to BDDs. We demonstrate the effectiveness of these heuristics using publicly available and automatically generated models. Our results are directly applicable in construction of feature modeling tools.&copy; 2008 ACM.},
key = {Computer software selection and evaluation},
keywords = {Formal methods;Heuristic methods;Systems analysis;Verification;},
note = {Configuration;Feature modeling;Formal verification;Model-driven development;Software-product lines;},
URL = {http://dx.doi.org/10.1145/1449913.1449918},
} 


@article{20062810002310 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Weaving deployment aspects into domain-specific models},
journal = {International Journal of Software Engineering and Knowledge Engineering},
author = {Balasubramanian, Krishnakumar and Gokhale, Aniruddha and Lin, Yuehua and Zhang, Jing and Gray, Jeff},
volume = {16},
number = {3},
year = {2006},
pages = {403 - 424},
issn = {02181940},
abstract = {Domain-specific models increase the level of abstraction used to develop large-scale component-based systems. Model-driven development (MDD) approaches (e.g., Model-Integrated Computing and Model-Driven Architecture) emphasize the use of models at all stages of system development. Decomposing problems using MDD approaches may result in a separation of the artifacts in a way that impedes comprehension. For example, a single concern (such as deployment of a distributed system) may crosscut different orthogonal activities (such as component specification, interaction, packaging and planning). To keep track of all entities associated with a component, and to ensure that the constraints for the system as a whole are not violated, a purely model-driven approach imposes extra effort, thereby negating some of the benefits of MDD. This paper provides three contributions to the study of applying aspect-oriented techniques to address the crosscutting challenges of model-driven component-based distributed systems development. First, we identify the sources of crosscutting concerns that typically arise in model-driven development of component-based systems. Second, we describe how aspect-oriented model weaving helps modularize these crosscutting concerns using model transformations. Third, we describe how we have applied model weaving using a tool called the Constraint-Specification Aspect Weaver (C-SAW) in the context of the Platform-Independent Component Modeling Language (PICML), which is a domain-specific modeling language for developing component-based systems. A case study of a joint-emergency response system is presented to express the challenges in modeling a typical distributed system. Our experience shows that model weaving is an effective and scalable technique for dealing with crosscutting aspects of component-based systems development. &copy; World Scientific Publishing Company.},
key = {Large scale systems},
keywords = {Computation theory;Computer programming languages;Constraint theory;Distributed computer systems;Mathematical models;Problem solving;},
note = {Aspect modeling;Component based middleware;Deployment and configuration;Domain specific modeling;},
URL = {http://dx.doi.org/10.1142/S021819400600280X},
} 


@inproceedings{2006179837365 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {User Modeling 2005 - 10th International Conference, UM 2005, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {3538 LNAI},
year = {2005},
issn = {03029743},
address = {Edinburgh, Scotland, United kingdom},
abstract = {The proceedings contain 76 papers. The topics discussed includes: user modeling meets usability goals; generative programming driven by user models; data-driven refinement of a probabilistic model of user affect; using learning curve to mine student models; task-oriented web user modeling for recommendation; using similarity to infer meta-cognitive behaviors during analogical problem solving; decision theoretic dialogue planning for initiative problem; a comparison of HMMs and dynamic Bayesian networks for recognizing office activities; motion-based adaptive of information services for mobile users; evaluation of a system for personalized summarization of web contents; discovering stages in web navigation; and modelling user ability in computer games.},
key = {Cognitive systems},
keywords = {Adaptive systems;Computer networks;Computer programming;Decision theory;Information services;Mathematical models;Navigation;Problem solving;Students;Websites;},
note = {Computer games;Learning curves;Personalized summarizations;Probabilistic models;},
} 


@inproceedings{20103813238965 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Development of high-integrity software product lines using model transformation},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Hutchesson, Stuart and McDermid, John},
volume = {6351 LNCS},
year = {2010},
pages = {389 - 401},
issn = {03029743},
address = {Vienna, Austria},
abstract = {Academic and commercial approaches to software product line development have concentrated on the rapid instantiation of source code assets to minimise product time to market. Generative programming and model-based software engineering approaches have been suggested as effective ways of achieving this. However, for high-integrity software systems the instantiated product source code has to be accompanied by development process assets that demonstrate and support the product assurance arguments. This paper describes an approach to the model-based development of software product lines that is specifically designed to address the needs of high-integrity software systems. The approach consists of a reference architecture model and component-based development style, supported by model transformations to instantiate the project-specific components and associated development assets. &copy; 2010 Springer-Verlag Berlin Heidelberg.},
key = {Software design},
keywords = {Computer software;Concurrent engineering;Electric sparks;Models;Network architecture;Safety engineering;},
note = {Decision models;High Integrity;M2M;Reference architecture;Safety-critical;Software Product Line;SPARK;UML;},
URL = {http://dx.doi.org/10.1007/978-3-642-15651-9_29},
} 


@inproceedings{20064410202754 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GrCen: A fast SPO-based graph rewriting tool},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Gei, Rubino and Batz, Gernot Veit and Grund, Daniel and Hack, Sebastian and Szalkowski, Adam},
volume = {4178 LNCS},
year = {2006},
pages = {383 - 397},
issn = {03029743},
address = {Natal, Rio Grando do Norte, Brazil},
abstract = {Graph rewriting is a powerful technique that requires graph pattern matching, which is an NP-complete problem. We present GRGEN, a generative programming system for graph rewriting, which applies heuristic optimizations. According to Varro&acute;'s benchmark it is at least one order of magnitude faster than any other tool known to us. Our graph rewriting tool implements the well-founded single-pushout approach. We define the notion of search plans to represent different matching strategies and equip these search plans with a cost model, taking the present host graph into account. The task of selecting a good search plan is then viewed as an optimization problem. For the ease of use, GRGEN features an expressive specification language and generates program code with a convenient interface. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Pattern matching},
keywords = {Automatic programming;Computer graphics;Cost effectiveness;Heuristic methods;Optimization;Problem solving;},
note = {Graph rewriting;Matching strategies;Optimization problem;Program codes;},
} 


@inproceedings{20084911760654 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A methodology to design information retrieval systems (MDIRS)},
journal = {Euro American Conference on Telematics and Information Systems - Proceedings of the 2007 Euro American Conference on Telematics and Information Systems, EATIS 2007},
author = {Ferreira, Joao and Silva, Alberto and Delgado, Jose},
year = {2007},
address = {Faro, Portugal},
abstract = {MDIRS is methodology to define the actors and the steps to build efficiently information retrieval (IR) System. MDRIS main mission is to analyze, develop and evaluate mechanisms and tools to produce IR systems from a more abstract, high level, efficient and productive way than it is done currently. MDIRS project is influenced by MDA reference model, and is mainly based on three principles: namely, high-level models specification; generative programming techniques; and it is component-based architecture-centric. In this paper we detail the methodology generative programming techniques used to produce IR Systems and the work that will be handled in the near future.},
key = {Information retrieval},
keywords = {Architectural design;Information retrieval systems;Information services;Information systems;Management information systems;},
note = {Generative programmings;Ir systems;Level models;Reference models;},
URL = {http://dx.doi.org/10.1145/1352694.1352759},
} 


@inproceedings{20094712485691 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings - 2009 IEEE International Symposium on Industrial Embedded Systems, SIES 2009},
journal = {Proceedings - 2009 IEEE International Symposium on Industrial Embedded Systems, SIES 2009},
year = {2009},
pages = {IEEE Industrial Electronics Society, IES - },
address = {Lausanne, Switzerland},
abstract = {The proceedings contain 40 papers. The topics discussed include: modeling and architecture exploration of a medium voltage protection device; exploration of a digital audio processing platform using a compositional system level performance estimation framework; generative programming with support for formal verification; temporal data matching in component based real time systems; modular architecture for real-time contract-based framework; dependency-aware stochastic analysis of chained execution times; a modular fast simulation framework for stream-oriented MPSoC; SoC-level risk assessment using FMEA approach in system design with systemC; fault isolation with intermediate checks of end-to-end checksums in the time- triggered system-on-chip architecture; minimizing expected energy consumption for streaming applications with linear dependencies on chip multiprocessors; and an in-vehicle infotainment software architecture based on Google android.},
} 


@article{1997293661253 ,
language = {German},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {PC-based robot control system with generated system components},
title = {PC-basiertes Robotersteuerungssystem mit generierten Systemkomponenten},
journal = {ZWF Zeitschrift fuer Wirtschaftlichen Fabrikbetrieb},
author = {Duelen, Gerard and Fries, Thomas and Foitzik, Volker},
volume = {92},
number = {3},
year = {1997},
pages = {132 - 135},
issn = {09470085},
address = {Munich, Germany},
abstract = {Modern control architectures and new software development methods, such as generative programming, assist the development of efficient and still favourably priced control systems. The PC-based robot control system introduced in this article has a maintenance-friendly software architecture where generated software components are integrated.},
key = {Computer control systems},
keywords = {Computer architecture;Computer software;Personal computers;Robotics;Software engineering;},
note = {Personal computer based robot control system;Software components;},
} 


@inproceedings{2003507773192 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Multistage programming support in CLI},
journal = {IEE Proceedings: Software},
author = {Attardi, G. and Cisternino, A.},
volume = {150},
number = {5},
year = {2003},
pages = {275 - 281},
issn = {14625970},
abstract = {Execution environments such as CLR and JVM provide many features needed by multistage programming languages, though there is no explicit support for them. Besides, staged computations are widely used in areas such as Web programming and generative programming. In the paper the authors present a possible CLR extension (which can also be ported to JVM) to provide support for multi-stage languages. The extension is based on CodeBricks - a framework for run-time code generation which allows expressing homogenous transformations of intermediate language as a composition of methods. They discuss the code generation strategy adopted by the framework and how an extension to CLR may improve the performance of multi-stage applications, although CodeBricks can also be implemented using the standard CLR. An informal discussion of how to translate MetaML staging annotations into CodeBricks is provided with a simple example.},
key = {Computer programming},
keywords = {Computational methods;Java programming language;Problem solving;Program compilers;},
note = {Common language infrastructure (CLI);Multistage programming;},
URL = {http://dx.doi.org/10.1049/ip-sen:20030990},
} 


@inproceedings{20084711725316 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {IR-case tool},
journal = {Proceedings of the IASTED International Conference on Software Engineering, SE 2007},
author = {Ferreira, Joao and Silva, Alberto and Delgado, Jose},
year = {2007},
pages = {171 - 176},
address = {Innsbruck, Austria},
abstract = {We propose a new approach based on a methodology assisted by a IR-Case tool for the creation of IR (Information Retrieval) systems inspired on a set of best practices or principles: it is based on high-level models or specifications; it is component-based architecture centric; it is based on generative programming techniques. This approach follows in essence the MDA (Model Driven Architecture) philosophy with some specific characteristics. We propose a repository that keeps related information, such as models, applications, software architectures, generated artifacts and even information concerning the software process itself (e.g., generation steps, tests and integration milestones). Generically, this methodology receives system requirements (e.g., functional, non-functional and development requirements) as its main input, and produces a set of artifacts (e.g., source code, configuration scripts or data scripts) as its main output, that will be linked in the IRCase tool proposed, generating the IR-System. These aspects are implemented in a tool (IR-Case tool), providing a roadmap where designers can follow as well as model-to-model transformation templates in order to accelerate their system development tasks. This step facilitates the construction and consequently will contribute for the personalized IR-Systems and also a test platform for IR-Algorithms and IR-Process.},
key = {Software architecture},
keywords = {Architectural design;Computer programming languages;Information services;Philosophical aspects;Software engineering;Spontaneous emission;Unified Modeling Language;},
note = {AS models;Best practices;Case tool;CASE tools;Generative programmings;Information concerning;Level models;MDA;MDA(model driven architecture);Model transformations;New approaches;Retrieval information;Roadmap;Software processes;Source codes;Specific characteristics;System developments;System requirements;Test platforms;UML;},
} 


@article{2006279982830 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {In search of a program generator to implement generic transformations for high-performance computing},
journal = {Science of Computer Programming},
author = {Cohen, Albert and Donadio, Sebastien and Garzaran, Maria-Jesus and Herrmann, Christoph and Kiselyov, Oleg and Padua, David},
volume = {62},
number = {1},
year = {2006},
pages = {25 - 46},
issn = {01676423},
abstract = {The quality of compiler-optimized code for high-performance applications is far behind what optimization and domain experts can achieve by hand. Although it may seem surprising at first glance, the performance gap has been widening over time, due to the tremendous complexity increase in microprocessor and memory architectures, and to the rising level of abstraction of popular programming languages and styles. This paper explores in-between solutions, neither fully automatic nor fully manual ways to adapt a computationally intensive application to the target architecture. By mimicking complex sequences of transformations useful to optimize real codes, we show that generative programming is a practical means to implement architecture-aware optimizations for high-performance applications. This work explores the promises of generative programming languages and techniques for the high-performance computing expert. We show that complex, architecture-specific optimizations can be implemented in a type-safe, purely generative framework. Peak performance is achievable through the careful combination of a high-level, multi-stage evaluation language-MetaOCaml-with low-level code generation techniques. Nevertheless, our results also show that generative approaches for high-performance computing do not come without technical caveats and implementation barriers concerning productivity and reuse. We describe these difficulties and identify ways to hide or overcome them, from abstract syntaxes to heterogeneous generators of code generators, combining high-level and type-safe multi-stage programming with a back-end generator of imperative code. &copy; 2006 Elsevier B.V. All rights reserved.},
key = {Mathematical transformations},
keywords = {Abstracting;Automatic programming;Codes (symbols);Computation theory;Computational complexity;Computer architecture;Computer programming languages;Microprocessor chips;Optimization;Syntactics;},
note = {Adaptive libraries;Application-specific program generators;Loop transformations;Multi-stage programming;},
URL = {http://dx.doi.org/10.1016/j.scico.2005.10.013},
} 


@inproceedings{20080511074742 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Specialising simulator generators for high-performance Monte-Carlo methods},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Keller, Gabriele and Chaffey-Millar, Hugh and Chakravarty, Manuel M.T. and Stewart, Don and Barner-Kowollik, Christopher},
volume = {4902 LNCS},
year = {2007},
pages = {116 - 132},
issn = {03029743},
address = {San Francisco, CA, United states},
abstract = {We address the tension between software generality and performance in the domain of simulations based on Monte-Carlo methods. We simultaneously achieve generality and high performance by a novel development methodology and software architecture centred around the concept of a specialising simulator generator. Our approach combines and extends methods from functional programming, generative programming, partial evaluation, and runtime code generation. We also show how to generate parallelised simulators. We evaluated our approach by implementing a simulator for advanced forms of polymerisation kinetics. We achieved unprecedented performance, making Monte-Carlo methods practically useful in an area that was previously dominated by deterministic PDE solvers. This is of high practical relevance, as Monte-Carlo simulations can provide detailed microscopic information that cannot be obtained with deterministic solvers. &copy; Springer-Verlag Berlin Heidelberg 2008.},
key = {Software architecture},
keywords = {Codes (symbols);Functional programming;Monte Carlo methods;Partial differential equations;},
note = {Microscopic information;Simulator generators;},
} 


@inproceedings{20102813071715 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {SBGAMES2009 - 8th Brazilian Symposium on Games and Digital Entertainment},
journal = {SBGAMES2009 - 8th Brazilian Symposium on Games and Digital Entertainment},
year = {2009},
address = {Rio de Janeiro, Brazil},
abstract = {The proceedings contain 25 papers. The topics discussed include: prototyping games for training and education in second life: Time2Play and TREG; a novel algorithm to verify the solution of geometric puzzle games; a fine granularity load balancing technique for MMOG servers using a KD-tree to partition the space; GPU based fluid animation over elastic surface models; support vector machines for cinematography real-time camera control in storytelling environments; design and implementation of a flexible hand gesture command interface for games based on computer vision; a generative programming approach for game development; a serious game for exploring and training in participatory management of national parks for biodiversity conservation: design and experience; a neighborhood grid data structure for massive 3D crowd simulation on GPU; and GpuWars: design and implementation of a GPGPU game.},
} 


@article{20064910292514 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Three applications of aspect technology},
journal = {BT Technology Journal},
author = {Courbis, C. and Lesaint, D. and Mihailescu, P.},
volume = {24},
number = {3},
year = {2006},
pages = {170 - 174},
issn = {13583948},
abstract = {The emergence of converged services is driving communication service providers to cut back on software engineering costs, shorten time-to-market and build personalisable services. As illustrated by BT's 21CN architecture initiative, the industry is responding with the vision of next-generation service delivery platforms (SDPs). The move towards SDPs demands a principled approach to achieve reuse, modularity, and evolvability of software artefacts, ranging from business processes to application components. To this end, new proposals, such as generative programming, aspect-oriented programming, and model-driven engineering, are put forward to complement traditional object-oriented and component programming paradigms. Aspect-oriented programming - the focus of this paper - endorses the principle of separation of concerns. Originally devoted to the modularisation of crosscutting concerns (e.g. synchronisation, security, debugging, monitoring), it has grown from an aspect-oriented extension to Java (AspectJ) into a general approach for the development of adaptive software artefacts. The purpose of this paper is to introduce aspect technology and demonstrate its versatility across three different application domains. Specifically, we present an aspect-based extension to a process execution language (BPEL) for developing adaptable workflows, an AspectJ-based instrumentation of a field resource scheduling system, and a proposal to customise mobile services using aspects. While the technology is still maturing, we hope this paper will raise the level of awareness on the potential of aspects across BT. &copy; Springer Science+Business Media, Inc. 2006.},
key = {Telecommunication services},
keywords = {Java programming language;Marketing;Software engineering;Synchronization;},
note = {Aspect-oriented programming;Service delivery platforms (SDPs);},
URL = {http://dx.doi.org/10.1007/s10550-006-0089-7},
} 


@inproceedings{20110813675429 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Companion of the 18th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA'03},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
year = {2003},
pages = {Assoc. Comput. Mach., Spec. Interest Group; Program. Lang. (ACM SIGPLAN) - },
address = {Anaheim, CA, United states},
abstract = {The proceedings contain 101 papers. The topics discussed include: model driven development - the case for domain oriented programming; an end-to-end domain-driven software development framework; XAspects: an extensible system for domain-specific aspect languages; the power of symmetry: unifying inheritance and generative programming; domain driven web development with WebJinn; automated impact analysis of object-oriented software systems; a demonstration of JPie: an environment for live software construction in Java; reuse learning objects through LOM and XML; QuickUML: a tool to support iterative design and code development; GME: the generic modeling environment; generative model transformer; semantic software engineering tools; a policy based system to incorporate self-managing behaviors in applications; using events to debug Java programs backwards in time; and issues on building T++, a tool for web application development with C++.},
} 


@inproceedings{20094312394305 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the 2009 ICSE Workshop on Software Engineering for Computational Science and Engineering, SECSE 2009},
journal = {Proceedings of the 2009 ICSE Workshop on Software Engineering for Computational Science and Engineering, SECSE 2009},
year = {2009},
pages = {Association for Computing Machinery, ACM; IEEE; IEEE Computer Society; SIGSOFT - },
address = {Vancouver, BC, Canada},
abstract = {The proceedings contain 12 papers. The topics discussed include: how do scientists develop and use scientific software?; some challenges facing software engineers developing software for scientists; barely sufficient software engineering: 10 practices to improve your CSE software; a empirical characterization of scientific software development projects according to the Boehm and Turner model: A progress report; refactoring and the evolution of Fortran; integration strategies for Computational Science &amp; engineering software; rusability of FEA software: A program family approach; developing scientific applications using generative programming; testing for trustworthiness in scientific software; injecting software architectural constraints into legacy scientific applications; and comparing bioinformatics software development by computer scientists and biologists: an exploratory study.},
} 


@inproceedings{20084811738029 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generation of adapted, speech-based user interfaces for home and building automation systems},
journal = {IEEE International Workshop on Factory Communication Systems - Proceedings, WFCS},
author = {Ploennigs, Joern and Jokisch, Oliver and Ryssel, Uwe and Hirschfeld, Diane and Kabitzsch, Klaus},
year = {2008},
pages = {445 - 452},
address = {Dresden, Germany},
abstract = {Existing technologies in home and building automation offer extensive possibilities to improve the individual life. However, especially seniors have large problems with the usually technology-centered user interfaces and avoid the technology. Instead, they are used to speech, which leaves speech-recognition and -synthesis suitable technologies for barrier-free interfaces. However, speech-based user interfaces require a large effort for adaptation, from the design of the user and system interfaces, to the adequate installation of devices. This paper introduces an approach to reduce this effort by a generative programming approach of the user and system interface. &copy; 2008 IEEE.},
key = {User interfaces},
keywords = {Communication;Communication systems;Intelligent buildings;Speech;Speech recognition;Technical presentations;Technology;},
note = {Building automation systems;Building automations;Free interfaces;Generative programmings;System interfaces;},
URL = {http://dx.doi.org/10.1109/WFCS.2008.4638723},
} 


@inproceedings{20084811737531 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Integrated automated design approach for building automation systems},
journal = {IEEE Symposium on Emerging Technologies and Factory Automation, ETFA},
author = {Runde, Stefan and Dibowski, Henrik and Fay, Alexander and Kabitzsch, Klaus},
year = {2008},
pages = {1488 - 1495},
address = {Hamburg, Germany},
abstract = {The planning and design of building automation systems is a time consuming, error prone and nowadays more and more expensive task, consisting of a lot of repeated manual design steps done by specialized engineers. To reduce the engineering costs for such systems, the authors present a new automated top-down design approach within this paper. A knowledge-based system supports the planner at the requirement analysis by means of a guided dialog. Subsequently, the complete automation system is automatically designed in two steps. The abstract design proceeds a design based on platform- and manufacturer- independent function blocks via generative programming. The detailed design replaces the function blocks by platform- and manufacturerspecific profiles by means of evolutionary techniques. &copy; 2008 IEEE.},
key = {Automation},
keywords = {Design;Enterprise resource planning;Factory automation;Information retrieval systems;Intelligent buildings;Knowledge based systems;Planning;Probability density function;Semiconductor quantum dots;Systems analysis;},
note = {Automated designs;Automation systems;Building automation systems;Design approaches;Detailed designs;Engineering costs;Evolutionary techniques;Function blocks;Generative programmings;Independent functions;Manual designs;Planning and designs;Requirement analyses;Time consuming;Top downs;},
URL = {http://dx.doi.org/10.1109/ETFA.2008.4638592},
} 


@inproceedings{2003097374248 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the fourth ACM SIGPLAN conference on principles and practice of declarative programming (PPDP'02)},
journal = {Proceedings of the ACM SIGPLAN Conference on Principles and Practice of Declarative Programming (PPDP'02)},
year = {2002},
pages = {ACM/SIGPLAN - },
address = {Pittsburg, PA, United states},
abstract = {The proceedings contain 20 papers from the Fourth ACM SIGPLAN Conference on Principles and Practice of Declarative Programming (PPDP'02). The topics discussed include: program generation, termination, and binding-time analysis; modular termination of context-sensitive rewriting; secure calling contexts for stack inspection; precise pair-sharing analysis of logic programs and generative programming for embedded systems.},
key = {Software engineering},
keywords = {Algorithms;Bandwidth;Broadcasting;Computer architecture;Computer graphics;Computer simulation;Context sensitive languages;Data structures;Formal logic;Java programming language;Network protocols;Parallel processing systems;Program compilers;PROLOG (programming language);Security of data;Theorem proving;},
note = {Abstraction mechanism;Array operations;Computer communication;Context-sensitive rewriting;Distributed programming;EiRev;Linear logic;Logical relations;},
} 


@article{20074210876963 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Supporting reconfigurable object distribution for customized web applications},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Chang, Po-Hao and Agha, Gul},
year = {2007},
pages = {1286 - 1292},
address = {Seoul, Korea, Republic of},
abstract = {In current practice, Web applications are tightly coupled with the platforms that a particular service provider intends to support and the execution scenario envisioned at the design time. The resulting applications do not adapt well to all clients and runtime execution contexts. The goal of our research is to develop methods and software to support recon-figurable distributed applications which can be customized to specific requirements. We view a Web application as a composition of actors, i.e. distributed active objects, and apply techniques of generative programming to develop a virtual application framework which separates the logic of objects from aspects relevant to object distribution on different platforms. We describe ActorSpec, a specification system allowing programmers to express desired object distribution and assisting application generators to produce highly customized versions of an application. The resulting flexibility facilitates the development of customizable Web applications on an increasingly complex Web infrastructure. Copyright 2007 ACM.},
key = {Computer applications},
keywords = {Client server computer systems;Computer aided logic design;Computer programming;Computer software;Web services;},
note = {ActorSpec;Runtime execution contexts;Web applications;Web infrastructure;},
URL = {http://dx.doi.org/10.1145/1244002.1244280},
} 


@inproceedings{20090211846786 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {DeXteR - An extensible framework for declarative parameter passing in distributed object systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Gopal, Sriram and Tansey, Wesley and Kannan, Gokulnath C. and Tilevich, Eli},
volume = {5346 LNCS},
year = {2008},
pages = {144 - 163},
issn = {03029743},
address = {Leuven, Belgium},
abstract = {In modern distributed object systems, reference parameters are passed to a remote method based on their runtime type. We argue that such type-based parameter passing is limiting with respect to expressiveness, readability, and maintainability, and that parameter passing semantics should be decoupled from parameter types. We present declarative parameter passing, an approach that fully decouples parameter passing semantics from parameter types in distributed object systems. In addition, we describe DeXteR, an extensible framework for transforming a type-based remote parameter passing model to a declaration-based model transparently. Our framework leverages aspect-oriented and generative programming techniques to enable adding new remote parameter passing semantics, without requiring detailed understanding of the underlying middleware implementation. Our approach is applicable to both application and library code and incurs negligible performance overhead. We validate the expressive power of our framework by adding several non-trivial remote parameter passing semantics (i.e., copy-restore, lazy, streaming) to Java RMI. &copy; 2008 Springer Berlin Heidelberg.},
key = {Middleware},
keywords = {Codes (symbols);Computer programming;Computer software;Information theory;Maintainability;Metadata;Semantics;},
note = {Aspect oriented programming;Declarative programming;Distributed object systems;Expressive powers;Extensible frameworks;Extensible middleware;Generative programmings;Java rmi;Library codes;Middleware implementations;Parameter passing;Reference parameters;Runtime types;},
URL = {http://dx.doi.org/10.1007/978-3-540-89856-6_8},
} 


@inproceedings{2005058819960 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An executable model for a family of election algorithms},
journal = {Proceedings -  International Parallel and Distributed Processing Symposium, IPDPS 2004 (Abstracts and CD-ROM)},
author = {Shi, Wei and Corriveau, Jean-Pierre},
volume = {18},
year = {2004},
pages = {2525 - 2532},
address = {Santa Fe, NM, United states},
abstract = {In this paper, we present an executable model for a family of algorithms dealing with leader election in a ring topology. We follow the traditional approach of system family engineering [7]. That is, we develop a feature model that captures variability across these algorithms. We then proceed to produce a generator. This generator receives as inputs specific values for each of the variation points (i.e., features) we identify. And it produces the behavior corresponding to the specific configuration of features at hand. Contrary to existing generative programming literature, we do not resort to C++ meta-programming but instead develop an executable model using Rational Rose RT. More precisely, we have designed a single State Chart that can model all the algorithms of the family we studied. We focus here on how to obtain such a State Chart, rather than on the identification of the features we used, or on ROSE-RT semantics. We do believe however that our approach can be reused to provide a semantically unified and executable modelling approach for other families of algorithms.},
key = {Algorithms},
keywords = {Computer simulation;Large scale systems;Mathematical models;Metadata;Object oriented programming;Problem solving;Real time systems;Systems engineering;Topology;},
note = {Election algorithms;Executable model;Ring topology;Smart chart;},
} 


@inproceedings{2006079704139 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {ESEC/FSE'05 - Proceedings of the Joint 10th European Software Engineering Conference (ESEC) and 13th ACM SIGSOFT symposium on the Foundations of Software Engineering (FSE-13)},
journal = {ESEC/FSE'05 - Proceedings of the Joint 10th European Software Engineering Conference (ESEC) and 13th ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE-13)},
editor = {Gall, H.;},
year = {2005},
pages = {ACM SIGSOFT; Council of European Professional Informatics Societies, CEPIS - },
address = {Lisbon, Portugal},
abstract = {The proceedings contain 49 papers. The topics discussed include: automatic generation of suggestions for program investigation; permissive interfaces; a case study on value-based requirements tracing; arithmetic program paths; dynamically discovering architectures with DiscoTect; performance data collection using a hybrid approach; information hiding interfaces for aspect-oriented design; matching execution histories of program versions; joining dataflow with predicates; visual tool for generative programming; online testing with model programs; reuse and variability in large software applications; anchoring and adjustment in software estimation; and a refinement calculus for software components and architectures.},
key = {Software engineering},
keywords = {Computer programming;Data acquisition;Data flow analysis;Hybrid computers;Interfaces (computer);},
note = {Aspect-oriented design;Automatic generation;Dataflow;},
} 


@inproceedings{20084911759657 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a model-driven engineering approach for developing embedded hard real-time software},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Cruz, Fabiano and Barreto, Raimundo and Cordeiro, Lucas},
year = {2008},
pages = {308 - 314},
address = {Fortaleza, Ceara, Brazil},
abstract = {Model-Driven Engineering (MDE) has been advocated as an effective way to deal with today's software complexity. MDE can be seen as an integrative approach combining existing techniques Buch as Domain-Specific Modeling Languages (DSML) and Transformation Engines. ThiB paper presents the ezRealtime. an MDE-based tool that relies on the Time Petri Net (TPN) formalism and defines a DSML to provide an easy-to-use environment for specifying Embedded Hard Real-Time (EHRT) systems and for synthesizing timely and predictable scheduled C code. The ezRealtime adopts the universal XML-based transfer syntax for Petri nets, named as PNML. The main idea of this work is to propose a generative programming method and tool to boost code quality and improve developer productivity with automated software synthesis. The ezRealtime tool reads and automatically translates the specification to a time Petri net model through composition of building blocks with the purpose of providing a complete model of all tasks in the system. Therefore, this model is used to find a feasible schedule by applying a depth-first search algorithm. Finally, the scheduled code is generated by traversing the feasible schedule, and replacing transition's instances by the respective code segments. We also present the application of the proposed method in a case study. Copyright 2008 ACM.},
key = {Real time systems},
keywords = {DSL;Embedded systems;Engineering;Graph theory;Learning algorithms;Marine biology;Markup languages;Modems;Petri nets;Systems analysis;Telecommunication lines;},
note = {Building Blocks;C codes;Case studies;Code qualities;Code segments;Depth-first searches;Embedded hard real-time systems;Feasible schedules;Generative programmings;Modeling languages;Petri net models;Software complexities;Software synthesis;},
URL = {http://dx.doi.org/10.1145/1363686.1363765},
} 


@inproceedings{20073110738409 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A linguistic patterns approach for requirements specification},
journal = {Proceedings - 32nd Euromicro Conference on Software Engineering and Advanced Applications, SEAA},
author = {Videira, Carlos and Ferreira, David and Da Silva, Alberto Rodrigues},
year = {2006},
pages = {302 - 309},
address = {Cavtat/Dubrovnik, Croatia},
abstract = {Despite the efforts made to overcome the problems associated with the development of information systems, we must consider that it is still an immature activity, with negative consequences in time, budget and quality. One of the root causes for this situation is the fact that many projects do not follow a structured, standard and systematic approach, like the methodologies and best practices proposed by Software Engineering. In this paper, we present a requirements specification language, called ProjectlTRSL, based on the identification of the most frequently used linguistic patterns in requirements documents, written in natural language. To guarantee the consistency of the written requirements and the integration with generative programming tools, the requirements are analyzed by parsing tools, and immediately validated according with the syntactic and semantic rules of the language. &copy; 2006 IEEE.},
key = {Linguistics},
keywords = {Budget control;Information systems;Pattern recognition;Problem solving;Software engineering;Standards;},
note = {Linguistic patterns;Parsing tools;Programming tools;Written requirements;},
URL = {http://dx.doi.org/10.1109/EUROMICRO.2006.8},
} 


@inproceedings{20074210867686 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative gateway toolkit for heterogeneous C3I systems},
journal = {Proceedings - IEEE Military Communications Conference MILCOM},
author = {Hupf, Greg and Davis, Rodney},
year = {2007},
address = {Washington, D.C., United states},
abstract = {Command and Control Technologies Corporation (CCT) has developed a composable reference architecture and a comprehensive integrated software toolkit for developing interoperable platform-independent C3I gateway systems under Air Force sponsored research. Gateways provide interoperability among disparate systems by providing a transparent connectivity solution that eliminates the need to replace or modify the systems themselves. The new Generative Gateway Toolkit (GGTK) approach achieves this interoperability by leveraging common data-transport and data-exchange semantics, and abstracting hardware platform and device interface details from core gateway functionality. Software product line architecture methods are used to ensure large-scale reuse and provide the capability to specify at a high-level 'what to build'. Generative programming techniques extend this capability, using the high-level specifications to actually build functional component-based gateways. Central to the architecture is accommodation for variation and evolutionary extension of its communications and semantic processing services. The scope of this research is focused on addressing new and legacy system interoperability problems caused by stove piped architectures and a proliferation of interfaces. Primary focus is placed on the current use of gateways to solve DoD Tactical Data Link (TDL) interoperability problems. Traditional gateway development approaches have led to a proliferation of custom point-to-point solutions built from the ground-up on a project-by-project basis. The new GGTK approach exploits the common and variable features of the communications gateway domain, combining reusable software assets that were systematically developed and assembled for generation into fully-functional customized gateways. Instead of coding new gateways, developers 'compose' new gateways by selecting data link protocols, I/O devices and runtime environments so GGTK can produce the actual gateway.},
key = {Gateways (computer networks)},
keywords = {Computer software;Data transfer;Interoperability;Network architecture;},
note = {Generative Gateway Toolkit (GGTK);Reusable software;},
URL = {http://dx.doi.org/10.1109/MILCOM.2006.302165},
} 


@inproceedings{2005429416282 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An architecture for implementing application interoperation with heterogeneous systems},
journal = {Lecture Notes in Computer Science},
author = {Hatzisymeon, George and Houssos, Nikos and Andreadis, Dimitris and Samoladas, Vasilis},
volume = {3543},
year = {2005},
pages = {194 - 205},
issn = {03029743},
address = {Athens, Greece},
abstract = {We are concerned with the issues faced by software developers with a certain family of distributed applications; those that connect to and interoperate with a heterogeneous infrastructure, i.e., a large heterogeneous collection of external systems (databases, embedded devices, network equipment, internet servers etc.) using different communication protocols. This product family includes applications such as e-commerce systems, network management applications and Grid-based collaborations. For such applications, implementing the interoperation logic is both challenging and expensive. We discuss the major concerns that contribute to the problem, such as transaction support, security and management, as well as integration with workflow or component frameworks. We propose an architecture and related development methodology, based on generative programming, to reduce implementation complexity, allow for rapid application development, ease deployment and manageability. &copy; IFIP International Federation for Information Processing 2005.},
key = {Computer architecture},
keywords = {Computer supported cooperative work;Database systems;Electronic commerce;Integration;Internet;Interoperability;Network protocols;Problem solving;Security of data;Servers;},
note = {Ease deployment;Embedded devices;Heterogeneous systems;Network equipment;},
} 


@inproceedings{20072510656481 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven engineering for development-time QoS validation of Component-based software systems},
journal = {Proceedings of the International Symposium and Workshop on Engineering of Computer Based Systems},
author = {Hill, James H. and Tambe, Sumant and Gokhale, Aniruddha},
year = {2007},
pages = {307 - 316},
address = {Tucson, AZ, United states},
abstract = {Model-driven engineering (MDE) techniques are increasingly being used to address many of the development and operational lifecycle concerns of large-scale component-based systems. One such concern lacking significant research deals with the validation of quality-of-service (QoS) properties of component-based systems throughout their development lifecycle instead of waiting until system integration time, which is very late and can be detrimental to project schedules and costs. This paper describes our novel MDE-based solution to address this challenge. At the core of our solution approach are (1) a set of domain-specific modeling languages that allow us to mimic component "business logic," and (2) a generative programming framework that synthesizes empirical benchmarking code for system emulation and continuous QoS evaluation. &copy; 2007 IEEE.},
key = {Computer software},
keywords = {Benchmarking;Binary codes;Computer programming languages;Computer simulation;Large scale systems;Quality of service;},
note = {Benchmarking codes;Model driven engineering (MDE);Modeling languages;System integration;},
URL = {http://dx.doi.org/10.1109/ECBS.2007.53},
} 


@inproceedings{20071710565367 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Research journey towards industrial application of reuse technique},
journal = {Proceedings - International Conference on Software Engineering},
author = {Jarzabek, Stan and Pettersson, Ulf},
volume = {2006},
year = {2006},
pages = {608 - 611},
issn = {02705257},
address = {Shanghai, China},
abstract = {Component-based reuse in mission critical Command and Control system domain was a starting point for a long lasting research collaboration between National University of Singapore (NUS) and ST Electronics Pte. Ltd. (STEE). STEE industrial projects as well as NUS lab studies revealed limitations of conventional architecture-centric, component-based reuse in the area of generic design to unify similarity patterns (e.g., similar classes, components or architectural patterns) commonly found in software. Further research showed that meta-level extensions to conventional techniques could strengthen their generic design capabilities, considerably improving effectiveness of reuse solutions, and increasing productivity gains due to reuse. These experiences led to development of "mixed strategy" approach based on synergistic application of meta-level generative programming technique of XVCL, together with conventional programming techniques. In the paper, we describe university-industry collaboration that proved beneficial for both parties: STEE advanced reuse practice via application of XVCL in several software product line projects. Early inputs from STEE helped NUS team validate and refine XVCL reuse methods, and expand into new research directions. We describe a sequence of projects that led to successful application of XVCL in industrial projects. We describe experiences from those projects and their significance for both industrial practice and understanding principles of flexible software, i.e., software that can be easily changed and adapted to various reuse contexts.},
key = {Software design},
keywords = {Computer architecture;Computer software maintenance;Control system analysis;Industrial applications;Project management;},
note = {Flexible software;Generic design;Meta level extensions;Software product lines;},
} 


@inproceedings{2004298264208 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a context-driven development framework for Ambient intelligence},
journal = {Proceedings - International Conference on Distributed Computing Systems},
author = {Wagelaar, Dennis},
volume = {24},
year = {2004},
pages = {304 - 309},
address = {Hachioji, Japan},
abstract = {Portable and embedded devices form an increasingly large group of computers, often referred to as Ambient Intelligence (Ami). This new variety in computing platforms will cause a corresponding diversity in software/hardware platforms and other context factors. Component-based middleware platforms offer a uniform environment for software, but they do not take away specific context differences, such as hardware resources, user identity/role and logical/physical location. Specialised component versions and/or configurations have to be made for each computing context if that computing context is to be used to its full extent. This is because the fine differences between component versions cannot be separated into finer components with the current component models. Aspect-oriented programming and generative programming technologies can be used to provide the fine-grained modularity that is necessary. In addition, the diversity of component-based platforms themselves form an extra reason for different component versions. We propose using a context-driven framework for the development of Ami components, which is based upon a gradual refinement mechanism. This refinement mechanism can cope with the course-grained differences between component models as well as the fine-grained differences between computing configurations.},
key = {Software engineering},
keywords = {Computer programming;Context free languages;Interfaces (computer);Object oriented programming;Optimization;Personal digital assistants;},
note = {Ambient intelligence (AmI);Context-driven framework;Hardware platforms;},
} 


@inproceedings{20081411178722 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {RPython: A step towards reconciling dynamically and statically typed OO languages},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Ancona, Davide and Ancona, Massimo and Cuni, Antonio and Matsakis, Nicholas D.},
year = {2007},
pages = {53 - 64},
address = {Montreal, QC, Canada},
abstract = {Although the C-based interpreter of Python is reasonably fast, implementations on the CLI or the JVM platforms offers some advantages in terms of robustness and interoperability. Unfortunately, because the CLI and JVM are primarily designed to execute statically typed, object-oriented languages, most dynamic language implementations cannot use the native bytecodes for common operations like method calls and exception handling; as a result, they are not able to take full advantage of the power offered by the CLI and JVM. We describe a different approach that attempts to preserve the flexibility of Python, while still allowing for efficient execution. This is achieved by limiting the use of the more dynamic features of Python to an initial, bootstrapping phase. This phase is used to construct a final RPython (Restricted Python) program that is actually executed. RPython is a proper subset of Python, is statically typed, and does not allow dynamic modification of class or method definitions; however, it can still take advantage of Python features such as mixins and first-class methods and classes. This paper presents an overview of RPython, including its design and its translation to both CLI and JVM bytecode. We show how the bootstrapping phase can be used to implement advanced features, like extensible classes and generative programming. We also discuss what work remains before RPython is truly ready for general use, and compare the performance of RPython with that of other approaches. &copy; 2007 ACM.},
key = {Object oriented programming},
keywords = {Computer systems;Data handling;Interoperability;Robustness (control systems);},
note = {Bootstrapping;Bytecodes;Object-oriented languages;RPython;},
URL = {http://dx.doi.org/10.1145/1297081.1297091},
} 


@inproceedings{20103213128343 ,
language = {Russian},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Message system refactoring using DSL},
journal = {2009 5th Central and Eastern European Software Engineering Conference in Russia, CEE-SECR 2009},
author = {Sushkov, Nikita and Zykov, Sergey},
year = {2009},
pages = {153 - 158},
address = {Moscow, Russia},
abstract = {This article covers the message delivery system refactoring using Domain Driven Development (DDD) and Domain Specific Language (DSL) approach. First it explains the main concepts of Domain Driven Development and Domain Specific Language. After that it describes the steps of development process based on Domain Specific Language including domain model design and development of DSL notation by the example of message delivery system. In conclusion it overviews key benefits provided by DDD and DSL approach (compare with previous version of message delivery system). &copy;2009 IEEE.},
key = {Query languages},
keywords = {Computer software;Linguistics;},
note = {Development process;Domain model;Domain specific languages;Message delivery;Message systems;Refactorings;},
URL = {http://dx.doi.org/10.1109/CEE-SECR.2009.5501172},
} 


@inproceedings{20092912197614 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using ontologies in the domain analysis of domain-specific languages},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Tairas, Robert and Mernik, Marjan and Gray, Jeff},
volume = {5421},
year = {2009},
pages = {332 - 342},
issn = {03029743},
address = {Toulouse, France},
abstract = {The design stage of domain-specific language development, which includes domain analysis, has not received as much attention compared to the subsequent stage of language implementation. This paper investigates the use of ontology in domain analysis for the development of a domain-specific language. The standard process of ontology development is investigated as an aid to determine the pertinent information regarding the domain (e.g., the conceptualization of the domain and the common and variable elements of the domain) that should be modeled in a language for the domain. Our observations suggest that ontology assists in the initial phase of domain understanding and can be combined with further formal domain analysis methods during the development of a domain-specific language.},
key = {Ontology},
keywords = {Computer software;Graphical user interfaces;Linguistics;Models;Query languages;Standardization;},
note = {Design stage;Domain analysis;Domain-Specific languages;Ontology development;},
URL = {http://dx.doi.org/10.1007/978-3-642-01648-6_35},
} 


@inproceedings{2006109739235 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Rapidly prototyping implementation infrastructure of Domain Specific Languages: A semantics-based approach},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Wang, Qian and Gupta, Gopal},
volume = {2},
year = {2005},
pages = {1419 - 1426},
address = {Santa Fe, NM, United states},
abstract = {Domain Specific Languages (DSLs) are high level languages designed for solving problems in a particular domain, and have been suggested as means for developing reliable software systems. However, designing of a domain specific language is a difficult task. The design of a domain specific language will evolve as it is used more and more and experienced is gained by its designers. Being able to rapidly develop the implementation infrastructure (interpreter, compiler, debugger, profiler, etc.) of a domain specific language is thus of utmost importance so that as the language evolves, the implementation infrastructure can keep pace. In this paper we present a framework for automatically generating interpreters, compilers, debuggers, and profilers from semantic specification of a domain specific language. We illustrate our approach via the SCR language, a language used by the US defense department for developing control systems. Copyright 2005 ACM.},
key = {Software prototyping},
keywords = {Computer programming languages;Control systems;Machine design;Problem solving;Program compilers;Program debugging;Program interpreters;Semantics;},
note = {Domain Specific Languages (DSL);Horn Logical Semantics;SCR language;Semantic specifications;},
} 


@inproceedings{20112013988133 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Supporting modularization in textual DSL development},
journal = {Proceedings - International Conference of the Chilean Computer Science Society, SCCC},
author = {Irazabal, Jeronimo and Pons, Claudia},
year = {2011},
pages = {124 - 130},
issn = {15224902},
address = {Antofagasta, Chile},
abstract = {A domain-specific language DSL provides a notation tailored towards an application domain. The closer the language is to their target domain, the more useful the language is for developers. But this increment in the level of specificity raises the issue of duplication of concepts among different languages, and leads to the definition of a family of languages. Despite the advance in tool support for defining the abstract and concrete syntaxes of DSLs, developing a family of DSLs still requires a significant amount of duplicated effort. In this work we present an infrastructure for implementing families of textual DSLs. We introduce a technique based on XText that reduces the effort required to create editors and interpreters by enabling the modularization of the common features and the smooth specification of variability between the DSLs. &copy; 2010 IEEE.},
key = {Modular construction},
keywords = {Computer science;Problem oriented languages;},
note = {Application domains;Common features;Concrete syntax;Domain specific languages;Modularizations;Target domain;Tool support;},
URL = {http://dx.doi.org/10.1109/SCCC.2010.52},
} 


@inproceedings{20093912331274 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {HAAIS-DSL: DSL to develop home Automation and Ambient Intelligence systems},
journal = {Proceedings of the 2nd Workshop on Isolation and Integration in Embedded Systems, IIES'09},
author = {Clemente, Pedro J. and Conejero, Jose M. and Hernandez, Juan and Sanchez, Lara},
year = {2009},
pages = {13 - 18},
address = {Nuremberg, Germany},
abstract = {Domain Specific Language (DSL) is an emergent software engineering discipline that allows software architects to model systems based on the elements of a specific domain. Home Automation (HA) and Ambient Intelligence (AmI) are examples of specific domains and they are considered the key elements in the future of home development. However, software for these domains is usually hand coded based on embedded devices and specific implementation technologies and frameworks. In this paper we present a Model Driven Development (MDD) approach to develop software systems for HA and AmI. A Domain Specific Language has been designed to model the architecture of these kinds of systems. Then, taking as input the architecture models, a set of model transformations allows code and configuration generation for a specific device platform like KNX/EIB (European Installation Bus). Copyright 2009 ACM.},
key = {Embedded systems},
keywords = {Automation;Biological materials;DSL;Embedded software;Hydroxylation;Linguistics;Modems;Network components;Software engineering;Telecommunication lines;},
note = {Ambient Intelligence;Code generation;Embedded devices;Home Automation;Model Driven Development;},
URL = {http://dx.doi.org/10.1145/1519130.1519133},
} 


@inproceedings{20105013482204 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Introducing Kansas Lava},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Gill, Andy and Bull, Tristan and Kimmell, Garrin and Perrins, Erik and Komp, Ed and Werling, Brett},
volume = {6041 LNCS},
year = {2010},
pages = {18 - 35},
issn = {03029743},
address = {South Orange, NJ, United states},
abstract = {Kansas Lava is a domain specific language for hardware description. Though there have been a number of previous implementations of Lava, we have found the design space rich, with unexplored choices. We use a direct (Chalmers style) specification of circuits, and make significant use of Haskell overloading of standard classes, leading to concise circuit descriptions. Kansas Lava supports both simulation (inside GHCi), and execution via VHDL, by having a dual shallow and deep embedding inside our Signal type. We also have a lightweight sized-type mechanism, allowing for MATLAB style matrix based specifications to be directly expressed in Kansas Lava. &copy; 2010 Springer-Verlag.},
key = {Computer hardware description languages},
keywords = {Specifications;},
note = {Based specification;Circuit description;Design spaces;Domain specific languages;Hardware descriptions;Haskell overloading;matrix;},
URL = {http://dx.doi.org/10.1007/978-3-642-16478-1_2},
} 


@inproceedings{20101812898240 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Declarative scripting in Haskell},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Bauer, Tim and Erwig, Martin},
volume = {5969 LNCS},
year = {2010},
pages = {294 - 313},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {We present a domain-specific language embedded within the Haskell programming language to build scripts in a declarative and type-safe manner. We can categorize script components into various orthogonal dimensions, or concerns, such as IO interaction, configuration, or error handling. In particular, we provide special support for two dimensions that are often neglected in scripting languages, namely creating deadlines for computations and tagging and tracing of computations. Arbitrary computations may be annotated with a textual tag explaining its purpose. Upon failure a detailed context for that error is automatically produced. The deadline combinator allows one to set a timeout on an operation. If it fails to complete within that amount of time, the computation is aborted. Moreover, this combinator works with the tag combinator so as to produce a contextual trace. &copy; 2010 Springer-Verlag.},
key = {Query languages},
keywords = {Computer aided software engineering;Computer software;Linguistics;Problem oriented languages;},
note = {Domain specific languages;Error handling;Haskell;Haskell programming language;Scripting languages;Two-dimension;},
URL = {http://dx.doi.org/10.1007/978-3-642-12107-4_21},
} 


@article{20100712718844 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Interpretable program specification language},
journal = {Programming and Computer Software},
author = {Novikov, F.A. and Novoseltsev, V.B.},
volume = {36},
number = {1},
year = {2010},
pages = {48 - 57},
issn = {03617688},
address = {Profsoyuznaya Ul. 90, Moscow, 117997, Russia},
abstract = {In the paper, a domain-specific language of executable specifications is proposed. This language makes it possible to describe models of formalized subject domains in a graphical form, formulate computational problems on these models, and synthesize programs for solving these problems (including parallel ones) based on deductive inference in a special class of proposition calculus. &copy; 2010 Pleiades Publishing, Ltd.},
key = {Linguistics},
keywords = {Problem oriented languages;Specification languages;Specifications;},
note = {Computational problem;Domain specific languages;Executable specifications;Graphical forms;Program specification;Special class;},
URL = {http://dx.doi.org/10.1134/S036176881001007X},
} 


@inproceedings{20105013482206 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {ChalkBoard: Mapping functions to polygons},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Matlage, Kevin and Gill, Andy},
volume = {6041 LNCS},
year = {2010},
pages = {55 - 71},
issn = {03029743},
address = {South Orange, NJ, United states},
abstract = {ChalkBoard is a domain specific language for describing images. The ChalkBoard language is uncompromisingly functional and encourages the use of modern functional idioms. ChalkBoard uses off-the-shelf graphics cards to speed up rendering of functional descriptions. In this paper, we describe the design of the core ChalkBoard language, and the architecture of our static image generation accelerator. &copy; 2010 Springer-Verlag.},
key = {Computer graphics},
note = {Domain specific languages;Graphics card;Mapping functions;Speed-ups;Static images;},
URL = {http://dx.doi.org/10.1007/978-3-642-16478-1_4},
} 


@inproceedings{20102813072486 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Linguistic symbiosis between actors and threads},
journal = {ACM International Conference Proceeding Series},
author = {Van Cutsem, Tom and Mostinckx, Stijn and De Meuter, Wolfgang},
volume = {286},
year = {2007},
pages = {222 - 248},
address = {Lugano, Switzerland},
abstract = {We describe a linguistic symbiosis between AmbientTalk, a flexible, domain-specific language for writing distributed programs and Java, a conventional object-oriented language. This symbiosis allows concerns related to distribution (service discovery, asynchronous communication, failure handling) to be handled in the domain-specific language, while still enabling the reuse of existing software components written in a conventional language. The symbiosis is novel in the sense that a mapping is defined between the concurrency models of both languages. AmbientTalk employs an inherently event-driven model based on actors, while conventional object-oriented languages employ a concurrency model based on threads. The contribution of this paper is a linguistic symbiosis which ensures that the invariants of the event-driven concurrency model are not violated by engaging in symbiosis with multi-threaded programs.},
key = {Linguistics},
keywords = {Computer software reusability;Java programming language;Object oriented programming;Problem oriented languages;Query languages;},
note = {Asynchronous communication;Distributed program;Domain specific languages;Event driven;Failure handling;Linguistic symbiosis;Model-based;Multi-threaded programs;Object-oriented languages;Service discovery;Software component;},
URL = {http://dx.doi.org/10.1145/1352678.1352693},
} 


@article{20093312246626 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Bilingual cluster based models for statistical machine translation},
journal = {IEICE Transactions on Information and Systems},
author = {Yamamoto, Hirofumi and Sumita, Eiichiro},
volume = {E91-D},
number = {3},
year = {2008},
pages = {588 - 597},
issn = {09168532},
address = {P.O. Box 247, Nihonbashi, Tokyo, 103-8691, Japan},
abstract = {We propose a domain specific model for statistical machine translation. It is well-known that domain specific language models perform well in automatic speech recognition. We show that domain specific language and translation models also benefit statistical machine translation. However, there are two problems with using domain specific models. The first is the data sparseness problem. We employ an adaptation technique to overcome this problem. The second issue is domain prediction. In order to perform adaptation, the domain must be provided, however in many cases, the domain is not known or changes dynamically. For these cases, not only the translation target sentence but also the domain must be predicted. This paper focuses on the domain prediction problem for statistical machine translation. In the proposed method, a bilingual training corpus, is automatically clustered into sub-corpora. Each sub-corpus is deemed to be a domain. The domain of a source sentence is predicted by using its similarity to the sub-corpora. The predicted domain (sub-corpus) specific language and translation models are then used for the translation decoding. This approach gave an improvement of 2.7 in BLEU score on the IWSLT05 Japanese to English evaluation corpus (improving the score from 52.4 to 55.1). This is a substantial gain and indicates the validity of the proposed bilingual cluster based models. Copyright &copy; 2008 The Institute of Electronics, Information and Communication Engineers.},
key = {Translation (languages)},
keywords = {Computational linguistics;Computer aided language translation;Information theory;Software agents;Speech recognition;Speech transmission;Statistics;},
note = {Adaptation techniques;Automatic speech recognition;Cluster-based;Data sparseness problem;Domain estimation;Domain specific;Domain specific languages;Domain specific model;Prediction problem;Sentence clustering;Specific languages;Statistical machine translation;Training corpus;Translation models;},
URL = {http://dx.doi.org/10.1093/ietisy/e91-d.3.588},
} 


@article{IP51516200 ,
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A Model-Driven Domain-Specific Scripting Language for Measurement-System Frameworks},
journal = {IEEE Transactions on Instrumentation and Measurement},
author = {Arpaia, Pasquale and Fiscarelli, Lucio and La Commara, Giuseppe and Petrone, Carlo},
year = {2011},
issn = {00189456},
abstract = {A measurement-domain-specific language, which is based on a model-driven paradigm for measurement-test-procedure definition, instrument configurations, and task synchronization, is proposed. This formal language, which is particular for a specific measurement field, aims at specifying complete, easy-to-understand, easy-to-reuse, and easy-to-maintain applications efficiently and quickly by means of a script. The script is checked and integrated into the existing software framework automatically by a specific parser-builder chain, in order to produce the measurement application. Constructs for abstracting key concepts of the domain allow the test engineer to write more concise and higher level programs by natural language-like sentences in a shorter time without being a skilled programmer. As an experimental case study, the proposed language has been applied to the flexible framework for magnetic measurements at the European Organization for Nuclear Research (CERN).},
key = {Magnetic domains},
keywords = {Formal languages;Natural language processing systems;Nuclear engineering;Problem oriented languages;},
note = {Domain specific;European organization for nuclear researches;Flexible framework;Measurement field;Model-driven;Scripting languages;Software frameworks;Task synchronization;Test engineers;},
URL = {http://dx.doi.org/10.1109/TIM.2011.2149310},
} 


@inproceedings{20113714324487 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Guaranteeing strong (X)HTML compliance for dynamic Web applications},
journal = {WEBIST 2011 - Proceedings of the 7th International Conference on Web Information Systems and Technologies},
author = {Talaga, Paul G. and Chapin, Steve J.},
year = {2011},
pages = {71 - 79},
address = {Noordwijkerhout, Netherlands},
abstract = {We report on the embedding of a domain specific language, (X)HTML, into Haskell and demonstrate how this superficial context-free language can be represented and rendered to guarantee World Wide Web Consortium (W3C) compliance. Compliance of web content is important for the health of the Internet, accessibility, visibility, and reliable search. While tools exist to verify web content is compliant according to the W3C, few systems guarantee that all dynamically produced content is compliant. We present CH-(X)HTML, a library for generating compliant (X)HTML content for all dynamic content by using Haskell to encode the non-trivial syntax of (X)HTML set forth by the W3C. Any compliant document can be represented with this library, while a compilation or run-time error will occur if non-compliant markup is attempted. To demonstrate our library we present examples and performance measurements.},
key = {User interfaces},
keywords = {Context free languages;HTML;Information systems;Websites;},
note = {Domain specific languages;Dynamic content;Dynamic web applications;Haskell;Non-trivial;Performance measurements;Run-time errors;W3C compliance;Web content;Web development;World wide web consortiums;},
} 


@inproceedings{20093512277599 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generic libraries in c++ with concepts from high-level domain descriptions in haskell a domain-specific library for computational vulnerability assessment},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Lincke, Daniel and Jansson, Patrik and Zalewski, Marcin and Ionescu, Cezar},
volume = {5658 LNCS},
year = {2009},
pages = {236 - 261},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {A class of closely related problems, a problem domain, can often be described by a domain-specific language, which consists of algorithms and combinators useful for solving that particular class of problems. Such a language can be of two kinds: it can form a new language or it can be embedded as a sublanguage in an existing one. We describe an embedded DSL in the form of a library which extends a general purpose language. Our domain is that of vulnerability assessment in the context of climate change, formally described at the Potsdam Institute for Climate Impact Research. The domain is described using Haskell, yielding a domain specific sublanguage of Haskell that can be used for prototyping of implementations. In this paper we present a generic C++ library that implements a domain-specific language for vulnerability assessment, based on the formal Haskell description. The library rests upon and implements only a few notions, most importantly, that of a monadic system, a crucial part in the vulnerability assessment formalisation. We describe the Haskell description of monadic systems and we show our mapping of the description to generic C++ components. Our library heavily relies on concepts, a C++ feature supporting generic programming: a conceptual framework forms the domain-specific type system of our library. By using functions, parametrised types and concepts from our conceptual framework, we represent the combinators and algorithms of the domain. Furthermore, we discuss what makes our library a domain specific language and how our domain-specific library scheme can be used for other domains (concerning language design, software design, and implementation techniques). &copy; IFIP International Federation for Information Processing 2009.},
key = {Query languages},
keywords = {Climate change;Computer programming;DSL;Graphical user interfaces;Java programming language;Linguistics;Modems;Software design;Telecommunication lines;XML;},
note = {C++ libraries;Climate impacts;Combinators;Conceptual frameworks;Domain specific;Domain specific languages;Formalisation;General purpose languages;Generic libraries;Generic programming;Haskell;High-level domain;Implementation techniques;Language design;Potsdam;Problem domain;Prototyping;Type systems;Vulnerability assessments;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_12},
} 


@inproceedings{20105113505552 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GPGPU kernel implementation and refinement using Obsidian},
journal = {Procedia Computer Science},
author = {Svensson, Joel and Claessen, Koen and Sheeran, Mary},
volume = {1},
number = {1},
year = {2010},
pages = {2065 - 2074},
issn = {18770509},
address = {Amsterdam, Netherlands},
abstract = {Obsidian is a domain specific language for data-parallel programming on graphics processors (GPUs). It is embedded in the functional programming language Haskell. The user writes code using constructs familiar from Haskell (like map and reduce), recursion and some specially designed combinators for combining GPU programs. NVIDIA CUDA code is generated from these high level descriptions, and passed to the nvcc compiler [1]. Currently, we consider only the generation of single kernels, and not their coordination. This paper is focussed on how the user should work with Obsidian, starting with an obviously correct (or welltested) description of the required function, and refining it by the introduction of constructs to give finer control of the computation on the GPU. For some combinators, this approach results in CUDA code with satisfactory performance, promising increased productivity, as the high level descriptions are short and uncluttered. But for other combinators, the performance of generated code is not yet satisfactory. Ways to tackle this problem and plans to integrate Obsidian with another higher-level embedded language for GPU programming in Haskell are briefly discussed.},
key = {Parallel programming},
keywords = {Functional programming;Program processors;Refining;},
note = {Combinators;Data parallel;Data-parallel programming;Domain specific languages;Embedded Languages;Functional programming languages;GPU programming;GPU programs;GPUs;Graphics processor;Haskell;High level description;Increased productivity;Recursions;Single kernel;},
URL = {http://dx.doi.org/10.1016/j.procs.2010.04.231},
} 


@inproceedings{20073110742062 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A graphical programming system for molecular motif search},
journal = {Proceedings of the 5th International Conference on Generative Programming and Component Engineering, GPCE'06},
author = {Reeder, Janina and Giegerich, Robert},
year = {2006},
pages = {131 - 140},
address = {Portland, OR, United states},
abstract = {We describe a graphical programming system for a domain specific language in biosequence analysis. It supports the development of programs for RNA structure prediction and motif search, created by biologists with little or no programming skills. The system combines several programming paradigms in a productive way. It has a client - server architecture, with a transport layer in XML. The graphical front-end is implemented in the object-oriented paradigm (using Java). Graphics are compiled into a declarative domain-specific language for dynamic programming (ADP) that is embedded in Haskell. Finally, motif search programs expressed in ADP are compiled to imperative code in C, a step which includes substantial domain-specific optimization. Copyright &copy; 2006 ACM.},
key = {Graphical user interfaces},
keywords = {Computer architecture;Dynamic programming;Molecular structure;RNA;Servers;XML;},
note = {Biosequence analysis.;Graphical programming systems;RNA structure;Server architecture;},
URL = {http://dx.doi.org/10.1145/1173706.1173727},
} 


@inproceedings{20101912921409 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Deriving a relationship from a single example},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Mitchell, Neil},
volume = {5812 LNCS},
year = {2010},
pages = {1 - 24},
issn = {03029743},
address = {Edinburgh, United kingdom},
abstract = {Given an appropriate domain specific language (DSL), it is possible to describe the relationship between Haskell data types and many generic functions, typically type-class instances. While describing the relationship is possible, it is not always an easy task. There is an alternative - simply give one example output for a carefully chosen input, and have the relationship derived. When deriving a relationship from only one example, it is important that the derived relationship is the intended one. We identify general restrictions on the DSL, and on the provided example, to ensure a level of predictability. We then apply these restrictions in practice, to derive the relationship between Haskell data types and generic functions. We have used our scheme in the Derive tool, where over 60% of type classes are derived from a single example. &copy; 2010 Springer-Verlag.},
key = {Modems},
keywords = {Telecommunication lines;},
note = {Data type;Domain specific languages;Generic functions;Haskell;Level of predictabilities;Type class;},
URL = {http://dx.doi.org/10.1007/978-3-642-11931-6-1},
} 


@inproceedings{20112214019090 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An access control language based on term rewriting and description logic},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Baggi, Michele and Ballis, Demis and Falaschi, Moreno},
volume = {6559 LNCS},
year = {2011},
pages = {66 - 83},
issn = {03029743},
address = {Madrid, Spain},
abstract = {This paper presents a rule-based, domain specific language for modeling access control policies which is particularly suitable for managing security in the semantic web, since (i) it allows one to evaluate authorization requests according to semantic information retrieved from remote knowledge bases; (ii) it supports semantic-based policy composition, delegation and closure via flexible operators which can be defined by security administrators in a pure declarative way with little effort. The operational engine of the language smoothly integrates description logic into standard term rewriting giving support to reasoning capabilities which are particularly useful in this context, since they allow one to naturally combine and reuse data extracted from multiple knowledge bases. Such a rewrite engine can be used to evaluate authorization requests w.r.t. a policy specification as well as to formally check properties regarding the security domain to be protected. The language we propose has been implemented in a prototypical system, which is written in Haskell. Some case studies have been analyzed to highlight the potentiality of our approach. &copy; 2011 Springer-Verlag.},
key = {Access control},
keywords = {Automata theory;Computer programming languages;Data description;Formal languages;Functional programming;Logic programming;Multi agent systems;Security systems;Semantic Web;Semantics;User interfaces;},
note = {Access control language;Access control policies;Description logic;Domain specific languages;Haskell;Knowledge basis;Policy specification;Reasoning capabilities;Rewrite engines;Rule based;Security administrator;Security domains;Semantic information;Term rewriting;},
URL = {http://dx.doi.org/10.1007/978-3-642-20775-4_4},
} 


@inproceedings{20081011128617 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Composable language extensions for computational geometry: A case study},
journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
author = {Van Wyk, Eric and Johnson, Eric},
year = {2007},
issn = {15301605},
address = {Big Island, HI, United states},
abstract = {This paper demonstrates how two different sets of powerful domain specific language features can be specified and deployed as composable language extensions. These extensions in-corporate analyses and transformations that simplify the process of writing efficient and robust computational geometry programs and can be automatically added to a host language and used simultaneously. This is not possible in domain-specific language and library-based implementations of these features. One extension relies on characteristics of geometric algorithms to implement efficient exact-precision integers; the other employs a technique that symbolically perturbs geometric coordinates to safely and automatically handle degeneracies in the input data. These language extensions are implemented in an extensible language framework based on higher-order attribute grammars and forwarding. Attribute evaluation on the new language extension constructs is used to implement the static analysis and code transformations that enable the generation of efficient code. &copy; 2007 IEEE.},
key = {Computational geometry},
keywords = {Automation;Computer programming languages;Integer programming;Perturbation techniques;Robust control;Static analysis;},
note = {Code transformations;Composable language extensions;Degeneracies;Input data;},
URL = {http://dx.doi.org/10.1109/HICSS.2007.139},
} 


@inproceedings{20093512277604 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Embedded probabilistic programming},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Kiselyov, Oleg and Shan, Chung-Chieh},
volume = {5658 LNCS},
year = {2009},
pages = {360 - 384},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {Two general techniques for implementing a domain-specific language (DSL) with less overhead are the finally-tagless embedding of object programs and the direct-style representation of side effects. We use these techniques to build a DSL for probabilistic programming, for expressing countable probabilistic models and performing exact inference and importance sampling on them. Our language is embedded as an ordinary OCaml library and represents probability distributions as ordinary OCaml programs. We use delimited continuations to reify probabilistic programs as lazy search trees, which inference algorithms may traverse without imposing any interpretive overhead on deterministic parts of a model. We thus take advantage of the existing OCaml implementation to achieve competitive performance and ease of use. Inference algorithms can easily be embedded in probabilistic programs themselves. &copy; IFIP International Federation for Information Processing 2009.},
key = {Probability distributions},
keywords = {DSL;Graphical user interfaces;Inference engines;Linguistics;Modems;Query languages;Telecommunication lines;},
note = {Domain specific languages;Ease of use;Exact inference;Importance sampling;Inference algorithm;Object program;Probabilistic models;Probabilistic programming;Probabilistic programs;Search trees;Side effect;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_17},
} 


@inproceedings{20112214019089 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Mixed-level embedding and JIT compilation for an iteratively staged DSL},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Giorgidze, George and Nilsson, Henrik},
volume = {6559 LNCS},
year = {2011},
pages = {48 - 65},
issn = {03029743},
address = {Madrid, Spain},
abstract = {This paper explores how to implement an iteratively staged domain-specific language (DSL) by embedding into a functional language. The domain is modelling and simulation of physical systems where models are expressed in terms of non-causal differential-algebraic equations; i.e., sets of constraints solved through numerical simulation. What distinguishes our language is that the equational constraints are first class entities allowing for an evolving model structure characterised by repeated generation of updated constraints. Hence iteratively staged. Our DSL can thus be seen as a combined functional and constraint programming language, albeit a two-level one, with the functional language chiefly serving as a meta language. However, the two levels do interact throughout the simulation. The embedding strategy we pursue is a mixture of deep and shallow, with the deep embedding enabling just-in-time (JIT) compilation of the constraints as they are generated for efficiency, while the shallow embedding is used for the remainder for maximum leverage of the host language. The paper is organised around a specific DSL, but our implementation strategy should be applicable for iteratively staged languages in general. Our DSL itself is further a novel variation of a declarative constraint programming language. &copy; 2011 Springer-Verlag.},
key = {Functional programming},
keywords = {Computer programming languages;Computer simulation;Constraint theory;Iterative methods;Just in time production;Logic programming;Model structures;Models;Problem oriented languages;},
note = {Constraint programming languages;Differential algebraic equations;Domain specific languages;Functional languages;Implementation strategies;Just-in-time compilation;Meta language;Modelling and simulations;Numerical simulation;Physical systems;Shallow embedding;},
URL = {http://dx.doi.org/10.1007/978-3-642-20775-4_3},
} 


@inproceedings{20094612441885 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {High assurance programming in cryptol},
journal = {ACM International Conference Proceeding Series},
author = {Erkok, Levent and Matthews, John},
year = {2009},
address = {Oak Ridge, TN, United states},
abstract = {Cryptol is a domain specific language tailored for cryptographic algorithms (www.cryptol.net). Explicit support for program verification is an indispensable part of the Cryptol toolset, due to the inherent high-assurance requirements of the application domain. To this end, Cryptol comes with a suite of formal-methods based tools, allowing users to perform various program verification tasks. In this extended abstract, we provide an overview of the Cryptol language and its verification environment. The challenges in this domain are multifaceted: from the engineering concerns of providing an easy-to-use system for non-experts, to open research problems in program verification. Copyright &copy; 2009 ACM.},
key = {Research},
keywords = {Cryptography;Formal logic;Linguistics;},
note = {Application domains;Assurance requirements;Cryptographic algorithms;Domain specific languages;Extended abstracts;High assurance;Program Verification;Research problems;Toolsets;Verification environment;},
URL = {http://dx.doi.org/10.1145/1558607.1558676},
} 


@inproceedings{20095212579635 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Weaving web applications with WebDSL (demonstration)},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Groenewegen, Danny M. and Visser, Eelco},
year = {2009},
pages = {797 - 798},
address = {Orlando, FL, United states},
abstract = {WebDSL is a domain-specific language for the development of web applications that integrates data-models, user-interface models, actions, validation, access control, and workflow. The compiler verifies the consistency of applications and generates complete implementations in Java or Python. We illustrate the key concepts of the language with a small web application.},
key = {Object oriented programming},
keywords = {Access control;Computer systems programming;Graphical user interfaces;Java programming language;Linguistics;Models;Problem oriented languages;Query languages;Security systems;World Wide Web;XML;},
note = {Data model;Domain specific languages;Interface model;WEB application;},
URL = {http://dx.doi.org/10.1145/1639950.1640020},
} 


@inproceedings{20114014396713 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Bilingual cluster based models for statistical machine translation},
journal = {EMNLP-CoNLL 2007 - Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
author = {Yamamoto, Hirofumi and Sumita, Eiichiro},
year = {2007},
pages = {514 - 523},
address = {Prague, Czech republic},
abstract = {We propose a domain specific model for statistical machine translation. It is well-known that domain specific language models perform well in automatic speech recognition. We show that domain specific language and translation models also benefit statistical machine translation. However, there are two problems with using domain specific models. The first is the data sparseness problem. We employ an adaptation technique to overcome this problem. The second issue is domain prediction. In order to perform adaptation, the domain must be provided, however in many cases, the domain is not known or changes dynamically. For these cases, not only the translation target sentence but also the domain must be predicted. This paper focuses on the domain prediction problem for statistical machine translation. In the proposed method, a bilingual training corpus, is automatically clustered into sub-corpora. Each sub-corpus is deemed to be a domain. The domain of a source sentence is predicted by using its similarity to the sub-corpora. The predicted domain (sub-corpus) specific language and translation models are then used for the translation decoding. This approach gave an improvement of 2.7 in BLEU (Papineni et al., 2002) score on the IWSLT05 Japanese to English evaluation corpus (improving the score from 52.4 to 55.1). This is a substantial gain and indicates the validity of the proposed bilingual cluster based models. &copy; 2007 Association for Computational Linguistics.},
key = {Translation (languages)},
keywords = {Computational linguistics;Information theory;Natural language processing systems;Software agents;Speech recognition;},
note = {Adaptation techniques;Automatic speech recognition;Cluster-based;Data sparseness problem;Domain specific;Domain specific languages;Prediction problem;Specific languages;Statistical machine translation;Training corpus;Translation models;},
} 


@inproceedings{20110613647258 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using constraints for intrusion detection: The NeMODe system},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Salgueiro, Pedro and Diaz, Daniel and Brito, Isabel and Abreu, Salvador},
volume = {6539 LNCS},
year = {2011},
pages = {115 - 129},
issn = {03029743},
address = {Austin, TX, United states},
abstract = {In this work we present NeMODe a declarative system for Computer Network Intrusion detection which provides a declarative Domain Specific Language for describing computer network intrusion signatures that could spread across several network packets, which allows to state constraints over network packets, describing relations between several packets, and providing several back-end detection mechanisms which relies on Constraint Programming (CP) methodologies to find those intrusions. &copy; 2011 Springer-Verlag.},
key = {Intrusion detection},
keywords = {Computer crime;Computer systems programming;Constraint theory;Internet;XML;},
note = {Constraint programming;Detection mechanism;Domain specific languages;Intrusion Detection Systems;Network intrusion detection;Network intrusions;Network packets;State constraints;},
URL = {http://dx.doi.org/10.1007/978-3-642-18378-2_11},
} 


@inproceedings{20104813441588 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Formalizing train control language: Automating analysis of train stations},
journal = {WIT Transactions on the Built Environment},
author = {Svendsen, A. and Mller-Pedersen, B. and Haugen, ?. and Endresen, J. and Carlson, E.},
volume = {114},
year = {2010},
pages = {245 - 256},
issn = {17433509},
address = {Beijing, China},
abstract = {The Train Control Language (TCL) is a domain-specific language that allows automation of the production of interlocking source code. From a graphical editor a model of a train station is created. This model can then be transformed to other representations, e.g. an interlocking table and functional blocks, keeping the representations internally consistent. Formal methods are mathematical techniques for precisely expressing a system, contributing to the reliability and robustness of the system through analysis. Traditionally, applying formal methods involves a high cost. This paper presents a formalization of TCL, including its behavior expressed in the constraint solving language Alloy. We show how analysis of station models can be performed automatically. Analysis, such as simulation of a station, searching for dangerous train movements and deadlocks, is used to illustrate the approach. &copy; 2010 WIT Press.},
key = {Formal methods},
keywords = {Alloys;Mathematical techniques;Problem oriented languages;Railroads;Reliability analysis;},
note = {A-train;Constraint Solving;Domain specific languages;Functional block;Graphical editors;High costs;interlocking;model analysis;Reliability and robustness;Source codes;Train control;Train movement;Train stations;},
URL = {http://dx.doi.org/10.2495/CR100241},
} 


@inproceedings{20102613042243 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Sectional domain specific languages},
journal = {Proceedings of the 4th Workshop on Domain-Specific Aspect Languages, DSAL '09, Co-located with the 8th International Conference on Aspect-Oriented Software Development, AOSD.09},
author = {Cazzola, Walter and Speziale, Ivan},
year = {2009},
pages = {11 - 14},
address = {Charlottesville, VA, United states},
abstract = {Nowadays, many problems are solved by using a domain specific language (DSL), i.e., a programming language tailored to work on a particular application domain. Normally, a new DSL is designed and implemented from scratch requiring a long time-to-market due to implementation and testing issues. Whereas when the DSL simply extends another language it is realized as a source-to-source transformation or as an external library with limited flexibility. The Hive framework is developed with the intent of overcoming these issues by providing a mechanism to compose different programming features together forming a new DSL, what we call a sectional DSL. The support (both at compiler and interpreter level) of each feature is separately described and easily composed with the others. This approach is quite flexible and permits to build up a new DSL from scratch or simplifying an existing language without penalties. Moreover, it has the desirable side-effect that each DSL can be extended at any time potentially also at run-time. Copyright 2009 ACM.},
key = {Query languages},
keywords = {Computer software;Computer systems programming;Linguistics;Program compilers;Program interpreters;Software design;},
note = {aosd;Application domains;Domain specific languages;Programming language;Runtimes;Side effect;Source-to-source transformations;Time-to-market;},
URL = {http://dx.doi.org/10.1145/1509307.1509311},
} 


@inproceedings{20101212790628 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A DSL for the SegBus platform},
journal = {Proceedings - IEEE International SOC Conference, SOCC 2009},
author = {Niazi, Moazzam Fareed and Latif, Khalid and Tenhunen, Hannu and Seceleanu, Tiberiu},
year = {2009},
pages = {393 - 398},
address = {Belfast, Ireland},
abstract = {The paper presents a Domain Specific Language (DSL) for a multi-core segmented bus platform, SegBus. The DSL, based on a UML profile, consists of graphical platform elements in the form of stereotypes with the necessary tagged values to depict platform aspects at high level of abstraction. Customizations are applied to each stereotyped element in the form of user-defined rules to restrict relationship between platform elements. The Object Constraint Language (OCL) is employed to introduce constraints, in order to impose structural requirements between platform elements, for which we introduce mechanisms to validate them. We present a simplified example of a H.264 video encoder application where the DSL is used to specify and validate application and platform model in a unified representation manner. &copy;2009 IEEE.},
key = {Modems},
keywords = {DSL;Linguistics;Microprocessor chips;Motion estimation;Programmable logic controllers;Telecommunication lines;},
note = {Domain specific languages;H.264 video encoder;High level of abstraction;Multi core;Object Constraint Language;Platform elements;Platform models;Segmented bus platform;Structural requirements;UML profiles;},
URL = {http://dx.doi.org/10.1109/SOCCON.2009.5398012},
} 


@inproceedings{20101212784068 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generation of ERP systems from REA specifications},
journal = {ICSOFT 2008 - Proceedings of the 3rd International Conference on Software and Data Technologies},
author = {Schultz-Mller, Nicholas Poul and Hlmer, Christian and Hansen, Michael R.},
volume = {ISDM},
number = {ABF/-},
year = {2008},
pages = {12 - 19},
address = {Porto, Portugal},
abstract = {We present an approach to the construction of Enterprise Resource Planning (ERP) Systems, which is based on the Resources, Events and Agents (REA) ontology. Though this framework deals with processes involving exchange and flow of resources, the conceptual models have high-level graphical representations describing what the major entities are rather than how they engage in computations. We show how to develop a declarative, domain-specific language on the basis of REA, and for this language we have developed a tool which automatically can generate running web-applications. A main contribution is a proof-of-concept result showing that business-domain experts can, using a declarative, REA-based domain-specific language, generate their own applications without worrying about implementation details. In order to have a well-defined domain-specific language, a formal model of REA has been developed using the specification language Object-Z. This formalization led to clarifications as well as the introduction of new concepts. The compiler for our language is written in Objective CAML and as implementation platform we used Ruby on Rails. The aim of this paper is to give an overview of whole construction of a running application on the basis of a REA specification.},
key = {Enterprise resource planning},
keywords = {Computer software;Graphic methods;Linguistics;Ontology;Problem oriented languages;Resource allocation;Specification languages;Specifications;},
note = {Conceptual model;Construction of enterprise;Domain experts;Domain specific languages;Enterprise resource planning systems;ERP system;Formal model;Graphical representations;Implementation platforms;New concept;Proof of concept;Ruby on Rails;Running applications;},
} 


@inproceedings{20112514077185 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Analyzing variability: Capturing semantic ripple effects},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Svendsen, Andreas and Haugen, Oystein and Mller-Pedersen, Birger},
volume = {6698 LNCS},
year = {2011},
pages = {253 - 269},
issn = {03029743},
address = {Birmingham, United kingdom},
abstract = {This paper shows how to incrementally analyze how variability described in the Common Variability Language (CVL) affects the semantics of a model in a domain-specific language (DSL). CVL is a generic language for modeling variability. Using Alloy for definition of semantics we perform analysis to capture the elements in the model, which are semantically affected by applying the variabilities specified by the CVL model. An extension to the CVL editor is provided to automate the analysis. To illustrate the approach, we combine CVL with the Train Control Language (TCL) to capture how the semantics of TCL models are affected when applying CVL to them. We show how the analysis can be applied e.g., for testing. &copy; 2011 Springer-Verlag.},
key = {Semantics},
keywords = {Cerium alloys;Problem oriented languages;},
note = {Common Variability Language;Domain specific languages;Language composition;model analysis;Modeling variability;Ripple effects;Train control;},
URL = {http://dx.doi.org/10.1007/978-3-642-21470-7_18},
} 


@inproceedings{20093112224855 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Verifiable composition of deterministic grammars},
journal = {ACM SIGPLAN Notices},
author = {Schwerdfeger, August C. and Van Wyk, Eric R.},
volume = {44},
number = {6},
year = {2009},
pages = {199 - 210},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {There is an increasing interest in extensible languages, (domain-specific) language extensions, and mechanisms for their specification and implementation. One challenge is to develop tools that allow non-expert programmers to add an eclectic set of language extensions to a host language. We describe mechanisms for composing and analyzing concrete syntax specifications of a host language and extensions to it. These specifications consist of context-free grammars with each terminal symbol mapped to a regular expression, from which a slightly-modified LR parser and context-aware scanner are generated. Traditionally, conflicts are detected when a parser is generated from the composed grammar, but this comes too late since it is the non-expert programmer directing the composition of independently developed extensions with the host language. The primary contribution of this paper is a modular analysis that is performed independently by each extension designer on her extension (composed alone with the host language). If each extension passes this modular analysis, then the language composed later by the programmer will compile with no conflicts or lexical ambiguities. Thus, extension writers can verify that their extension will safely compose with others and, if not, fix the specification so that it will. This is possible due to the context-aware scanner's lexical disambiguation and a set of reasonable restrictions limiting the constructs that can be introduced by an extension. The restrictions ensure that the parse table states can be partitioned so that each state can be attributed to the host language or a single extension. Copyright &copy; 2009 ACM.},
key = {Query languages},
keywords = {Computational linguistics;Electric reactors;Formal languages;Linguistics;Scanning;Specifications;},
note = {Context-aware scanning;Extensible languages;Grammar composition;Language composition;LR parsing;},
} 


@inproceedings{20094912521887 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Verifiable composition of deterministic grammars},
journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
author = {Schwerdfeger, August C. and Van Wyk, Eric R.},
year = {2009},
pages = {199 - 210},
address = {Dublin, Ireland},
abstract = {There is an increasing interest in extensible languages, (domain-specific) language extensions, and mechanisms for their specification and implementation. One challenge is to develop tools that allow non-expert programmers to add an eclectic set of language extensions to a host language. We describe mechanisms for composing and analyzing concrete syntax specifications of a host language and extensions to it. These specifications consist of context-free grammars with each terminal symbol mapped to a regular expression, from which a slightly-modified LR parser and context-aware scanner are generated. Traditionally, conflicts are detected when a parser is generated from the composed grammar, but this comes too late since it is the non-expert programmer directing the composition of independently developed extensions with the host language. The primary contribution of this paper is a modular analysis that is performed independently by each extension designer on her extension (composed alone with the host language). If each extension passes this modular analysis, then the language composed later by the programmer will compile with no conflicts or lexical ambiguities. Thus, extension writers can verify that their extension will safely compose with others and, if not, fix the specification so that it will. This is possible due to the context-aware scanner's lexical disambiguation and a set of reasonable restrictions limiting the constructs that can be introduced by an extension. The restrictions ensure that the parse table states can be partitioned so that each state can be attributed to the host language or a single extension. Copyright &copy; 2009 ACM.},
key = {Query languages},
keywords = {C (programming language);Computational linguistics;Computer software;Electric reactors;Formal languages;Linguistics;Scanning;Specifications;},
note = {Composition languages;Concrete syntax;Context-Aware;Context-aware scanning;Domain specific;Expert programmers;Language extensions;Lexical ambiguity;Lexical disambiguation;LR parsers;LR parsing;Modular analysis;Parse table;Primary contribution;Regular expressions;Terminal symbols;},
URL = {http://dx.doi.org/10.1145/1542476.1542499},
} 


@inproceedings{20104813445710 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model checking programmable router configurations},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Zanolin, Luca and Mascolo, Cecilia and Emmerich, Wolfgang},
volume = {5765 LNCS},
year = {2010},
pages = {473 - 491},
issn = {03029743},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {Programmable networks offer the ability to customize router behaviour at run time, thus increasing flexibility of network administration. Programmable network routers are configured using domain-specific languages. In this paper, we describe our approach to defining the syntax and semantics of such a domain-specific language. The ability to evolve router programs dynamically creates potential for misconfigurations. By exploiting domain-specific abstractions, we are able to translate router configurations into Promela and validate them using the Spin model checker, thus providing reasoning support for our domain-specific language. To evaluate our approach we use our configuration language to express the IETF's Differentiated Services specification and show that industrial-sized DiffServ router configurations can be validated using Spin on a standard PC. &copy; 2010 Springer-Verlag Berlin Heidelberg.},
key = {Routers},
keywords = {Graphical user interfaces;Model checking;Problem oriented languages;Programmed control systems;Quality of service;Query languages;},
note = {Configuration languages;Differentiated Services;DiffServ;Domain specific;Domain specific languages;Misconfigurations;Network Administration;Programmable network;Programmable routers;PROMELA;Router configuration;Runtimes;Spin models;Spin-on;},
URL = {http://dx.doi.org/10.1007/978-3-642-17322-6_20},
} 


@inproceedings{20102713061360 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Metaprogramming approaches to finite state machine modeling for SIP applications},
journal = {Proceedings of the Mediterranean Electrotechnical Conference - MELECON},
author = {Pjanic, Edin and Hasanovic, Amer and Suljanovic, Nermin and Mujcic, Aljo and Zajc, Matej},
year = {2010},
pages = {592 - 596},
address = {Valletta, Malta},
abstract = {This paper presents a methodology to develop a complete domain specific language (DSL) for simple finite state machine (FSM) modeling, utilizing metaprogramming techniques found in Ruby programming language. Additionally, two libraries for FSM modeling are reviewed. A simple vending machine model is used to demonstrate the effectiveness of the DSL code. The proposed techniques together with the SIP Servlet API can be combined with Ruby's web development environments to develop complex converged telecom applications. &copy; 2010 IEEE.},
key = {Ruby},
keywords = {Contour followers;Internet protocols;Linguistics;},
note = {Domain specific languages;Finite state machines;Meta Programming;Programming language;SIP application;SIP servlets;Telecom applications;Web development;},
URL = {http://dx.doi.org/10.1109/MELCON.2010.5476022},
} 


@inproceedings{20112214019092 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Parameterized models for on-line and off-line use},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Wuille, Pieter and Schrijvers, Tom},
volume = {6559 LNCS},
year = {2011},
pages = {101 - 118},
issn = {03029743},
address = {Madrid, Spain},
abstract = {The Monadic Constraint Programming framework leverages Haskell's rich static type system and powerful abstraction mechanisms to implement an embedded domain specific language (EDSL) for constraint programming. In this paper we show how the same constraint model expressed in the EDSL can be processed in various modes by external constraint solvers. We distinguish between on-line and off-line use of solvers. In off-line mode, the model is not solved; instead it is compiled to lower-level code that will search for solutions when compiled and run. For on-line use, the search can be handled by either the framework or in the external solver. Off-line mode requires recompilation after each change to the model. To avoid repeated recompilation, we separate model from data by means of parameters that need not be known at compile time. Parametrization poses several challenges, which we resolve by embedding the EDSL more deeply. &copy; 2011 Springer-Verlag.},
key = {Computer programming languages},
keywords = {Constraint theory;Functional programming;Logic programming;},
note = {Abstraction mechanism;Compile time;Constraint model;Constraint programming;Embedded domain specific languages;External constraints;Haskell;Offline modes;Online use;Parameterized model;Parametrizations;Recompilation;Static type systems;},
URL = {http://dx.doi.org/10.1007/978-3-642-20775-4_6},
} 


@article{20111913960000 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A framework for reviewing domain specific conceptual models},
journal = {Computer Standards and Interfaces},
author = {Tanriover, O. Ozgur and Bilgen, Semih},
volume = {33},
number = {5},
year = {2011},
pages = {448 - 464},
issn = {09205489},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Conceptual models are used in understanding and communicating the domain of interest during analysis phase of system development. As they are used in early phases, errors and omissions may propagate to later phases and may be very costly to correct. This paper proposes a framework for evaluating conceptual models when represented in a domain specific language based on UML constructs. The framework describes the main aspects to be considered when conceptual models are represented in a domain specific language, presents a classification of semantic issues and some evaluation indicators. The indicators can, in principle, identify situations in the models where inconsistencies or incompleteness might occur. Whether these are real concerns might depend on domain semantics, hence these are semantic, not syntactic checks. The use of the proposed review framework is illustrated in the context of two conceptual models in a domain specific notation, KAMA. With reviews based on the framework, it is possible to spot semantic issues which are not noticed by case tools and help the analyst to identify more information about the domain. &copy; 2011 Elsevier B.V.},
key = {Semantics},
note = {CASE tools;Conceptual model;Domain semantics;Domain specific;Domain specific languages;Evaluation indicators;System development;UML inspection;},
URL = {http://dx.doi.org/10.1016/j.csi.2010.12.001},
} 


@inproceedings{20112914149699 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The GReTL transformation language},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Horn, Tassilo and Ebert, Jurgen},
volume = {6707 LNCS},
year = {2011},
pages = {183 - 197},
issn = {03029743},
address = {Zurich, Switzerland},
abstract = {This paper introduces the graph-based transformation language GReTL. GReTL is an operational transformation language whose operations are either specified in plain Java using the GReTL API or in a simple domain-specific language. GReTL follows the conception of incrementally constructing the target metamodel together with the target graph. When creating a new metamodel element, a set-based semantic expression is specified that describes the set of instances that have to be created in the target graph. This expression is described by a query on the source graph. After a description of the foundations of GReTL, its most important elements are introduced along with a simple example. &copy; 2011 Springer-Verlag.},
key = {Java programming language},
keywords = {Problem oriented languages;Semantics;},
note = {Domain specific languages;Graph-based;Meta model;Operational transformation;},
URL = {http://dx.doi.org/10.1007/978-3-642-21732-6_13},
} 


@inproceedings{20104513353521 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Semi-supervised learning of language model using unsupervised topic model},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
author = {Bai, Shuanhu and Huang, Chien-Lin and Ma, Bin and Li, Haizhou},
year = {2010},
pages = {5386 - 5389},
issn = {15206149},
address = {Dallas, TX, United states},
abstract = {We present a semi-supervised learning (SSL) method for building domain-specific language models (LMs) from general-domain data using probabilistic latent semantic analysis (PLSA). The proposed technique first performs topic decomposition (TD) on the combined dataset of domain-specific and general-domain data. Then it derives latent topic distribution of the interested domain, and derives domain-specific word n-gram counts with a PLSA style mixture model. Finally, it uses traditional n-gram modeling to construct domain-specific LMs from the domain-specific word n-gram counts. Experimental results show that this technique outperforms both states-of-the-art relative entropy text selection and traditional supervised training methods. &copy;2010 IEEE.},
key = {Models},
keywords = {Computational linguistics;Problem oriented languages;Signal processing;Supervised learning;},
note = {Data sets;Domain specific;Domain specific languages;Interested domains;Language model;Mixture model;N-gram modeling;Probabilistic latent semantic analysis;Relative entropy;Semi-supervised learning;Topic model;Training methods;},
URL = {http://dx.doi.org/10.1109/ICASSP.2010.5494940},
} 


@inproceedings{20093512277601 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A haskell hosted dsl for writing transformation systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Gill, Andy},
volume = {5658 LNCS},
year = {2009},
pages = {285 - 309},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {KURE is a Haskell hosted Domain Specific Language (DSL) for writing transformation systems based on rewrite strategies. When writing transformation systems, a significant amount of engineering effort goes into setting up plumbing to make sure that specific rewrite rules can fire. Systems like Stratego and Strafunski provide most of this plumbing as infrastructure, allowing the DSL user to focus on the rewrite rules. KURE is a strongly typed strategy control language in the tradition of Stratego and Strafunski. It is intended for writing reasonably efficient rewrite systems, makes use of type families to provide a delimited generic mechanism for tree rewriting, and provides support for efficient identity rewrite detection. &copy; IFIP International Federation for Information Processing 2009.},
key = {Linguistics},
keywords = {DSL;Modems;Plumbing;Query languages;Telecommunication lines;XML;},
note = {Domain specific languages;Generic mechanism;Haskell;Rewrite rules;Rewrite strategies;Rewrite systems;Strafunski;Stratego;Transformation systems;Tree rewriting;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_14},
} 


@inproceedings{20103413181584 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An event view model and DSL for engineering an event-based SOA monitoring infrastructure},
journal = {Proceedings of the 4th ACM International Conference on Distributed Event-Based Systems, DEBS 2010},
author = {Mulo, Emmanuel and Zdun, Uwe and Dustdar, Schahram},
year = {2010},
pages = {62 - 72},
address = {Cambridge, United kingdom},
abstract = {An event-based solution that uses events to convey information to a monitoring tool is well suited to implementing a non-intrusive monitoring infrastructure. This enables an SOA system's stakeholders to observe the system aspects of interest to them. However, implementation of SOA today, let alone the monitoring infrastructure, is a complex task due to the heterogeneous environment consisting of multiple technologies, platforms and components. We propose an approach for implementing such an event-based SOA monitoring infrastructure, that introduces a dedicated event view model and an eventing domain-specific language in a model-driven framework. The event view model captures SOA artifacts and links them with the event domain, while the eventing domain-specific language enables a system developer to specify instances of the event view model. With our model-driven approach, most of the runtime monitoring infrastructure is generated. These two ingredients (view model and domain-specific language) focus implementation efforts on the concern of eventing, thereby helping to manage complexity. We apply and evaluate our approach in the context of a case study. &copy; 2010 ACM.},
key = {Monitoring},
keywords = {Distributed computer systems;Information services;Linguistics;Problem oriented languages;Software architecture;Software design;},
note = {Complex task;Domain specific languages;Event-based;Eventing;Heterogeneous environments;Model driven approach;Model-driven;model-driven software development;Monitoring tools;Multiple technology;Non-intrusive;Runtime Monitoring;System aspects;System developers;},
URL = {http://dx.doi.org/10.1145/1827418.1827428},
} 


@inproceedings{20093012216790 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Program interpolation},
journal = {Proceedings of the 2009 ACM SIGPLAN Symposium on Partial Evaluation and Program Manipulation, PEPM'09},
author = {Moss, Andrew and Page, Dan},
year = {2009},
pages = {31 - 40},
address = {Savannah, GA, United states},
abstract = {Program interpolation is a new type of transformation that given an input program written in a specially constructed Domain Specific Language(DSL), produces a family of functionally equivalent instruction sequences as output. Each sequence is an "interpolation" between the control-flows of implementation strategies supplied in the input program. The purpose of the transformation is to expose behavioural differences (e.g. performance) within the sequences, and thus allow automated optimisation with respect to architectural trade-offs that are difficult to quantify and model. We present results from a prototype compiler that demonstrate a 63% speedup in the domain of multi-precision integer arithmetic. &copy; 2009 ACM.},
key = {Interpolation},
keywords = {Binary codes;},
note = {Domain specific languages;Dynamic feedback;Implementation strategies;Input programs;Integer arithmetic;Optimisation;Program interpolation;Program optimization;},
URL = {http://dx.doi.org/10.1145/1480945.1480951},
} 


@inproceedings{20071410525551 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Strategies for language model web-data collection},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
author = {Wan, Vincent and Hain, Thomas},
volume = {1},
year = {2006},
pages = {I1069 - I1072},
issn = {15206149},
address = {Toulouse, France},
abstract = {This paper presents an analysis of the use of textual information collected from the internet via a search engine for the purpose of building domain specific language models. A framework to analyse the effect of search query formulation on the resulting web-data language model performance in an evaluation is developed. The framework gives rise to improved methods of selecting n-gram search engine queries, which return documents that make better domain specific language models. &copy; 2006 IEEE.},
key = {Data acquisition},
keywords = {Linguistics;Query languages;Search engines;Text processing;World Wide Web;},
note = {Language models;Search engine queries;Specific language models;Textual information;},
} 


@article{20073110710373 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Declarative GUI programming in Microsoft Windows},
journal = {IEEE Software},
author = {Louridas, Panagiotis},
volume = {24},
number = {4},
year = {2007},
pages = {16 - 19},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {A domain-specific language for building user interfaces offers a transparent way for programmers to specify interface elements. Microsoft's Extensible Application Markup Language is an XML dialect for this purpose. However, XAML isn't the only choice for programmers who wish to try a declarative approach, and some options are even open source. &copy; 2007 IEEE.},
key = {Graphical user interfaces},
keywords = {Computer programming;Computer programming languages;Markup languages;XML;},
note = {Domain-specfic languages;Extensible application markup language;},
URL = {http://dx.doi.org/10.1109/MS.2007.105},
} 


@inproceedings{20110413613000 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Language-Oriented Programming VIA DSL stacking},
journal = {ICSOFT 2010 - Proceedings of the 5th International Conference on Software and Data Technologies},
author = {Humm, Bernhard G. and Engelschall, Ralf S.},
volume = {2},
year = {2010},
pages = {279 - 287},
address = {Athens, Greece},
abstract = {According to the paradigm of Language-Oriented Programming, an application for a problem should be implemented in the most appropriate domain-specific language (DSL). This paper introduces DSL stacking, an efficient method for implementing Language-Oriented Programming where DSLs and general-purpose languages are incrementally developed on top of a base language. This is demonstrated with components of a business information system that are implemented in different DSLs for Semantic Web technology in Lisp.},
key = {LISP (programming language)},
keywords = {Graphical user interfaces;Information systems;Object oriented programming;Problem oriented languages;Semantic Web;Semantics;},
note = {Business information systems;Domain specific languages;Language-oriented programming;Lisp;Meta Programming;Programming language;},
} 


@inproceedings{20110613647266 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Nettle: Taking the sting out of programming network routers},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Voellmy, Andreas and Hudak, Paul},
volume = {6539 LNCS},
year = {2011},
pages = {235 - 249},
issn = {03029743},
address = {Austin, TX, United states},
abstract = {We describe a language-centric approach to solving the complex, low-level, and error-prone problem of network control. Specifically, we have designed a domain-specific language called Nettle, embedded in Haskell, that allows programming OpenFlow networks in an elegant, declarative style. Nettle is based on the principles of functional reactive programming (FRP), and as such has both continuous and discrete abstractions, each of which is leveraged in the design. We have implemented Nettle and tested it on real OpenFlow switches. We demonstrate our methodology by writing several non-trivial OpenFlow controllers. &copy; 2011 Springer-Verlag.},
key = {Routers},
keywords = {Functional programming;Problem oriented languages;},
note = {Discrete abstraction;Domain specific languages;Error prones;Haskell;Network control;Network routers;Non-trivial;Reactive programming;},
URL = {http://dx.doi.org/10.1007/978-3-642-18378-2_19},
} 


@inproceedings{20093512277595 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Combining DSLs and ontologies using metamodel integration},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Walter, Tobias and Ebert, Jurgen},
volume = {5658 LNCS},
year = {2009},
pages = {148 - 169},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {This paper reports on a case study where the domain specific language BEDSL for the description of network devices for computer networks is combined with the feature description language FODA used for defining the variability structure of product lines. Furthermore, annotations by fragments of the web ontology language OWL can be added. In essence, the approach is a three-way integration, which regards two documents written in BEDSL and FODA, respectively, and semantic OWL-annotations as three equally important views of the system under discussion. The integration of languages is done on the level of their metamodels. The standard metamodel of OWL 2 is merged with two self-developed metamodels for the respective domain specific languages. The merge is loss-free, i.e. the resulting merged model still contains all information from its parts. Thus, the BEDSL part can be used to visualize the network model, the FODA part still defines the feature structure of the corresponding product line and the OWL part can be extracted and fed into an OWL tool to assert the semantic conditions. &copy; IFIP International Federation for Information Processing 2009.},
key = {Linguistics},
keywords = {Computer networks;DSL;Mergers and acquisitions;Modems;Ontology;Query languages;Semantics;Telecommunication lines;},
note = {Domain specific languages;Feature description;Feature structure;Meta model;Network devices;Network models;Product-lines;Web ontology language;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_8},
} 


@inproceedings{2003297553071 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Can a parser be generated from examples?},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Mernik, Marjan and Gerlic, Goran and Zumer, Viljem and Bryant, Barrett R.},
year = {2003},
pages = {1063 - 1067},
address = {Melbourne, FL, United states},
abstract = {One of the open problems in the area of domain-specific languages is how to make domain-specific language development easier for domain experts not versed in a programming language design. Possible approaches are to build a domain-specific language from parameterized building blocks or by language (grammar) induction. This paper uses an evolutionary approach to grammar induction. Grammar-specific genetic operators for crossover and mutation are proposed to achieve this task. Suitability of the approach is shown by small experiments where underlying grammars are successfully genetically obtained and parsers are than automatically generated.},
key = {Computer programming languages},
keywords = {Context free grammars;Evolutionary algorithms;Heuristic methods;Mathematical operators;Program compilers;Semantics;},
note = {Parser generation;},
URL = {http://dx.doi.org/10.1145/952532.952740},
} 


@inproceedings{20102713062132 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {FPGA circuit synthesis of accelerator data-parallel programs},
journal = {Proceedings -  IEEE Symposium on Field-Programmable Custom Computing Machines, FCCM 2010},
author = {Bond, Barry and Hammil, Kerry and Litchev, Lubomir and Singh, Satnam},
year = {2010},
pages = {167 - 170},
address = {Charlotte, NC, United states},
abstract = {This paper describes the techniques used to describe and synthesize FPGA circuits expressed in a data-parallel domain specific language (DSL) called Accelerator. We identify the subset of data-parallel descriptions that are upported by our system and explain how we track memory access patterns which allow us to generate efficient FPGA circuits. &copy; 2010 IEEE.},
key = {Computers},
keywords = {Parallel architectures;},
note = {Accelerator data;Data parallel;Domain specific languages;FPGA circuits;Memory access patterns;Techniques used;},
URL = {http://dx.doi.org/10.1109/FCCM.2010.51},
} 


@inproceedings{20105113497601 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Xtext - Implement your language faster than the quick and dirty way tutorial summary},
journal = {Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion, SPLASH '10},
author = {Eysholdt, Moritz and Behrens, Heiko},
year = {2010},
pages = {307 - 309},
address = {Reno/Tahoe, NV, United states},
abstract = {Whether there is an (emerging or legacy) Domain-Specific Language to increase the expressiveness of your coworkers or whether you are about to invent a new General Purpose Prgramming Language: Tool support that goes beyond a parser/compiler is essential to make other people adopt your language and to be more productive. Xtext is an award-winning<sup>1</sup> framework to build such tooling. In this tutorial we explain how to define a language and a statically typed, EMF-based Abstract Syntax Tree using only a grammar. We then generate a parser, a serializer and a smart editor from it. The editor provides many features out-of-the-box, such as syntax highlighting, content-assist, folding, jump-to-declaration and reverse-reference lookup across multiple files. Then, it is shown how literally every aspects of the language and its complementary tool support can be customized using Dependency Injection, especially how this can be done for linking, formatting and validation. As an outlook, we will demonstrate how to integrate a custom language with Java, how Xtext maintains a workspace-wide index of named elements and how to implement incremental code generation or attach an interpreter. &copy; 2010 ACM.},
key = {Object oriented programming},
keywords = {Computer systems programming;Java programming language;Problem oriented languages;Syntactics;Trees (mathematics);},
note = {Eclipse;EMF;MDSD;Modeling;Xtext;},
URL = {http://dx.doi.org/10.1145/1869542.1869625},
} 


@inproceedings{20111713940054 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Hist-inspect: A tool for history-sensitive detection of code smells},
journal = {Proceedings of the 10th International Conference on Aspect-Oriented Software Development Companion, AOSD.11},
author = {Mara, Leandra and Honorato, Gustavo and Dantas, Francisco and Garcia, Alessandro and Lucena, Carlos},
year = {2011},
pages = {65 - },
address = {Porto de Galinhas, Brazil},
abstract = {Hist-Inspect is a tool that allows the specification and evaluation of different configurations for detection strategies by means of a domain-specific language. The tool enables to easily adjust thresholds and combination of software metrics as well as compare the performance of conventional and history-sensitive detection strategies. The tool also provides a diverse set of views, including graphical representation of module evolution measures. These views enable the code reviewer to reason about the stability of individual modules, the growth or decline of a particular structural property (e.g. coupling or cohesion), without the burden of recovering all the values for each version under analysis.},
key = {Software design},
keywords = {Computer systems programming;Problem oriented languages;},
note = {Code smell;Detection strategy;Domain specific languages;Graphical representations;Metrics;Sensitive detection;Software metrics;},
URL = {http://dx.doi.org/10.1145/1960314.1960335},
} 


@inproceedings{20101812898243 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generating smart wrapper libraries for arbitrary APIs},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Jugel, Uwe},
volume = {5969 LNCS},
year = {2010},
pages = {354 - 373},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {"Library design is language design" [1]. The development of a smart program library is very similar to the creation of a domain specific language (DSL). Both are currently created in an ad-hoc manner, taking account of best practices and software patterns. Creating new languages and the tools needed to integrate them can be very cumbersome. We propose a reproducible, model-driven methodology to add automation to the DSL-creation process. Our novel approach presents an easy way to design and generate smart, API-wrapping libraries, similar to internal DSLs. These libraries increase the usability of an existing API and can be easily integrated into existing software development tool chains. To generate these DSLs, we propose an enhanced code generation that applies usability-enhancing software patterns. Our current generator leverages the Expression Builder pattern, which is described in detail. We validate our methodology and our enhanced code generation by applying it to Java APIs resulting in smart Java libraries that we call "dotLings". &copy; 2010 Springer-Verlag.},
key = {Linguistics},
keywords = {Application programming interfaces (API);Computer software;Design;DSL;Java programming language;Libraries;Modems;Network components;Query languages;Telecommunication lines;Usability engineering;},
note = {Best practice;Code Generation;Creation process;Current generator;Domain specific languages;Java library;Language design;Language integration;Library designs;Model-driven methodology;Software development tools;Software patterns;},
URL = {http://dx.doi.org/10.1007/978-3-642-12107-4_24},
} 


@inproceedings{20111413889432 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An access layer to PolNet - Polish WordNet},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Kubis, Marek},
volume = {6562 LNAI},
year = {2011},
pages = {444 - 455},
issn = {03029743},
address = {Poznan, Poland},
abstract = {The paper describes an access layer developed in order to provide access to PolNet (a lexical database developed for the Polish language). The access layer was developed on top of a domain-specific language designed to query WordNet-like lexical databases (WQuery). The paper presents the overall architecture of the access layer and shows typical queries passed by an AI system with NL competence (POLINT-112-SMS) to WQuery. The paper discusses the reasons for integrating an ontology into an NLP system through a domain-specific query language. &copy; 2011 Springer-Verlag.},
key = {Ontology},
keywords = {Problem oriented languages;Query languages;},
note = {AI systems;Domain specific languages;Domain-specific query languages;lexical database;NLP systems;Polish WordNet;Wordnet;},
URL = {http://dx.doi.org/10.1007/978-3-642-20095-3_41},
} 


@inproceedings{2006079699088 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Haskell server pages through dynamic loading},
journal = {Haskell'05 - Proceedings of the ACM SIGPLAN 2005 Haskell Workshop},
author = {Broberg, Niklas},
year = {2005},
pages = {39 - 48},
address = {Tallinn, Estonia},
abstract = {Haskell Server Pages (HSP) is a domain specific language, based on Haskell, for writing dynamic web pages. Its main features are concrete XML expressions as first class values, pattern-matching on XML, and a runtime system for evaluating dynamic web pages. The first design of HSP was made by Erik Meijer and Danny van Velzen in 2000, but it was never fully designed nor implemented. In this paper we refine, extend and improve their design of the language and describe how to implement HSP using dynamic loading of pages. Copyright &copy; 2005 ACM.},
key = {Computer programming languages},
keywords = {Servers;Websites;XML;},
note = {Dynamic loading;Haskell;Web server;},
URL = {http://dx.doi.org/10.1145/1088348.1088353},
} 


@inproceedings{20094912521831 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Language support for processing distributed ad hoc data},
journal = {PPDP'09 - Proceedings of the 11th International ACM SIGPLAN Symposium on Principles and Practice of Declarative Programming},
author = {Zhu, Kenny Q. and Dantas, Daniel S. and Fisher, Kathleen and Jia, Limin and Mandelbaum, Yitzhak and Pai, Vivek and Walker, David},
year = {2009},
pages = {243 - 254},
address = {Coimbra, Portugal},
abstract = {This paper presents the design, theory and implementation of GLOVES1, a domain-specific language that allows users to specify the provenance (the derivation history starting from the origins), syntax and semantic properties of collections of distributed data sources. In particular, GLOVES specifications indicate where to locate desired data, how to obtain it, when to get it or to give up trying, and what format it will be in on arrival. The GLOVES system compiles such specification into a suite of data-processing tools including an archiver, a provenance tracking system, a database loading tool, an alert system, an RSS feed generator and a debugging tool. In addition, the system generates description-specific libraries so that developers can create their own applications. GLOVES also provides a generic infrastructure so that advanced users can build new tools applicable to any data source with a GLOVES description. We show how GLOVES may be used to specify data sources from two domains: CoMon, a monitoring system for PlanetLab's 800+ nodes, and Arrakis, a monitoring system for an AT&amp;T web hosting service. We show experimentally that our system can scale to distributed systems the size of CoMon. Finally, we provide a de-notational semantics for GLOVES and use this semantics to prove two important theorems. The first shows that our denotational semantics respects the typing rules for the language, while the second demonstrates that our system correctly maintains the provenance. Copyright &copy; 2009 ACM.},
key = {Monitoring},
keywords = {Computer programming;Data processing;Linguistics;Problem oriented languages;Query languages;Semantics;Specifications;},
note = {Alert systems;Data source;Debugging tools;Denotational semantics;Distributed data sources;Distributed systems;Domain specific languages;Monitoring system;New tools;PlanetLab;Processing tools;Rss feeds;Semantic properties;Support for processing;Tracking system;Two domains;Typing rules;Web hosting services;},
URL = {http://dx.doi.org/10.1145/1599410.1599440},
} 


@inproceedings{20104913467778 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the 10th Workshop on Language Descriptions, Tools and Applications, LDTA 2010},
journal = {Proceedings of the 10th Workshop on Language Descriptions, Tools and Applications, LDTA 2010},
year = {2010},
pages = {ACM Special Interest Group on Programming Languages (SIGPLAN); University of Minnesota Software Engineering Center - },
address = {Paphos, Cyprus},
abstract = {The proceedings contain 12 papers. The topics discussed include: a domain specific language for complex natural and artificial systems simulations; on the ro&circ;le of minimal typing derivations in type-driven program transformation; GamaSlicer: an online laboratory for program verification and analysis; dependence condition graph for semantics-based abstract program slicing; faster ambiguity detection by grammar filtering; tear-insert-fold grammars; embedding a web-based workflow management system in a functional language; specifying generic Java programs: two case studies; language description for frontend implementation; on the impact of DSL tools on the maintainability of language implementations; using DSLs for developing enterprise systems; and formally specified type checkers for domain specific languages.},
} 


@inproceedings{20064710254981 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Challenges in the compilation of a domain specific languages for dynamic programming},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Giegerich, Robert and Steffen, Peter},
volume = {2},
year = {2006},
pages = {1603 - 1609},
address = {Dijon, France},
abstract = {Many combinatorial optimization problems in biosequence analysis are solved via dynamic programming. To increase programming productivity and program reliability, a domain specific language embedded in Haskell has been suggested. We point out several shortcomings of this approach, and report on some challenges in the (ongoing) project of migrating this domain specific language from its host language to a directly compiled implementation. Most of these challenges are domain specific optimizations, which not only improve significant constant factors of runtime and space requirements, but also affect asymptotic efficiency. We report on our solutions to some of these problems, and point out others that are still open. Copyright 2006 ACM.},
key = {Computer programming languages},
keywords = {Asymptotic stability;Combinatorial mathematics;Dynamic programming;Optimization;Problem solving;Reliability theory;},
note = {Biosequence analysis;Domain specific languages;Program reliability;},
} 


@inproceedings{20104913467773 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Language description for front end implementation},
journal = {Proceedings of the 10th Workshop on Language Descriptions, Tools and Applications, LDTA 2010},
author = {Bagge, Anya Helene},
year = {2010},
pages = {ACM Special Interest Group on Programming Languages (SIGPLAN); University of Minnesota Software Engineering Center - },
address = {Paphos, Cyprus},
abstract = {For a language to be useful, it requires a robust and reliable implementation. Writing and maintaining such an implementation is a hard task, particularly for experimental or domain-specific language projects where resources are limited. This paper describes an implementation approach based on modular specifications of syntax and static semantics. Specification is done in a language description DSL, which serves both as a specification, and as code from which compiler front ends can be automatically generated. &copy; ACM 2010.},
key = {Specifications},
keywords = {Problem oriented languages;Semantics;},
note = {Automatically generated;Domain specific languages;Front end;Hard task;Implementation approach;Language description;Languages;Modular specifications;Static semantics;},
URL = {http://dx.doi.org/10.1145/1868281.1868290},
} 


@inproceedings{20100212619706 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {LAIR: A language for automated semantics-aware text sanitization based on frame semantics},
journal = {ICSC 2009 - 2009 IEEE International Conference on Semantic Computing},
author = {Hedegaard, Steffen and Houen, Sren and Simonsen, Jakob Grue},
year = {2009},
pages = {47 - 52},
address = {Berkeley, CA, United states},
abstract = {We present LAIR: A domain-specific language that enables users to specify actions to be taken upon meeting specific semantic frames in a text, in particular to rephrase and redact the textual content. While LAIR presupposes superficial knowledge of frames and frame semantics, it requires only limited prior programming experience. It neither contain scripting or I/O primitives, nor does it contain general loop constructions and is not Turing-complete. We have implemented a LAIR compiler and integrated it in a pipeline for automated redaction of web pages. We detail our experience with automated redaction of web pages for subjectively undesirable content; initial experiments suggest that using a small language based on semantic recognition of undesirable terms can be highly useful as a supplement to traditional methods of text sanitization. &copy; 2009 IEEE.},
key = {Semantics},
keywords = {Automation;Character recognition;Linguistics;Problem oriented languages;Query languages;World Wide Web;},
note = {Domainspecific languages;General loops;Programming experience;Sanitization;Semantic recognition;Specific semantics;Textual content;Web page;},
URL = {http://dx.doi.org/10.1109/ICSC.2009.79},
} 


@article{1998534679160 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Frob - functional robotics},
journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
author = {Ling, Gary Shu},
year = {1998},
pages = {345 - },
address = {Baltimore, MD, USA},
abstract = {Frob or functional robotics is a domain-specific language embedded in Haskell to control robotic systems. It promotes a style of programming largely independent of the underlying hardware. Frob is based on the core of Fran, a reactive system for computer animation.},
key = {Robot programming},
keywords = {Animation;Embedded systems;Robotics;},
note = {Functional robotics;},
} 


@inproceedings{20084811748421 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using ASM to achieve executability within a family of DSL},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Ober, Ileana and Abou Dib, Ali},
volume = {5238 LNCS},
year = {2008},
pages = {354 - },
issn = {03029743},
address = {London, United kingdom},
abstract = {We propose an approach to achieve interoperability in a family of domain specific language based on the use of their ASM semantics and of the category theory. The approach is based on the construction of a unifying language of the family, by using categorical colimits. Since the unifying language is obtained by construction, translators to this one are obtained easily. These are the premises for using ASM tools for symbolically executing systems made of components specified in domain specific languages of a same family. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Query languages},
keywords = {Information theory;Intrusion detection;Linguistics;},
note = {ASM semantics;Category theories;Domain specifics;Executing systems;},
URL = {http://dx.doi.org/10.1007/978-3-540-87603-8_41},
} 


@inproceedings{20101612866855 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Dynamic domain specific languages for trust models},
journal = {Computation World: Future Computing, Service Computation, Adaptive, Content, Cognitive, Patterns, ComputationWorld 2009},
author = {Laird, Paul and Dondio, Pierpaolo and Barrett, Stephen},
year = {2009},
pages = {713 - 718},
address = {Athens, Greece},
abstract = {We propose the development of a framework for the dynamic interpretation of Trust models, defined via a Domain Specific Language. A trust model usually defines abstractions, the interpretation of which change in conjunction with changes in the domain or changes in the context in which the program executes. In a scenario where trust model assumptions encoded in the DSL change, programmers must still work with the existing DSL, and therefore take more effort to describe their program or sometimes fail to specify their intent. In such changing circumstances a trust model risks becoming less effective and fit for purpose. We seek to develop an approach in which a trust model adapts to a changing environment by making the underlying DSL less restrictive, maintaining flexibility and adaptability to cope with changing or novel contexts without reducing the expressiveness of the abstractions used. &copy; 2009 IEEE.},
key = {Linguistics},
keywords = {Abstracting;DSL;Modems;Program interpreters;Query languages;Telecommunication lines;},
note = {Changing environment;Context sensitivity;Domain specific languages;Dynamic adaptations;Dynamic domains;Dynamic interpretation;Trust models;},
URL = {http://dx.doi.org/10.1109/ComputationWorld.2009.82},
} 


@inproceedings{20084511681799 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Adding standardized variability to domain specific languages},
journal = {Proceedings - 12th International Software Product Line Conference, SPLC 2008},
author = {Haugen, Oystein and Moller-Pedersen, Birger and Oldevik, Jon and Olsen, Gran K. and Svendsen, Andreas},
year = {2008},
pages = {139 - 148},
address = {Limerick, Ireland},
abstract = {We show how a common language of variability can be used to enhance the expressiveness of a Domain Specific Language (DSL). DSLs have been proposed as a mechanism for expressing variability. Variability between models in a given domain or of a family of systems is captured by language constructs, implying that all possible models in this language are the allowed variations. We explore the possibility of expressing variability in a language independently of the base modeling language. We explore how this works for small DSLs as well as for general purpose languages like UML. Implications of this approach are that the variability language can be standardized, and that DSLs do not have to include variability mechanisms. &copy; 2008 IEEE.},
key = {Query languages},
keywords = {Linguistics;Unified Modeling Language;},
note = {Common languages;Domain specifics;General purpose languages;Language constructs;Modeling languages;Possible models;Variability mechanisms;},
URL = {http://dx.doi.org/10.1109/SPLC.2008.25},
} 


@inproceedings{20090111838314 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings - International Conference of the Chilean Computer Science Society, SCCC 2008},
journal = {Proceedings - International Conference of the Chilean Computer Science Society, SCCC},
year = {2008},
pages = {Chilean Computer Science Society; CONICYT Chile; Yahoo Research Latin America; Santiago of Chile; University of Magallanes - },
issn = {15224902},
address = {Punta Arenas, Chile},
abstract = {The proceedings contain 16 papers. The topics discussed include: a domain specific language for the development of collaborative systems; a framework of composable access control definition, enforcement and assurance; an experimental study of the FIB framework driven by the PDCA cycle; behavior specification of product lines via feature models and UML statecharts with variabilities; deconstructing agile processes: would planned design be helpful in XP projects?; GeoMergeP: supporting an ontological approach to geographic information integration; weak constraint programming to identify alternative composite COTS-based software systems from imperfect information; a scheduling algorithm to optimize parallel processes; and mapping tasks to processors in heterogeneous multiprocessor architectures: the MATEHa algorithm.},
} 


@inproceedings{1998354270529 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modular domain specific languages and tools},
journal = {International Conference on Software Reuse},
author = {Hudak, Paul},
year = {1998},
pages = {134 - 142},
address = {Los Alamitos, CA, United States},
abstract = {A domain specific language (DSL) allows one to develop software for a particular application domain quickly and effectively, yielding programs that are easy to understand, reason about, and maintain. On the other hand, there may be a significant overhead in creating the infrastructure needed to support a DSL. To solve this problem, a methodology is described for building domain specific embedded languages (DSELs), in which a DSL is designed within an existing, higher-order and typed, programming language such as Haskell or ML. In addition, techniques are described for building modular interpreters and tools for DSELs. The resulting methodology facilitates reuse of syntax, semantics, implementation code, software tools, as well as look-and-feel.},
key = {Computer programming languages},
keywords = {Codes (symbols);Computational linguistics;Computer aided software engineering;Formal logic;Program interpreters;},
note = {Domain specific embedded languages (DSEL);Functional languages;Software reuse;},
} 


@inproceedings{20113514266456 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A compositional implementation of Modbus in Protege},
journal = {SIES 2011 - 6th IEEE International Symposium on Industrial Embedded Systems, Conference Proceedings},
author = {Wang, Yan and Gaspes, Veronica},
year = {2011},
pages = {123 - 131},
address = {Vasteras, Sweden},
abstract = {Network protocols today play a major role in embedded software for industrial automation, with constant efforts to adapt existing device software to new emerging standards. In earlier work, we have proposed a compilation-based approach using a domain-specific language, Protege, which automatically generates protocol stack implementations in C from modular high-level descriptions. In this paper, we provide a case study of the Protege language in an industrial setting. We have implemented the Modbus protocol over TCP/IP and over serial line, and tested it using an industrial gateway. Our implementation demonstrates Protege's advantages for software productivity, easy maintenance and code reuse, and it achieves many desirable properties of industrial embedded network software. &copy; 2011 IEEE.},
key = {Embedded software},
keywords = {C (programming language);Computer software maintenance;Computer software reusability;Embedded systems;Gateways (computer networks);Industry;Network protocols;Problem oriented languages;Software engineering;},
note = {Code reuse;Domain specific languages;Embedded network;High level description;Industrial automation;Industrial settings;Modbus protocol;Protege;Protocol stack;Serial line;Software productivity;},
URL = {http://dx.doi.org/10.1109/SIES.2011.5953654},
} 


@inproceedings{20112814132699 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a framework for modelling and verification of relay interlocking systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Haxthausen, Anne E.},
volume = {6662 LNCS},
year = {2011},
pages = {176 - 192},
issn = {03029743},
address = {Redmond, WA, United states},
abstract = {This paper describes a framework currently under development for modelling, simulation, and verification of relay interlocking systems as used by the Danish railways. The framework is centred around a domain-specific language (DSL) for describing such systems, and provides (1) a graphical editor for creating DSL descriptions, (2) a data validator for checking that DSL descriptions follow the structural rules of the domain, (3) a graphical simulator for simulating the dynamic behaviour of relay interlocking systems, and (4) verification support for deriving and verifying safety properties of relay interlocking systems. &copy; 2011 Springer-Verlag.},
key = {Verification},
keywords = {Adaptive systems;Computer simulation;Computer software;Problem oriented languages;Safety devices;},
note = {Domain specific languages;Dynamic behaviours;Graphical editors;Graphical simulators;Interlocking systems;Safety property;Structural rules;},
URL = {http://dx.doi.org/10.1007/978-3-642-21292-5_10},
} 


@article{20103713236413 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An experiment description language for wireless network research},
journal = {Journal of Internet Technology},
author = {Gunes, Mesut and Juraschek, Felix and Blywis, Bastian},
volume = {11},
number = {4},
year = {2010},
pages = {465 - 472},
issn = {16079264},
address = {121 F, 106, Sec.2, Heping E.Road, Taipei, Taiwan},
abstract = {This article introduces a network experiment description language that is designed as a general approach for testbed networks and simulation environments. The approach is based on a domain specific language simplifying the execution of experiments by using an easily comprehensible and straight-forward design scheme. By laying out a clear logical structure, experiment descriptions provide the user with the possibility to only focus on the crucial matter of experiments. An experiment description file serves as the input for a software tool that executes the experiment automatically, thus being able to use a reliable timing for all specified actions. We developed this approach as DES-Cript for the DES-Testbed at the Freie Universita&die;t Berlin, but it is not limited to this particular testbed.},
key = {Experiments},
keywords = {Computer simulation;Linguistics;Test facilities;Testbeds;Wireless networks;},
note = {Description languages;Domain specific languages;Forward designs;General approach;Logical structure;Networking experiments;Simulation environment;Software tool;Testbed networks;Wireless testbed;},
} 


@inproceedings{20083711537153 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Case studies in model manipulation for scientific computing},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Carette, Jacques and Smith, Spencer and McCutchan, John and Anand, Christopher and Korobkine, Alexandre},
volume = {5144 LNAI},
year = {2008},
pages = {24 - 37},
issn = {03029743},
address = {Birmingham, United kingdom},
abstract = {The same methodology is used to develop 3 different applications. We begin by using a very expressive, appropriate Domain Specific Language, to write down precise problem definitions, using their most natural formulation. Once defined, the problems form an implicit definition of a unique solution. From the problem statement, our model, we use mathematical transformations to make the problem simpler to solve computationally. We call this crucial step "model manipulation." With the model rephrased in more computational terms, we can also derive various quantities directly from this model, which greatly simplify traditional numeric solutions, our eventual goal. From all this data, we then use standard code generation and code transformation techniques to generate lower-level code to perform the final numerical steps. This methodology is very flexible, generates faster code, and generates code that would have been all but impossible for a human programmer to get correct. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Mathematical transformations},
keywords = {Administrative data processing;Artificial intelligence;Classification (of information);Codes (symbols);Computer networks;Cosine transforms;Information management;Knowledge management;Management information systems;Mathematical models;Problem solving;Solutions;},
note = {International conferences;Problem statements;Symbolic com-putation;},
URL = {http://dx.doi.org/10.1007/978-3-540-85110-3_4},
} 


@inproceedings{20083811577325 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Declarative access control for webDSL: Combining language integration and separation of concerns},
journal = {Proceedings - 8th International Conference on Web Engineering, ICWE 2008},
author = {Groenewegen, Danny and Visser, Eelco},
year = {2008},
pages = {175 - 188},
address = {Yorktown Heights, NY, United states},
abstract = {In this paper, we present the extension of WebDSL, a domain-specific language for web application development, with abstractions for declarative definition of access control. The extension supports the definition of a wide range of access control policies concisely and transparently as a separate concern. In addition to regulating the access to pages and actions, access control rules are used to infer navigation options not accessible to the current user, preventing the presentation of inaccessible links. The extension is an illustration of a general approach to the design of domain-specific languages for different technical domains to support separation of concerns in application development, while preserving linguistic integration. This approach is realized by means of a transformational semantics that weaves separately defined aspects into an integrated implementation. &copy; 2008 IEEE.},
key = {Access control},
keywords = {Computer programming languages;Graphical user interfaces;Information theory;Isomers;Linguistics;Query languages;Security systems;Separation;},
note = {International conferences;Separation of concerns;Web engineering;},
URL = {http://dx.doi.org/10.1109/ICWE.2008.15},
} 


@inproceedings{20105213517683 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {On using LALP to map an audio encoder/decoder on FPGAs},
journal = {IEEE International Symposium on Industrial Electronics},
author = {Menotti, Ricardo and Cardoso, Joao M.P. and Fernandes, Marcio M. and Marques, Eduardo},
year = {2010},
pages = {3063 - 3068},
address = {Bari, Italy},
abstract = {This paper presents the use of LALP to implement typical industrial application kernels, ADPCM Encoder and Decoder, in FPGAs. LALP is a domain specific language and its compilation framework aims to the direct mapping of algorithms originally described in a high-level language onto FPGAs. In particular, LALP focuses on loop pipelining, a key technique for the design of hardware accelerators. While the language syntax resembles C, it contains certain constructs that allow programmer interventions to enforce or relax data dependences as needed, and so optimize the performance of the generated hardware. We present experimental results showing significant performance gains using this approach, while still keeping the language syntax and semantics close to popular high level software languages, a desirable feature when considering time to market constraints. We believe the performance gains observed for the ADPCM implementation can be extended to other industrial applications relying on algorithms spending most of their execution time on loop structures, such signal and image processing. &copy; 2010 IEEE.},
key = {High level languages},
keywords = {Algorithms;Image processing;Industrial applications;Industrial electronics;Industry;Semantics;Syntactics;},
note = {Data dependence;Direct mapping;Domain specific languages;Encoder/decoder;Execution time;Hardware accelerators;Key techniques;Language syntax;Loop pipelining;Loop structure;Performance Gain;Signal and image processing;Software languages;Time to market;},
URL = {http://dx.doi.org/10.1109/ISIE.2010.5637845},
} 


@inproceedings{20110713667528 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {2010 IEEE International Conference on Networked Embedded Systems for Enterprise Applications, NESEA 2010},
journal = {2010 IEEE International Conference on Networked Embedded Systems for Enterprise Applications, NESEA 2010},
year = {2010},
address = {Suzhou, China},
abstract = {The proceedings contain 10 papers. The topics discussed include: composition challenges and approaches for cyber physical systems; mobDSL: a domain specific language for multiple mobile platform deployment; extending sensor networks into the cloud using Amazon web services; SenaaS: an event-driven sensor virtualization approach for Internet of things cloud; middleware for resource sharing in multi-purpose wireless sensor networks; data traffic based route selection for real-time data delivery in wireless sensor networks; preserving privacy and assuring integrity in data aggregation for wireless sensor networks; a pattern based methodology for the design and implementation of multiplexed master-slave devices at the system-level use-case: modeling a level-2 cache IP module at transaction level; and low power, small die-size PLL using semi-digital storage instead of big loop filter capacitance.},
} 


@inproceedings{20105113510261 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards semantic modeling of network physical devices},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Miksa, Krzysztof and Kasztelnik, Marek and Sabina, Pawel and Walter, Tobias},
volume = {6002 LNCS},
year = {2010},
pages = {329 - 343},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {One of the challenges faced by network management systems is the increasing need for consistent management of physical network equipment. We propose a solution where equipment is modelled using a dedicated Domain Specific Language (DSL) enriched with the power of logic-based reasoning services. This enables us to define a rich layer of semantics on top of the structural description of the devices. This way, the configuration related constraints are expressed declaratively, in a platform independent manner, and are managed in an integrated way with the structural model. The information kept in the model can then be used on runtime to give guidance to the system user. &copy; Springer-Verlag Berlin Heidelberg 2010.},
key = {Network management},
keywords = {Model structures;Optical communication;Semantics;Software engineering;},
note = {Domain specific languages;Network management systems;Physical devices;Physical network;Platform independent;Runtimes;Semantic modeling;Structural models;},
URL = {http://dx.doi.org/10.1007/978-3-642-12261-3_31},
} 


@inproceedings{1998394311347 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Microprocessor specification in hawk},
journal = {Proceedings of the IEEE International Conference on Computer Languages},
author = {Matthews, John and Cook, Byron and Launchbury, John},
year = {1998},
pages = {90 - 101},
issn = {10748970},
address = {Chicago, IL, USA},
abstract = {Modern microprocessors require an immense investment of time and effort to create and verify, from the high-level architectural design downwards. We are exploring ways to increase the productivity of design engineers by creating a domain-specific language for specifying and simulating processor architectures. We believe that the structuring principles used in modern functional programming languages, such as static typing, parametric polymorphism, first-class functions, and lazy evaluation provide a good formalism for such a domain-specific language, and have made initial progress by creating a library on top of the functional language Haskell. We have specified the integer subset of an out-of-order, superscalar DLX microprocessor, with register-renaming, a reorder buffer, a global reservation station, multiple execution units, and speculative branch execution. Two key abstractions of this library are the signal abstract data type (ADT), which models the simulation history of a wire, and the transaction ADT, which models the state of an entire instruction as it travels through the microprocessor.},
key = {Computer hardware description languages},
keywords = {Buffer storage;Computer architecture;Computer simulation;Formal languages;Formal logic;Microprocessor chips;Subroutines;},
note = {Domain specific languages;Functional programming languages;Global reservation stations;Multiple execution units;Register renaming;Reorder buffers;Speculative branch execution;},
} 


@inproceedings{20104113278391 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Bringing extensibility to verified compilers},
journal = {ACM SIGPLAN Notices},
author = {Tatlock, Zachary and Lerner, Sorin},
volume = {45},
number = {6},
year = {2010},
pages = {111 - 121},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Verified compilers, such as Leroy's CompCert, are accompanied by a fully checked correctness proof. Both the compiler and proof are often constructed with an interactive proof assistant. This technique provides a strong, end-to-end correctness guarantee on top of a small trusted computing base. Unfortunately, these compilers are also challenging to extend since each additional transformation must be proven correct in full formal detail. At the other end of the spectrum, techniques for compiler correctness based on a domain-specific language for writing optimizations, such as Lerner's Rhodium and Cobalt, make the compiler easy to extend: The correctness of additional transformations can be checked completely automatically. Unfortunately, these systems provide a weaker guarantee since their end-to-end correctness has not been proven fully formally. We present an approach for compiler correctness that provides the best of both worlds by bridging the gap between compiler verification and compiler extensibility. In particular, we have extended Leroy's CompCert compiler with an execution engine for optimizations written in a domain specific language and proved that this execution engine preserves program semantics, using the Coq proof assistant. We present our CompCert extension, XCert, including the details of its execution engine and proof of correctness in Coq. Furthermore, we report on the important lessons learned for making the proof development manageable. Copyright &copy; 2010 ACM.},
key = {Program compilers},
keywords = {Cobalt;Optimization;Problem oriented languages;Rhodium;},
note = {Compiler correctness;Compiler optimizations;Compiler verifications;Coq proof assistant;Correctness;Correctness proofs;Domain specific languages;End-to-end correctness;Execution engine;Extensibility;Interactive proof assistants;Program semantics;Proof development;Proof of correctness;Trusted computing base;},
URL = {http://dx.doi.org/10.1145/1809028.1806611},
} 


@article{20103113113924 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An optimized cell BE special function library generated by coconut},
journal = {IEEE Transactions on Computers},
author = {Anand, Christopher Kumar and Kahl, Wolfram},
volume = {58},
number = {8},
year = {2009},
pages = {1126 - 1138},
issn = {00189340},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {Abstract-Coconut, a tool for developing high-assurance, high-performance kernels for scientific computing, contains an extensible domain-specific language (DSL) embedded in Haskell. The DSL supports interactive prototyping and unit testing, simplifying the process of designing efficient implementations of common patterns. Unscheduled C and scheduled assembly language output are supported. Using the patterns, even nonexpert users can write efficient function implementations, leveraging special hardware features. A production-quality library of elementary functions for the Cell BE SPU compute engines has been developed. Coconutgenerated and -scheduled vector functions were more than four times faster than commercially distributed functions written in C with intrinsics (a nicer syntax for in-line assembly), wrapped in loops and scheduled by spuxlc. All Coconut functions were faster, but the difference was larger for hard-to-approximate functions for which register-level SIMD lookups made a bigger difference. Other helpful features in the language include facilities for translating interval and polynomial descriptions between GHCi, a Haskell interpreter used to prototype in the DSL, and Maple, used for exploration and minimax polynomial generation. This makes it easier to match mathematical properties of the functions with efficient calculational patterns in the SPU ISA. By using single, literate source files, the resulting functions are remarkably readable. &copy; 2009 IEEE.},
key = {Functions},
keywords = {DSL;Functional programming;Linguistics;Network components;Problem oriented languages;Program interpreters;Query languages;},
note = {Applicative (functional) programming;Approximate function;Assembly language;Distributed function;Domain specific languages;Efficient implementation;Elementary function;Haskell;In-line assembly;Interactive prototyping;Lookups;Mathematical properties;Minimax;Polynomial generation;Programming codes;Scientific computing;Source files;Special function approximations;Special functions;Special hardware;Specialized application languages;Unit testing;Vector functions;},
URL = {http://dx.doi.org/10.1109/TC.2008.223},
} 


@inproceedings{20105013485868 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Pwrake: A parallel and distributed flexible workflow management tool for wide-area data intensive computing},
journal = {HPDC 2010 - Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
author = {Tanaka, Masahiro and Tatebe, Osamu},
year = {2010},
pages = {356 - 359},
address = {Chicago, IL, United states},
abstract = {This paper proposes Pwrake, a parallel and distributed flexible workflow management tool based on Rake, a domain specific language for building applications in the Ruby programming language. Rake is a similar tool to make and ant. It uses a Rakefile that is equivalent to a Makefile in make, but written in Ruby. Due to a flexible and extensible language feature, Rake would be a powerful workflow management language. The Pwrake extends Rake to manage distributed and parallel workflow executions that include remote job submission and management of parallel executions. This paper discusses the design and implementation of the Pwrake, and demonstrates its power of language and extensibility of the system using a practical e-Science data-intensive workflow in astronomical data analysis on the Gfarm file system as a case study. Extending a scheduling algorithm to be aware of file locations, 20% of speed up is observed using 8 nodes (32 cores) in a PC cluster. Using two PC clusters located in different institutions, the file location aware scheduling shows scalable speedup. The extensible Pwrake is a promising workflow management tool even for wide-area data analysis. &copy; Copyright 2010 ACM.},
key = {Management},
keywords = {Data handling;Distributed computer systems;Parallel programming;Ruby;Scheduling algorithms;Work simplification;},
note = {Astronomical data;Data analysis;Data-intensive computing;Domain specific languages;e-Science;File location;File systems;Flexible workflows;Gfarm file systems;Job submission;Language features;Parallel executions;PC clusters;Performance evaluation;Programming language;Speed-ups;Wide area;Workflow;Workflow execution;Workflow managements;},
URL = {http://dx.doi.org/10.1145/1851476.1851529},
} 


@inproceedings{20092912200711 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using integrative models in an advanced heterogeneous system simulation},
journal = {Proceedings of the International Symposium and Workshop on Engineering of Computer Based Systems},
author = {Gulotta, Jacob and Chu, Diyang and Yu, Ximing and Al-Helal, Hussain and Patki, Tapasya and Hansen, Jason and Hudson, Maribel and Sprinkle, Jonathan},
year = {2009},
pages = {3 - 10},
address = {San Francisco, CA, United states},
abstract = {This paper is an academic experience report describing the use by researchers at the University of Arizona of a domain-specific language developed by the Institute for Software Integrated Systems (at Vanderbilt University). The domain in question is heterogeneous, distributed simulation of quad-rotor unmanned aerial vehicles (UAVs) as they respond to command and control requests from a human operator. We describe in detail how our individual designs of the controller and guidance laws for the UAV, its rendering and position updates, on-board sensors, and the various commands to delegate mission-critical behaviors, all interact using the ISIS-developed modeling language. We then discuss the outlook for this domain (heterogeneous system simulation and integration) for domain-specific languages and models, specifically for unmanned vehicle control and interaction. &copy; 2009 IEEE.},
key = {Command and control systems},
keywords = {Computer simulation languages;Control system synthesis;Graphical user interfaces;Linguistics;Query languages;Remotely operated vehicles;Simulators;Unmanned aerial vehicles (UAV);},
note = {Command and control;Critical behavior;Distributed simulations;Domain specific languages;Experience report;Guidance laws;Heterogeneous systems;Human operator;Integrated systems;Modeling languages;On-board sensors;University of Arizona;Vanderbilt University;},
URL = {http://dx.doi.org/10.1109/ECBS.2009.42},
} 


@inproceedings{2001175069928 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Language for specifying recursive traversals of object structures},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Ovlinger, Johan and Wand, Mitchell},
volume = {34},
number = {10},
year = {1999},
pages = {70 - 81},
address = {Denver, CO, USA},
abstract = {We present a domain-specific language for specifying recursive traversals of object structures, for use with the visitor pattern. Traversals are traditionally specified as iterations, forcing the programmer to adopt an imperative style, or are hard-coded into the program or visitor. Our proposal allows a number of problems best approached by recursive means to be tackled with the visitor pattern, while retaining the benefits of a separate traversal specification.},
key = {Computer hardware description languages},
keywords = {Algorithms;Iterative methods;Object oriented programming;Recursive functions;Structured programming;},
note = {Object structures;Recursive traversals;Visitor pattern;},
} 


@inproceedings{20100912734909 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific languages in practice: A user study on the success factors},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Hermans, Felienne and Pinzger, Martin and Van Deursen, Arie},
volume = {5795 LNCS},
year = {2009},
pages = {423 - 437},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {In this paper we present an empirical study on the use of a domain-specific language(DSL) in industry. This DSL encapsulates the details of services that communicate using Windows Communication Foundation (WCF). From definitions of the data contracts between clients and servers, WCF/C# code for service plumbing is generated. We conducted a survey amongst developers that use this DSL while developing applications for customers. The DSL has been used in about 30 projects all around the world. We describe the known success factors of the use of DSLs, such as improved maintainability and ease of re-use, and assert how well this DSL scores on all of them. The analysis of the results of this case study also shows which conditions should be fulfilled in order to increase the chances of success in using a DSL in a real life case. &copy; 2009 Springer Berlin Heidelberg.},
key = {Telecommunication lines},
keywords = {DSL;Graphical user interfaces;Linguistics;Maintainability;Models;Modems;Problem oriented languages;Query languages;},
note = {Domain specific languages;Empirical studies;Improved maintainability;Success factors;User study;},
URL = {http://dx.doi.org/10.1007/978-3-642-04425-0_33},
} 


@inproceedings{20090911932736 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Speech act annotation for domain specific multilingual expression services},
journal = {Proceedings of the 2nd International Symposium on Universal Communication, ISUC 2008},
author = {Bourdon, Julien and Ishida, Toru},
year = {2008},
pages = {243 - 250},
address = {Osaka, Japan},
abstract = {We propose an approach to overcome cultural barriers, specifically pragmatic misunderstandings about the intention of the speaker by annotating domain specific language resources according to an ontology based on speech acts. These annotations are capable to account for indirect speech acts as well as for phenomena of mitigation and reinforcement. The presented architecture preserves the original structure of the resource by providing metadata specified using RDF. We illustrate our purpose by a manually annotated corpus designed to facilitate interaction with foreign patients in Japanese hospitals. &copy; 2008 IEEE.},
key = {Linguistics},
keywords = {Metadata;Ontology;Reinforcement;},
note = {Domain specifics;Domain-specific languages;Ontology-based;Original structures;Speech acts;},
URL = {http://dx.doi.org/10.1109/ISUC.2008.86},
} 


@inproceedings{20094612439749 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {From specification to optimisation: An architecture for optimisation of java bytecode},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Warburton, Richard and Kalvala, Sara},
volume = {5501 LNCS},
year = {2009},
pages = {17 - 31},
issn = {03029743},
address = {York, United kingdom},
abstract = {We present the architecture of the Rosser toolkit that allows optimisations to be specified in a domain specific language, then compiled and deployed towards optimising object programs. The optimisers generated by Rosser exploit model checking to apply dataflow analysis to programs to find optimising opportunities. The transformational language is derived from a formal basis and consequently can be proved sound. We validate the technique by comparing the application of optimisers generated by our system against hand-written optimisations using the Java based Scimark 2.0 benchmark. &copy; 2009 Springer Berlin Heidelberg.},
key = {Java programming language},
keywords = {Benchmarking;Computer software;Data flow analysis;Linguistics;Model checking;Optimization;Program compilers;},
note = {Domain specific languages;Java byte codes;Object program;Optimisations;},
URL = {http://dx.doi.org/10.1007/978-3-642-00722-4_3},
} 


@inproceedings{20094712491556 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific approach to network software architecture assuring conformance between architecture and code},
journal = {Proceedings - 2009 4th International Conference on Digital Telecommunications, ICDT 2009},
author = {Wang, Yan and Gaspes, Veronica},
year = {2009},
pages = {127 - 132},
address = {Colmar, France},
abstract = {Network software is typically organized according to a layered architecture that is well understood. However, writing correct and efficient code that conforms with the architecture still remains a problem. To overcome this problem we propose to use a domain specific language based approach. The architectural constraints are captured in a domain specific notation that can be used as a source for automatic program generation. Conformance with the architecture is thus assured by construction. Knowledge from the domain allows us to generate efficient code. In addition, this approach enforces reuse of both code and designs, one of the major concerns in software architecture. In this paper, we illustrate our approach with PADDLE, a tool that generates packet processing code from packet descriptions. To describe packets we use a domain specific language of dependent types that includes packet overlays. From the description we generate C libraries for packet processing that are easy to integrate with other parts of the code. We include an evaluation of our tool. &copy; 2009 IEEE.},
key = {Software architecture},
keywords = {Architecture;Automatic programming;Computer software reusability;Linguistics;Packet networks;},
note = {Architectural constraints;Automatic programs;Dependent types;Domain specific;Domain specific languages;Layered architecture;Network software;Packet processing;Program generation;},
URL = {http://dx.doi.org/10.1109/ICDT.2009.31},
} 


@inproceedings{20071710565413 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Easy language extension with meta-AspectJ},
journal = {Proceedings - International Conference on Software Engineering},
author = {Huang, Shan Shan and Smaragdakis, Yannis},
volume = {2006},
year = {2006},
pages = {865 - 868},
issn = {02705257},
address = {Shanghai, China},
abstract = {Domain-specific languages hold the potential of automating the software development process. Nevertheless, the adoption of a domain-specific language is hindered by the difficulty of transitioning to different language syntax and employing a separate translator in the software build process. We present a methodology that simplifies the development and deployment of small language extensions, in the context of Java. The main language design principle is that of language extension through unobtrusive annotations. The main language implementation idea is to express the language as a generator of customized AspectJ aspects, using our Meta-Aspect J tool. The advantages of the approach are twofold. First, the tool integrates into an existing software application much as a regular API or library, instead of as a language extension. This means that the programmer can remove the language extension at any point and choose to implement the required functionality by hand without needing to rewrite the client code. Second, a mature language implementation is easy to achieve with little effort since AspectJ takes care of the low-level issues of interfacing with the base Java language*.},
key = {Computer programming languages},
keywords = {Codes (symbols);Computer aided software engineering;Digital libraries;Interfaces (computer);Program translators;Software design;},
note = {Domain specific languages;Language extension;Language extensions;Language syntax;},
} 


@inproceedings{2004318291772 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Efficient development of data migration transformations},
journal = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
author = {Carreira, Paulo and Galhardas, Helena},
year = {2004},
pages = {915 - 916},
issn = {07308078},
address = {Paris, France},
abstract = {In this paper, we present a data migration tool named DATA FUSION. Its main features are: A domain specific language designed to conveniently model complex data transformations; an integrated development environment that assists users on managing complex data transformation projects and an auditing facility that provides relevant information to project managers and external auditors.},
URL = {http://dx.doi.org/10.1145/1007568.1007692},
} 


@article{20102513028344 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Abstractions for programming SIP back-to-back user agents},
journal = {IPTComm 2009: Services and Security for Next Generation Networks - Proceedings of the 3rd International Conference on Principles, Systems and Applications of IP Telecommunications},
author = {Zave, Pamela and Bond, Gregory W. and Cheung, Eric and Smith, Thomas M.},
year = {2009},
pages = {Georgia Tech; Tekelec; AT and T; Mu Dynamics; Telchemy - },
address = {Atlanta, GA, United states},
abstract = {In SIP services, back-to-back user agents (B2BUAs) are powerful but difficult to program correctly. StratoSIP is a highlevel, domain-specific language for programming SIP B2BUAs safely. This paper describes the four major abstractions on which the language is based. It explains how each abstraction is used in programming, and how it is implemented in SIP. Because the abstractions are derived from the Distributed Feature Composition (DFC) architecture, StratoSIP programs compose easily with each other at runtime. The implementation of StratoSIP runs in SIP Servlet containers. Copyright 2009 ACM.},
key = {Internet protocols},
keywords = {Abstracting;Linguistics;Problem oriented languages;},
note = {Distributed feature compositions;Domain specific languages;Runtimes;SIP servlets;User agents;},
URL = {http://dx.doi.org/10.1145/1595637.1595652},
} 


@inproceedings{20105113505524 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards generating optimised finite element solvers for GPUs from high-level specifications},
journal = {Procedia Computer Science},
author = {Markall, Graham R. and Ham, David A. and Kelly, Paul H. J.},
volume = {1},
number = {1},
year = {2010},
pages = {1815 - 1823},
issn = {18770509},
address = {Amsterdam, Netherlands},
abstract = {We argue that producing maintainable high-performance implementations of finite element methods for multiple targets requires that they are written using a high-level domain-specific language. We make the case for using one such language, the Unified Form Language (UFL), by discussing how it allows the generation of high-performance code from maintainable sources. We support this case by showing that optimal implementations of a finite element solver written for a Graphics Processing Unit and a multicore CPU require the use of different algorithms and data formats that are embodied by the UFL representation. Finally we describe a prototype compiler that generates low-level code from high-level specifications, and outline how the high-level UFL representation can be lowered to facilitate optimisation using existing techniques prior to code generation.},
key = {Finite element method},
keywords = {Computer graphics equipment;Optimization;Problem oriented languages;Program compilers;Specifications;},
note = {Code Generation;Data format;Finite element solver;GPU;Graphics Processing Unit;High level specification;High-level domain;Multi core;Multiple targets;Optimisations;Performance code;Performance implementation;Unified form;},
URL = {http://dx.doi.org/10.1016/j.procs.2010.04.203},
} 


@inproceedings{20114014397208 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Forest: A language and toolkit for programming with filestores},
journal = {ACM SIGPLAN Notices},
author = {Fisher, Kathleen and Foster, Nate and Walker, David and Zhu, Kenny Q.},
volume = {46},
number = {9},
year = {2011},
pages = {292 - 306},
issn = {15232867},
address = {General Post Office, P.O. Box 30777, NY 10087-0777, United States},
abstract = {A filestore is a structured collection of data files housed in a conventional hierarchical file system. Many applications use filestores as a poor-man's database, and the correct execution of these applications requires that the collection of files, directories, and symbolic links stored on disk satisfy a variety of precise invariants. Moreover, all of these structures must have acceptable ownership, permission, and timestamp attributes. Unfortunately, current programming languages do not provide support for documenting assumptions about filestores, detecting errors in them, or safely loading from and storing to them. This paper describes the design, implementation, and semantics of Forest, a new domain-specific language for describing filestores. The language uses a type-based metaphor to specify the expected structure, attributes, and invariants of filestores. Forest generates loading and storing functions that make it easy to connect data on disk to an isomorphic representation in memory that can be manipulated as if it were any other data structure. Forest also generates metadata that describes the degree to which the structures on the disk conform to the specification, making error detection easy. In a nutshell, Forest extends the rigorous discipline of typed programming languages to the untyped world of file systems. We have implemented Forest as an embedded domain-specific language in Haskell. In addition to generating infrastructure for reading, writing and checking file systems, our implementation generates type class instances that make it easy to build generic tools that operate over arbitrary filestores.We illustrate the utility of this infrastructure by building a file system visualizer, a file access checker, a generic query interface, description-directed variants of several standard UNIX shell tools and (circularly) a simple Forest description inference engine. Finally, we formalize a core fragment of Forest in a semantics inspired by classical tree logics and prove round-tripping laws showing that the loading and storing functions behave sensibly. Copyright &copy; 2011 ACM.},
key = {Problem oriented languages},
keywords = {Building codes;Computer aided software engineering;Data structures;Error detection;Graphical user interfaces;Loading;Metadata;Semantics;},
note = {Ad hoc datum;Bidirectional transformation;Data description languages;Domain specific languages;File systems;Filestores;Generic programming;Haskell;},
URL = {http://dx.doi.org/10.1145/2034574.2034814},
} 


@inproceedings{20110613642559 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling deployment of enterprise applications},
journal = {Lecture Notes in Business Information Processing},
author = {Patig, Susanne},
volume = {72 LNBIP},
year = {2011},
pages = {253 - 266},
issn = {18651348},
address = {Hammamet, Tunisia},
abstract = {Deployment comprises installing, activating and updating applications. The applications to be deployed usually require certain conditions that can refer to hardware capabilities, other software (dependencies), physical artifacts or configuration. Deployment planning aims at satisfying the applications' prerequisites without violating the hardware's capabilities. This paper presents the domain-specific language ADeL (Application Deployment Language) thatwas designed to describe and validate deployment plans. The ADeL metamodel was implemented within the Eclipse Modeling Framework (EMF) and contains a set of OCL constraints (implemented with the tool Topcased) to enable the automatic validation of deployment plans. &copy; 2011 Springer-Verlag Berlin Heidelberg.},
key = {Information systems},
keywords = {Problem oriented languages;System theory;},
note = {Application deployment;Automatic validation;Deployment planning;Deployment plans;Domain specific languages;Eclipse modeling framework;Enterprise applications;Meta model;Physical artifacts;},
URL = {http://dx.doi.org/10.1007/978-3-642-17722-4_18},
} 


@inproceedings{20113714315180 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using Haskell to script combinatoric testing of web services},
journal = {Proceedings of the 6th Iberian Conference on Information Systems and Technologies, CISTI 2011},
author = {Prasetya, I.S.W.B. and Amorim, J. and Vos, T.E.J. and Baars, A.},
year = {2011},
address = {Chaves, Portugal},
abstract = {The Classification Tree Method (CTM) is a popular approach in functional testing as it allows the testers to systematically partition the input domain of an SUT, and specifies the combinations they want. We have implemented the approach as a small domain specific language (DSL) embedded in the functional language Haskell. Such an embedding leads to clean syntax and moreover we can natively access Haskell's full features. This paper will explain the approach, and how it is applied for testing Web Services. &copy; 2011 AISTI.},
key = {Web services},
keywords = {Combinatorial mathematics;Information systems;User interfaces;},
note = {Automated testing;Classification tree method;combinatoric testing;Domain specific languages;Functional languages;Functional testing;Haskell;},
} 


@inproceedings{20080711091951 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A functional-logic library for wired},
journal = {Haskell'07: Proceedings of the ACM SIGPLAN 2007 Haskell Workshop},
author = {Naylor, Matthew and Axelsson, Emil and Runciman, Colin},
year = {2007},
pages = {37 - 48},
address = {Freiburg, Germany},
abstract = {We develop a Haskell library for functional-logic programming, motivated by the implementation of Wired, a relational embedded domain-specific language for describing and analysing digital circuits at the VLSI-layout level. Compared to a previous library for logic programming by Claessen and Ljunglo&die;f, we support residuation, easier creation of logical data types, and pattern matching. We discuss other applications of our library, including test-data generation, and various extensions, including lazy narrowing. Copyright &copy; 2007 ACM.},
key = {Digital libraries},
keywords = {Digital circuits;Logic programming;Pattern matching;},
note = {Haskell library;Logical data types;},
URL = {http://dx.doi.org/10.1145/1291201.1291207},
} 


@inproceedings{20112013985744 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A formal approach for the construction and verification of railway control systems},
journal = {Formal Aspects of Computing},
author = {Haxthausen, Anne E. and Peleska, Jan and Kinder, Sebastian},
volume = {23},
number = {2},
year = {2011},
pages = {191 - 219},
issn = {09345043},
address = {The Guildway, Old Portsmouth Road, Artington, Guildford, GU3 1LP, United Kingdom},
abstract = {This paper describes a complete model-based development and verification approach for railway control systems. For each control system to be generated, the user makes a description of the application-specific parameters in a domain-specific language. This description is automatically transformed into an executable control system model expressed in SystemC. This model is then compiled into object code. Verification is performed using threemainmethods applied to different levels. (0) The domain-specific description is validated wrt. internal consistency by static analysis. (1) The crucial safety properties are verified for the SystemC model by means of bounded model checking. (2) The object code is verified to be I/O behaviourally equivalent to the SystemC model from which it was compiled. BCS &copy; 2009.},
key = {Mathematical models},
keywords = {Control theory;Formal methods;Graphical user interfaces;Model checking;Problem oriented languages;Railroads;Static analysis;},
note = {Application-Specific;Bounded model checking;Code Generation;Control system models;Domain engineering;Domain specific;Domain specific languages;Formal approach;Internal consistency;Model based development;Object code;Railway control systems;Safety property;SystemC;},
URL = {http://dx.doi.org/10.1007/s00165-009-0143-6},
} 


@article{20092912192352 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Design and evaluation of a compiler for embedded stream programs},
journal = {ACM SIGPLAN Notices},
author = {Newton, Ryan R. and Craig, Michael B. and Girod, Lewis D. and Madden, Samuel R. and Morrisett, J. Greg},
volume = {43},
number = {7},
year = {2008},
pages = {131 - 140},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Applications that combine live data streams with embedded, parallel, and distributed processing are becoming more commonplace. WaveScript is a domain-specific language that brings high-level, type-safe, garbage-collected programming to these domains. This is made possible by three primary implementation techniques, each of which leverages characteristics of the streaming domain. First, we employ a novel evaluation strategy that uses a combination of interpretation and reification to partially evaluate programs into stream dataflow graphs. Second, we use profile-driven compilation to enable many optimizations that are normally only available in the synchronous (rather than asynchronous) dataflow domain. Finally, we incorporate an extensible system for rewrite rules to capture algebraic properties in specific domains (such as signal processing). We have used our language to build and deploy a sensornetwork for the acoustic localization of wild animals, in particular, the Yellow-Bellied marmot. We evaluate WaveScript's performance on this application, showing that it yields good performance on both embedded and desktop-class machines, including distributed execution and substantial parallel speedups. Our language allowed us to implement the application rapidly, while outperforming a previous C implementation by over 35%, using fewer than half the lines of code. We evaluate the contribution of our optimizations to this success. Copyright &copy; 2008 ACM.},
key = {High level languages},
keywords = {Animals;Biodiversity;Data flow analysis;Linguistics;Program interpreters;Sensor networks;Signal processing;},
note = {Acoustic localization;Algebraic properties;Data stream;Data-flow graphs;Dataflow;Distributed execution;Distributed processing;Domain specific languages;Evaluation strategies;Extensible systems;Implementation techniques;Lines of code;Parallel speedups;Rewrite rules;Streaming domains;Streamprocessing language;Wild animals;Yellow-bellied marmot;},
} 


@article{20090811918392 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Virtual machine framework for constructing domain-specific languages},
journal = {IET Software},
author = {Kourie, D.G. and Fick, D. and Watson, B.W.},
volume = {3},
number = {1},
year = {2009},
pages = {1 - 13},
issn = {17518806},
address = {Six Hills Way, Stevenage, SG1 2AY, United Kingdom},
abstract = {An object-oriented framework is proposed for constructing a virtual machine (VM) to be used in the context of incrementally and iteratively developing a domain-specific language (DSL). The framework is written in C. It includes abstract instruction and environment classes. By extending these, a concrete layer of classes is obtained whose instances define the semantics of a set of instructions, as well as one or more execution environment instances that can be manipulated by the instructions. The framework provides a generic mechanism for reading a set of instructions, executing them sequentially by default but branching if necessary, storing or retrieving internal variables, and accessing and manipulating the environment as per the instructions. In general, each instruction can execute an arbitrary C method as specified by the developer. The syntactic form of instructions is limited to five possibilities. Using the framework, a range of VMs can be generated, each tailored to support a developer-designed target-level DSL. Since each such language is built in terms of these five instruction formats, these target-level languages share a common syntactic structure. The result is a platform to support an incremental iterative language design and implementation approach that involves the following three phases: determine a set of target-level instructions with semantics appropriate to the specific domain; determine source-level language instructions whose syntax appeals to the domain specialist and provide a simple compiler to map the source to target instructions. The first two phases are relatively disjoint and importantly separate syntax concerns from semantics concerns. The final phase is quite straightforward. Comparative performance results support the use of the framework as an alternative to using an interpreter or hardcoded VM for DSL development. &copy; 2009 The Institution of Engineering and Technology.},
key = {Machine oriented languages},
keywords = {DSL;Graphical user interfaces;Information theory;Linguistics;Modems;Object oriented programming;Query languages;Semantics;Syntactics;Targets;Telecommunication lines;XML;},
note = {C methods;Concrete layers;Domain-Specific Languages;Execution environments;Generic mechanisms;Implementation approaches;Internal variables;Language designs;Object-oriented frameworks;Syntactic structures;Three phasis;Virtual machines;},
URL = {http://dx.doi.org/10.1049/iet-sen:20060068},
} 


@inproceedings{20105113504730 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Human-Centred Software Engineering - Third International Conference, HCSE 2010, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {6409 LNCS},
year = {2010},
issn = {03029743},
address = {Reykjavik, Iceland},
abstract = {The proceedings contain 19 papers. The topics discussed include: approaches to software engineering: a human-centered perspective; model-based design and implementation of interactive spaces for information interaction; a domain specific language for contextual design; an MDE approach for user interface adaptation to the context of use; desktop-to-mobile web adaptation through customizable two-dimensional semantic redesign; the secret lives of assumptions: developing and refining assumption personas for secure system design; dazed and confused considered normal: an approach to create interactive systems for people with dementia; supporting multimodality in service-oriented model-based development environments; web applications usability testing with task model skeletons; evaluating relative contributions of various HCI activities to usability; and understanding formal description of pitch-based input.},
} 


@inproceedings{20114014397211 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Binders unbound},
journal = {ACM SIGPLAN Notices},
author = {Weirich, Stephanie and Yorgey, Brent A. and Sheard, Tim},
volume = {46},
number = {9},
year = {2011},
pages = {333 - 345},
issn = {15232867},
address = {General Post Office, P.O. Box 30777, NY 10087-0777, United States},
abstract = {Implementors of compilers, program refactorers, theorem provers, proof checkers, and other systems that manipulate syntax know that dealing with name binding is difficult to do well. Operations such as &lambda;-equivalence and capture-avoiding substitution seem simple, yet subtle bugs often go undetected. Furthermore, their implementations are tedious, requiring " boilerplate" code that must be updated whenever the object language definition changes. Many researchers have therefore sought to specify binding syntax declaratively, so that tools can correctly handle the details behind the scenes. This idea has been the inspiration for many new systems (such as Beluga, Delphin, FreshML, FreshOCaml, C&alpha;ml, FreshLib, and Ott) but there is still room for improvement in expressivity, simplicity and convenience. In this paper, we present a new domain-specific language, UNBOUND, for specifying binding structure. Our language is particularly expressive-it supports multiple atom types, pattern binders, type annotations, recursive binders, and nested binding (necessary for telescopes, a feature found in dependently-typed languages). However, our specification language is also simple, consisting of just five basic combinators. We provide a formal semantics for this language derived from a locally nameless representation and prove that it satisfies a number of desirable properties. We also present an implementation of our binding specification language as a GHC Haskell library implementing an embedded domain specific language (EDSL). By using Haskell type constructors to represent binding combinators, we implement the EDSL succinctly using datatype-generic programming. Our implementation supports a number of features necessary for practical programming, including flexibility in the treatment of user-defined types, besteffort name preservation (for error messages), and integration with Haskell's monad transformer library. Copyright &copy; 2011 ACM.},
key = {Program compilers},
keywords = {Binders;Formal methods;Problem oriented languages;Semantics;Specification languages;Specifications;Syntactics;Theorem proving;},
note = {Best-effort;Combinators;Delphin;Domain specific languages;Embedded domain specific languages;Error messages;Formal Semantics;Generic programming;Haskell;Implementation support;Monad transformers;Name-binding;Patterns;Proof checkers;Theorem provers;User-defined types;},
URL = {http://dx.doi.org/10.1145/2034574.2034818},
} 


@inproceedings{20080411055579 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Service-Oriented Computing - ICSOC 2007: Fifth International Conference, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {4749 LNCS},
year = {2007},
issn = {03029743},
address = {Vienna, Austria},
abstract = {The proceedings contain 56 papers. The topics discussed include: pattern based SOA development; a domain specific language for web APIs and services mashups; faster and more focused control-flow analysis for business process models through SESE decomposition; discovering service compositions that feature a desired behaviour; architectural decisions and patterns for transactional workflows in SOA; stochastic modeling of composite web services for closed-form analysis of their performance and reliability bottlenecks; monitoring the QoS for web services; specification and verification of artifact behaviours in business process models; maintaining data dependencies across BPEL process fragments; supporting dynamics in service descriptions - the key to automatic service usage; high performance approach for multi-QoS constrained web services selection; and negotiation of service level agreements: an architecture and a search-based approach.},
key = {Web services},
keywords = {Data reduction;Data structures;Information management;Quality of service;Search engines;Specification languages;},
note = {Architectural decisions;Automatic service usages;Service-Oriented Computing;},
} 


@inproceedings{20081511190038 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Language-driven development of Web-based learning applications},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Sierra, Jose-Luis and Fernandez-Manjon, Baltasar and Fernandez-Valmayor, Alfredo},
volume = {4823 LNCS},
year = {2008},
pages = {520 - 531},
issn = {03029743},
address = {Edinburgh, United kingdom},
abstract = {In this paper we propose a language-driven approach for the high-level design of web-based learning applications. In our approach we define a domain-specific language that characterizes the key application aspects. Then we assign a suitable operational semantics to this language, and we keep it independent of low-level implementation details such as interaction / presentation or database updating. The resulting design can be easily implemented using the model-view-controller pattern that is very well supported by standard implementation technologies. In addition, these language-driven designs also allow for rapid prototyping, exploration and early discovery of application features, as well as for rational collaboration processes between instructors and developers. We exemplify our approach with a Socratic Tutoring System. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Computer programming languages},
keywords = {Database systems;Learning systems;Semantics;World Wide Web;},
note = {Development of web-based learning applications;Domain-specific languages document-oriented approach;Language-driven development;Socratic tutors;},
URL = {http://dx.doi.org/10.1007/978-3-540-78139-4_46},
} 


@inproceedings{20093112224413 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Making monads first-class with template Haskell?},
journal = {ACM SIGPLAN Notices},
author = {Kariotis, Pericles S. and Procter, Adam M. and Harrison, William L.},
volume = {44},
number = {2},
year = {2009},
pages = {99 - 110},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Monads as an organizing principle for programming and semantics are notoriously difficult to grasp, yet they are a central and powerful abstraction in Haskell. This paper introduces a domain-specific language, MonadLab, that simplifies the construction of monads, and describes its implementation in Template Haskell. MonadLab makes monad construction truly first class, meaning that arcane theoretical issues with respect to monad transformers are completely hidden from the programmer. The motivation behind the design of MonadLab is to make monadic programming in Haskell simpler while providing a tool for non-Haskell experts that will assist them in understanding this powerful abstraction. Copyright &copy; 2008 ACM.},
key = {Graphical user interfaces},
keywords = {Abstracting;Linguistics;Query languages;},
note = {Domain-specific languages;Haskell;Monad transformers;Monads;Staged programming;},
} 


@inproceedings{20091412009806 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Making monads first-class with template Haskell},
journal = {Haskell'08 - Proceedings of the ACM SIGPLAN 2008 Haskell Symposium},
author = {Kariotis, Pericles S. and Procter, Adam M. and Harrison, William L.},
year = {2008},
pages = {99 - 110},
address = {Victoria, BC, Canada},
abstract = {Monads as an organizing principle for programming and semantics are notoriously difficult to grasp, yet they are a central and powerful abstraction in Haskell. This paper introduces a domain-specific language, MonadLab, that simplifies the construction of monads, and describes its implementation in Template Haskell. MonadLab makes monad construction truly first class, meaning that arcane theoretical issues with respect to monad transformers are completely hidden from the programmer. The motivation behind the design of MonadLab is to make monadic programming in Haskell simpler while providing a tool for non-Haskell experts that will assist them in understanding this powerful abstraction. Copyright &copy; 2008 ACM.},
key = {Graphical user interfaces},
keywords = {Abstracting;Information theory;Linguistics;Query languages;},
note = {Domain-specific languages;Haskell;Monad transformers;Monads;Staged programming;},
URL = {http://dx.doi.org/10.1145/1411286.1411300},
} 


@article{20090111825768 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-checking for adventure videogames},
journal = {Information and Software Technology},
author = {Moreno-Ger, Pablo and Fuentes-Fernandez, Ruben and Sierra-Rodriguez, Jose-Luis and Fernandez-Manjon, Baltasar},
volume = {51},
number = {3},
year = {2009},
pages = {564 - 580},
issn = {09505849},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {This paper describes a model-checking approach for adventure games focusing on &lang;e-Adventure&rang;, a platform for the development of adaptive educational adventure videogames. In &lang;e-Adventure&rang;, games are described using a domain-specific language oriented to game writers. By defining a translation from this language to suitable state-based models, it is possible to automatically extract a verification model for each &lang;e-Adventure&rang; game. In addition, temporal properties to be verified are described using an extensible assertion language, which can be tailored to each specific application scenario. When the framework determines that some of these properties do not hold, it generates an animation of a counterexample. This approach facilitates the collaboration of multidisciplinary teams of experts during the verification of the integrity of the game scripts, exchanging hours of manual verification for semi-automatic verification processes that also facilitate the diagnosis of the conditions that may potentially break the games. &copy; 2008 Elsevier B.V. All rights reserved.},
key = {Model checking},
keywords = {Animation;Computer programming languages;Game theory;Graphical user interfaces;Linguistics;Query languages;},
note = {Adventure games;Application scenarios;Assertion languages;Do-mains;Domain-specific languages;Multidisciplinary teams;Semi automatics;Temporal properties;Verification models;},
URL = {http://dx.doi.org/10.1016/j.infsof.2008.08.003},
} 


@inproceedings{2005219115121 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Cobalt: A Language for Writing Provably-Sound Compiler Optimizations},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Lerner, Sorin and Millstein, Todd and Chambers, Craig},
volume = {132},
year = {2005},
pages = {5 - 17},
issn = {15710661},
abstract = {We overview the current status and future directions of the Cobalt project. Cobalt is a domain-specific language for implementing compiler optimizations as guarded rewrite rules. Cobalt optimizations operate over a C-like intermediate representation including unstructured control flow, pointers to local variables and dynamically allocated memory, and recursive procedures. The design of Cobalt engenders a natural inductive strategy for proving the soundness of optimizations. This strategy is fully automated by requiring an automatic theorem prover to discharge a small set of simple proof obligations for each optimization. We have written a variety of forward and backward intraprocedural dataflow optimizations in Cobalt, including constant propagation and folding, branch folding, full and partial redundancy elimination, full and partial dead assignment elimination, and simple forms of points-to analysis. The implementation of our soundness-checking strategy employs the Simplify automatic theorem prover, and we have used this implementation to automatically prove the above optimizations correct. An execution engine for Cobalt optimizations is implemented as part of the Whirlwind compiler infrastructure. &copy; 2005 Elsevier B.V. All rights reserved.},
key = {Computer programming languages},
keywords = {Computation theory;Optimization;Program assemblers;Program compilers;Redundancy;Theorem proving;},
note = {Assembly languages;Automated correctness proofs;Cobalt languages;Complier optimization;Domain-specific languages;},
URL = {http://dx.doi.org/10.1016/j.entcs.2005.03.022},
} 


@article{20100112612480 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Essay on semantics definition in MDE: An instrumented approach for model verification},
journal = {Journal of Software},
author = {Combemale, Benoit and Cregut, Xavier and Garoche, Pierre-Loic and Thirioux, Xavier},
volume = {4},
number = {9},
year = {2009},
pages = {943 - 958},
issn = {1796217X},
address = {P.O.Box 40, FIN-90571, OULU, Finland},
abstract = {In the context of MDE (Model-Driven Engineering), our objective is to define the semantics for a given DSL (Domain Specific Language) either to simulate its models or to check properties on them using model-checking techniques. In both cases, the purpose is to formalize the DSL semantics as it is known by the DSL designer but often in an informal way. After several experiments to define operational semantics on the one hand, and translational semantics on the other hand, we discuss both approaches and we specify in which cases these semantics seem to be judicious. As a second step, we introduce a pragmatic and instrumented approach to define a translational semantics and to validate it against a reference operational semantics expressed by the DSL designer. We apply this approach to the XSPEM process description language in order to verify process models. &copy; 2009 Academy Publisher.},
key = {Semantics},
keywords = {DSL;Linguistics;Model checking;Models;Modems;Multi agent systems;Telecommunication lines;Translation (languages);},
note = {Domain specific languages;Model verification;Model-checking techniques;Model-driven Engineering;Operational semantics;Process description languages;Process model;},
URL = {http://dx.doi.org/10.4304/jsw.4.9.943-958},
} 


@inproceedings{20104513364221 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Declarative business process modelling and the generation of ERP systems},
journal = {Communications in Computer and Information Science},
author = {Schultz-Mller, Nicholas Poul and Hlmer, Christian and Hansen, Michael R.},
volume = {47},
year = {2009},
pages = {134 - 146},
issn = {18650929},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {We present an approach to the construction of Enterprise Resource Planning (ERP) Systems, which is based on the Resources, Events and Agents (REA) ontology. This framework deals with processes involving exchange and flow of resources in a declarative, graphically-based manner describing what the major entities are rather than how they engage in computations. We show how to develop a domain-specific language on the basis of REA, and a tool which automatically can generate running web-applications. A main contribution is a proof-of-concept showing that business-domain experts can generate their own applications without worrying about implementation details. In order to have a well-defined domain-specific language, a formal model of REA has been developed using the specification language Object-Z and this led to clarifications as well as the introduction of new concepts. The compiler for our language is written in Objective CAML and as implementation platform we used Ruby on Rails. Our aim here is to give an overview of whole construction of a running application from a REA specification and to illustrate the adequacy of the development process. &copy; 2009 Springer-Verlag Berlin Heidelberg.},
key = {Enterprise resource planning},
keywords = {Industry;Ontology;Problem oriented languages;Resource allocation;Specification languages;Specifications;},
note = {Business process modelling;Construction of enterprise;Development process;Domain experts;Domain specific languages;Enterprise Resource Planning systems;ERP system;Formal model;Implementation platforms;Object Z;Proof of concept;REA;Ruby on Rails;Running applications;Web-applications;},
URL = {http://dx.doi.org/10.1007/978-3-642-05201-9_11},
} 


@article{20092912192297 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Experience report: A Haskell interpreter for CellML},
journal = {ACM SIGPLAN Notices},
author = {Cooper, Jonathan and McKeever, Steve},
volume = {42},
number = {9},
year = {2007},
pages = {247 - 250},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {In this paper we present our use of functional programming (FP), specifically Haskell, to provide an operational semantics for a domain-specific language, CellML, that describes mathematical models of biological processes. We analyse the benefits and shortcomings of this approach, in comparison with other semantic definitions for CellML. It is our claim that using FP for our semantics results in a more concise and useful artifact for describing what such a model means. The use of lazy evaluation removes the need to explicitly determine an evaluation order for the model, resulting in a more elegant interpreter. Crucially, using FP enablesustoprovethecorrectnessof optimisation techniques for such models. This gives us more confidence in scientific deductions from simulation results. We compare the Python implementation of these optimisation techniques with our use of Haskell in proving their correctness. &copy; 2007 ACM.},
key = {Semantics},
keywords = {Functional programming;Mathematical programming;Program interpreters;},
note = {Biological process;CellML;Domain specific languages;Evaluation order;Experience report;Haskell;Lazy evaluation;Operational semantics;Optimisation;Simulation result;},
} 


@inproceedings{20080711091695 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Experience report: A Haskell interpreter for cellML},
journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
author = {Cooper, Jonathan and McKeever, Steve},
year = {2007},
pages = {247 - 250},
address = {Freiburg, Germany},
abstract = {In this paper we present our use of functional programming (FP), specifically Haskell, to provide an operational semantics for a domain-specific language, CellML, that describes mathematical models of biological processes. We analyse the benefits and shortcomings of this approach, in comparison with other semantic definitions for CellML. It is our claim that using FP for our semantics results in a more concise and useful artifact for describing what such a model means. The use of lazy evaluation removes the need to explicitly determine an evaluation order for the model, resulting in a more elegant interpreter. Crucially, using FP enables us to prove the correctness of optimisation techniques for such models. This gives us more confidence in scientific deductions from simulation results. We compare the Python implementation of these optimisation techniques with our use of Haskell in proving their correctness. Copyright &copy; 2007 ACM.},
key = {Functional programming},
keywords = {Computer programming languages;Computer simulation;Mathematical models;Object oriented programming;Optimization;Semantics;},
note = {Domain specific languages;},
URL = {http://dx.doi.org/10.1145/1291151.1291190},
} 


@inproceedings{20101012758138 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {DSL route: An efficient integration solution for message routing},
journal = {SKG 2009 - 5th International Conference on Semantics, Knowledge, and Grid},
author = {Tang, Xinhuai and Luo, Xiangfeng and Mi, Xueqiang and Yuan, Xiaozhou and Chen, Delai},
year = {2009},
pages = {436 - 437},
address = {Zhuhai, China},
abstract = {As the core of current enterprise integration solution, messaging systems provide important functionalities for reliable message delivery and complicated service routing. This paper introduces a domain specific language (DSL) route to improve current messaging solution. DSL route provides fluent and graceful route definition. With DSL routes, the integration solutions are more agile and configurable since enterprise integration patterns (EIPs) are naturally supported in DSL route model. &copy; 2009 IEEE.},
key = {Modems},
keywords = {DSL;Semantics;Telecommunication lines;},
note = {Configurable;Domain specific languages;Enterprise Integration;Enterprise integration patterns;Message delivery;Message routing;Messaging system;Service routing;},
URL = {http://dx.doi.org/10.1109/SKG.2009.66},
} 


@inproceedings{20091812056763 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {DSAL'8: Aspect-oriented Software Development - Proceedings of the 2008 AOSD Workshop on Domain-specific Aspect Languages},
journal = {DSAL'08: Proceedings of the 2008 AOSD Workshop on Domain-specific Aspect Languages},
year = {2008},
address = {Brussels, Belgium},
abstract = {The proceedings contain 6 papers. The topics discussed include: a domain-specific language for parallel and grid computing; dynamically linked domain-specific extensions for advice languages; modularizing invasive aspect languages; towards a DSAL for object layout in virtual machines; towards a domain-specific aspect language for leasing in mobile ad hoc networks; and a DSL to declare aspect execution order.},
} 


@inproceedings{20080411045261 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Attribute grammar-based language extensions for java},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Van Wyk, Eric and Krishnan, Lijesh and Bodin, Derek and Schwerdfeger, August},
volume = {4609 LNCS},
year = {2007},
pages = {575 - 599},
issn = {03029743},
address = {Berlin, Germany},
abstract = {This paper describes the ableJ extensible language framework, a tool that allows one to create new domain-adapted languages by importing domain-specific language extensions into an extensible implementation of Java 1.4. Language extensions may define the syntax, semantic analysis, and optimizations of new language constructs. Java and the language extensions are specified as higher-order attribute grammars. We describe several language extensions and their implementation in the framework. For example, one extension embeds the SQL database query language into Java and statically checks for syntax and type errors in SQL queries. The tool supports the modular specification of composable language extensions so that programmers can import into Java the unique set of extensions that they desire. When extensions follow certain restrictions, they can be composed without requiring any implementation-level knowledge of the language extensions. The tools automatically compose the selected extensions and the Java host language specification. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Java programming language},
keywords = {Computational grammars;Optimization;Query languages;Semantics;},
note = {Java host language specifications;Language extensions;SQL database;},
} 


@inproceedings{20093512277606 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {J is for javaScript: A direct-style correspondence between algol-like languages and javascript using first-class continuations},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Danvy, Olivier and Shan, Chung-Chieh and Zerny, Ian},
volume = {5658 LNCS},
year = {2009},
pages = {1 - 19},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {It is a time-honored fashion to implement a domain-specific language (DSL) by translation to a general-purpose language. Such an implementation is more portable, but an unidiomatic translation jeopardizes performance because, in practice, language implementations favor the common cases. This tension arises especially when the domain calls for complex control structures. We illustrate this tension by revisiting Landin's original correspondence between Algol and Church's lambda-notation. We translate domain-specific programs with lexically scoped jumps to JavaScript. Our translation produces the same block structure and binding structure as in the source program, a&grave; la Abdali. The target code uses a control operator in direct style, a&grave; la Landin. In fact, the control operator used is almost Landin's J-hence our title. Our translation thus complements a continuation-passing translation a&grave; la Steele. These two extreme translations require JavaScript implementations to cater either for first-class continuations, as Rhino does, or for proper tail recursion. Less extreme translations should emit more idiomatic control-flow instructions such as for, break, and throw. The present experiment leads us to conclude that translations should preserve not just the data structures and the block structure of a source program, but also its control structure. We thus identify a new class of use cases for control structures in JavaScript, namely the idiomatic translation of control structures from DSLs. &copy; IFIP International Federation for Information Processing 2009.},
key = {Translation (languages)},
keywords = {ALGOL (programming language);Data structures;DSL;Graphical user interfaces;Linguistics;Modems;Program translators;Query languages;Telecommunication lines;},
note = {Block structures;Complex control;Control operators;Control structure;Control-flow;Domain specific;Domain specific languages;Javascript;Recursions;Target codes;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_1},
} 


@inproceedings{20090511881942 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Distributed Computing and Internet Technology - 5th International Conference, ICDCIT 2008, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {5375 LNCS},
year = {2008},
issn = {03029743},
address = {New Delhi, India},
abstract = {The proceedings contain 20 papers. The topics discussed include: a denotational model for Web services choreography; automated testing of description logic reasoners; a domain-specific language for application-level checkpointing; data replication using experienced based trust in a data grid environment; back-edge heuristic for efficient data distribution in grid systems; Web users' personality traits analysis; a new approach for security in MPLS multicast networks; application for a secure fax system; forward-secure multi-signatures; modeling and analysis of mobility in MANeTs for distributed applications; scalability and route failure time of a hybrid protocol for identification of node-disjoint paths in mobile ad hoc networks; a strict priority based QoS-aware MAC protocol for mobile ad hoc networks; and QoS-aware dynamic source routing using diffserv principles.},
} 


@inproceedings{20112714122868 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Bringing domain-specific languages to digital forensics},
journal = {Proceedings - International Conference on Software Engineering},
author = {Van Den Bos, Jeroen and Van Der Storm, Tijs},
year = {2011},
pages = {671 - 680},
issn = {02705257},
address = {Waikiki, Honolulu, HI, United states},
abstract = {Digital forensics investigations often consist of analyzing large quantities of data. The software tools used for analyzing such data are constantly evolving to cope with a multiplicity of versions and variants of data formats. This process of customization is time consuming and error prone. To improve this situation we present Derric, a domain-specific language (DSL) for declaratively specifying data structures. This way, the specification of structure is separated from data processing. The resulting architecture encourages customization and facilitates reuse. It enables faster development through a division of labour between investigators and software engineers. We have performed an initial evaluation of Derric by constructing a data recovery tool. This so-called carver has been automatically derived from a declarative description of the structure of JPEG files. We compare it to existing carvers, and show it to be in the same league both with respect to recovered evidence, and runtime performance. &copy; 2011 ACM.},
key = {Data handling},
keywords = {Computer aided software engineering;Data structures;DSL;Electronic crime countermeasures;Graphical user interfaces;Modems;Problem oriented languages;Software design;XML;},
note = {Data description languages;Data format;Data recovery;Declarative descriptions;Digital forensic;Domain specific languages;Error prones;JPEG files;Model-driven Engineering;Runtime performance;Software engineers;},
URL = {http://dx.doi.org/10.1145/1985793.1985887},
} 


@article{2004128062438 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic generation of device drivers},
journal = {ACM SIGPLAN Notices},
author = {Zhang, Qing-Li and Zhu, Ming-Yuan and Chen, Shuo-Ying},
volume = {38},
number = {6},
year = {2003},
pages = {60 - 69},
issn = {03621340},
abstract = {This paper proposes a new approach to resolve the problem of device driver development: To design a domain specific language, named DEVIL+. With this language, users can write a complete device driver, including: interrupt handler, timer controller, logic controller and so on. DEVIL+ allows a description to be checked for consistency and completeness. This not only improves the safety of the device driver but also uncovers bugs as early as possible in the development process.},
key = {Computer programming languages},
keywords = {Computer aided software engineering;Embedded systems;Input output programs;Interfaces (computer);Logic programming;},
note = {Device drivers;Interrupt handler;Timer controller;},
} 


@inproceedings{20104813441637 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Use of model transformation for the formal analysis of railway interlocking models},
journal = {WIT Transactions on the Built Environment},
author = {Xu, T. and Santos, O.M. and Ge, X. and Woodcock, J.},
volume = {114},
year = {2010},
pages = {815 - 826},
issn = {17433509},
address = {Beijing, China},
abstract = {Model transformation is at the heart of Model-Driven Engineering (MDE). In MDE, the system model is specified using a modelling language, such as UML (Unified Modelling Language) or a DSL (Domain-Specific Language). Once a model is specified, executable code for a computing platform can be automatically generated by means of model transformation (code generation). Besides the support for incremental model development, MDE also enables the formal verification of system properties. In the context of safety-critical systems, such as railway interlockings, the system model (e.g., specified in terms of UML) can be translated to a formal (mathematical) language more amendable to rigorous analysis. This paper presents a model transformation that takes a railway interlocking model (specified in Executable UML (xUML)) as input and outputs a formal model that can be mathematically analysed. This can potentially bridge the gap between well-known modelling languages (such as xUML) and formal languages, which facilitates the systematic development of safety-critical systems in terms of MDE. A small xUML railway interlocking model is used to illustrate the proposed method. &copy; 2010 WIT Press.},
key = {Interlocking signals},
keywords = {Embedded systems;Formal languages;Formal methods;Problem oriented languages;Railroad transportation;Railroads;Safety devices;Safety engineering;Security systems;Software design;Systems analysis;Unified Modeling Language;},
note = {Automatically generated;Code Generation;Computing platform;Domain specific languages;Executable codes;Executable UML;Formal analysis;Formal model;Formal verifications;Incremental models;Input and outputs;Interlockings;model driven engineering (MDE);Model transformation;Model-driven engineering;Modelling language;Railway interlocking system;Rigorous analysis;Safety critical systems;System models;System property;UML (unified modelling language);},
URL = {http://dx.doi.org/10.2495/CR100741},
} 


@inproceedings{20091812056760 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a DSAL for object layout in virtual machines},
journal = {DSAL'08: Proceedings of the 2008 AOSD Workshop on Domain-specific Aspect Languages},
author = {Timbermont, Stijn and Adams, Bram and Haupt, Michael},
year = {2008},
address = {Brussels, Belgium},
abstract = {High-level language virtual machine implementations offer a challenging domain for modularization, not only because they are inherently complex, but also because efficiency is not likely to be traded for modularity. The central data structure used throughout the VM, the object layout, cannot be succinctly modularised by current aspect technology, as provisions for static crosscutting are not fine-grained enough. This position paper motivates the need for a declarative, domain-specific language for handling the tangled object layout concern. Based on observations in real-world VM implementations, we propose such a language, D4OL. It combines a two-level layout mapping, constraints and an engine to divide responsibilities between VM component and VM developers. We consider a domain-specific language like D4OL a necessary complement to behavioural aspect languages in order to modularize VM implementations. &copy; 2008 ACM.},
key = {High level languages},
keywords = {Data structures;Linguistics;Modular construction;Query languages;},
note = {Aspect technologies;Behavioural aspects;Domain-specific aspect language;Domain-specific languages;Modularization;Object layout;Position papers;Real-world;Virtual machine;},
URL = {http://dx.doi.org/10.1145/1404927.1404932},
} 


@article{20111513900557 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A framework for developing home automation systems: From requirements to code},
journal = {Journal of Systems and Software},
author = {Sanchez, Pedro and Jimenez, Manuel and Rosique, Francisca and Alvarez, Barbara and Iborra, Andres},
volume = {84},
number = {6},
year = {2011},
pages = {1008 - 1021},
issn = {01641212},
address = {360 Park Avenue South, New York, NY 10010, United States},
abstract = {This article presents an integrated framework for the development of home automation systems following the model-driven approach. By executing model transformations the environment allows developers to generate executable code for specific platforms. The tools presented in this work help developers to model home automation systems by means of a domain specific language which is later transformed into code for home automation specific platforms. These transformations have been defined by means of graph grammars and template engines extended with traceability capabilities. Our framework also allows the models to be reused for different applications since a catalogue of requirements is provided. This framework enables the development of home automation applications with techniques for improving the quality of both the process and the models obtained. In order to evaluate the benefits of the approach, we conducted a survey among developers that used the framework. The analysis of the outcome of this survey shows which conditions should be fulfilled in order to increase reusability. &copy; 2011 Elsevier Inc. All rights reserved.},
key = {Automation},
keywords = {Embedded systems;Formal languages;Network components;Reusability;Surveys;},
note = {Code Generation;Domain specific languages;Executable codes;Graph grammar;Home automation;Home automation systems;Integrated frameworks;Model driven;Model driven approach;Model transformation;Template engines;},
URL = {http://dx.doi.org/10.1016/j.jss.2011.01.052},
} 


@inproceedings{20103013097953 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven service level management},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Correia, Anacleto and Brito E Abreu, Fernando},
volume = {6155 LNCS},
year = {2010},
pages = {85 - 88},
issn = {03029743},
address = {Zurich, Switzerland},
abstract = {Service-level agreements (SLA) definition and monitoring are open issues within the IT Service Management (ITSM) domain. Our main goals are to propose a model-based approach to IT services SLA specification and compliance verification. The specification will be accomplished by proposing a SLA language-a domain specific language for defining quality attributes as non functional requirements (NFRs) in the context of ITSM. This will allow that SLA monitoring and compliance validation at a level of abstraction that is understood by the stakeholders involved in the service specification. &copy; 2010 Springer-Verlag Berlin Heidelberg.},
key = {Information technology},
keywords = {Access control;Linguistics;Management;Ocean currents;Software architecture;Specifications;},
note = {Compliance validation;Compliance verification;Domain specific languages;IT service management;IT services;Level of abstraction;Model based approach;Model-driven;Non-functional requirements;Quality attributes;Service level agreements;Service level management;Service specifications;},
URL = {http://dx.doi.org/10.1007/978-3-642-13986-4_10},
} 


@inproceedings{20080711091957 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Harpy: Run-time code generation in haskell},
journal = {Haskell'07: Proceedings of the ACM SIGPLAN 2007 Haskell Workshop},
author = {Grabmueller, Martin and Kleeblatt, Dirk},
year = {2007},
pages = {94 - },
address = {Freiburg, Germany},
abstract = {We present Harpy, a Haskell library for run-time code generation of x86 machine code. Harpy provides efficient generation of machine code, a convenient domain specific language for generating code and a collection of code generation combinators.},
key = {Digital libraries},
keywords = {Automatic programming;Computer programming languages;},
note = {Dynamic code generation;Machine code;},
URL = {http://dx.doi.org/10.1145/1291201.1291214},
} 


@inproceedings{20094212372791 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The perceived value of authoring and automating acceptance tests using a model driven development toolset},
journal = {Proceedings of the 2009 ICSE Workshop on Automation of Software Test, AST 2009},
author = {Talby, David},
year = {2009},
pages = {154 - 157},
address = {Vancouver, BC, Canada},
abstract = {One approach to applying keyword driven testing in a model-driven development environment is by defining a domain specific language for test cases. The toolset then provides test editors, versioning, validation, reporting and hyperlinks across models - in addition to enabling automated test execution. This case study evaluates the effectiveness of such a solution as perceived by two teams of professional testers, who used it to test several products over a two year period. The results suggest that in addition to the expected benefits of automation, the solution reduces the time and effort required to write tests, maintain tests and plan the test authoring and execution efforts - at the expense of requiring longer training and a higher bar for recruiting testers.},
key = {Testing},
keywords = {Automation;Computer software;Hypertext systems;},
note = {Acceptance tests;Automated test;Domain specific languages;Hyperlinks;Keyword driven;Model driven development;Perceived value;Test case;Toolsets;Versioning;},
URL = {http://dx.doi.org/10.1109/IWAST.2009.5069055},
} 


@inproceedings{20093512278195 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-Specific Languages - IFIP TC 2 Working Conference, DSL 2009, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {5658 LNCS},
year = {2009},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {The proceedings contain 18 papers. The topics discussed include: J is for JavaScript: a direct-style correspondence between Algol-like languages and JavaScript using first-class continuations; model-driven engineering from modular monadic semantics: implementation techniques targeting hardware and software; a taxonomy-driven approach to visually prototyping pervasive computing applications; LEESA: embedding strategic and XPath-like object structure traversals in C++; combining DSLs and ontologies using metamodel integration; a domain specific language for composable memory transactions in Java; CLOPS: a DSL for command line options; Nettle: a language for configuring routing networks; generic libraries in C++ with concepts from high-level domain descriptions in Haskell: a domain-specific library for computational vulnerability assessment; domain-specific language for HW/SW co-design for FPGAs; a Haskell hosted DSL for writing transformation systems; and varying domain representations in Hagl: extending the expressiveness of a DSL for experimental game theory.},
} 


@inproceedings{20064410207025 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MDA-based Re-engineering with object-Z},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Suc, Jorn Guy and McComb, Tim and Kim, Soon-Kyeong and Wildman, Luke and Watson, Geoffrey},
volume = {4199 LNCS},
year = {2006},
pages = {291 - 305},
issn = {03029743},
address = {Genova, Italy},
abstract = {This paper describes a practical application of MDA and reverse engineering based on a domain-specific modelling language. A well defined metamodel of a domain-specific language is useful for verification and validation of associated tools. We apply this approach to SIFA, a security analysis tool. SIFA has evolved as requirements have changed, and it has no metamodel. Hence, testing SIFA's correctness is difficult. We introduce a formal metamodelling approach to develop a well-defined metamodel of the domain. Initially, we develop a domain model in EMF by reverse engineering the SIFA implementation. Then we transform EMF to Object-Z using model transformation. Finally, we complete the Object-Z model by specifying system behavior. The outcome is a well-defined metamodel that precisely describes the domain and the security properties that it analyses. It also provides a reliable basis for testing the current SIFA implementation and forward engineering its successor. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Reverse engineering},
keywords = {Computer programming languages;Computer simulation;Computer software maintenance;Computer system firewalls;Mathematical models;Mathematical transformations;},
note = {Metamodels;Model transformation;Modelling languages;Security analysis tools;},
} 


@inproceedings{2005229132418 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Programmable type systems for domain specific languages},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Thiemann, Peter},
volume = {76},
year = {2002},
pages = {241 - 259},
issn = {15710661},
abstract = {A language with a programmable type system is vital for the construction of an embedded domain specific language (EDSL). Driven by the requirements posed by the implementation of an EDSL for server-side Web scripting, we examine two major of extensions to the type system of the host language, Haskell. We show that a component that ensures the generation of correct HTML documents can take good advantage of type-level functions, as implemented using functional logic overloading. We further show that a function that ensures the consistency of data submitted to a Web script with the data expected by the script is less awkward to use in the presence of lambda expressions in the type language. In both cases we assess the guarantees obtained by the use of the typing and explore alternative solutions. &copy; 2002 Published by Elsevier Science B.V.},
key = {Computer programming languages},
keywords = {Abstracting;Embedded systems;Functions;HTML;Problem solving;Semantics;World Wide Web;},
note = {Embedded domain specific languages (EDSL);Functional programming languages;Generic programming;Web services;},
URL = {http://dx.doi.org/10.1016/S1571-0661(04)80796-5},
} 


@inproceedings{20113814347549 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Identifying desirable game character behaviours through the application of evolutionary algorithms to model-driven engineering metamodels},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Williams, James R. and Poulding, Simon and Rose, Louis M. and Paige, Richard F. and Polack, Fiona A. C.},
volume = {6956 LNCS},
year = {2011},
pages = {112 - 126},
issn = {03029743},
address = {Szeged, Hungary},
abstract = {This paper describes a novel approach to the derivation of model-driven engineering (MDE) models using metaheuristic search, and illustrates it using a specific engineering problem: that of deriving computer game characters with desirable properties. The character behaviour is defined using a human-readable domain-specific language (DSL) that is interpreted using MDE techniques. We apply the search to the underlying MDE metamodels, rather than the DSL directly, and as a result our approach is applicable to a wide range of MDE models. An implementation developed using the Eclipse Modeling Framework, the most widely-used toolset for MDE, is evaluated. The results demonstrate not only the derivation of characters with the desired properties, but also the identification of unexpected features of the behavioural description language and the game itself. &copy; 2011 Springer-Verlag.},
key = {Models},
keywords = {Problem oriented languages;Software engineering;},
note = {Computer game;Description languages;Domain specific languages;Eclipse modeling framework;Engineering problems;Human-readable;Meta model;Meta-heuristic search;Model-driven engineering;Toolsets;},
URL = {http://dx.doi.org/10.1007/978-3-642-23716-4_13},
} 


@inproceedings{2003057345716 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Tagless staged interpreters for typed languages},
journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
author = {Paalic, Emir and Taha, Walid and Sheard, Tim},
year = {2002},
pages = {218 - 229},
address = {Pittsburgh, PA, United states},
abstract = {Multi-stage programming languages provide a convenient notation for explicitly staging programs. Staging a definitional interpreter for a domain specific language is one way of deriving an implementation that is both readable and efficient. In an untyped setting, staging an interpreter "removes a complete layer of interpretive overhead", just like partial evaluation. In a typed setting however, Hindley-Milner type systems do not allow us to exploit typing information in the language being interpreted. In practice, this can mean a slowdown cost by a factor of three or more. Previously, both type specialization and tag elimination were applied to this problem. In this paper we propose an alternative approach, namely, expressing the definitional interpreter in a dependently typed programming language. We report on our experience with the issues that arise in writing such an interpreter and in designing such a language. To demonstrate the soundness of combining staging and dependent types in a general sense, we formalize our language (called Meta-D) and prove its type safety. To formalize Meta-D, we extend Shao, Saha, Trifonov and Papaspyrou's &lambda;H language to a multilevel setting. Building on &lambda;H allows us to demonstrate type safety in a setting where the type language contains all the calculus of inductive constructions, but without having to repeat the work needed for establishing the soundness of that system.},
key = {Computer programming languages},
keywords = {Computer programming;Program interpreters;Programming theory;Semantics;},
note = {Meta language;Multi stage programming languages;Tagless staged interpreters;Typed languages;},
} 


@inproceedings{20102513027621 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {LiFT: Driving development using a business-readable DSL for web testing},
journal = {ICSTW 2010 - 3rd International Conference on Software Testing, Verification, and Validation Workshops},
author = {Chatley, Robert and Ayres, John and White, Tom},
year = {2010},
pages = {460 - 468},
address = {Paris, France},
abstract = {This paper describes the development and evolution of LiFT, a framework for writing automated tests in a style that makes them very readable, even for non-programmers. We call this style 'literate testing'. By creating a domain-specific language embedded within Java, we were able to write automated tests that read almost like natural language, allowing business requirements to be expressed very clearly. This allows development to be driven from tests that are created by developers and customers together, helping give all stakeholders confidence that the right things are being tested and hence a correct system being built. We discuss the experiences of a team using these tools and techniques in a large commercial project, and the lessons learned from the experience. &copy; 2010 IEEE.},
key = {Verification},
keywords = {Computer programming;Computer software selection and evaluation;Java programming language;Linguistics;Problem oriented languages;Software testing;},
note = {Automated test;Business requirement;Commercial projects;Domain specific languages;Lessons learned;Natural languages;Tools and techniques;Web testing;},
URL = {http://dx.doi.org/10.1109/ICSTW.2010.12},
} 


@inproceedings{20113514266399 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {System synthesis from AADL using Polychrony},
journal = {2011 Electronic System Level Synthesis Conference, ESLsyn 2011},
author = {Ma, Yue and Yu, Huafeng and Gautier, Thierry and Talpin, Jean-Pierre and Besnard, Loic and Le Guernic, Paul},
year = {2011},
address = {San Diego, CA, United states},
abstract = {The increasing system complexity and time to market constraints are great challenges in current electronic system design. Raising the level of abstraction in the design and performing fast yet efficient high-level analysis, validation and synthesis has been widely advocated and considered as a promising solution. Motivated by the same approach, our work on system-level synthesis is presented in this paper: use the high-level modeling, domain-specific, language AADL for system-level co-design; use the formal framework Polychrony, based on the synchronous language Signal, for analysis, validation and synthesis. According to SIGNAL's polychronous model of computation, we propose a model for AADL, which takes both software, hardware and allocation into account. This model enables an early phase timing analysis and synthesis via tools associated with Polychrony. &copy; 2011 IEEE.},
key = {Systems analysis},
keywords = {Design;Electronics engineering;High level languages;System theory;},
note = {AADL;Co-designs;Domain specific;Electronic system design;Formal framework;High-level analysis;High-level modeling;Level of abstraction;Model of computation;Polychrony;Synchronous languages;System complexity;System levels;System synthesis;Time to market;Timing Analysis;},
URL = {http://dx.doi.org/10.1109/ESLsyn.2011.5952285},
} 


@article{20111813953338 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {SoC performance modeling methodology and implementation basedon transaction dataflow},
journal = {Zhejiang Daxue Xuebao (Gongxue Ban)/Journal of Zhejiang University (Engineering Science)},
author = {Meng, Xin and Shen, Hai-Bin and Yan, Xiao-Lang},
volume = {45},
number = {2},
year = {2011},
pages = {314 - 322},
issn = {1008973X},
address = {20 Yugu Road, Hangzhou, 310027, China},
abstract = {Traditional modeling method based on module descriptions is neither accurate nor flexible and also expansive in design iteration. A transaction dataflow based performance modeling (TBPM) methodology for SoC was proposed with data flow specification, resource allocation, performance parameter annotation, and arbitration algorithm specification. The TBPM methodology was implemented by a C++ generic library named TDFLib containing SystemC timing controlling mechanism, and a domain specific language named PML to describe SoC performance model. The PML source code could be used to generate C++ code that includes TDFLib API call, and then the C++ code was compiled and linked with reusable simulation framework to construct an executable model. Cycle-accurate simulation was performed with this model under control of SystemC kernel, and all runtime status was dumped into MySQL database for post analysis. A experiment demonstrated that the TBPM methodology can improve efficiency of architectural design and analysis.},
key = {Data flow analysis},
keywords = {Architectural design;Computer simulation;Computer software;Integrated circuits;Space research;Specifications;},
note = {Architecture designs;Design space exploration;Domain specific languages;Performance analysis modeling;Transaction dataflow;},
URL = {http://dx.doi.org/10.3785/j.issn.1008-973X.2011.02.019},
} 


@article{1999504871260 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {BDL: A specialized language for per-object reactive control},
journal = {IEEE Transactions on Software Engineering},
author = {Bertrand, F. and Augeraud, M.},
volume = {25},
number = {3},
year = {1999},
pages = {347 - 362},
issn = {00985589},
abstract = {The problem of describing the concurrent behavior of objects in object-oriented languages is addressed. The approach taken is to let methods be the behavior units whose synchronization is controlled separate from their specification. Our proposal is a domain-specific language, called BDL, for expressing constraints on this control and actually implementing its enforcement. We propose a model where each object includes a so-called `execution controller,' programmed in BDL. This separates cleanly the concepts of what the methods do, the object processes, from the circumstances in which they are allowed to do it, the control. The object controller ensures that scheduling constraints between the object's methods are met. Aggregate objects can be controlled in terms of their components. This language has a convenient formal base. Thus, using BDL expressions, behavioral properties of objects or groups of interesting objects can be verified. Our approach allows, for example, deadlock detection or verification of safety properties, while maintaining a reasonable code size for the running controller. A compiler from BDL has been implemented, automatically generating controller code in an Esterel program, i.e., in a reactive programming language. From this code, the Esterel compiler, in turn, generates an automaton on which verifications are done. Then this automaton is translated into a C code to be executed. This multistage process typifies the method for successful use of a domain-specific language. This also allows high-level concurrent programming.},
key = {Object oriented programming},
keywords = {Codes (symbols);Computer programming languages;Constraint theory;Program compilers;},
note = {Concurrent object oriented programming;},
URL = {http://dx.doi.org/10.1109/32.798324},
} 


@article{20092612151766 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Making aspect-orientation accessible through syntax-based language composition},
journal = {IET Software},
author = {Winter, V. and Kniesel, G. and Siy, H. and Zand, M.},
volume = {3},
number = {3},
year = {2009},
pages = {219 - 237},
issn = {17518806},
address = {Six Hills Way, Stevenage, SG1 2AY, United Kingdom},
abstract = {A generic syntax-based approach is presented by which a fixed set of aspect-oriented features belonging to an aspect language family L<inf>A</inf> can be applied to a domain-specific language (DSL). The approach centres on the construction of a grammar in which a predefined and fixed set of abstract join points and join point environments are linked with their concrete counterparts within the DSL. This connection enables the behaviour of static weaving to be expressed in a generic manner. The resulting framework is one in which aspect orientation is accessible to non-experts across a wide spectrum of abstractions. &copy; The Institution of Engineering and Technology 2009.},
key = {Linguistics},
keywords = {Abstracting;DSL;Modems;Object oriented programming;Syntactics;Telecommunication lines;},
note = {Aspect orientation;Aspect-oriented;Domain specific languages;Join point;Syntax-based approach;Wide spectrum;},
URL = {http://dx.doi.org/10.1049/iet-sen.2007.0125},
} 


@article{20113314231881 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A technique for non-invasive application-level checkpointing},
journal = {Journal of Supercomputing},
author = {Arora, Ritu and Bangalore, Purushotham and Mernik, Marjan},
volume = {57},
number = {3},
year = {2011},
pages = {227 - 255},
issn = {09208542},
address = {Van Godewijckstraat 30, Dordrecht, 3311 GZ, Netherlands},
abstract = {One of the key elements required for writing self-healing applications for distributed and dynamic computing environments is checkpointing. Checkpointing is a mechanism by which an application is made resilient to failures by storing its state periodically to the disk. The main goal of this research is to enable non-invasive reengineering of existing applications to insert Application-Level Checkpointing (ALC) mechanism. The Domain-Specific Language (DSL) developed in this research serves as a perfect means towards this end and is used for obtaining the ALC-specifications from the end-users. These specifications are used for generating and inserting the actual checkpointing code into the existing application. The performance of the application having the generated checkpointing code is comparable to the performance of the application in which the checkpointing code was inserted manually. With slight modifications, the DSL developed in this research can be used for specifying the ALC mechanism in several base languages (e.g., C/C++, Java, and FORTRAN). &copy; 2010 Springer Science+Business Media, LLC.},
key = {Java programming language},
keywords = {Fault tolerance;Problem oriented languages;Research;Specifications;},
note = {Base language;Check pointing;Computing environments;Domain specific languages;End-users;Key elements;Non-invasive;Self-healing;},
URL = {http://dx.doi.org/10.1007/s11227-010-0383-5},
} 


@inproceedings{2005028787276 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Software development with grammatical approach},
journal = {Informatica (Ljubljana)},
author = {Kosar, Tomaz and Mernik, Marjan and Zumer, Viljem and Henriques, Pedro Rangel and Pereira, Maria Joao Varanda},
volume = {28},
number = {4},
year = {2004},
pages = {393 - 404},
issn = {03505596},
abstract = {The paper presents a grammatical approach to software development. It supports formal software specification using attribute grammars, from which a rapid prototype can be generated, as well as the incremental software development. Domain concepts and relationships among them have to be identified from a problem statement and represented as a context-free grammar. The obtained context-free grammar describes the syntax of a domain-specific language whose semantics is the same as the functionality of the system under implementation. The semantics of this language is then described using attribute grammars from which a compiler is automatically generated. The execution of a particular program written in that domain-specific language corresponds to the execution of a prototype of the system on a particular use case.},
key = {Software engineering},
keywords = {Context free grammars;Life cycle;Program compilers;Rapid prototyping;Semantics;},
note = {Attribute grammers;Domain-specific languages;Software design and modeling;},
} 


@inproceedings{20101612857140 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Ypnos: Declarative, parallel structured grid programming},
journal = {DAMP'10 - Proceedings of the 2010 ACM SIGPLAN Workshop on Declarative Aspects of Multicore Programming},
author = {Orchard, Dominic A. and Bolingbroke, Max and Mycroft, Alan},
year = {2010},
pages = {15 - 24},
address = {Madrid, Spain},
abstract = {A fully automatic, compiler-driven approach to parallelisation can result in unpredictable time and space costs for compiled code. On the other hand, a fully manual approach to parallelisation can be long, tedious, prone to errors, hard to debug, and often architecture-specific. We present a declarative domain-specific language, Ypnos, for expressing structured grid computations which encourages manual specification of causally sequential operations but then allows a simple, predictable, static analysis to generate optimised, parallel implementations. We introduce the language and provide some discussion on the theoretical aspects of the language semantics, particularly the structuring of computations around the category theoretic notion of a comonad. Copyright &copy; 2010 ACM.},
key = {Structured programming},
keywords = {Linguistics;Parallel programming;Problem oriented languages;Technical presentations;},
note = {Comonads;Domain specific languages;Language semantics;Parallel implementations;Parallelisation;Sequential operations;Structured grid;Theoretical aspects;Time and space;},
URL = {http://dx.doi.org/10.1145/1708046.1708053},
} 


@inproceedings{20074410901211 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {AVal: An extensible attribute-oriented programming validator for Java},
journal = {Journal of Software Maintenance and Evolution},
author = {Noguera, Carlos and Pawlak, Renaud},
volume = {19},
number = {4},
year = {2007},
pages = {253 - 275},
issn = {1532060X},
address = {Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom},
abstract = {Attribute-oriented programming (@OP) permits programmers to extend the semantics of a base program by annotating it with attributes defined in an attribute domain-specific language ( AttDSL). In this article, we propose AVal: a Java5 framework for the definition and checking of rules for @OP in Java. We define a set of meta-annotations to allow the validation of @OP programs, as well as the means to extend these meta-annotations by using a compile-time model of the program's source code. AVal is fully integrated into the Eclipse IDE. We show the usefulness of the approach by using examples of its use applied to three AttDSLs: an @OP framework that helps programming Simple API for XML parsers, an @OP extension for the Fractal component model called Fraclet, and the JSR 181 for web services definition. Copyright &copy; 2007 John Wiley &amp; Sons, Ltd.},
key = {Object oriented programming},
keywords = {Codes (symbols);Java programming language;Model checking;Program compilers;Semantics;XML;},
note = {Base programs;Meta annotations;Program checking;Source codes;},
URL = {http://dx.doi.org/10.1002/smr.349},
} 


@inproceedings{20090911933610 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using omg's sysml to support simulation},
journal = {Proceedings - Winter Simulation Conference},
author = {Paredis, Christiaan J. J. and Johnson, Thomas},
year = {2008},
pages = {2350 - 2352},
issn = {08917736},
address = {Miami, FL, United states},
abstract = {Currently, system engineering problems are solved using a wide range of domain-specific models and corresponding languages. It is unlikely that a single unified modeling language will be able to model in sufficient detail the large number of system aspects addressed by these domainspecific languages. Instead, a model integration framework is needed for managing the various modeling languages used to solve systems engineering problems. The Systems Modeling Language (OMG SysMLTM) can provide an answer to this need for model integration. Using SysML, a modeler can abstract a domain-specific language to a level that permits its interaction with other system models. In addition, graph transformation approach can be use to accomplishing automated, bidirectional transformation between SysML and the domain specific language. In this paper, a generic approach for defining such graph transformations is presented.&copy;2008 IEEE.},
key = {Unified Modeling Language},
keywords = {Fischer-Tropsch synthesis;Fourier transforms;Linguistics;Model structures;Models;Query languages;Systems engineering;},
note = {Bidirectional transformations;Domain specifics;Domain-specific languages;Engineering problems;Generic approaches;Graph transformations;Model integrations;Modeling languages;System aspects;System engineerings;System models;Systems modeling;Unified modeling;},
URL = {http://dx.doi.org/10.1109/WSC.2008.4736341},
} 


@inproceedings{20104913464571 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Influence of domain-specific notation to program Understanding},
journal = {Proceedings of the International Multiconference on Computer Science and Information Technology, IMCSIT '09},
author = {Kosar, Tomaz and Mernik, Marjan and Crepinek, Matej and Henriques, Pedro Rangel and Da Cruz, Danielaqs and Pereira, Maria Joao Varanda and Oliveira, Nuno},
volume = {4},
year = {2009},
pages = {675 - 682},
address = {Mragowo, Poland},
abstract = {Application libraries are the most commonly used implementation approach to solve problems in general-purpose languages. Their competitors are domain-specific languages, which can provide notation close to the problem domain. We carried out an empirical study on comparing domain-specific languages and application libraries regarding program understanding. In this paper, one case study is presented. Over 3000 lines of code were studied and more than 86 pages long questionnaires were answered by end-users, answering questions on learning, perceiving and evolving programs written in domain-specific language as well as general-purpose language using application library. In this paper, we present comparison results on end-users' correctness and consumed time. For domain-specific language and application library same problem domain has been used-a well-known open source graph description language, DOT. &copy; 2009 IEEE.},
key = {Problem solving},
keywords = {Computer science;Graphical user interfaces;Information technology;Libraries;Problem oriented languages;},
note = {Commonly used;Comparison result;Description languages;Domain specific;Domain specific languages;Empirical studies;End-users;Implementation approach;Lines of code;Open sources;Problem domain;Program understanding;},
URL = {http://dx.doi.org/10.1109/IMCSIT.2009.5352767},
} 


@inproceedings{20113814339980 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Every animation should have a beginning, a middle, and an end: A case study of using a functor-based animation language},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Matlage, Kevin and Gill, Andy},
volume = {6546 LNCS},
year = {2011},
pages = {150 - 165},
issn = {03029743},
address = {Norman, OK, United states},
abstract = {Animations are sequences of still images chained together to tell a story. Every story should have a beginning, a middle, and an end. We argue that this advice leads to a simple and useful idiom for creating an animation Domain Specific Language (DSL). We introduce our animation DSL, and show how it captures the concept of beginning, middle, and end inside a Haskell applicative functor we call Active. We have an implementation of our DSL inside the image generation accelerator, ChalkBoard, and we use our DSL on an extended example, animating a visual demonstration of the Pythagorean Theorem. &copy; 2011 Springer-Verlag.},
key = {Animation},
keywords = {Functional programming;},
note = {Domain specific languages;Functors;Haskell;Image generations;Pythagorean theorem;Still images;},
URL = {http://dx.doi.org/10.1007/978-3-642-22941-1_10},
} 


@inproceedings{20112514077184 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Extending SysML with AADL concepts for comprehensive system architecture modeling},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Behjati, Razieh and Yue, Tao and Nejati, Shiva and Briand, Lionel and Selic, Bran},
volume = {6698 LNCS},
year = {2011},
pages = {236 - 252},
issn = {03029743},
address = {Birmingham, United kingdom},
abstract = {Recent years have seen a proliferation of languages for describing embedded systems. Some of these languages have emerged from domain-specific frameworks, and some are adaptions or extensions of more general-purpose languages. In this paper, we focus on two widely-used standard languages: the Architecture Analysis and Design Language (AADL) and the Systems Modeling Language (SysML). AADL was born as an avionics-focused domain-specific language and later on has been revised to represent and support a more general category of embedded real-time systems. SysML is an extension of the Unified Modeling Language (UML) intended to support system engineering and modeling. We propose the ExSAM profile that extends SysML by adding AADL concepts to it with the goal of exploiting the key advantages of both languages in a seamless way. More precisely, by using ExSAM and any SysML modeling environment, we will be able to both model system engineering concepts and use AADL analysis tools where needed. We describe the ExSAM profile through several examples and compare it with existing alternatives. We have implemented ExSAM using IBM Rational Rhapsody and evaluated its completeness and usefulness through two case studies. &copy; 2011 Springer-Verlag.},
key = {Unified Modeling Language},
keywords = {Architecture;Control system analysis;Control systems;Embedded systems;Intelligent control;Problem oriented languages;Real time systems;Systems engineering;},
note = {AADL;Architecture modeling languages;Embedded control systems;SysML;Systems modeling languages;},
URL = {http://dx.doi.org/10.1007/978-3-642-21470-7_17},
} 


@inproceedings{20094812515305 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Causal commutative arrows and their optimization},
journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
author = {Liu, Hai and Cheng, Eric and Hudak, Paul},
year = {2009},
pages = {35 - 46},
address = {Edinburgh, United kingdom},
abstract = {Arrows are a popular form of abstract computation. Being more general than monads, they are more broadly applicable, and in particular are a good abstraction for signal processing and dataflow computations. Most notably, arrows form the basis for a domain specific language called Yampa, which has been used in a variety of concrete applications, including animation, robotics, sound synthesis, control systems, and graphical user interfaces. Our primary interest is in better understanding the class of abstract computations captured by Yampa. Unfortunately, arrows are not concrete enough to do this with precision. To remedy this situation we introduce the concept of commutative arrows that capture a kind of non-interference property of concurrent computations. We also add an init operator, and identify a crucial law that captures the causal nature of arrow effects. We call the resulting computational model causal commutative arrows. To study this class of computations in more detail, we define an extension to the simply typed lambda calculus called causal commutative arrows (CCA), and study its properties. Our key contribution is the identification of a normal form for CCA called causal commutative normal form (CCNF). By defining a normalization procedure we have developed an optimization strategy that yields dramatic improvements in performance over conventional implementations of arrows.We have implemented this technique in Haskell, and conducted benchmarks that validate the effectiveness of our approach. When combined with stream fusion, the overall methodology can result in speed-ups of greater than two orders of magnitude. Copyright &copy; 2009 ACM.},
key = {Functional programming},
keywords = {Abstracting;Animation;Computer hardware description languages;Control system synthesis;Differentiation (calculus);Graphical user interfaces;Hydraulics;Linguistics;Optimization;Signal processing;},
note = {Arrows;Data flow language;Program optimization;Reactive programming;Stream processing;},
URL = {http://dx.doi.org/10.1145/1596550.1596559},
} 


@article{20092712169554 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Policies of System Level Pipeline Modeling},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Harcourt, Ed},
volume = {238},
number = {2},
year = {2009},
pages = {13 - 23},
issn = {15710661},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Pipelining is a well understood and often used implementation technique for increasing the performance of a hardware system. We develop several SystemC/C++ modeling techniques that allow us to quickly model, simulate, and evaluate pipelines. We employ a small domain specific language (DSL) based on resource usage patterns that automates the drudgery of boilerplate code needed to configure connectivity in simulation models. The DSL is embedded directly in the host modeling language SystemC/C++. Additionally we develop several techniques for parameterizing a pipeline's behavior based on policies of function, communication, and timing (performance modeling). &copy; 2009 Elsevier B.V. All rights reserved.},
key = {Simulators},
keywords = {DSL;Linguistics;Logic design;Modems;Pipelines;Systems analysis;Telecommunication lines;},
note = {Behavior-based;Domain specific languages;generic programming;Hardware system;Implementation techniques;Modeling languages;Modeling technique;Parameterizing;Performance Modeling;policies;Resource usage;Simulation model;system level design;System level pipelines;SystemC;},
URL = {http://dx.doi.org/10.1016/j.entcs.2009.05.003},
} 


@inproceedings{20103213132850 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An algorithm model to mapping mealy machines for a software manufacture cell Petri net},
journal = {ITNG2010 - 7th International Conference on Information Technology: New Generations},
author = {Fernandes, Danilo Douradinho and Cardoso, Felipe Rafael Mota and Montini, Denis Avila and Supino, Francisco Marcondes and Tasinaffo, Paulo Marcelo and Dias, Luiz Alberto Vieira},
year = {2010},
pages = {1306 - 1308},
address = {Las Vegas, NV, United states},
abstract = {This paper shows how to use the state machines and systematic approaches for modeling software to help improve the consistency of the model, verification and validation of an analysis area through a Domain Specific Language (Domain Specifical Language - DSL), in addition to the refinement of the business process (since the mapping of domain analysis and process of business development). The main objective of this approach is how to obtain systematically a DSL from a domain analysis that may be using the system code compliance to all Business Rules outlined, and no documents and settings very complex. Many problems of Systems Computer Software (Computer Software Systems-CSS) are derived from a specification with and without its behavior defined. To resolve these problems, business rules will be treated since its formalization to its construction and testing. In this context, Petri Nets provide a graphical description technique easy to understand and, closed to state-transition diagrams. Parallelism, concurrency and sincronization are easy to model in a Petri net. Add to this, many techniques and tools (in software) are available for the analysis of Petri nets. However, too much formalization can bring problems to software development and the time and cost grow. Furthermore it is suggested that formal methods have fewer errors than the heuristic methods. &copy; 2010 IEEE.},
key = {Formal methods},
keywords = {Computer software;Contour followers;Graph theory;Heuristic methods;Information technology;Linguistics;Management science;Petri nets;Software design;Verification;},
note = {Algorithm model;Business development;Business Process;Business rules;Domain analysis;Domain specific languages;Graphical description;Modeling softwares;Software development;State machine;State-transition diagrams;System codes;Verification and validation;},
URL = {http://dx.doi.org/10.1109/ITNG.2010.83},
} 


@inproceedings{20113214209188 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {ScienceCloud'11 - Proceedings of the 2nd International Workshop on Scientific Cloud Computing},
journal = {ScienceCloud'11 - Proceedings of the 2nd International Workshop on Scientific Cloud Computing},
year = {2011},
pages = {ACM SIGARCH; The University of Arizona - },
address = {San Jose, CA, United states},
abstract = {The proceedings contain 8 papers. The topics discussed include: the case for being lazy: how to leverage lazy evaluation in MapReduce; cloud resource usage - extreme distributions invalidating traditional capacity planning models; experiences using cloud computing for a scientific workflow application; adaptive rate stream processing for smart grid applications on clouds; an automated approach to cloud storage service selection; Neptune: a domain specific language for deploying HPC software on cloud platforms; Magellan: experiences from a science cloud; and Cumulus: an open source storage cloud for science.},
} 


@inproceedings{20112113995966 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A metamodel based approach for UML notated domain specific modelling language},
journal = {Proceedings - 2011 UKSim 13th International Conference on Modelling and Simulation, UKSim 2011},
author = {Kleins, Arnis and Teilans, Artis and Merkuryev, Yuri and Krasts, Ojars},
year = {2011},
pages = {270 - 275},
address = {Cambridge, United kingdom},
abstract = {This paper focuses on a metamodel based approach to UML systems modelling and simulation. The approach allows creating a system model by operating with artefacts from the problem domain. As a novelty for UML modelling, especially for simulation purposes, the presented meta-model is enriched by a set of stochastic attributes of modelled activities. Modelling process is ensured by developing UML based Domain Specific Language (DSL) that is suitable for the metamodel, where UML diagrams are complemented with attributes necessary for model simulation. A modelling tool prototype was developed with Microsoft Visual Studio using Microsoft Visualization and Modelling SDK. Elaborated models are stored in a model base which conforms to the described metamodel. Relevant DEVS simulation software will be developed for ability to run those models and analyse gathered results. The given approach facilitates increases of the productivity in development of domain specific modelling and simulation tools up to 10 times. &copy; 2011 IEEE.},
key = {Computer simulation},
keywords = {Computer simulation languages;Computer software;Stochastic models;Visualization;},
note = {DEVS simulation;Domain specific languages;Domain-specific modelling;meta-model;MicroSoft;Model base;Model simulation;Modelling process;Modelling tools;Problem domain;simulation;System models;Systems modelling;UML diagrams;UML modelling;Visual studios;},
URL = {http://dx.doi.org/10.1109/UKSIM.2011.58},
} 


@inproceedings{20094512424354 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Causal commutative arrows and their optimization},
journal = {ACM SIGPLAN Notices},
author = {Liu, Hai and Cheng, Eric and Hudak, Paul},
volume = {44},
number = {9},
year = {2009},
pages = {35 - 46},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Arrows are a popular form of abstract computation. Being more general than monads, they are more broadly applicable, and in particular are a good abstraction for signal processing and dataflow computations. Most notably, arrows form the basis for a domain specific language called Yampa, which has been used in a variety of concrete applications, including animation, robotics, sound synthesis, control systems, and graphical user interfaces. Our primary interest is in better understanding the class of abstract computations captured by Yampa. Unfortunately, arrows are not concrete enough to do this with precision. To remedy this situation we introduce the concept of commutative arrows that capture a kind of non-interference property of concurrent computations. We also add an init operator, and identify a crucial law that captures the causal nature of arrow effects. We call the resulting computational model causal commutative arrows. To study this class of computations in more detail, we define an extension to the simply typed lambda calculus called causal commutative arrows (CCA), and study its properties. Our key contribution is the identification of a normal form for CCA called causal commutative normal form (CCNF). By defining a normalization procedure we have developed an optimization strategy that yields dramatic improvements in performance over conventional implementations of arrows.We have implemented this technique in Haskell, and conducted benchmarks that validate the effectiveness of our approach. When combined with stream fusion, the overall methodology can result in speed-ups of greater than two orders of magnitude. &copy; 2009 ACM.},
key = {Computer hardware description languages},
keywords = {Abstracting;Animation;Control system synthesis;Differentiation (calculus);Functional programming;Graphical user interfaces;Linguistics;Signal processing;},
note = {Arrows;Dataflow language;Functional reactiveprogramming;Programoptimization;Stream processing;},
} 


@inproceedings{20102312996622 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {XML templates and caching in WASH},
journal = {Proceedings of the 2003 ACM SIGPLAN Workshop on Haskell, Haskell '03},
author = {Thiemann, Peter},
year = {2003},
pages = {19 - 26},
address = {Uppsala, Sweden},
abstract = {Caching of documents is an important concern on the Web. It is a major win in all situations where bandwidth is limited. Unfortunately, the increasing spread of dynamically generated documents seriously hampers traditional caching techniques in browsers and on proxy servers. WASH/CGI is a Haskell-based domain specific language for creating interactive Web applications. The Web pages generated by a WASH/CGI application are highly dynamic and cannot be cached with traditional means. We show how to implement the dynamic caching scheme of the BigWig language [2] in the context of WASH/CGI. The main issue in BigWig's caching scheme is the distinction between fixed parts (that should be cached) and variable parts (that need not be cached) of a document. Since BigWig is a standalone domain-specific language, its compiler can perform the distinction as part of its static analysis. Hence, the challenge in our implementation is to obtain the same information without involving the compiler. To this end, we extend WASH/CGI's document language by mode annotations and define the translation of the resulting annotated document language into JavaScript. To alleviate the awkwardness of programming directly in annotated language, we have defined a surface syntax in the style of HSP (Haskell Server Pages) [11]. Copyright 2003 ACM.},
key = {Query languages},
keywords = {Linguistics;Problem oriented languages;Program compilers;Servers;World Wide Web;},
note = {Caching scheme;Caching technique;Document languages;Domain specific languages;Dynamic caching;Haskell;Haskell servers;Interactive web applications;Javascript;Proxy server;Web page;Web programming;},
URL = {http://dx.doi.org/10.1145/871895.871898},
} 


@inproceedings{20113914363977 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A DSL for context quality modeling in context-aware applications},
journal = {Advances in Intelligent and Soft Computing},
author = {Hoyos, Jose R. and Preuveneers, Davy and Garcia-Molina, Jesus J. and Berbers, Yolande},
volume = {92},
year = {2011},
pages = {41 - 49},
issn = {18675662},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {Developing reliable context-aware applications remains a big challenge, even after a decade of research in this area. Usually a lot of code is required to handle an application's correct behavior in a variety of different situations. Along with a growing amount of code, also increases the risk of programming errors that may lead to an undesired behavior in particular situations. In this paper we present a domain specific language (DSL) for developing context-aware applications. It allows creating context quality models which are transformed into software artifacts of the final application. This code generation saves time and effort, and helps to ensure an appropriate autonomic behavior at runtime in inherently uncertain situations. &copy; 2011 Springer-Verlag Berlin Heidelberg.},
key = {Computer applications},
keywords = {Artificial intelligence;Image quality;},
note = {Code Generation;Context aware applications;Context-Aware;Domain specific languages;MDD;Programming errors;Quality modeling;Quality models;Runtimes;Software artifacts;Undesired behavior;},
URL = {http://dx.doi.org/10.1007/978-3-642-19937-0_6},
} 


@inproceedings{20111213849603 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Managing feature models with familiar: A demonstration of the language and its tool support},
journal = {ACM International Conference Proceeding Series},
author = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert B.},
year = {2011},
pages = {91 - 96},
address = {Namur, Belgium},
abstract = {Developing software product lines involves modeling a large number of features, usually using feature models, that represent different viewpoints, sub-systems or concerns of the software system. To manage complexity on a large scale, there is a need to separate, relate and compose several feature models while automating the reasoning on their compositions. This demonstration gives an overview of a Domain-Specific Language, familiar, that is dedicated to the management of feature models. Its comprehensive programming environment, based on Eclipse, is also described. It complements existing tool support (i.e., FeatureIDE). Copyright 2011 ACM.},
key = {Software design},
keywords = {Problem oriented languages;},
note = {Domain specific languages;Feature models;Product-lines;Programming environment;Software Product Line;Software systems;Sub-systems;Tool support;},
URL = {http://dx.doi.org/10.1145/1944892.1944903},
} 


@inproceedings{20104313319578 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A DSL for intrusion detection based on Constraint Programming},
journal = {SIN'10 - Proceedings of the 3rd International Conference of Security of Information and Networks},
author = {Salgueiro, Pedro D. and Abreu, Salvador P.},
year = {2010},
pages = {224 - 232},
address = {Taganrog, Rostov-on-Don, Russia},
abstract = {Intrusion Detection Systems (IDS) are increasingly important in computer networks, allowing the early diagnosis and detection of anomalous situations, which could otherwise put network performance at risk or even compromise the security or integrity of user data. In this work we present NeMODe, a domain specific language for network intrusion detection that allows to describe network intrusions that spread across several network packets, relying on Constraint Programming(CP), a programming methodology that starts with a declarative description of the desirable network situations and, based on that description, a set of parameterizations for network intrusion detection mechanisms will execute to find those intrusions. Copyright 2010 ACM.},
key = {Intrusion detection},
keywords = {Computer crime;Computer programming;Constraint theory;Frequency hopping;Network performance;Problem oriented languages;XML;},
note = {Constraint programming;Declarative descriptions;Domain specific languages;Early diagnosis;Intrusion detection systems;Network intrusion detection;Network intrusions;Network packets;Parameterizations;Programming methodology;User data;},
URL = {http://dx.doi.org/10.1145/1854099.1854145},
} 


@inproceedings{2004138082692 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {XML Templates and Caching in WASH},
journal = {Proceedings of the 2003 ACM SIGPLAN Haskell Workshop},
author = {Thiemann, Peter},
year = {2003},
pages = {19 - 26},
address = {Uppsala, Sweden},
abstract = {Caching of documents is an important concern on the Web. It is a major win in all situations where bandwidth is limited. Unfortunately, the increasing spread of dynamically generated documents seriously hampers traditional caching techniques in browsers and on proxy servers. WASH/CGI is a Haskell-based domain specific language for creating interactive Web applications. The Web pages generated by a WASH/CGI application are highly dynamic and cannot be cached with traditional means. We show how to implement the dynamic caching scheme of the BigWig language in the context of WASH/CGI. The main issue in BigWig's caching scheme is the distinction between fixed parts (that should be cached) and variable parts (that need not be cached) of a document. Since BigWig is a standalone domain-specific language, its compiler can perform the distinction as part of its static analysis. Hence, the challenge in our implementation is to obtain the same information without involving the compiler. To this end, we extend WASH/CGI's document language by mode annotations and define the translation of the resulting annotated document language into JavaScript. To alleviate the awkwardness of programming directly in annotated language, we have defined a surface syntax in the style of HSP (Haskell Server Pages).},
key = {World Wide Web},
keywords = {Cache memory;Computer aided software engineering;Computer programming;Database systems;Digital libraries;Program compilers;Web browsers;XML;},
note = {Annotated languages;Caching;Web programming;},
URL = {http://dx.doi.org/10.1145/871895.871898},
} 


@inproceedings{20082211278378 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Languages and Compilers for Parallel Computing: 18th International Workshop, LCPC 2005},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {4339 LNCS},
year = {2006},
pages = {National Science Foundation; International Business Machines Corporation - },
issn = {03029743},
address = {Hawthorne, NY, United states},
abstract = {The proceedings contain 34 papers. The topics discussed include: manipulating MAXLIVE for spill-free register allocation; optimizing packet accesses for a domain specific language on network processors; array replication to increase parallelism in applications mapped to configure architectures; generation of control and data flow graphs from scheduled and pipelined assembly code; optimizing matrix multiplication with a classifier learning system; a language for the compact representation of multiple program versions; evaluating the impact of thread escape analysis on a memory consistency model-aware compiler; concurrency analysis for parallel programs with textually aligned barriers; automatic measurement of instruction cache capacity; an efficient approach for self-scheduling parallel loops on multiprogrammed parallel computers; and compiler supports and optimizations for PAC VLIW DSP processors.},
key = {Parallel processing systems},
keywords = {Data flow analysis;Graph theory;Learning systems;Optimization;},
note = {Concurrency analysis;Model-aware compiler;},
} 


@inproceedings{20102913088685 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {From scripts to specifications: The evolution of a flight software testing effort},
journal = {Proceedings - International Conference on Software Engineering},
author = {Groce, Alex and Havelund, Klaus and Smith, Margaret},
volume = {2},
year = {2010},
pages = {129 - 138},
issn = {02705257},
address = {Cape Town, South africa},
abstract = {This paper describes the evolution of a software testing effort during a critical period for the flagship Mars Science Laboratory rover project at the Jet Propulsion Laboratory. Formal specification for post-run analysis of log files, using a domain-specific language, LogScope, replaced scripted real-time analysis. Log analysis addresses the key problems of on-the-fly approaches and cleanly separates specification and execution. Mining the test repository suggested the inadequacy of the scripted approach, and encouraged a partly engineer-driven development. LogScope development should hold insights for others facing the tight deadlines and reactionary nature of testing for critical projects. LogScope received a JPL Mariner Award for "improving productivity and quality of the MSL Flight Software" and has been discussed as an approach for other flight missions. We note LogScope features that most contributed to ease of adoption and effectiveness. LogScope is general and can be applied to any software producing logs. &copy; 2010 ACM.},
key = {Computer software selection and evaluation},
keywords = {Internal combustion engines;Martian surface analysis;Problem oriented languages;Software testing;Space flight;Specifications;Temporal logic;Time domain analysis;Verification;},
note = {Critical periods;Critical projects;development practices;Domain specific languages;Flight mission;Flight Software;Formal Specification;Jet Propulsion Laboratory;Key problems;Log analysis;Log file;logs;Mars science laboratory;On-the-fly;Post-run analysis;Python;Real time analysis;Run-time verification;Testing effort;},
URL = {http://dx.doi.org/10.1145/1810295.1810314},
} 


@article{20073710812024 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Google's MapReduce programming model - Revisited},
journal = {Science of Computer Programming},
author = {Lammel, Ralf},
volume = {68},
number = {3},
year = {2007},
pages = {208 - 237},
issn = {01676423},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Google's MapReduce programming model serves for processing large data sets in a massively parallel manner. We deliver the first rigorous description of the model including its advancement as Google's domain-specific language Sawzall. To this end, we reverse-engineer the seminal papers on MapReduce and Sawzall, and we capture our findings as an executable specification. We also identify and resolve some obscurities in the informal presentation given in the seminal papers. We use typed functional programming (specifically Haskell) as a tool for design recovery and executable specification. Our development comprises three components: (i) the basic program skeleton that underlies MapReduce computations; (ii) the opportunities for parallelism in executing MapReduce computations; (iii) the fundamental characteristics of Sawzall's aggregators as an advancement of the MapReduce approach. Our development does not formalize the more implementational aspects of an actual, distributed execution of MapReduce computations. &copy; 2007 Elsevier B.V. All rights reserved.},
key = {Computer programming languages},
keywords = {Computational methods;Data processing;Functional programming;Mathematical models;Parallel programming;Software design;},
note = {Distributed programming;Executable specification;List homomorphism;Typed functional programming;},
URL = {http://dx.doi.org/10.1016/j.scico.2007.07.001},
} 


@inproceedings{20111013716590 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An embedded language for programming protocol stacks in embedded systems},
journal = {PERM'11 - Proceedings of the 20th ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation},
author = {Wang, Yan and Gaspes, Veronica},
year = {2011},
pages = {63 - 72},
address = {Austin, TX, United states},
abstract = {Protocol stack specifications are well-structured documents that follow a number of conventions and notations that have proven very useful for the design and dissemination of communication protocols. Protocol stack implementations on the other hand, are done in low-level languages, using error-prone programming techniques resulting in programs that are difficult to relate to the specifications, difficult to maintain, modify, extend and reuse. To overcome these problems we propose a domain-specific language that provides abstractions close to the notations used in protocol specifications. From descriptions in our language we generate C programs that can be integrated with other systems software. The language provides constructs to describe packet formats, including physical layout, constraints and dependencies. It also provides constructs for state machines and for layering protocols into stacks. Experiments show that the C programs we generate are comparable in performance and binary size to hand-crafted C programs. &copy; 2011 ACM.},
key = {Computer software reusability},
keywords = {C (programming language);Communication;Embedded software;Embedded systems;Problem oriented languages;Specifications;},
note = {C programs;Communication protocols;Domain specific languages;Embedded compilation;Embedded Languages;Embedded network;Error prones;Low-level language;Packet formats;Physical layout;Programming technique;Protocol specifications;Protocol stack;State machine;Structured document;Systems software;},
URL = {http://dx.doi.org/10.1145/1929501.1929511},
} 


@inproceedings{20112914162229 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Implementing the compiler of UDLC},
journal = {Proceedings - 9th International Conference on Grid and Cloud Computing, GCC 2010},
author = {Hu, Caihua and Zhang, Rui Sheng and Wei, Tong Ming and Wei, Rui Peng and Li, Shu Ping and Cheng, Yao},
year = {2010},
pages = {383 - 387},
address = {Nanjing, Jiangsu, China},
abstract = {The increasing complexity of chemical problems often requiring multiple chemical software work together to complete. Most chemical software uses different script languages to describe jobs, chemists have to consume lots of time to learn them before work. Unified Job-Description Language on Chemical Grid (UDLC) is designed to solve the problem. It is a domain specific-language (DSL), aims at reducing the cost of chemical research substantially by providing a general-purpose chemical job description language standard on grid. Using UDLC to describe a job is simple and can be translate to other chemical software script automatically by computer. Many heterogeneous chemical resources integrated in the grid can be directly invoked using UDLC. In this article, we focus on the three main parts in implementing the compiler of UDLC. Firstly, use ANTLR to build Abstract Syntax tree (AST) for UDLC. The AST is an intermediate form not only records the content of the UDLC input, but also records the structure of it. With the help of AST, we can get the chemical information out conveniently. Secondly, traverse the AST for Semantic processing. The major task of this part is to map the AST into chemical markup language (CML) file and produce jobs written by specified chemical script languages. Lastly, generate the target code. In this part, we insert the jobs into flow control sentences to make the target JAVA code which will be executed in the dynamic runtime we built. &copy; 2010 IEEE.},
key = {Program compilers},
keywords = {Cloud computing;Computer systems;Employment;Job analysis;Semantics;Trees (mathematics);XML;},
note = {Abstract Syntax Trees;ANTLR;AST;Chemical information;Chemical markup languages;Chemical problems;Chemical research;Java codes;Job description;Runtimes;Script Languages;Semantic processing;Software use;Target codes;UDLC;},
URL = {http://dx.doi.org/10.1109/GCC.2010.80},
} 


@inproceedings{20104213302780 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {IPTV service modeling in magneto networks},
journal = {2010 IEEE/IFIP Network Operations and Management Symposium Workshops, NOMS 2010},
author = {Handurukande, Sidath and Wallin, Stefan and Jonsson, Andreas},
year = {2010},
pages = {51 - 54},
address = {Osaka, Japan},
abstract = {One of the main steps of service assurance is service monitoring using Key Performance Indicators (KPIs) and Service Level Agreements (SLAs). We show an approach for service modeling, first starting with an abstract service model that depends on the network. And then, we show how a corresponding model can be realized using a domain specific language. This solution is able to condense various sources of service model requirements into a condense formal and executable model including service decomposition and KPI aggregation. We have described this solution in the context of Magneto project and uses IPTV as a service in our description. &copy; 2010 IEEE.},
key = {Technical presentations},
keywords = {Benchmarking;IPTV;Magnetos;},
note = {Domain specific languages;Executable model;IPTV services;Key performance indicators;Service assurance;Service Level Agreements;Service Model;Service modeling;Service monitoring;},
URL = {http://dx.doi.org/10.1109/NOMSW.2010.5486602},
} 


@inproceedings{20102913088721 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A flexible tool suite for change-aware test-driven development of web applications},
journal = {Proceedings - International Conference on Software Engineering},
author = {Robles Luna, Esteban and Burella, Juan and Grigera, Julian and Rossi, Gustavo},
volume = {2},
year = {2010},
pages = {297 - 298},
issn = {02705257},
address = {Cape Town, South africa},
abstract = {Though Web Applications development fits well with Test-Driven Development, there are some problems that hinder its success. In this demo we present a tool suite to improve TDD; the suite supports the representation of web requirements using a domain-specific language and the automatic generation of interaction tests among others. &copy; 2010 ACM.},
key = {World Wide Web},
keywords = {Computer software;Management;Problem oriented languages;},
note = {Automatic Generation;Change management;Domain specific languages;Flexible tool;Test driven development;Toolsuite;WEB application;Web engineering;},
URL = {http://dx.doi.org/10.1145/1810295.1810359},
} 


@inproceedings{20104413350215 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings - 2010 6th World Congress on Services, Services-1 2010},
journal = {Proceedings - 2010 6th World Congress on Services, Services-1 2010},
year = {2010},
pages = {IEEE Comput. Soc. Tech. Comm. Serv. Comput. (TC-SVC) - },
address = {Miami, FL, United states},
abstract = {The proceedings contain 116 papers. The topics discussed include: an adaptive solution for web service composition; LOG4SWS.KOM: self-adapting semantic web service discovery for SAWSDL; proactive SLA negotiation for service based systems; towards knowledge management in self-adaptable clouds; a SOA approach for domain-specific language implementation; PECoDiM: an agent based framework for autonomic web services; service discovery with semantic characteristics; a service composition approach for the fulfillment of temporally sequential requirements; an approach to event driven services and composite services; improving performance for decentralized execution of composite web services; model driven approach for dynamic service composition based on QoS constraints; integrating information systems using web oriented integration architecture and RESTful web services; and ranking-based suggestion algorithms for semantic web service composition.},
} 


@article{20091612039585 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Constructive and destructive use of compilers in elliptic curve cryptography},
journal = {Journal of Cryptology},
author = {Barbosa, M. and Moss, A. and Page, D.},
volume = {22},
number = {2},
year = {2009},
pages = {259 - 281},
issn = {09332790},
address = {233 Springer Street, New York, 10013-1578, United States},
abstract = {Although cryptographic software implementation is often performed by expert programmers, the range of performance and security driven options, as well as more mundane software engineering issues, still make it a challenge. The use of domain specific language and compiler techniques to assist in description and optimisation of cryptographic software is an interesting research challenge. In this paper we investigate two aspects of such techniques, focusing on Elliptic Curve Cryptography (ECC) in particular. Our constructive results show that a suitable language allows description of ECC based software in a manner close to the original mathematics; the corresponding compiler allows automatic production of an executable whose performance is competitive with that of a hand-optimised implementation. In contrast, we study the worrying potential for nai&die;ve compiler driven optimisation to render cryptographic software insecure. Both aspects of our work are set within the context of CACE, an ongoing EU funded project on this general topic. &copy; 2008 International Association for Cryptologic Research.},
key = {Cryptography},
keywords = {Linguistics;Program compilers;Software engineering;},
note = {Compilers;Elliptic curve cryptography (ECC);Implementation;Optimisation;Specialisation;},
URL = {http://dx.doi.org/10.1007/s00145-008-9023-0},
} 


@inproceedings{20084811738138 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {FlatCAD and flatlang: Kits by code},
journal = {Proceedings - 2008 IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC 2008},
author = {Johnson, Gabe},
year = {2008},
pages = {117 - 120},
address = {Herrsching am Ammersee, Germany},
abstract = {The FlatCAD system lets you create physical construction kits by coding in the LOGO-like FlatLang language. Designers often use structured CAD tools to specify physical form. Programming offers an alternative and powerful method for designing shapes. This paper describes our experimental domain-specific language used to program and manufacture physical shape in the domain of construction kits. &copy; 2008 IEEE.},
key = {Linguistics},
keywords = {Computer aided design;Programming theory;Query languages;},
note = {CAD tools;Construction kits;Do-mains;Specific languages;},
URL = {http://dx.doi.org/10.1109/VLHCC.2008.4639070},
} 


@inproceedings{20103013092355 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An industrial case study using an MBE approach: From architecture to safety analysis},
journal = {ISORC Workshops 2010 - 2010 13th IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing Workshops},
author = {Dalpez, Stefano and Passerone, Roberto and Cancila, Daniela and Terrier, Francois},
volume = {2},
year = {2010},
pages = {116 - 122},
address = {Carmona, Sevilla, Spain},
abstract = {We discuss the initial phases of software development of a real industrial safety-related device in the railway application domain. In particular, to achieve greater confidence in the system, we illustrate the development of the system architecture (using a standard model domain-specific language), the computation of the safety integrity level and the calculation of the reliability of the whole system. We reiterate the safety analysis on the sub-systems. The proposed methodology has found immediate industrial applications. &copy; 2010 IEEE.},
key = {Quality assurance},
keywords = {Hazards;Industrial applications;Industrial railroads;Industry;Problem oriented languages;Reliability analysis;Risk management;Security systems;Software design;Standardization;},
note = {Industrial case study;Industrial safety;Initial phasis;Model-based;Model-based safety engineering;Preliminary hazard analysis;Railway applications;Safety analysis;Safety integrity levels;Software development;Standard model;Sub-systems;System architectures;Whole systems;},
URL = {http://dx.doi.org/10.1109/ISORCW.2010.11},
} 


@inproceedings{20095112547965 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {DNA Computing and Molecular Programming - 15th International Conference, DNA 15, Revised Selected Papers},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {5877 LNCS},
year = {2009},
pages = {Air Force Office of Scientific Research; Arkansas Biosciences Institute; Arkansas Science and Technology Authority; University of Arkansas College of Engineering; University of Arkansas Graduate School - },
issn = {03029743},
address = {Fayetteville, AR, United states},
abstract = {The proceedings contain 16 papers. The topics discussed include: filter position in networks of evolutionary processors does not matter: a direct proof; strand algebras for DNA computing; a domain-specific language for programming in the tile assembly model; advancing the deoxyribozyme-based logic gate design process; DNA chips for species identification and biological phylogenies; renewable, time-responsive DNA logic gates for scalable digital circuits; self-assembly of the discrete Sierpinski carpet and related fractals; automatic design of DNA logic gates based on kinetic simulation; design of a biomolecular device that executes process algebra; the effect of malformed tiles on tile assemblies within kTAM; positional state representation and its transition control for photonic DNA automation; construction of AND gate for RTRACS with the capacity of extension to NAND gate; and time-complexity of multilayered DNA strand displacement circuits.},
} 


@inproceedings{20064310192192 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Language-driven development of videogames: The e-game experience},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Moreno-Ger, Pablo and Martinez-Ortiz, Ivan and Sierra, Jose Luis and Fernandez-Manjon, Baltasar},
volume = {4161 LNCS},
year = {2006},
pages = {153 - 164},
issn = {03029743},
address = {Cambridge, United kingdom},
abstract = {In this paper we describe a language-driven approach to the development of videogames. In our approach the development process starts with the design of a suitable domain-specific language for building games, along with an abstract syntax for the language and its operational semantics. Next an engine supporting the language is built. Finally games are built using the customized language and they are executed using the engine. This approach is exemplified with the &lang;e-Game&rang; project, which delivers the design of a language and the construction of an engine for the documental development of graphical adventure videogames with educational purposes. &copy; IFIP International Federation for Information Processing 2006.},
key = {Animation},
keywords = {Computer programming languages;Project management;Semantics;Syntactics;},
note = {Adventure games;Development process;Document-oriented approach;Storyboard markup language;},
} 


@article{20063810118906 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {HOTTest: A model-based test design technique for enhanced testing of domain-specific applications},
journal = {ACM Transactions on Software Engineering and Methodology},
author = {Sinha, Avik and Smidts, Carol},
volume = {15},
number = {3},
year = {2006},
pages = {242 - 278},
issn = {1049331X},
abstract = {Model-based testing is an effective black-box test generation technique for applications. Existing model-based testing techniques, however, fail to capture implicit domain-specific properties, as they overtly rely on software artifacts such as design documents, requirement specifications, etc., for completeness of the test model. This article presents a technique, HOTTest, which uses a strongly typed domain-specific language to model the system under test. This allows extraction of type-related system invariants, which can be related to various domain-specific properties of the application. Thus, using HOTTest, it is possible to automatically extract and embed domain-specific requirements into the test models. In this article we describe HOTTest, its principles and methodology, and how it is possible to relate domain-specific properties to specific type constraints. HOTTest is described using the example of HaskellDB, which is a Haskell-based embedded domain-specific language for relational databases. We present an example application of the technique and compare the results to some other commonly used Model-based test automation techniques like ASML-based testing, UML-based testing, and EFSM-based testing. &copy; 2006 ACM.},
key = {Software engineering},
keywords = {Automation;Computer programming languages;Database systems;Embedded systems;Mathematical models;},
note = {Database-specific test case generation;Domain-specific languages;Domain-specific testing;HaskellDB;Haskells;Model-based testing;Test case generation;Test generation tools;},
URL = {http://dx.doi.org/10.1145/1151695.1151697},
} 


@inproceedings{2004128062420 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatically proving the correctness of compiler optimizations},
journal = {ACM SIGPLAN Notices},
author = {Lerner, Sorin and Millstein, Todd and Chambers, Craig},
volume = {38},
number = {5},
year = {2003},
pages = {220 - 231},
issn = {03621340},
address = {San Diego, CA, United states},
abstract = {We describe a technique for automatically proving compiler optimizations sound, meaning that their transformations are always semantics-preserving. We first present a domain-specific language, called Cobalt, for implementing optimizations as guarded rewrite rules. Cobalt optimizations operate over a C-like intermediate representation including unstructured control flow, pointers to local variables and dynamically allocated memory, and recursive procedures. Then we describe a technique for automatically proving the soundness of Cobalt optimizations. Our technique requires an automatic theorem prover to discharge a small set of simple, optimization-specific proof obligations for each optimization. We have written a variety of forward and backward intraprocedural dataflow optimizations in Cobalt, including constant propagation and folding, branch folding, full and partial redundancy elimination, full and partial dead assignment elimination, and simple forms of points-to analysis. We implemented our soundness-checking strategy using the Simplify automatic theorem prover, and we have used this implementation to automatically prove our optimizations correct. Our checker found many subtle bugs during the course of developing our optimizations. We also implemented an execution engine for Cobalt optimizations as part of the Whirlwind compiler infrastructure.},
key = {Error correction},
keywords = {Formal logic;Optimization;Program compilers;Program debugging;Redundancy;Semantics;Software engineering;Storage allocation (computer);Subroutines;},
note = {Compiler optimization;Partial redundancy elimination;Validation;Verification;},
} 


@inproceedings{20110113547642 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Implementing domain specific process modelling},
journal = {Communications in Computer and Information Science},
author = {Volz, Bernhard and Dornstauder, Sebastian},
volume = {69 CCIS},
year = {2010},
pages = {120 - 132},
issn = {18650929},
address = {Milan, Italy},
abstract = {Business process modelling becomes more productive when modellers can use process modelling languages which optimally fit to the application domain. This requires the proliferation and management of domain specific modelling languages and modelling tools. In this paper we address the issue of providing domain specific languages in a systematic and structural way without having to implement modelling tools for each domain specific language separately. Our approach is based on a two dimensional meta modelling stack. &copy; 2010 Springer-Verlag.},
key = {Software engineering},
note = {Application domains;Business process modelling;Domain specific;Domain specific languages;Domain-specific modelling;Meta-modelling;Modelling tools;Process modelling;},
URL = {http://dx.doi.org/10.1007/978-3-642-14819-4_9},
} 


@inproceedings{2002507274262 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Business compilers: Towards supporting a highly re-configurable architectural style for service-oriented architecture},
journal = {Conference on Software Maintenance},
author = {Arsanjani, Ali},
year = {2002},
pages = {287 - 288},
address = {Montreal, Canada},
abstract = {Grammar-oriented Object design (GOOD) uses a business domain-specific language to model the flow and constraints on a set of collaborating enterprise components (EC). Maintenance of these components and their flow composition is a major issue. We present a software tool called the Business Compiler (BC) that facilitates the definition, debugging and execution of business flow languages in order to help animate and execute the collaboration of components reflecting the business process steps defined by a business modeler. Architects enhance the grammar with component services that serve as actions in the grammar. The combination of flow definition by modelers and component services by software architects provides a powerful collaborative environment for enabling the incremental creation of a highly re-configurable architectural style. BC consists of an application framework that supports component-based development and includes a GUI debugger front end. This helps modelers by providing dynamic documentation and can be used by architects to create and execute a formal specification of business flow to facilitate maintainability through a highly adaptive and re-configurable architectural style.},
key = {Computer aided software engineering},
keywords = {Administrative data processing;Graphical user interfaces;Program compilers;Program debugging;},
note = {Grammar oriented object design (GOOD);},
URL = {http://dx.doi.org/10.1109/ICSM.2002.1167783},
} 


@article{20112814142308 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific languages bridge the semantic gap in programming},
journal = {Queue},
author = {Ghosh, Debasish},
volume = {9},
number = {6},
year = {2011},
pages = {10 - 21},
issn = {15427730},
address = {General Post Office, P.O. Box 30777, NY 10087-0777, United States},
abstract = {One of the main reasons why software projects fail is the lack of communication between the business users, who actually know the problem domain, and the developers who design and implement the software model. Business users understand the domain terminology, and they speak a vocabulary that may be quite alien to the software people; it's no wonder that the communication model can break down right at the beginning of the project life cycle. A DSL (domain-specific language)1,3 bridges the semantic gap between business users and developers by encouraging better collaboration through shared vocabulary. The domain model that the developers build uses the same terminologies as the business. The abstractions that the DSL offers match the syntax and semantics of the problem domain. As a result, users can get involved in verifying business rules throughout the life cycle of the project. This article describes the role that a DSL plays in modeling expressive business rules. It starts with the basics of domain modeling and then introduces DSLs, which are classified according to implementation techniques. The article then explains in detail the design and implementation of an embedded DSL from the domain of securities trading operations. &copy; 2011 ACM.},
key = {Semantics},
keywords = {Graphical user interfaces;Information theory;Life cycle;Problem oriented languages;Terminology;XML;},
note = {Break down;Business rules;Business-users;Communication models;Domain model;Domain modeling;Domain specific languages;Implementation techniques;Problem domain;Project life cycle;Semantic gap;Software model;Software project;},
URL = {http://dx.doi.org/10.1145/1989748.1989750},
} 


@inproceedings{20093512277607 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven engineering from modular monadic semantics: Implementation techniques targeting hardware and software},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Harrison, William L. and Procter, Adam M. and Agron, Jason and Kimmell, Garrin and Allwein, Gerard},
volume = {5658 LNCS},
year = {2009},
pages = {20 - 44},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {Recent research has shown how the formal modeling of concurrent systems can benefit from monadic structuring. With this approach, a formal system model is really a program in a domain specific language defined by a monad for shared-state concurrency. Can these models be compiled into efficient implementations? This paper addresses this question and presents an overview of techniques for compiling monadic concurrency models directly into reasonably efficient software and hardware implementations. The implementation techniques described in this article form the basis of a semantics-directed approach to model-driven engineering. &copy; IFIP International Federation for Information Processing 2009.},
key = {XML},
keywords = {Computer software;DSL;Hardware;Linguistics;Model structures;Modems;Query languages;Semantics;Systems analysis;Telecommunication lines;},
note = {Concurrent systems;Domain specific languages;Efficient implementation;Formal modeling;Formal systems;Hardware and software;Hardware implementations;Implementation techniques;Model-driven Engineering;Modular monadic semantics;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_2},
} 


@inproceedings{2003317571763 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatically proving the correctness of compiler optimizations},
journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
author = {Lerner, Sorin and Millstein, Todd and Chambers, Craig},
year = {2003},
pages = {220 - 231},
address = {San Diego, CA, United states},
abstract = {We describe a technique for automatically proving compiler optimizations sound, meaning that their transformations are always semantics-preserving. We first present a domain-specific language, called Cobalt, for implementing optimizations as guarded rewrite rules. Cobalt optimizations operate over a C-like intermediate representation including unstructured control flow, pointers to local variables and dynamically allocated memory, and recursive procedures. Then we describe a technique for automatically proving the soundness of Cobalt optimizations. Our technique requires an automatic theorem prover to discharge a small set of simple, optimization-specific proof obligations for each optimization. We have written a variety of forward and backward intraprocedural dataflow optimizations in Cobalt, including constant propagation and folding, branch folding, full and partial redundancy elimination, full and partial dead assignment elimination, and simple forms of points-to analysis. We implemented our soundness-checking strategy using the Simplify automatic theorem prover, and we have used this implementation to automatically prove our optimizations correct. Our checker found many subtle bugs during the course of developing our optimizations. We also implemented an execution engine for Cobalt optimizations as part of the Whirlwind compiler infrastructure.},
key = {Program compilers},
keywords = {Optimization;Semantics;Theorem proving;},
note = {Pointers;},
URL = {http://dx.doi.org/10.1145/781131.781156},
} 


@inproceedings{20112914153936 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A marking language for the oto assignment marking tool},
journal = {ITiCSE'11 - Proceedings of the 16th Annual Conference on Innovation and Technology in Computer Science},
author = {Tremblay, Guy and Lessard, Paul},
year = {2011},
pages = {148 - 152},
address = {Darmstadt, Germany},
abstract = {Marking programming assignments involves a lot of work, and with large classes, the feedback provided to students through marking is often rather limited and late. Oto is a customizable and extensible marking tool that provides support for the submission and marking of assignments. Oto aims at reducing the marking workload and, also, at providing timely feedback to students. In this paper, we present Oto's new marking language and give an overview of its implementation as a Domain-Specific Language. &copy; 2011 ACM.},
key = {Innovation},
keywords = {Computer aided software engineering;Computer programming;Engineering research;Problem oriented languages;},
note = {Automated marking;Customizable;Domain specific languages;Educational software;Large class;Programming assignments;scripting;Timely feedback;},
URL = {http://dx.doi.org/10.1145/1999747.1999791},
} 


@inproceedings{1998394311346 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic generation of microarchitecture simulators},
journal = {Proceedings of the IEEE International Conference on Computer Languages},
author = {Onder, Soner and Gupta, Rajiv},
year = {1998},
pages = {80 - 89},
issn = {10748970},
address = {Chicago, IL, USA},
abstract = {In this paper we describe the UPFAST system that automatically generates a cycle level simulator, an assembler and a disassembler from a microarchitecture specification written in a domain specific language called the Architecture Description Language (ADL). Using the UPFAST system it is easy to retarget a simulator for an existing architecture to a modified architecture since one has to simply modify the input specification and the new simulator is generated automatically. UPFAST also allows porting of simulators to different platforms with minimal effort. We have been able to develop three simulators ranging from simple pipelined processors to complicated out-of-order issue processors over a short period of three months. While the specifications of the architectures varied from 5000 to 6000 lines of ADL code, the sizes of automatically generated software varied from 20,000 to 30,000 lines of C++ code. The automatically generated simulators are less than 2 times slower than hand coded simulators for similar architectures.},
key = {Computer architecture},
keywords = {C (programming language);Codes (symbols);Computer hardware description languages;Computer simulation;Computer systems programming;Pipeline processing systems;},
note = {Architecture description languages (ADL);Microarchitecture simulators;},
} 


@inproceedings{20103813238963 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Reliability analysis of safety-related communication architectures},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Schulz, Oliver and Peleska, Jan},
volume = {6351 LNCS},
year = {2010},
pages = {1 - 14},
issn = {03029743},
address = {Vienna, Austria},
abstract = {In this paper we describe a novel concept for reliability analysis of communication architectures in safety-critical systems. This concept has been motivated by applications in the railway control systems domain, where transitions into stable safe state are usually considered as undesired events because they cause a severe deterioration of the service reliability expected by end users. We introduce a domain-specific language for modelling communication architectures, the protocols involved and the fault hypotheses about anticipated deviations of communication channels and possibly other components from expected behaviour. From such model, a generator creates mutant models associated with probability formulae expressing each mutant's probability of occurrence. Each mutant is analysed with respect to its unreliability, that is, whether it contains paths leading into stable safe state. Then the system reliability can be conservatively estimated by calculating an upper bound of the probability for the system to perform a transition into stable safe state within a given operational period. Our approach deliberately refrains from utilising probabilistic model checking, in order to avoid the state space explosions typically occurring when considering all possible erroneous behaviours within a single model. Instead, we analyse many different models, each only containing a restricted variant of deviations, which leads to faster evaluation times. In addition, several models can be evaluated in parallel in a distributed multi-core environment. &copy; 2010 Springer-Verlag Berlin Heidelberg.},
key = {Reliability analysis},
keywords = {Communication systems;Explosions;Model checking;Network architecture;Probability;Problem oriented languages;Quality assurance;Railroad transportation;},
note = {Communication architectures;Communication channel;Domain specific languages;End users;Multi core;Novel concept;Operational periods;Probabilistic model checking;Probability of occurrence;Railway control systems;Safety critical systems;Service reliability;State-space explosion;System reliability;Upper Bound;},
URL = {http://dx.doi.org/10.1007/978-3-642-15651-9_1},
} 


@article{20083811572606 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Linguistic symbiosis between event loop actors and threads},
journal = {Computer Languages, Systems and Structures},
author = {Van Cutsem, Tom and Mostinckx, Stijn and De Meuter, Wolfgang},
volume = {35},
number = {1},
year = {2009},
pages = {80 - 98},
issn = {14778424},
address = {Langford Lane, Kidlington, Oxford, OX5 1GB, United Kingdom},
abstract = {In modern programming languages, concurrency control can be traced back to one of two different schools: actor-based message passing concurrency and thread-based shared-state concurrency. This paper describes a linguistic symbiosis between two programming languages with such different concurrency models. More specifically, we describe a novel symbiosis between actors represented as event loops on the one hand and threads on the other. This symbiosis ensures that the invariants of the actor-based concurrency model are not violated by engaging in symbiosis with multithreaded programs. The proposed mapping is validated by means of a concrete symbiosis between AmbientTalk, a flexible, domain-specific language for writing distributed programs and Java, a conventional object-oriented language. This symbiosis allows the domain-specific language to reuse existing software components written in a multithreaded language without sacrificing the beneficial event-driven properties of the actor concurrency model. &copy; 2008 Elsevier Ltd. All rights reserved.},
key = {Concurrency control},
keywords = {Computer programming languages;Computer software;Computer software reusability;Computers;Linguistics;Message passing;Multitasking;Object oriented programming;Query languages;},
note = {Actors;AmbientTalk;Events;Futures;Linguistic symbiosis;Threads;},
URL = {http://dx.doi.org/10.1016/j.cl.2008.06.005},
} 


@inproceedings{20111413887121 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Formalizing and operationalizing industrial standards},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Dietrich, Dominik and Schroder, Lutz and Schulz, Ewaryst},
volume = {6603 LNCS},
year = {2011},
pages = {81 - 95},
issn = {03029743},
address = {Saarbrucken, Germany},
abstract = {Industrial standards establish technical criteria for various engineering artifacts, materials, or services, with a view to ensuring their functionality, safety, and reliability. We develop a methodology and tools to systematically formalize such standards, in particular their domain specific calculation methods, in order to support the automatic verification of functional properties for concrete physical artifacts. We approach this problem in the setting of the Bremen heterogeneous tool set Hets, which allows for the integrated use of a wide range of generic and custom-made logics. Specifically, we (i) design a domain specific language for the formalization of industrial standards; (ii) formulate a semantics of this language in terms of a translation into the higher-order specification language HasCasl, and (iii) integrate computer algebra systems (CAS) with the Hets framework via a generic CAS-Interface in order to execute explicit and implicit calculations specified in the standard. This enables a wide variety of added-value services based on formal reasoning, including verification of parameterized designs and simplification of standards for particular configurations. We illustrate our approach using the European standard EN 1591, which concerns calculation methods for gasketed flange connections that assure the impermeability and mechanical strength of the flange-bolt-gasket system. &copy; 2011 Springer-Verlag.},
key = {Standards},
keywords = {Accident prevention;Flanges;Gaskets;Industry;Interfaces (computer);Semantics;Software engineering;Specification languages;},
note = {Added-value services;Automatic verification;Calculation methods;Computer algebra systems;Domain specific;Domain specific languages;European Standards;Flange connection;Formal reasoning;Functional properties;Gasket system;Higher order;Industrial standards;Mechanical strength;Parameterized design;Physical artifacts;},
URL = {http://dx.doi.org/10.1007/978-3-642-19811-3_7},
} 


@inproceedings{20105213530463 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Reducing development costs in industrial safety projects with CESAR},
journal = {Proceedings of the 15th IEEE International Conference on Emerging Technologies and Factory Automation, ETFA 2010},
author = {Wien, Tormod and Reichenbach, Frank and Carlson, Erik and Stalhane, Tor},
year = {2010},
pages = {IEEE Industrial Electronics Society - },
address = {Bilbao, Spain},
abstract = {The demand for high Safety levels in industrial applications is growing. New certification and documentation requirements increase the product cost significantly. New or improved methods for high level specification and design may help to do part of the development process more automatically. In the CESAR project ABB, NTNU and SINTEF investigates if the Boiler Plate and Domain Specific Language approach for specification can be used to facilitate automatic generation of safety code and help to automatically document the process as required for safety authorization. &copy;2010 IEEE.},
key = {Accident prevention},
keywords = {Automatic programming;Cost accounting;Factory automation;Industrial applications;Risk management;Specifications;},
note = {Automatic Generation;Development costs;Development process;Domain specific languages;High level specification;High safety;Improved methods;Industrial safety;Product cost;Safety codes;},
URL = {http://dx.doi.org/10.1109/ETFA.2010.5641070},
} 


@inproceedings{20101212788420 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Computer generation of efficient software viterbi decoders},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {De Mesmay, Frederic and Chellappa, Srinivas and Franchetti, Franz and Puschel, Markus},
volume = {5952 LNCS},
year = {2010},
pages = {353 - 368},
issn = {03029743},
address = {Pisa, Italy},
abstract = {This paper presents a program generator for fast software Viterbi decoders for arbitrary convolutional codes. The input to the generator is a specification of the code and a single-instruction multiple-data (SIMD) vector length. The output is an optimized C implementation of the decoder that uses explicit Intel SSE vector instructions. At the heart of the generator is a small domain-specific language called VL to express the structure of the forward pass. Vectorization is done by rewriting VL expressions, which a compiler then translates into actual code in addition to performing further optimizations specific to the vector instruction set. Benchmarks show that the generated decoders match the performance of available expert hand-tuned implementations, while spanning the entire space of convolutional codes. An online interface to the generator is provided at www.spiral.net. &copy; 2010 Springer-Verlag.},
key = {Viterbi algorithm},
keywords = {Computer software;Convolution;Convolutional codes;Decoding;Linguistics;Problem oriented languages;Program compilers;},
note = {Computer generation;Domain specific languages;Instruction set;Library generation;Online interface;Single-instruction multiple-data;Software libraries;Vectorization;Viterbi decoder;},
URL = {http://dx.doi.org/10.1007/978-3-642-11515-8_26},
} 


@article{IP51491808 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {WebSpec: a visual language for specifying interaction and navigation requirements in web applications},
journal = {Requirements Engineering},
author = {Robles Luna, Esteban and Rossi, Gustavo and Garrigos, Irene},
year = {2011},
pages = {1 - 25},
issn = {09473602},
abstract = {Web application development is a complex and time-consuming process that involves different stakeholders (ranging from customers to developers); these applications have some unique characteristics like navigational access to information, sophisticated interaction features, etc. However, there have been few proposals to represent those requirements that are specific to Web applications. Consequently, validation of requirements (e.g., in acceptance tests) is usually informal and as a result troublesome. To overcome these problems, we present WebSpec, a domain-specific language for specifying the most relevant and characteristic requirements of Web applications: those involving interaction and navigation. We describe WebSpec diagrams, discussing their abstraction and expressive power. With a simple though realistic example, we show how we have used WebSpec in the context of an agile Web development approach discussing several issues such as automatic test generation, management of changes in requirements, and improving the understanding of the diagrams through application simulation. &copy; 2011 Springer-Verlag London Limited.},
key = {User interfaces},
keywords = {Navigation;Problem oriented languages;World Wide Web;},
note = {Acceptance tests;Application simulation;Automatic test generation;Domain specific languages;Expressive power;Interaction features;Management of change;Time-consuming process;Visual language;WEB application;Web application development;Web development;},
URL = {http://dx.doi.org/10.1007/s00766-011-0124-1},
} 


@inproceedings{20094712464034 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A DSM approach for end-user programming in the automation domain},
journal = {IEEE International Conference on Industrial Informatics (INDIN)},
author = {Pfeiffer, Michael and Pichler, Josef},
year = {2009},
pages = {142 - 148},
issn = {19354576},
address = {Cardiff, United kingdom},
abstract = {In this paper we present an approach and a software prototype that enables domain experts to program control software in the automation domain. The approach follows the principles of domain-specific modeling providing a graphical domain-specific language to model the control cycle of an injection molding machine, a user interface to manipulate and monitor the control cycle as well as code generators to generate control code that can be executed by the machine. As result, domain experts like machine operators can manipulate and monitor the control cycle directly on the touch-screen of a machine without detailed software development expertise. &copy; 2009 IEEE.},
key = {Software prototyping},
keywords = {Computer software;Injection molding;Problem oriented languages;User interfaces;},
note = {Automation domain;Code generators;Control codes;Control cycles;Domain experts;Domain specific languages;Domain specific modeling;End user programming;Injection molding machines;Machine operators;Program control;Software development;Software prototypes;Touch screen;},
URL = {http://dx.doi.org/10.1109/INDIN.2009.5195793},
} 


@inproceedings{20094812505000 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A little language for surveys: Constructing an internal DSL in Ruby},
journal = {Proceedings of the 46th Annual Southeast Regional Conference on XX, ACM-SE 46},
author = {Cunningham, H. Conrad},
year = {2008},
pages = {282 - 287},
address = {Auburn, AL, United states},
abstract = {Using a problem domain motivated by Bentley's "Little Languages" column [1], this paper explores the use of the Ruby programming language's flexible syntax, dynamic nature, and reflexive metaprogramming facilities to implement an internal domain-specific language (DSL) for surveys. Copyright 2008 ACM.},
key = {Linguistics},
keywords = {Computer aided software engineering;Corundum;DSL;Modems;Problem oriented languages;Query languages;Ruby;Spontaneous emission;Surveys;Telecommunication lines;},
note = {Bentley;Domain specific languages;Dynamic nature;Meta Programming;Problem domain;Programming language;Reflexive metaprogramming;},
URL = {http://dx.doi.org/10.1145/1593105.1593181},
} 


@inproceedings{2005038791176 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Invited application paper: Language design for implementing process scheduling hierarchies},
journal = {Proceedings of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation},
author = {Lawall, Julia L. and Muller, Gilles and Duchesne, Herve},
year = {2004},
pages = {80 - 91},
address = {Verona, Italy},
abstract = {Standard operating systems provide only a single fixed scheduler, which does not meet all possible application scheduling needs. More flexibility can be achieved using a hierarchy of schedulers, allowing multiple schedulers to coexist in a single operating system (OS). Bossa is a framework for facilitating the implementation and deployment of OS process schedulers. In this paper, we describe the features of Bossa that enable the creation and management of a scheduling hierarchy. These features include a domain-specific language for implementing schedulers and a type system for describing requirements on scheduler behavior. The use of the domain-specific language eases scheduler development and enables scheduler verification. We have found that the approach allows programmers, even students who are not kernel or scheduling experts, to easily and safely implement and deploy schedulers that meet specific application needs.},
key = {Hierarchical systems},
keywords = {Computer operating systems;Computer programming languages;Process control;Product design;Scheduling;Servers;Societies and institutions;World Wide Web;},
note = {Domain-specific languages;Operating system extension;Process scheduling;Scheduling hierarchies;Verification;},
URL = {http://dx.doi.org/10.1145/1014007.1014016},
} 


@inproceedings{20105213514879 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The VisualAORE DSL},
journal = {2010 5th International Workshop on Requirements Engineering Visualization, REV 2010},
author = {Oliveira, Ana Rita and Araujo, Joao and Amaral, Vasco},
year = {2010},
pages = {11 - 19},
address = {Sydney, NSW, Australia},
abstract = {Aspect-Oriented Requirements Engineering consists of identifying, modularizing, specifying, and composing crosscutting concerns, also known as aspects. AORE is a pioneer systematic approach used to discover and structure requirements based on viewpoints and aspects. One of its limitations to be widely adopted is due to the fact that it lacks visual support to improve its usability. This paper describes a new Eclipse plug-in entitled VisualAORE. It is based on a DSL (Domain Specific Language) representing all the concepts of the AORE domain, allowing an implementation of an editor to specify models using the defined visual language. The work presented in this paper is a major contribution to AORE, since it replaces the traditional AORE's XML textual representation by a graphical one. This contribution helps software engineers to decrease AORE's model specification time, improving its understanding and usability. &copy;2010 IEEE.},
key = {Engineering},
keywords = {Problem oriented languages;Requirements engineering;Visualization;},
note = {Aspect oriented requirement engineerings;Aspect-Oriented Requirements Engineering;Crosscutting concern;Domain specific languages;Model driven development;Model specifications;Plug-ins;Software engineers;Textual representation;Visual language;},
URL = {http://dx.doi.org/10.1109/REV.2010.5625665},
} 


@article{20113614297648 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Ontologies and simulation: A practical approach},
journal = {Journal of Simulation},
author = {McGinnis, L. and Huang, E. and Kwon, K.S. and Ustun, V.},
volume = {5},
number = {3},
year = {2011},
pages = {190 - 201},
issn = {17477778},
address = {Houndmills, Basingstoke, Hants., RG21 6XS, United Kingdom},
abstract = {The challenges in cost-effectively deploying simulation technology are well known. Two major challenges are creating an appropriate conceptual model and translating that conceptual model correctly into a computational model. Ontologies have been widely discussed as one mechanism for capturing modelling knowledge in a reusable form, making it effectively available in the conceptual and computational modelling phases. In this paper, we show how ontologies can be effectively deployed in simulation using recent innovations from systems engineering and software engineering. We use OMG SysML to create an ontology implementation referred to as a domain-specific language, or DSL, for a class of simulation applications; the DSL is used to create a specific (conceptual) user model for a problem in the domain. We then use model transformation to automate the translation to a computational simulation model. Two proof-of-concept implementations are described, one using a legacy simulation language, and another using an object-oriented simulation language. &copy; 2011 Operational Research Society Ltd. All rights reserved.},
key = {Computer simulation},
keywords = {Computer simulation languages;Computer software;Formal languages;Innovation;Ontology;Problem oriented languages;Translation (languages);},
note = {Computational model;Computational modelling;Computational simulation;Conceptual model;Domain specific languages;Model transformation;Object oriented simulation;Proof of concept;Simulation applications;Simulation language;Simulation technologies;Use-model;User models;},
URL = {http://dx.doi.org/10.1057/jos.2011.3},
} 


@inproceedings{20113714324943 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Lessons learned in applying MDE to the development of Home Automation systems},
journal = {ICSOFT 2011 - Proceedings of the 6th International Conference on Software and Database Technologies},
author = {Rosique, Francisca and Sanche, Pedroz and Jimenez, Manuel and Alonso, Diego},
volume = {2},
year = {2011},
pages = {265 - 268},
address = {Seville, Spain},
abstract = {Home Automation (HA) systems represent a domain of interest to evaluate the benefits and difficulties of adopting the well known Model Driven Engineering (MDE) approach. This is due to the existence of determining factors in the development of such systems that makes MDE applicable with some considerations. This article presents the lessons learned after the definition of a methodology and the implementation of a set of tools to support the MDE-base development of HA systems. In particular, the definition of a Domain Specific Language has made possible the generation of code although we have identified some peculiarities and differences from a classical MDE perspective. These results can be extrapolated to other domains with similar characteristic.},
key = {Engineering education},
keywords = {Automation;},
note = {Domain specific languages;Home Automation;Home automation systems;Model transformations;Model-driven Engineering;},
} 


@inproceedings{20104513369512 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Grammar inference technology applications in software engineering},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Bryant, Barrett R. and Mernik, Marjan and Hrncic, Dejan and Javed, Faizan and Liu, Qichao and Sprague, Alan},
volume = {6339 LNAI},
year = {2010},
pages = {276 - 279},
issn = {03029743},
address = {Valencia, Spain},
abstract = {While Grammar Inference (GI) has been successfully applied to many diverse domains such as speech recognition and robotics, its application to software engineering has been limited, despite wide use of context-free grammars in software systems. This paper reports current developments and future directions in the applicability of GI to software engineering, where GI is seen to offer innovative solutions to the problems of inference of domain-specific language (DSL) specifications from example DSL programs and recovery of metamodels from instance models. &copy; 2010 Springer-Verlag.},
key = {Speech recognition},
keywords = {Computational grammars;Graphical user interfaces;Innovation;Models;Problem oriented languages;Software engineering;},
note = {Diverse domains;Domain specific languages;Future directions;grammar inference;Innovative solutions;Meta model;Software systems;Technology application;},
URL = {http://dx.doi.org/10.1007/978-3-642-15488-1_25},
} 


@inproceedings{20113014169058 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling and verification of memory architectures with AADL and REAL},
journal = {Proceedings - 2011 16th IEEE International Conference on Engineering of Complex Computer Systems, ICECCS 2011},
author = {Rubini, Stephane and Singhoff, Frank and Hugues, Jerome},
year = {2011},
pages = {338 - 343},
address = {Las Vegas, NV, United states},
abstract = {Real-Time Embedded systems must respect a wide range of non-functional properties, including safety, respect of deadlines, power or memory consumption. We note that correct hardware resource dimensioning requires taking into account the impact of the whole software, both the user code and the underlying runtime environment. AADL allows one to precisely capture all of them. In this article, we evaluate the AADL modeling to define memory architectures, and then verification rules to assess that the memory is correctly dimensioned. We use the REAL domain-specific language to express memory requirements (such as layout or size) and then validate them on a case-study using the VxWorks real-time kernel. &copy; 2011 IEEE.},
key = {Memory architecture},
keywords = {Embedded systems;Problem oriented languages;Real time systems;},
note = {AADL;Constraint language;Domain specific languages;Hardware resources;Memory consumption;Memory requirements;Non functional properties;REAL;Real-time embedded systems;Real-time kernel;Runtime environments;User codes;Vxworks;},
URL = {http://dx.doi.org/10.1109/ICECCS.2011.40},
} 


@inproceedings{20111613914146 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A little language for rapidly constructing automated performance tests},
journal = {ICPE'11 - Proceedings of the 2nd Joint WOSP/SIPEW International Conference on Performance Engineering},
author = {Dunning, Shaun and Sawyer, Darren},
year = {2011},
pages = {371 - 380},
address = {Karlsruhe, Germany},
abstract = {In order to effectively measure the performance of large scale data management solutions at NetApp, we use a fully automated infrastructure to execute end-to-end system performance tests. Both the software and user requirements of this infrastructure are complex: the system under test runs a multi-protocol, highly specialized operating system and the infrastructure serves a diverse audience of developers, analysts, and field engineers (including both sales and support). In this paper we describe our approach to rapidly constructing automated performance system tests by using a lightweight, little, or domain-specific language called SLSL in order to more effectively express test specifications. Using a real world example, we illustrate the efficacy of SLSL in terms of its expressiveness, flexibility, and ease of use by showing a complex test configuration expressed with just a few language constructs. We also demonstrate how SLSL can be used in conjunction with our performance measurement lab to quickly deploy performance tests that yield highly repeatable measurements.},
key = {Testing},
keywords = {Automation;Graphical user interfaces;Information management;Problem oriented languages;},
note = {Domain specific languages;Ease of use;End-to-end systems;Field engineers;Language constructs;Large-scale data management;Little language;Multiprotocols;Operating systems;Performance;Performance measurements;Performance system;Performance tests;System under test;Test automation;Test configurations;Test specifications;User requirements;},
URL = {http://dx.doi.org/10.1145/1958746.1958798},
} 


@inproceedings{2004158110019 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automating Feature-Oriented Domain Analysis},
journal = {Proceedings of the International Conference on Software Engineering Research and Practise},
author = {Cao, Fei and Bryant, Barrett R. and Burt, Carol C. and Huang, Zhisheng and Raje, Rajeev R. and Olson, Andrew M. and Auguston, Mikhail},
volume = {2},
year = {2003},
pages = {944 - 949},
address = {Las Vegas, NV, United states},
abstract = {Feature modeling is commonly used to capture the commonalities and variabilities of systems in a domain during Domain Analysis. The output of feature modeling will be some reusable assets (components, patterns, domain-specific language, etc.) to be fed into the application engineering phase for ultimate software products. But current practice lacks an automatic approach for seamless generation of reusable assets from feature models. This paper presents an algorithm for generating sets of instance descriptions (feature instances) from feature models of a domain and applies this algorithm in creating a Generic Feature Modeling Environment for automating Feature-Oriented Domain Analysis.},
key = {Object oriented programming},
keywords = {Algorithms;Computer hardware description languages;Computer programming;XML;},
note = {Domain analysis;Feature modeling;Generative programing;},
} 


@inproceedings{20113614299855 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {From archetypes based domain model via requirements to software: Exemplified by LIMS software factory},
journal = {MIPRO 2011 - 34th International Convention on Information and Communication Technology, Electronics and Microelectronics - Proceedings},
author = {Piho, Gunnar and Tepandi, Jaak and Roost, Mart and Parman, Marko and Puusep, Viljam},
year = {2011},
pages = {570 - 575},
address = {Opatija, Croatia},
abstract = {The Archetypes Based Development (ABD) proceeds from archetypes based domain model via requirements to software. We give an overview of ABD and exemplify its application on Laboratory Information Management Systems (LIMS) Software Factory development. ABD is guided by Zachman Framework and utilizes software engineering triptych together with archetypes and archetype patterns. For modelling of domains the Test Driven Modelling (TDM) techniques are used. TDM utilizes test driven development techniques in domain engineering. The resultant domain models serve as the Domain Specific Language for prescribing requirements. Implementation and testing of the LIMS Software Factory proves feasibility of archetypes based techniques in real life systems. ABD helps developers to better understand business requirements, to design cost effective enterprise applications through systematic reuse of archetypal components, as well as to validate and verify requirements resulting in higher quality software. &copy; 2011 MIPRO.},
key = {Software design},
keywords = {Computer software reusability;Information management;Information technology;Microelectronics;Query languages;Software testing;},
note = {Archetype patterns;Archetypes;Domain analysis;Domain model;Domain modelling;Laboratory information management system (LIMS);Software factory;},
} 


@inproceedings{20113614299856 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Test Driven domain modelling},
journal = {MIPRO 2011 - 34th International Convention on Information and Communication Technology, Electronics and Microelectronics - Proceedings},
author = {Piho, Gunnar and Tepandi, Jaak and Parman, Marko and Puusep, Viljam and Roost, Mart},
year = {2011},
pages = {576 - 581},
address = {Opatija, Croatia},
abstract = {To write software we have to know requirements; to know requirements we have to know domain; to know the domain we have to analyze and model one. We propose a methodology for applying Test Driven Modelling in engineering of domains, requirements and software. We will restrict ourselves here to enterprise information systems and therefore to business domains. As common for Software Factories, domain models (as well as all other models) are software artefacts, not only documentation artefacts. In our approach Test Driven Modelling utilizes Test Driven Development for domain modelling. Domain models engineered in this way are used as Domain Specific Language for specifying software requirements. The hypothesis is that such domain models can be used for validation of requirements and verification of software, lead developments towards Software Factories, and increase dependability of software. &copy; 2011 MIPRO.},
key = {Software testing},
keywords = {Computer software selection and evaluation;Information systems;Microelectronics;Query languages;Testing;Verification;},
note = {Domain analysis and engineering;Domain model;Software factory;Test driven development;Test driven modelling;Verification and validation;},
} 


@inproceedings{20094612439835 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A language and a methodology for prototyping user interfaces for control systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Risoldi, Matteo and Amaral, Vasco and Barroca, Bruno and Bazargan, Kaveh and Buchs, Didier and Cretton, Fabian and Falquet, Gilles and Le Calve, Anne and Malandain, Stephane and Zoss, Pierrick},
volume = {5440 LNCS},
year = {2009},
pages = {221 - 248},
issn = {03029743},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {The BATIC<sup>3</sup>S project<sup>1</sup> (Building Adaptive Three-dimensional Interfaces for Controlling Complex Control Systems) proposes a methodology to prototype adaptive graphical user interfaces (GUI) for control systems. We present a domain specific language for the control systems domain, including useful and understandable abstractions for domain experts. This is coupled with a methodology for validation, verification and automatic GUI prototype generation. The methodology is centered on metamodel-based techniques and model transformations, and its foundations rely on formal models. Our approach is based on the assumption that a GUI can be induced from the characteristics of the system to control. &copy; 2009 Springer Berlin Heidelberg.},
key = {Adaptive control systems},
keywords = {Control theory;Graphical user interfaces;Linguistics;Three dimensional;},
note = {Complex control systems;Domain experts;Domain specific languages;Formal model;Gui prototype;Meta model;Model transformation;Prototyping;Three dimensional interface;},
URL = {http://dx.doi.org/10.1007/978-3-642-00437-7_9},
} 


@inproceedings{20091211969466 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {SALmon - A service modeling language and monitoring engine},
journal = {Proceedings of the 4th IEEE International Symposium on Service-Oriented System Engineering, SOSE 2008},
author = {Leijon, Viktor and Wallin, Stefan and Ehnmark, Johan},
year = {2008},
pages = {202 - 207},
address = {Jhongli, Taiwan},
abstract = {To be able to monitor complex services and examine their properties we need a modeling language that can express them in an efficient manner. As telecom operators deploy and sell increasingly complex services the need to monitor these services increases. We propose a novel domain specific language called SALmon, which allows for efficient representation of service models, together with a computational engine for evaluation of service models. This working prototype allows us to perform experiments with full scale service models, and proves to be a good trade-off between simplicity and expressive power. &copy; 2008 IEEE.},
key = {Linguistics},
keywords = {Systems engineering;},
note = {Complex services;Expressive power;Full scale;Modeling languages;Monitoring engines;Novel domains;Service modeling languages;Service models;Telecom operators;},
URL = {http://dx.doi.org/10.1109/SOSE.2008.29},
} 


@inproceedings{20084811751672 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The future of train signaling},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Svendsen, Andreas and Olsen, Gran K. and Endresen, Jan and Moen, Thomas and Carlson, Erik and Alme, Kjell-Joar and Haugen, Oystein},
volume = {5301 LNCS},
year = {2008},
pages = {128 - 142},
issn = {03029743},
address = {Toulouse, France},
abstract = {Producing the source code for a railway interlocking system based on the description of a station has traditionally been a multistage manual process. We show how this process can be automated and made less error-prone by introducing model-driven development (MDD). This paper addresses the experience of developing a Domain Specific Language (DSL) to describe railway stations, Train Control Language (TCL), and tools to support this language. In the railroad domain where there are extreme safety requirements, it is essential to show that consistency and completeness can be assured. We address how the model is used to generate several different representations for different purposes. We look at advantages and challenges with our approach, and we discuss improvements to existing technologies to support our case better. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Interlocking signals},
keywords = {DSL;Linguistics;Locomotives;Models;Modems;Query languages;Railroad cars;Railroads;Systems analysis;Telecommunication lines;},
note = {Do-mains;Domain specifics;Interlocking;Manual processes;MoSiS;Paper addresses;Railway Interlocking systems;Railway stations;Safety requirements;Source codes;Train;Train controls;},
URL = {http://dx.doi.org/10.1007/978-3-540-87875-9_9},
} 


@inproceedings{20074810948749 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings 10th IEEE International Symposium on Object and Component-Oriented Real-Time Distributed Computing ISORC 2007},
journal = {Proceedings - 10th IEEE International Symposium on Object and Component-Oriented Real-Time Distributed Computing, ISORC 2007},
year = {2007},
pages = {IEEE Computer Soc. Technical Committee on Distributed Processing - },
address = {Santorini Island, Greece},
abstract = {The proceedings contain 54 papers. The topics discussed include: a systematic approach to domain-specific language design using UML; periodic finite-state machines; engineering self-coordinating real-time systems; efficient adaptations of the non-blocking buffer for event message communication between real-time threads; a timing assumption and a t-resilient protocol for implementing an eventual leader service in asynchronous shared memory systems; time-predictable task preemption for real-time systems with direct-mapped instruction cache; integrating priority inheritance algorithms in the real-time specification; analyzing behavior of concurrent software design for embedded systems; and evaluating real-time publish/subscribe service integration approaches in QoS-enabled component middleware.},
key = {Computer programming languages},
keywords = {Algorithms;Embedded systems;Middleware;Network protocols;Real time control;Software design;Time domain analysis;Unified Modeling Language;},
note = {Event message communication;Non blocking buffer;Real time threads;},
} 


@inproceedings{20113014186683 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An automated control code generation approach for the SegBus platform},
journal = {Proceedings - IEEE International SOC Conference, SOCC 2010},
author = {Niazi, Moazzam Fareed and Seceleanu, Tiberiu and Tenhunen, Hannu},
year = {2010},
pages = {199 - 204},
address = {Las Vegas, NV, United states},
abstract = {We present here a model-driven approach for the generation of low-level control code for the arbiters, to support application implementation and scheduled execution on a multi-core segmented bus platform, SegBus. The approach considers Model-Driven Architecture as a key to model the application at two different abstraction levels, namely as Packet-Synchronous Dataflow and Platform Specific Model, using the SegBus platform's Domain Specific Language. Both models are transformed into Extensible Markup Language schemes, and then utilized by an emulator program to generate the application-dependent VHDL code, the so-called snippets. The obtained code is inserted in a specific section of the platform arbiters. We present an example of a simplified stereo MP3 decoder where the methodology is employed to generate the control code of arbiters. &copy; 2010 IEEE.},
key = {Data flow analysis},
keywords = {Computer hardware description languages;Microprocessor chips;XML;},
note = {Abstraction level;Automated control;Control codes;Dataflow;Domain specific languages;Low level control;Model driven approach;Model driven architectures;MP3 decoders;Multi core;Platform specific model;Segmented bus platform;},
URL = {http://dx.doi.org/10.1109/SOCC.2010.5784752},
} 


@inproceedings{20091311976144 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Design of a metamodel-based telecoms modelling language},
journal = {9th International Conference on Computer-Aided Industrial Design and Conceptual Design: Multicultural Creation and Design - CAIDCD 2008},
author = {Han, Yu and Liu, Shufen and Wang, Xiaoyan and Li, Bin},
year = {2008},
pages = {1235 - 1238},
address = {Kunming, China},
abstract = {Along with the evolution of computer technology, language oriented programming came out as a revolutionary progress which beyond the object-oriented programming. In current object-oriented programming, the general modeling language UML lacks of rich syntax and semantics in the specific domain. Developing and using domain specific language model in the progress of language oriented programming can solve this problem well. By constructing a executable model based on the MOF, defining an abstract syntax model and an concrete syntax model and extending semantics, this paper designs a telecommunication topology modelling language TML which based on the MOF metamodel. TML contains rich syntax, semantics and constraints which are telecommunication domain specific, and has the executable feature, thus it greatly simplifies the complexity of system modelling in domain and enhances the efficiency of software production. &copy; 2008 IEEE.},
key = {Object oriented programming},
keywords = {Computational linguistics;Conceptual design;Fischer-Tropsch synthesis;Information theory;Java programming language;Product design;Semantics;Syntactics;Telecommunication;Telecommunication systems;},
note = {Abstract syntaxes;Computer technologies;Concrete syntaxes;Domain modelling;Domain specifics;Domain-specific languages;Executable models;Meta models;Meta object facility;Modeling languages;Modelling language design;Software productions;System modelling;},
URL = {http://dx.doi.org/10.1109/CAIDCD.2008.4730787},
} 


@article{2006129767382 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An experimental evaluation of a higher-ordered-typed-functional specification-based test-generation technique},
journal = {Empirical Software Engineering},
author = {Sinha, Avik and Smidts, Carol},
volume = {11},
number = {2},
year = {2006},
pages = {173 - 202},
issn = {13823256},
abstract = {HOTTest is a model based test automation technique of software systems based on models of the system described using HaskellDB. HaskellDB is an embedded domain specific language derived from Haskell. HOTTest enforces a systematic abstraction process and exploits system invariants for automatically producing test cases for domain specific requirements. Use of functional languages for system modeling is a new concept and hence HOTTest is subject to concerns of usability, like any other new technique. Also, the syntax and the declarative style of Haskell based languages make them difficult to learn. Similar concerns can be raised for HOTTest as it shares the same syntax with Haskell. In this paper we describe an experiment designed to study the usability of HOTTest and to compare it with existing model based test design techniques. The results show that HOTTest is more usable than the traditional technique and demonstrate that the test suites produced by HOTTest are more effective and efficient than those generated using the traditional model based test design technique. &copy; Springer Science + Business Media, Inc. 2006.},
key = {Software engineering},
keywords = {Automation;Computer hardware description languages;Computer software;Mathematical models;},
note = {Controlled experiment;EFSM software model;Empirical study;Functional specification language;Software test automation;},
URL = {http://dx.doi.org/10.1007/s10664-006-6401-9},
} 


@inproceedings{20070910440585 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A configurable framework for stream programming exploration in baseband applications},
journal = {20th International Parallel and Distributed Processing Symposium, IPDPS 2006},
author = {Bengtsson, Jerker and Svensson, Bertil},
volume = {2006},
year = {2006},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {This paper presents a configurable framework to be used for rapid prototyping of stream based languages. The framework is based on a set of design patterns defining the elementary structure of a domain specific language for high-performance signal processing. A stream language prototype for baseband processing has been implemented using the framework. We introduce language constructs to efficiently handle dynamic reconfiguration of distributed processing parameters. It is also demonstrated how new language specific primitive data types and operators can be used to efficiently and machine independently express computations on bit-fields and data-parallel vectors. These types and operators yield code that is readable, compact and amenable to a stricter type checking than is common practice. They make it possible, for a programmer to explicitly express parallelism to be exploited by a compiler. In short, they provide a programming style that is less error prone and has the potential to lead to more efficient implementations. &copy; 2006 IEEE.},
key = {Computer programming languages},
keywords = {Codes (symbols);Dynamic programming;Parallel processing systems;Program compilers;Rapid prototyping;Signal processing;},
note = {Baseband applications;Design patterns;High performance signal processing;Stream programming exploration;},
URL = {http://dx.doi.org/10.1109/IPDPS.2006.1639502},
} 


@inproceedings{20094112365240 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Integrated data mapping for a software meta-tool},
journal = {Proceedings of the Australian Software Engineering Conference, ASWEC},
author = {Huh, Jun and Grundy, John and Hosking, John and Liu, Karen and Amor, Robert},
year = {2009},
pages = {111 - 120},
address = {Gold Coast, Australia},
abstract = {Complex data mapping tasks often arise in software engineering, particularly in code generation and model transformation. We describe Marama Torua, a tool supporting high-level specification and implementation of complex data mappings. Marama Torua is embedded in, and provides model transformation support for, our Eclipse-based Marama domain-specific language meta-tool. Developers can quickly develop stand alone data mappers and model translation and code import-export components for their tools. Complex data schema and mapping relationships are represented in multiple, high-level notational forms and users are provided semiautomated mapping assistance for large models. MaramaTorua is a set of Eclipse plug-ins allowing close integration with other tools such as schema browsers, and with the Marama meta-tool itself. &copy; 2009 IEEE.},
key = {Mapping},
keywords = {Computer software;},
note = {Close integration;Code Generation;Complex data;Data mapper;Domain specific languages;Eclipse plug-ins;High level specification;Integrated data;Model transformation;Model translation;Semi-automated;Stand -alone;Tool supporting;},
URL = {http://dx.doi.org/10.1109/ASWEC.2009.21},
} 


@inproceedings{20102913088898 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Bringing extensibility to verified compilers},
journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
author = {Tatlock, Zachary and Lerner, Sorin},
year = {2010},
pages = {111 - 121},
address = {Toronto, ON, Canada},
abstract = {Verified compilers, such as Leroy's CompCert, are accompanied by a fully checked correctness proof. Both the compiler and proof are often constructed with an interactive proof assistant. This technique provides a strong, end-to-end correctness guarantee on top of a small trusted computing base. Unfortunately, these compilers are also challenging to extend since each additional transformation must be proven correct in full formal detail. At the other end of the spectrum, techniques for compiler correctness based on a domain-specific language for writing optimizations, such as Lerner's Rhodium and Cobalt, make the compiler easy to extend: the correctness of additional transformations can be checked completely automatically. Unfortunately, these systems provide a weaker guarantee since their end-to-end correctness has not been proven fully formally. We present an approach for compiler correctness that provides the best of both worlds by bridging the gap between compiler verification and compiler extensibility. In particular, we have extended Leroy's CompCert compiler with an execution engine for optimizations written in a domain specific and proved that this execution engine preserves program semantics, using the Coq proof assistant. We present our CompCert extension, XCert, including the details of its execution engine and proof of correctness in Coq. Furthermore, we report on the important lessons learned for making the proof development manageable. &copy; 2010 ACM.},
key = {Program compilers},
keywords = {C (programming language);Cobalt;Computer aided software engineering;Linguistics;Optimization;Problem oriented languages;Rhodium;},
note = {Compiler correctness;Compiler optimizations;Coq proof assistant;Correctness proofs;Domain specific;Domain specific languages;End-to-end correctness;Execution engine;Interactive proof assistants;Lessons learned;Program semantics;Proof development;Proof of correctness;Trusted computing base;},
URL = {http://dx.doi.org/10.1145/1806596.1806611},
} 


@article{20113414251532 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A constrained crawling approach and its application to a specialised search engine},
journal = {International Journal of Information and Communication Technology},
author = {Adda, Mehdi},
volume = {3},
number = {3},
year = {2011},
pages = {258 - 273},
issn = {14666642},
address = {P.O.Box 735, Olney, Bucks, MK46 5WB, United Kingdom},
abstract = {In this paper, we present an approach to crawl and parse websites based on their logical structure rather than on an aleatory exploration method. In this approach, we use a set of constraints to identify web pages and their components. To enforce these constraints, we present a set of primitives that rely on predicate verification. Our model has the attractiveness of being flexible to reflect tree-like logical structures of websites, thus it avoids the need to use complex information analysis and content classification techniques. Furthermore, because the model is implemented as a domain specific language (DSL), describing crawling tasks is straightforward. Using this DSL, we developed and deployed a prototype of dynamic web application with full-text search capabilities that periodically crawls, parses, and analyses the content of selected online newspapers. A set of experiments, and comparisons highlight the effectiveness of the proposed crawling approach. Copyright &copy; 2011 Inderscience Enterprises Ltd.},
key = {Search engines},
keywords = {Information retrieval;User interfaces;Websites;},
note = {Content classification;Domain specific languages;Dynamic web applications;Exploration methods;Full-text search;Logical structure;Online newspaper;Predicate verification;Web crawling;},
URL = {http://dx.doi.org/10.1504/IJICT.2011.041928},
} 


@article{IP51559560 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The semantics of alarm definitions: Enabling systematic reasoning about alarms},
journal = {International Journal of Network Management},
author = {Wallin, Stefan and Leijon, Viktor and Nordlander, Johan and Bystedt, Nicklas},
year = {2011},
issn = {10557148},
abstract = {The development and integration of an alarm interface between network elements and a network management system is a costly process, largely because of the informal way in which alarm interfaces are expressed and communicated. Low-quality alarm documentation and confusion around fundamental concepts like alarm states and alarm types are typical consequences of current practices. If alarm interfaces were expressed in a more formal manner, costs could be reduced and more advanced analysis and automation would be enabled. We present a novel approach to alarm interfaces by providing a formal alarm model together with a domain-specific language that allows us to specify both the alarm models and the constraints placed on the alarm models in a consistent manner. This means that we can verify the consistency of an alarm interface and automatically generate artifacts such as alarm correlation rules or alarm documentation based only on the model. &copy; 2011 John Wiley &amp; Sons, Ltd.},
key = {Alarm systems},
keywords = {Network management;Problem oriented languages;Semantics;},
note = {Advanced analysis;Alarm correlation;Domain specific languages;Fundamental concepts;Low qualities;Network element;Network management systems;},
URL = {http://dx.doi.org/10.1002/nem.800},
} 


@inproceedings{20102913087460 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Interchangeable consistency constraints for public health care systems},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Teiken, Yvette and Bruggemann, Stefan and Appelrath, Hans-Jurgen},
year = {2010},
pages = {1411 - 1416},
address = {Sierre, Switzerland},
abstract = {Severe data quality problems exist in most public health care systems and inconsistent data sets often occur. Consistency constraints can be used to define valid and invalid data. Existing solutions of such constraints like rule systems are often difficult to maintain, not human-readable, and of a bad quality like containing contradictory rules. With In-DaQu we present an approach that allows domain experts to easily create and maintain consistency constraints using an introduced domain-specific language. These constraints are being stored in an ontology, which allows for an automated inconsistency detection in the defined rules themselves. We identified several scenarios in which consistency constraints can be interchanged and exchanged between different participants. The approach has been successfully evaluated in the cancer registry of Lower Saxony. &copy; 2010 ACM.},
key = {Knowledge representation},
keywords = {Health care;Information science;Ontology;Problem oriented languages;},
note = {Bad quality;Consistency constraints;Contradictory rules;Data quality;Domain experts;Domain ontologies;Domain specific languages;Domain specific modeling;Human-readable;Inconsistency detection;Inconsistent data;Medical informatics;Public health care;Rule systems;},
URL = {http://dx.doi.org/10.1145/1774088.1774387},
} 


@inproceedings{20101712894714 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Group operation assembly language - A flexible way to express collective communication},
journal = {Proceedings of the International Conference on Parallel Processing},
author = {Hoefler, Torsten and Siebert, Christian and Lumsdaine, Andrew},
year = {2009},
pages = {574 - 581},
issn = {01903918},
address = {Vienna, Austria},
abstract = {The implementation and optimization collective communication operations is an important field of active research. Such operations directly influence application performance and need to map the communication requirements in an optimal way to steadily changing network architectures. In this work, we define an abstract domain-specific language to express arbitrary group communication operations. We show the universality of this language and how all existing collective operations can be implemented with it. By design, it readily lends itself to blocking and nonblocking execution, as well as to off-loaded execution of complex group communication operations. We also define several offline and online optimizations (compiler transformations and scheduling decisions, respectively) to improve the overall performance of the operation. Performance results show that the overhead to express current collective operations is negligible in comparison to the potential gains in a highly optimized implementation. &copy; 2009 IEEE.},
key = {Communication},
keywords = {Linguistics;Optimization;Problem oriented languages;},
note = {Abstract domains;Application performance;Assembly language;Collective communication operations;Collective communications;Collective operations;Compiler transformations;Group communications;Group operations;Implementation and optimization;Non-blocking;Offline;Online optimization;Optimized implementation;Scheduling decisions;},
URL = {http://dx.doi.org/10.1109/ICPP.2009.70},
} 


@inproceedings{20110813686621 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards domain-driven development: The SmartTools software factory},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Parigot, Didier},
year = {2004},
pages = {37 - 38},
address = {Vancouver, BC, Canada},
abstract = {Nowadays, software needs to be more open, flexible, and capable of evolving quickly to meet new user or technology requirements. It should be easy to adapt, even by none computer-specialists. To tackle these challenges for DSL (Domain-Specific Language) tools, we have developed a software factory, named SmartTools.},
key = {Object oriented programming},
keywords = {Computer systems programming;Problem oriented languages;},
note = {Domain specific languages;Languages;Software factories;},
URL = {http://dx.doi.org/10.1145/1028664.1028685},
} 


@article{1999394752329 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Prototyping real-time vision systems: An experiment in DSL design},
journal = {Proceedings - International Conference on Software Engineering},
author = {Reid, Alastair and Peterson, John and Hager, Greg and Hudak, Paul},
year = {1999},
pages = {484 - 493},
issn = {02705257},
address = {Los Angeles, CA, USA},
abstract = {We describe the enhancement of XVision, a large library of C++ code for real-time vision processing, into FVision (pronounced `fission'), a fully-featured domain-specific language embedded in Haskell. The resulting prototype system substantiates the claims of increased modularity, effective code reuse, and rapid prototyping that characterize the DSL approach to system design. It also illustrates the need for judicious interface design: relegating computationally expensive tasks to XVision (pre-existing C++ components), and leaving modular compositional tasks to FVision (Haskell). At the same time, our experience demonstrates how Haskell's advanced language features (specifically parametric polymorphism, lazy evaluation, higher order functions and automatic storage reclamation) permit a rapid DSL design that is itself highly modular and easily modified. Overall, the resulting hybrid system exceeded our expectations: visual tracking programs continue to spend most of their time executing low level image-processing code, while Haskell's advanced features allow us to quickly develop and test small prototype systems within a matter of a few days and to develop realistic applications within a few weeks.},
key = {Software prototyping},
keywords = {C (programming language);Computer software reusability;Computer vision;Interfaces (computer);Rapid prototyping;Real time systems;},
note = {Domain-specific languages;Functional programming;Modularity;Software package FVision;Software package XVision;},
} 


@inproceedings{20072010600757 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Adding domain-specific and general purpose language features to Java with the Java language extender},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Van Wyk, Eric and Krishnan, Lijesh and Bodin, Derek and Johnson, Eric},
volume = {2006},
year = {2006},
pages = {728 - 729},
address = {Portland, OR, United states},
abstract = {The Java Language Extender is a compiler-generator tool that allows programmers to create new domain-adapted languages by importing a set of domain-specific language extensions into an extensible specification of Java 1.4. Language extensions define the syntax, semantic analysis, and optimizations of new language constructs. Java and the language extensions are specified as attribute grammar fragments written in Silver, an attribute grammar language supporting forwarding and higher-order attributes. Programmers need no implementation-level knowledge of the language extensions and the Silver tools automatically compose the programmer-selected extensions and the Java host language specification. We demonstrate several language extensions. One embeds the SQL database query language into Java and statically checks for syntax and type errors in SQL queries. Other extensions for the domain of computational geometry provide transformations that simplify the writing of efficient and robust geometric algorithms. General purpose extensions include Java 1.5 features such as the for-each loop and auto-boxing and unboxing and features from Pizza such as pattern matching.},
key = {Object oriented programming},
keywords = {Computational grammars;Computer aided software engineering;Java programming language;Semantics;Syntactics;},
note = {Attribute grammars;Extensible languages;Forwarding attributes;},
URL = {http://dx.doi.org/10.1145/1176617.1176696},
} 


@inproceedings{20102312989103 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Context-free grammar induction using genetic programming},
journal = {Proceedings of the Annual Southeast Conference},
author = {Javed, F. and Bryant, B.R. and Crepinek, M. and Mernik, M. and Sprague, A.},
year = {2004},
pages = {404 - 405},
address = {Huntsville, AL, United states},
abstract = {While grammar inference is used in areas like natural language acquisition, syntactic pattern recognition, etc., its application to the programming language problem domain has been limited. We propose a new application area for grammar induction which intends to make domain-specific language development easier and finds a second application in renovation tools for legacy systems. The genetic programming approach is used for grammatical inference. Our earlier work used grammar-specific heuristic operators in tandem with non-random construction of the initial grammar population and succeeded in inducing small grammars. Copyright 2004 ACM.},
key = {Genetic programming},
keywords = {Computational grammars;Computer aided software engineering;Legacy systems;Linguistics;Management information systems;Pattern recognition;Problem oriented languages;},
note = {Domain specific languages;Grammar induction;Grammar inference;Grammatical inferences;Natural language acquisition;New applications;Programming language;Syntactic pattern recognition;},
URL = {http://dx.doi.org/10.1145/986537.986635},
} 


@inproceedings{2005509533142 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Building compilers by combining algebras},
journal = {Proceedings - 12th IEEE International Conference and Workshops on the Engineering of Computer-Based Systems, ECS 2005},
author = {Kimmell, Garrin and Komp, Ed and Alexander, Perry},
year = {2005},
pages = {331 - 338},
address = {Greenbelt, MD, United states},
abstract = {Embedded systems present a wide variety of challenges for developers of language tools. Verification of correctness, flexibility for adding new language features, retreatingand retargeting new architectures all present significant problems when developing a compiler for embedded systems. In this paper we present a domain-specific language based on modular monadic semantics which addresses many of these challenges. &copy; 2005 IEEE.},
key = {Program compilers},
keywords = {Algebra;Computer architecture;Embedded systems;Problem solving;Semantics;},
note = {Language tools;Modular monadic semantics;},
} 


@article{IP51293977 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Harvesting models from web 2.0 databases},
journal = {Software and Systems Modeling},
author = {Diaz, Oscar and Puente, Gorka and Canovas Izquierdo, Javier Luis and Garcia Molina, Jesus},
year = {2011},
pages = {1 - 20},
issn = {16191366},
abstract = {Data rather than functionality are the sources of competitive advantage for Web2.0 applications such as wikis, blogs and social networking websites. This valuable information might need to be capitalized by third-party applications or be subject to migration or data analysis. Model-Driven Engineering (MDE) can be used for these purposes. However, MDE first requires obtaining models from the wiki/blog/website database (a.k.a. model harvesting). This can be achieved through SQL scripts embedded in a program. However, this approach leads to laborious code that exposes the iterations and table joins that serve to build the model. By contrast, a Domain-Specific Language (DSL) can hide these "how" concerns, leaving the designer to focus on the "what", i.e. the mapping of database schemas to model classes. This paper introduces Schemol, a DSL tailored for extracting models out of databases which considers Web2.0 specifics. Web2.0 applications are often built on top of general frameworks (a.k.a. engines) that set the database schema (e.g., MediaWiki, Blojsom). Hence, table names offer little help in automating the extraction process. In addition, Web2.0 data tend to be annotated. User-provided data (e.g., wiki articles, blog entries) might contain semantic markups which provide helpful hints for model extraction. Unfortunately, these data end up being stored as opaque strings. Therefore, there exists a considerable conceptual gap between the source database and the target metamodel. Schemol offers extractive functions and view-like mechanisms to confront these issues. Examples using Blojsom as the blog engine are available for download. &copy; 2011 Springer-Verlag.},
key = {Database systems},
keywords = {Competition;Internet;Problem oriented languages;Semantics;Web services;Websites;},
note = {Competitive advantage;Data analysis;Database schemas;Domain specific languages;Extraction process;MediaWiki;Meta model;Model extraction;Model-driven engineering;Semantic markup;Social networking;Web 2.0;},
URL = {http://dx.doi.org/10.1007/s10270-011-0194-z},
} 


@inproceedings{20110813687080 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Kumoi: A high-level scripting environment for collective virtual machines},
journal = {Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS},
author = {Sugiki, Akiyoshi and Kato, Kazuhiko and Ishii, Yoshiaki and Taniguchi, Hiroki and Hirooka, Nobuyuki},
year = {2010},
pages = {322 - 329},
issn = {15219097},
address = {Shanghai, China},
abstract = {We have designed and implemented a scripting environment called "Kumoi" for managing collective VMs in a large-scale data center. Kumoi is unlike other scripting environments because it exploits strong typing with type inference and high-level description. Kumoi introduces several advancements, including treating virtual machines as first-class objects and decoupling the scripting model and its execution for hiding as many details as possible. We implemented Kumoi as an embedded domain-specific language based on Scala along with distributed agents running on each physical machine. Evaluation using example scripts showed that an administrator can more concisely write the instructions for performing complex VM lifecycle management tasks. Use of this environment should improve management efficiency and agility. &copy; 2010 IEEE.},
key = {Cloud computing},
keywords = {Computer simulation;Computer systems;Problem oriented languages;},
note = {Class objects;Clusters;Data centers;Distributed agents;Embedded domains;High level description;Life-cycle management;Management efficiency;Scripting environment;Type inferences;Virtual machines;},
URL = {http://dx.doi.org/10.1109/ICPADS.2010.71},
} 


@inproceedings{20091311993034 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {CSIIRW'08 - 4th Annual Cyber Security and Information Intelligence Research Workshop: Developing Strategies to Meet the Cyber Security and Information Intelligence Challenges Ahead},
journal = {CSIIRW'08 - 4th Annual Cyber Security and Information Intelligence Research Workshop: Developing Strategies to Meet the Cyber Security and Information Intelligence Challenges Ahead},
year = {2008},
address = {Oak Ridge, TN, United states},
abstract = {The proceedings contain 26 papers. The topics discussed include: formal derivation of security design specifications from security requirements; semantics for a domain-specific language for the digital forensics domain; design for survivability: a tradeoff space; a rigorous methodology for security architecture modeling and verification; detecting sensitive data exfiltration by an insider attack; log-based distributed intrusion detection for hybrid networks; dynamic intrusion sequences monitor for virus detection; towards practical intrusion tolerant systems: a blueprint; ULISSE, a network intrusion detection system; real-world polymorphic attack detection using network-level emulation; extending hardware based mandatory access controls for memory to multicore architectures; active semantically aware hard real-time security hypervisors; a multi-layered security architecture for modelling complex systems; and optimizing quality of service of wireless mobile ad-hoc networks using evolutionary computation.},
} 


@inproceedings{20090611900852 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Write it recursively: A generic framework for optimal path queries},
journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
author = {Morihata, Akimasa and Matsuzaki, Kiminori and Takeichi, Masato},
year = {2008},
pages = {169 - 178},
address = {Victoria, BC, Canada},
abstract = {Optimal path queries are queries to obtain an optimal path specified by a given criterion of optimality. There have been many studies to give efficient algorithms for classes of optimal path problem. In this paper, we propose a generic framework for optimal path queries. We offer a domain-specific language to describe optimal path queries, together with an algorithm to find an optimal path specified in our language. One of the most distinct features of our framework is the use of recursive functions to specify queries. Recursive functions reinforce expressiveness of our language so that we can describe many problems including known ones; thus, we need not learn existing results. Moreover, we can derive an efficient querying algorithm from the description of a query written in recursive functions. Our algorithm is a generalization of existing algorithms, and answers a query in O(n log n) time on a graph of O(n) size. We also explain our implementation of an optimal path querying system, and report some experimental results. Copyright &copy; 2008 ACM.},
key = {Recursive functions},
keywords = {Algorithms;Automata theory;Computer programming;Fourier transforms;Functional programming;Functions;Linguistics;Optimization;Probability density function;Programming theory;Systems analysis;Translation (languages);},
note = {Domain-Specific Languages;Efficient algorithms;Finite state automaton;Generic frameworks;Given criterions;Optimal path query;Optimality;Program transformation;Querying systems;Recursive function;},
URL = {http://dx.doi.org/10.1145/1411204.1411229},
} 


@inproceedings{20101312803548 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model based testing of end-to-end chains using domain specific languages},
journal = {TAIC PART 2009 - Testing: Academic and Industrial Conference - Practice and Research Techniques},
author = {Hartmann, Tobias},
year = {2009},
pages = {82 - 91},
address = {Windsor, United kingdom},
abstract = {In this paper, the author explains a new approach of model based end-to-end chain testing using scenarios with original and simulated equipment. The first goal is to automatically derive test data and test cases from the model, which is defined by a domain specific language. Several solvers can be attached to the conversion to quickly create a wide variety of stimuli for the system(s) under test. Furthermore, the system under test can be stimulated by either original equipment - which is connected to the test bench - or the test bench can simulate equipment and create inputs for the tested systems. Any mixture of simulated and original equipment is possible and can be changed on the fly. In the end, the results from the system under test are collected. These results can then be displayed back in the model. This method is currently used and improved in the project "E-Cab" in which the author is involved. Passengers travelling by plane are in the focus of this project. Complete services and service chains - from the booking at home up to leaving the destination airport - are created and used by many systems communicating with each other. The author expects advantages from testing these end-to-end chains with this approach. &copy; 2009 IEEE.},
key = {Testing},
keywords = {Data communication systems;Equipment;Linguistics;Query languages;Test facilities;},
note = {Automatic test data generation;Automatic testcase generation;Chain models;Domain specific languages;Model based testing;Model-based;New approaches;On the flies;Service chain;System under test;Test benches;Test case;Test data;},
URL = {http://dx.doi.org/10.1109/TAICPART.2009.25},
} 


@inproceedings{20084811751684 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Managing model conflicts in distributed development},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Cicchetti, Antonio and Di Ruscio, Davide and Pierantonio, Alfonso},
volume = {5301 LNCS},
year = {2008},
pages = {311 - 325},
issn = {03029743},
address = {Toulouse, France},
abstract = {The growing complexity of current software systems naturally conveyed their development toward incremental and distributed approaches to speed up the process. Several developers update the same artefact operating concurrent manipulations which need to be coherently combined. The interaction among those changes inevitably involves conflicts which must be detected and reconciled. This paper proposes a domain specific language able to define and manage conflicts caused by cooperative updates over the same model elements. The approach relies on a model-based representation of model differences and enables the specification and the detection of both syntactical and semantic conflicts. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Models},
keywords = {Computational complexity;Information theory;Linguistics;Query languages;},
note = {Current softwares;Distributed approaches;Distributed developments;Domain specifics;Model elements;Model-based;Semantic conflicts;Speed-up;},
URL = {http://dx.doi.org/10.1007/978-3-540-87875-9_23},
} 


@inproceedings{20090611900876 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Groovy AOP: A dynamic AOP system for a JVM-based language},
journal = {ACM International Conference Proceeding Series},
author = {Kaewkasi, Chanwit and Gurd, John R.},
year = {2008},
address = {Brussels, Belgium},
abstract = {Groovy AOP is a general-purpose AOP system for Groovy, a JVM-based dynamic language. Groovy AOP provides a hybrid dynamic AOP implementation based on both metaprogramming and bytecode transformation. It implements the pointcut-advice model of AspectJ. Based on Groovy syntax, Groovy AOP introduces a domain-specific language for declaration of aspects, pointcut expressions, and advice. At runtime, it utilises the dynamic compilation capability of the JVM to convert advice codes woven by meta-programming into bytecodes. Preliminary results show that this dynamic weaving technique preserves the nature of a dynamic language, while reducing runtime overheads. Copyright &copy; 2008 ACM.},
key = {Machine oriented languages},
keywords = {Fourier transforms;Linguistics;Programming theory;Query languages;Software design;Software engineering;Weaving;},
note = {Aspect-j;Aspect-oriented programming;Byte-codes;Bytecode transformations;Domain-Specific Languages;Dynamic compilations;Dynamic languages;Dynamic weaving;Hybrid dynamics;Meta-programming;Pointcut;Run-time;Runtime overheads;Virtual machine;},
URL = {http://dx.doi.org/10.1145/1408647.1408650},
} 


@inproceedings{20113914362203 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Integrating DSL-CBI and NuSMV for modeling and verifiying interlocking systems},
journal = {2011 5th International Conference on Secure Software Integration and Reliability Improvement - Companion, SSIRI-C 2011},
author = {Cao, Yan and Lu, Qiuzi and Xu, Tianhua and Tang, Tao and Wang, Haifeng and Xu, Yongcheng},
year = {2011},
pages = {136 - 143},
address = {Jeju Island, Korea, Republic of},
abstract = {The Computer Based Interlocking System (CBI) is used to ensure safe train movements at a railway station. For a given station, all the train routes and the concrete safety rules associated with these are defined in the interlocking table. Currently, the development and verification of interlocking tables is entirely manual process, which is inefficient and error-prone due to the complexity of the CBI and the human interferences. Besides, the complexity and volume of the verification results tend to make users feel extremely non-understandable. In order to tackle these problems, we introduce a toolset based on Domain Specific Language for Computer Based Interlocking Systems (DSL-CBI) to automatically generate and verify the interlocking table, and then mark the conflicting routes in the railway station. In this paper, we also discuss the advantages of the toolset and the significant contribution in developing CBI based on the proposed toolset. &copy; 2011 IEEE.},
key = {Interlocking signals},
keywords = {Railroad stations;Railroads;Safety devices;Software reliability;Visualization;},
note = {Computer Based Interlocking;Domain specific languages;Error prones;Human interference;Interlocking systems;Interlocking table;Manual process;Railway stations;Safety rules;Toolsets;Train movement;Verification results;},
URL = {http://dx.doi.org/10.1109/SSIRI-C.2011.28},
} 


@article{20092912192407 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Write it recursively: A generic framework for optimal path queries},
journal = {ACM SIGPLAN Notices},
author = {Morihata, Akimasa and Matsuzaki, Kiminori and Takeichi, Masato},
volume = {43},
number = {9},
year = {2008},
pages = {169 - 178},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Optimal path queries are queries to obtain an optimal path specified by a given criterion of optimality. There have been many studies to give efficient algorithms for classes of optimal path problem. In this paper, we propose a generic framework for optimal path queries. We offer a domain-specific language to describe optimal path queries, together with an algorithm to find an optimal path specified in our language. One of the most distinct features of our framework is the use of recursive functions to specify queries. Recursive functions reinforce expressiveness of our language so that we can describe many problems including known ones; thus, we need not learn existing results. Moreover, we can derive an efficient querying algorithm from the description of a query written in recursive functions. Our algorithm is a generalization of existing algorithms, and answers a query in O(n log n) timeonagraphof O(n) size. We also explain our implementation of an optimal path querying system, and report some experimental results. Copyright &copy; 2008 ACM.},
key = {Recursive functions},
keywords = {Algorithms;Finite automata;Linguistics;Optimization;Systems analysis;Translation (languages);},
note = {Domain specific languages;Efficient algorithm;Finite state automaton;Generic frameworks;Given criterion;Optimal path query;Optimal paths;Optimality;Program transformation;Querying systems;},
} 


@inproceedings{20100412659583 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Concxsepts for model-based requirements testing of service oriented systems},
journal = {Proceedings of the IASTED International Conference on Software Engineering, SE 2009},
author = {Felderer, Michael and Breu, Ruth and Chimiak-Opoka, Joanna and Breu, Michael and Schupp, Felix},
year = {2009},
pages = {152 - 157},
address = {Innsbruck, Austria},
abstract = {In this paper we present the core concepts of Telling Test-Stories, a model - driven framework for test - driven requirements testing of service oriented systems. Telling TestSto-ries provides a new way of eliciting and validating requirements through intertwined specification of requirements and executable test stories. We define a Domain Specific Language (DSL) to formalize the system requirements and the test model. The DSL allows test cases to be specified based on the concepts of the requirements specification (actors, objects, services) and test cases to be separated from test data. To ensure the quality of the designed artifacts we introduce consistency and coverage checks expressed in OCL. We provide a prototypic implementation of the concepts and started an industrial validation of its usability.},
key = {Testing},
keywords = {Computer software;DSL;Flow patterns;Linguistics;Modems;Quality assurance;Quality control;Query languages;Requirements engineering;Specifications;Spontaneous emission;Telecommunication lines;Total quality management;},
note = {Domain specific languages;Industrial validation;Model based testing;Model-based;Model-driven;Requirements specifications;Service Oriented Systems;System requirements;Test case;Test data;Test models;},
} 


@inproceedings{20063010024199 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Massively parallel processors generator for reconfigurable system},
journal = {Proceedings - 13th Annual IEEE Symposium on Field-Programmable Custom Computing Machines, FCCM 2005},
author = {Hamada, Tsuyoshi and Nakasato, Naohito},
volume = {2005},
year = {2005},
pages = {329 - 330},
address = {Napa, CA, United states},
abstract = {We have developed PGR(Processors Generator for Reconfigurable system) package which generate (a) a suitable configuration file for the FPGAs, (b) the C source code for interfacing with an FPGA-based accelerator, and (c) a software emulator from a high-level domain specific language. Using PGR package, we can easily produce high performance implementations for the particle-based simulation. &copy; 2005 IEEE.},
key = {Parallel processing systems},
keywords = {Computer architecture;Computer simulation;Computer software;Field programmable gate arrays;Performance;},
note = {High-level domain specific languages;Parallel processors;Reconfigurable system;},
URL = {http://dx.doi.org/10.1109/FCCM.2005.45},
} 


@inproceedings{20113314241662 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Experimentation made easy},
journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering},
author = {Gunes, Mesut and Blywis, Bastian and Juraschek, Felix and Watteroth, Olaf},
volume = {28 LNICST},
year = {2010},
pages = {493 - 505},
issn = {18678211},
address = {Niagara Falls, ON, Canada},
abstract = {Scientifically sound network studies require the execution of large series of experiments. Researchers usually have to execute experiments manually, a labor-intensive and error-prone task, since there is no automation of the overall experimentation process. This task becomes especially hard on a distributed testbed and the researcher has to deal with additional challenges. In this paper we introduce the Distributed Embedded Systems Testbed Management System (DES-TBMS) for the automation of experimentation in wireless mesh networks and wireless sensor networks. DES-TBMS consists of several components including a domain specific language to describe and define experiments, a scheduler to manage and control experiments, a distributed monitoring system to gather system data, a visualization tool, and an evaluation tool to compute performance metrics from collected experiment data. Thus, DES-TBMS supports the researcher during the design, execution, and evaluation of experiments. &copy; 2010 ICST Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering.},
key = {Experiments},
keywords = {Ad hoc networks;Data visualization;Embedded systems;MESH networking;Monitoring;Test facilities;Testbeds;Visualization;Wireless sensor networks;},
note = {Control experiments;Distributed embedded system;Distributed monitoring systems;Domain specific languages;Error prones;Evaluation tool;Experiment data;Management systems;Performance metrics;Visualization tools;},
URL = {http://dx.doi.org/10.1007/978-3-642-11723-7_33},
} 


@inproceedings{20092312106271 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Patterns for modeling and composing workflows from grid services},
journal = {Lecture Notes in Business Information Processing},
author = {Bendaly Hlaoui, Yousra and Jemni Ben Ayed, Leila},
volume = {24 LNBIP},
year = {2009},
pages = {615 - 626},
issn = {18651348},
address = {Milan, Italy},
abstract = {We propose a set of composition patterns based on UML activity diagrams that support the different forms of matching and integrating Grid service operations in a workflow. The workflows are built on an abstract level using UML activity diagram language and following an MDA composition approach. In addition, we propose a Domain Specific Language (DSL) which extends the UML activity diagram notation allowing a systematic composition of workflows and containing appropriate data to describe a Grid service. These data are useful for the execution of the resulting workflow. &copy; 2009 Springer Berlin Heidelberg.},
key = {Systems analysis},
keywords = {Grid computing;Information systems;Linguistics;Management;Query languages;Semantics;},
note = {Grid services;MDA approach;Semantic composition;UML-activity diagram;Workflow;},
URL = {http://dx.doi.org/10.1007/978-3-642-01347-8_51},
} 


@inproceedings{20103013090676 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Objects, Models, Components, Patterns - 48th International Conference, TOOLS 2010, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {6141 LNCS},
year = {2010},
issn = {03029743},
address = {Malaga, Spain},
abstract = {The proceedings contain 16 papers. The topics discussed include: deep meta-modelling with METADEPTH; a generic meta-model-based approach for specifying framework functionality and usage; loosely-coupled distributed reactive programming in mobile ad hoc networks; understanding the impact of collection contracts on design; reasoning about function objects; welterweight Java; read-only execution for dynamic languages; optimizing aspect-oriented mechanisms for embedded applications; contract-driven testing of JavaScript code; late binding of AspectJ advice; EriLex: an embedded domain specific language generator; domain-specific program checking; revisiting parametric types and virtual classes; Moles: tool-assisted environment isolation with closures; encoding ownership types in Java; and visualizing dynamic metrics with profiling blueprints.},
} 


@inproceedings{20095012544702 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An end-to-end approach for QoS-aware service composition},
journal = {Proceedings - 13th IEEE International Enterprise Distributed Object Computing Conference, EDOC 2009},
author = {Rosenberg, Florian and Celikovic, Predrag and Michlmayr, Anton and Leitner, Philipp and Dustdar, Schahram},
year = {2009},
pages = {151 - 160},
address = {Auckland, New zealand},
abstract = {A simple and effective composition of software services into higher-level composite services is still a very challenging task. Especially in enterprise environments, Quality of Service (QoS) concerns play a major role when building software systems following the Service-Oriented Architecture (SOA) paradigm. In this paper we present a composition approach based on a domain-specific language (DSL) for specifying functional requirements of services and the expected QoS in form of constraint hierarchies by leveraging hard and soft constraints. A composition runtime will resolve the user's constraints to find an optimized composition semi-automatically. To this end we leverage data flow analysis to generate a structured composition model and use two different techniques for the optimization, a constraint programming and an integer programming approach. &copy; 2009 IEEE.},
key = {Integer programming},
keywords = {Computer programming;Computer software;Constrained optimization;Constraint theory;Data flow analysis;Information services;Problem oriented languages;Quality of service;Service oriented architecture (SOA);Software architecture;},
note = {Building softwares;Composite services;Composition model;Constraint hierarchy;Constraint programming;Domain specific languages;Enterprise environment;Functional requirement;Hard and soft constraints;Runtimes;Service compositions;Software services;},
URL = {http://dx.doi.org/10.1109/EDOC.2009.14},
} 


@inproceedings{20102012929260 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automating the implementation of analysis concerns in workflow applications},
journal = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
author = {Gonzalez, Oscar and Casallas, Rubby and Deridder, Dirk},
year = {2009},
pages = {585 - 589},
address = {Auckland, New zealand},
abstract = {In workflow management systems, analysis concerns related to monitoring, measurement, and control aim at identifying potential improvements of workflow applications. However, the specification of analysis concerns is done using a specific workflow language and engine, producing entangled code which is detrimental to their maintainability. The purpose of this paper is twofold. First, it presents briefly a domain-specific language to specify analysis concerns, independently of any workflow technology and in a modularized way. Second, it shows a strategy to assist developers to enhance a given workflow technology to support the automated implementation of analysis concerns into its workflow applications. Thus, given a workflow application and its analysis concerns, they are automatically integrated producing an enhanced executable workflow application. &copy; 2009 IEEE.},
key = {Management},
keywords = {Automation;Computer software;Linguistics;Maintainability;Network components;Problem oriented languages;Query languages;Work simplification;},
note = {Analysis concerns;Code Generation;Domain specific languages;Modularized;Workflow applications;Workflow language;Workflow Management Systems;Workflow managements;Workflow technology;},
URL = {http://dx.doi.org/10.1109/ASE.2009.29},
} 


@inproceedings{20080411044482 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Integrating databases, search engines and web applications: A model-driven approach},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Bozzon, Alessandro and Iofciu, Tereza and Nejdl, Wolfgang and Tonnies, Sascha},
volume = {4607 LNCS},
year = {2007},
pages = {210 - 225},
issn = {03029743},
address = {Como, Italy},
abstract = {This paper addresses conceptual modeling and automatic code generation for search engine integration with data intensive Web applications. We have analyzed the similarities (and differences) between IR and database systems to extend an existing domain specific language for data-driven Web applications. The extended Web modeling language specifies the search engine's index schemas based on the data schema of the Web application and uniquely designs the interaction between the database, the Web application, the search engine and users. We also provide an implementation of a CASE tool extension for visual modeling and code generation. Experimentation of the proposed approach has been successfully applied in the context of the COOPER project. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Search engines},
keywords = {Computer applications;Data reduction;Database systems;Formal languages;Web services;},
note = {Index modeling;Search engine design;Web engineering;Web site design;},
} 


@inproceedings{20100412654595 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {APRiL: A DSL for payroll reporting},
journal = {Future Trends of Model-Driven Development - Proceedings of the 1st International Workshop on Future Trends of Model-Driven Development - FTMDD 2009 In Conjunction with ICEIS 2009},
author = {Zhang, Xiaorui and Lin, Yun and Haugen, Oystein},
year = {2009},
pages = {23 - 32},
address = {Milan, Italy},
abstract = {The highly diverse payroll reporting structures within and between organizations pose challenges to enterprise information system vendors. Producing the database scripts for customized configuration of payroll reporting has been traditionally a costly manual process. We show how this process can be automated and made less error-prone and more user-friendly by introducing a combination of Model-Driven Development (MDD) and a Domain Specific Language (DSL). This paper addresses the development of Agresso Payroll Reporting Language (APRiL), a DSL to describe payroll structures and hierarchies. The language is supported by tailored tools created with open source technologies on Eclipse. We look at the potential implications of our approach on the development of payroll reporting system, along with its advantages and challenges. We also explore possible improvements and application of our approach in other areas of enterprise information systems.},
key = {Information systems},
keywords = {DSL;Linguistics;Modems;Telecommunication lines;Wages;},
note = {Domain specific languages;Enterprise informa-tion systems;Error prones;Manual process;Model-driven development;Open-source technology;Reporting systems;},
} 


@inproceedings{2006279974368 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling genome evolution with a DSEL for probabilistic programming},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Erwig, Martin and Kollmansberger, Steve},
volume = {3819 LNCS},
year = {2005},
pages = {134 - 149},
issn = {03029743},
address = {Charleston, SC, United states},
abstract = {Many scientific applications benefit from simulation. However, programming languages used in simulation, such as C++ or Matlab, approach problems from a deterministic procedural view, which seems to differ, in general, from many scientists' mental representation. We apply a domain-specific language for probabilistic programming to the biological field of gene modeling, showing how the mental-model gap may be bridged. Our system assisted biologists in developing a model for genome evolution by separating the concerns of model and simulation and providing implicit probabilistic non-determinism. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Genes},
keywords = {Computer programming languages;Computer simulation;Genetic engineering;Logic programming;Mathematical models;Probabilistic logics;},
note = {C++;Matlab;Modeling;Probabilistic programming;},
URL = {http://dx.doi.org/10.1007/11603023_10},
} 


@inproceedings{20090611900867 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Flask: Staged functional programming for sensor networks},
journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
author = {Mainland, Geoffrey and Morrisett, Greg and Welsh, Matt},
year = {2008},
pages = {335 - 345},
address = {Victoria, BC, Canada},
abstract = {Severely resource-constrained devices present a confounding challenge to the functional programmer: we are used to having powerful abstraction facilities at our fingertips, but how can we make use of these tools on a device with an 8- or 16-bit CPU and at most tens of kilobytes of RAM? Motivated by this challenge, we have developed Flask, a domain specific language embedded in Haskell that brings the power of functional programming to sensor networks, collections of highly resource-constrained devices. Flask consists of a staging mechanism, that cleanly separates node-level code from the meta-language used to generate node-level code fragments; syntactic support for embedding standard sensor network code; a restricted subset of Haskell that runs on sensor networks and constrains program space and time consumption; a higher-level "data stream" combinator library for quickly constructing sensor network programs; and an extensible runtime that provides commonly-used services. We demonstrate Flask through several small code examples as well as a compiler that generates node-level code to execute a network-wide query specified in a SQL-like language. We show how using Flask ensures constraints on space and time behavior. Through microbenchmarks and measurements on physical hardware, we demonstrate that Flask produces programs that are efficient in terms of CPU and memory usage and that can run effectively on existing sensor network hardware. Copyright &copy; 2008 ACM.},
key = {Sensor networks},
keywords = {Computer hardware description languages;Computer programming;Functional programming;Linguistics;Programming theory;Sensors;},
note = {Code fragments;Combinator libraries;Data streams;Domain-Specific Languages;Haskell;Memory usages;Meta languages;Meta programming;Microbenchmarks;Network codes;Resource-constrained devices;Run-time;Space and time;},
URL = {http://dx.doi.org/10.1145/1411204.1411249},
} 


@article{20092912192423 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Flask: Staged functional programming for sensor P},
journal = {ACM SIGPLAN Notices},
author = {Mainland, Geoffrey and Morrisett, Greg and Welsh, Matt},
volume = {43},
number = {9},
year = {2008},
pages = {335 - 345},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Severely resource-constrained devices present a confounding challenge to the functional programmer: we are used to having powerful abstraction facilities at our fingertips, but how can we make use of these tools on a device with an 8- or 16-bit CPU and at most tens of kilobytes of RAM? Motivated by this challenge, we have developed Flask, a domain specific language embedded in Haskell that brings the power of functional programming to sensor networks, collections of highly resource-constrained devices. Flask consists of a staging mechanism that cleanly separates node-level code from the meta-language used to generate node-level code fragments; syntactic support for embedding standard sensor network code; a restricted subset of Haskell that runs on sensor networks and constrains program space and time consumption; a higher-level "data stream" combinator library for quickly constructing sensor network programs; and an extensible runtime that provides commonly-used services. We demonstrate Flask through several small code examples as well as a compiler that generates node-level code to execute a network-wide query specified in a SQL-like language. We show how using Flask ensures constraints on space and time behavior. Through microbenchmarks and measurements on physical hardware, we demonstrate that Flask produces programs that are efficient in terms of CPU and memory usage and that can run effectively on existing sensor network hardware. Copyright &copy; 2008 ACM.},
key = {Sensor networks},
keywords = {Computer hardware description languages;Functional programming;Linguistics;},
note = {Code fragments;Combinator library;Data stream;Domain specific languages;Haskell;Memory usage;Meta language;Meta Programming;Microbenchmarks;Resourceconstrained devices;Runtime;Space and time;},
} 


@inproceedings{2005399389480 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Building a Software Factory for pervasive systems development},
journal = {Lecture Notes in Computer Science},
author = {Munoz, Javier and Pelechano, Vicente},
volume = {3520},
year = {2005},
pages = {342 - 356},
issn = {03029743},
address = {Porto, Portugal},
abstract = {The rise of the number and complexity of pervasive systems is a fact. Pervasive systems developers need advanced development methods in order to build better systems in an easy way. Software Factories and the Model Driven Architecture (MDA) are two important trends in the software engineering field. This paper applies the guidelines and strategies described by these proposals in order to build a methodological approach for pervasive systems development. Software Factories are based on the definition of software families supported by frameworks. Individual systems requirements are specified by means of domain specific languages. Following this strategy, our approach defines a framework and a domain specific language for pervasive systems. We use the MDA guidelines to support the development of our domain specific language and the automatic generation of the specific source code of a particular system. The approach presented in this paper raises the abstraction level in the development of pervasive systems and provides high reusable assets to reduce the effort in the development projects. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Computer software},
keywords = {Abstracting;Computational complexity;Computer architecture;Computer programming languages;Mathematical models;Project management;},
note = {Model driven architecture (MDA);Pervasive systems;Software factory;System development;},
} 


@inproceedings{20105113510233 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Catch me if you can - Debugging support for model transformations},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Schoenboeck, Johannes and Kappel, Gerti and Kusel, Angelika and Retschitzegger, Werner and Schwinger, Wieland and Wimmer, Manuel},
volume = {6002 LNCS},
year = {2010},
pages = {5 - 20},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {Model-Driven Engineering places models as first-class artifacts throughout the software lifecycle requiring the availability of proper transformation languages. Although numerous approaches are available, they lack convenient facilities for supporting debugging and understanding of the transformation logic. This is because execution engines operate on a low level of abstraction, hide the operational semantics of a transformation, scatter metamodels, models, transformation logic, and trace information across different artifacts, and provide limited verification support. To tackle these problems, we propose a Domain-Specific Language (DSL) on top of Colored Petri Nets (CPNs)-called Transformation Nets-for the execution and debugging of model transformations on a high level of abstraction. This formalism makes the afore hidden operational semantics explicit by providing a runtime model in terms of places, transitions and tokens, integrating all artifacts involved into a homogenous view. Moreover, the formal underpinnings of CPNs enable comprehensive verification of model transformations. &copy; Springer-Verlag Berlin Heidelberg 2010.},
key = {Models},
keywords = {Abstracting;Computer programming languages;Computer software selection and evaluation;Petri nets;Problem oriented languages;Semantics;Software engineering;},
note = {Colored Petri Nets;CPN;Debugging;Debugging support;Domain specific languages;Execution engine;High level of abstraction;Low level;Meta model;Model transformation;Model-driven Engineering;Operational semantics;Runtime models;Software life cycles;Trace information;},
URL = {http://dx.doi.org/10.1007/978-3-642-12261-3_2},
} 


@inproceedings{20112914152568 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A DSL for corporate wiki initialization},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Diaz, Oscar and Puente, Gorka},
volume = {6741 LNCS},
year = {2011},
pages = {237 - 251},
issn = {03029743},
address = {London, United kingdom},
abstract = {Some wikis support virtual communities that are built around the wiki itself (e.g., Wikipedia). By contrast, corporate wikis are not created in a vacuum since the community already exists. Documentation, organigrams, etc are all there by the time the wiki is created. The wiki should then be tuned to the existing information ecosystem. That is, wiki concerns (e.g., categories, permissions) are to be influenced by the corporate settings. So far, "all wikis are created equal": empty. This paper advocates for corporate wikis to be initialized with a "wiki scaffolding": a wiki installation where some categories, permissions, etc, are initialized to mimic the corporate settings. Such scaffolding is specified in terms of a Domain Specific Language (DSL). The DSL engine is then able to turn the DSL expression into a Media Wiki installation which is ready to be populated but now, along the company settings. The DSL is provided as a FreeMind plugin, and DSL expressions are denoted as mindmaps. &copy; 2011 Springer-Verlag.},
key = {Information systems},
keywords = {Scaffolds;Systems engineering;Virtual reality;},
note = {Domain specific languages;Information ecosystems;MDE;Plug-ins;Virtual community;wiki;Wikipedia;},
URL = {http://dx.doi.org/10.1007/978-3-642-21640-4_19},
} 


@inproceedings{20094712457557 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model Driven Architecture - Foundations and Applications - 5th European Conference, ECMDA-FA 2009, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {5562 LNCS},
year = {2009},
issn = {03029743},
address = {Enschede, Netherlands},
abstract = {The proceedings contain 23 papers. The topics discussed include: comparison of three model transformation languages; on the use of higher-order model transformations; managing model adaptation by precise detection of metamodel changes; a pattern mining approach using QVT; a language-theoretic view on guidelines and consistency rules of UML; a domain specific language for extracting models in software modernization; challenges in combining sysML and MARTE for model-based design of embedded systems; derivation and refinement of textual syntax for models; uniform random generation of huge metamodel instances; establishing correspondences between models with the epsilon comparison language; dependent and conflicting change operations of process models; enabling automated traceability maintenance through the upkeep of traceability relations; temporal extensions of OCL revisited; and an MDA-based approach for behavior modeling of context-aware mobile applications.},
} 


@inproceedings{20111013715423 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A case study for defining interoperable network components using MDD},
journal = {Proceedings - UKSim 4th European Modelling Symposium on Computer Modelling and Simulation, EMS2010},
author = {Boudjemil, Zohra and Phelan, Patrick and De Leon, Miguel Ponce and Van Der Meer, Sven},
year = {2010},
pages = {381 - 386},
address = {Pisa, Italy},
abstract = {The current Internet is built on a set of protocols, but exhibits problems in supporting applications. The network is optimised for best-effort traffic, but other functional aspects are widely neglected. Applying concepts well-known in software engineering (abstraction, composition, separation of concerns) to design the future Internet architecture is seen as a promising way forward. This paper presents a case study using Model Driven Development addressing interoperability requirements in next generation networks. Our approach focuses on the specification of a high level Contract Domain Specific Language we combine Component-based Software Engineering for the design with our long-term experience of network resource management and performance optimisation. Part of our case study is a tool chain that supports the network engineers who deploy next generation networks. &copy; 2010 Crown Copyright.},
key = {Computer simulation},
keywords = {Internet;Internet protocols;Interoperability;Network management;Research;Software engineering;},
note = {Best-Effort Traffic;Component-based software engineering;Domain specific languages;Functional aspects;Future internet architecture;Interoperable network;MDD;Model driven development;Network;Network engineers;Network resource management;Next generation network;Performance optimisation;Separation of concerns;},
URL = {http://dx.doi.org/10.1109/EMS.2010.69},
} 


@inproceedings{20103513193950 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Rule based constraints for the construction of genetic devices},
journal = {ISCAS 2010 - 2010 IEEE International Symposium on Circuits and Systems: Nano-Bio Circuit Fabrics and Systems},
author = {Densmore, Douglas and Kittlesony, Joshua T. and Bilitchenkoz, Lesia and Liux, Adam and Andersony, J. Christopher},
year = {2010},
pages = {557 - 560},
address = {Paris, France},
abstract = {The construction of composite genetic devices from primitive parts is a key activity in synthetic biology. Currently there does not exist a formal method to specify constraints on the construction of these devices. These constraints would help enable an automated design flow from device specification to physical assembly. This paper examines the laboratory creation of variations of a particular genetic device called a phagemid. We illustrate how lessons learned empirically from the non-functional designs can be captured formally as constraints in a newly created domain specific language called "Eugene". These constraints will prevent many faulty constructions automatically in the future saving time and money while increasing design abstraction and productivity. &copy;2010 IEEE.},
key = {Design},
keywords = {Fabrics;Formal methods;},
note = {Automated design;Design abstractions;Device specification;Domain specific languages;Non-functional;Physical assemblies;Rule based;Synthetic biology;},
URL = {http://dx.doi.org/10.1109/ISCAS.2010.5537540},
} 


@inproceedings{20100212619770 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {APIs a gogo: Automatic generation of ontology APIs},
journal = {ICSC 2009 - 2009 IEEE International Conference on Semantic Computing},
author = {Parreiras, Fernando Silva and Saathoff, Carsten and Walter, Tobias and Franz, Thomas and Staab, Steffen},
year = {2009},
pages = {342 - 348},
address = {Berkeley, CA, United states},
abstract = {When developing application programming interfaces of ontologies that include many instances of ontology design patterns, developers of semantic web applications usually have to handle complex mappings between descriptions of information given by ontologies and object oriented representations of the same information. In current approaches, annotations on API source code handle these mappings, leading to problems with reuse and maintenance. We propose a domain-specific language to tackle these mappings in a platform independent way - agogo. Agogo provides improvements on software engineering quality attributes like usability, reusability, maintainability, and portability. &copy; 2009 IEEE.},
key = {Ontology},
keywords = {Application programming interfaces (API);Computer software portability;Computer software reusability;Maintainability;Mapping;Network components;Object oriented programming;Problem oriented languages;Reusability;Semantic Web;Semantics;Software architecture;},
note = {Automatic Generation;Code Generation;Complex mapping;Domain specific languages;Model-driven Engineering;Object-oriented representation;Ontology design;Platform independent;Semantic web applications;Source codes;},
URL = {http://dx.doi.org/10.1109/ICSC.2009.90},
} 


@inproceedings{20093512277603 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A DSL for explaining probabilistic reasoning},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Erwig, Martin and Walkingshaw, Eric},
volume = {5658 LNCS},
year = {2009},
pages = {335 - 359},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {We propose a new focus in language design where languages provide constructs that not only describe the computation of results, but also produce explanations of how and why those results were obtained. We posit that if users are to understand computations produced by a language, that language should provide explanations to the user. As an example of such an explanation-oriented language we present a domain-specific language for explaining probabilistic reasoning, a domain that is not well understood by non-experts. We show the design of the DSL in several steps. Based on a story-telling metaphor of explanations, we identify generic constructs for building stories out of events, and obtaining explanations by applying stories to specific examples. These generic constructs are then adapted to the particular explanation domain of probabilistic reasoning. Finally, we develop a visual notation for explaining probabilistic reasoning. &copy; IFIP International Federation for Information Processing 2009.},
key = {Query languages},
keywords = {DSL;Graphical user interfaces;Linguistics;Modems;Telecommunication lines;},
note = {Domain specific languages;Language design;Probabilistic reasoning;Visual notations;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_16},
} 


@inproceedings{20102713054469 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Developing a service-oriented component framework for a landscape modeling language},
journal = {Proceedings of the 13th IASTED International Conference on Software Engineering and Applications, SEA 2009},
author = {Lahcen, Ayoub Ait and Degenne, Pascal and Seen, Danny Lo and Parigot, Didier},
year = {2009},
pages = {226 - 233},
address = {Cambridge, MA, United states},
abstract = {With modeling and simulation, it is possible to study how a system works before trying to predict how it would behave in a variety of situations. However, when modeling landscape processes, issues related to space, time and multiple scales need to be addressed. In order to investigate these issues, a modeling platform based on a Domain Specific Language (DSL) has been developed. One of the main technical challenges of this platform is the ability to build applications with the capacity to themselves dynamically adapt to their environment. In this paper, we present the arguments and motivations behind the choice of the Service-Oriented Computing (SOC) approach when implementing the execution framework of the DSL. The modeling platform is composed of a development environment based on Eclipse IDE, a code generator, and an execution framework. The execution framework, which is the focus of this paper, must meet the constraints set by dynamic landscapes modeling, while capitalizing on the possibilities offered by the SOC approach.},
key = {Computer software},
keywords = {Computer simulation;Linguistics;},
note = {Component framework;Landscape modeling;Service orientation;Service Oriented;},
} 


@inproceedings{20101112766936 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Practical Aspects of Declarative Languages - 12th International Symposium, PADL 2010, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {5937 LNCS},
year = {2010},
issn = {03029743},
address = {Madrid, Spain},
abstract = {The proceedings contain 23 papers. The topics discussed include: an introduction to Maude and some of its applications; efficient application of answer set programming for advanced data integration. an ASP-based system for team-building in the Gioia-Tauro Seaport; skeleton composition using remote data; Netlog, a rule-based language for distributed programming; similar code detection and elimination for Erlang programs; static detection of race conditions in Erlang; automating mathematical program transformations; lazy combinators for executable specifications of general attribute grammars; a domain-specific language approach to protocol stack implementation; lazy explanations for constraint propagators; a simple and efficient implementation of concurrent local tabling; an efficient implementation of linear tabling based on dynamic reordering of alternatives; and prospective storytelling agents.},
} 


@inproceedings{20114014397187 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A semantic model for graphical user interfaces},
journal = {ACM SIGPLAN Notices},
author = {Krishnaswami, Neelakantan R. and Benton, Nick},
volume = {46},
number = {9},
year = {2011},
pages = {45 - 57},
issn = {15232867},
address = {General Post Office, P.O. Box 30777, NY 10087-0777, United States},
abstract = {We give a denotational model for graphical user interface (GUI) programming using the Cartesian closed category of ultrametric spaces. The ultrametric structure enforces causality restrictions on reactive systems and allows well-founded recursive definitions by a generalization of guardedness. We capture the arbitrariness of user input (e.g., a user gets to decide the stream of clicks she sends to a program) by making use of the fact that the closed subsets of an ultrametric space themselves form an ultrametric space, allowing us to interpret nondeterminism with a "powerspace" monad. Algebras for the powerspace monad yield a model of intuitionistic linear logic, which we exploit in the definition of a mixed linear/non-linear domain-specific language for writing GUI programs. The non-linear part of the language is used for writing reactive stream-processing functions whilst the linear sublanguage naturally captures the generativity and usage constraints on the various linear objects in GUIs, such as the elements of a DOM or scene graph. We have implemented this DSL as an extension to OCaml, and give examples demonstrating that programs in this style can be short and readable. Copyright &copy; 2011 ACM.},
key = {Graphical user interfaces},
keywords = {Computer hardware description languages;Functional programming;Problem oriented languages;Semantics;},
note = {Denotational semantics;Functional reactive programming;Linear logic;Recursions;Ultrametric space;},
URL = {http://dx.doi.org/10.1145/2034574.2034782},
} 


@inproceedings{20094812502035 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings - 2009 18th International Conference on Parallel Architectures and Compilation Techniques, PACT 2009},
journal = {Parallel Architectures and Compilation Techniques - Conference Proceedings, PACT},
year = {2009},
pages = {ACM SIGARCH; IEEE Computer Society; IFIP - },
issn = {1089795X},
address = {Raleigh, NC, United states},
abstract = {The proceedings contain 34 papers. The topics discussed include: adaptive locks: combining transactions and locks for efficient concurrency; Anaphase: a fine-grain thread decomposition scheme for speculative multithreading; characterizing the TLB behavior of emerging parallel workloads on chip multiprocessors; interprocedural load elimination for dynamic optimization of parallel programs; algorithmic skeletons within an embedded domain specific language for the CELL processor; SHIP: scalable hierarchical power control for large-scale data centers; exploring phase change memory and 3D die-stacking for power/thermal friendly, fast and durable memory architectures; Chainsaw: using binary matching for relative instruction mix comparison; Stealthtest: low overhead online software testing using transactional memory; Flextream: adaptive compilation of streaming applications for heterogeneous architectures; and soft-OLP: improving hardware cache performance through software-controlled object-level partitioning.},
} 


@inproceedings{20100912734936 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model driven performance measurement and assessment with MoDePeMART},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Bokovic, Marko and Hasselbring, Wilhelm},
volume = {5795 LNCS},
year = {2009},
pages = {62 - 76},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {Software performance is one of important software Quality of Service attributes. For this reason, several approaches integrate performance prediction in Model Driven Engineering(MDE). However, MDE still lacks a systematic approach for performance measurement and metrics assessment. This paper presents MoDePeMART, an approach for Model Driven Performance Measurement and Assessment with Relational Traces. The approach suggests declarative specification of performance metrics in a domain specific language and usage of relational databases for storage and metric computation. The approach is evaluated with the implementation of a UML Profile for UML Class and State diagrams and transformations from profile to a commercial relational database management system. &copy; 2009 Springer Berlin Heidelberg.},
key = {Models},
keywords = {Computer software selection and evaluation;Linguistics;Management information systems;Quality of service;Query languages;},
note = {Domain specific languages;Model-driven;Model-driven Engineering;Performance measurements;Performance metrics;Performance prediction;Reactive system;Relational Database;Relational database management systems;Software performance;Software Quality;State diagram;UML profiles;},
URL = {http://dx.doi.org/10.1007/978-3-642-04425-0_6},
} 


@inproceedings{20093512277602 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Varying domain representations in hagl extending the expressiveness of a dsl for experimental game theory},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Walkingshaw, Eric and Erwig, Martin},
volume = {5658 LNCS},
year = {2009},
pages = {310 - 334},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {Experimental game theory is an increasingly important research tool in many fields, providing insight into strategic behavior through simulation and experimentation on game theoretic models. Unfortunately, despite relying heavily on automation, this approach has not been well supported by tools. Here we present our continuing work on Hagl, a domain-specific language embedded in Haskell, intended to drastically reduce the development time of such experiments and support a highly explorative research style. In this paper we present a fundamental redesign of the underlying game representation in Hagl. These changes allow us to better utilize domain knowledge by allowing different classes of games to be represented differently, exploiting existing domain representations and algorithms. In particular, we show how this supports analytical extensions to Hagl, and makes strategies for state-based games vastly simpler and more efficient. &copy; IFIP International Federation for Information Processing 2009.},
key = {Game theory},
keywords = {DSL;Graphical user interfaces;Linguistics;Modems;Query languages;Telecommunication lines;},
note = {Development time;Domain knowledge;Domain representations;Domain specific languages;Experimental game theory;Game-theoretic model;Haskell;Research tools;State-based;Strategic Behavior;Varying domains;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_15},
} 


@article{20103513199245 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Extensible transactional memory testbed},
journal = {Journal of Parallel and Distributed Computing},
author = {Harmanci, Derin and Gramoli, Vincent and Felber, Pascal and Fetzer, Christof},
volume = {70},
number = {10},
year = {2010},
pages = {1053 - 1067},
issn = {07437315},
address = {6277 Sea Harbor Drive, Orlando, FL 32887-4900, United States},
abstract = {Transactional Memory (TM) is a promising abstraction as it hides all synchronization complexities from the programmers of concurrent applications. More particularly, the TM paradigm operated a complexity shift from the application programming to the TM programming. Therefore, expert programmers have now started to look for the ideal TM that will bring, once-for-all, performance to all concurrent applications. Researchers have recently identified numerous issues TMs may suffer from. Surprisingly, no TMs have ever been tested in these scenarios. In this paper, we present the first to date TM testbed. We propose a framework, TMunit, that provides a domain specific language to write rapidly TM workloads so that our test-suite is easily extensible. Our reproducible semantic tests indicate through reproducible counter-examples that existing TMs do not satisfy recent consistency criteria. Our performance tests identify workloads where well-known TMs perform differently. Finally, additional tests indicate some workloads preventing contention managers from progressing. &copy; 2010 Elsevier Inc. All rights reserved.},
key = {Storage allocation (computer)},
keywords = {Semantics;Test facilities;Testbeds;},
note = {Application programming;Consistency criteria;Domain specific languages;Expert programmers;Performance;Performance tests;Synchronization complexity;Transactional memory;},
URL = {http://dx.doi.org/10.1016/j.jpdc.2010.02.008},
} 


@inproceedings{20094812502507 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A practical state machine project},
journal = {Proceedings of the 47th Annual Southeast Regional Conference, ACM-SE 47},
author = {Hunt, John M.},
year = {2009},
address = {Clemson, SC, United states},
abstract = {A widely noted problem in teaching undergraduate theory courses is a lack of student interest related to the perception of theory as being irrelevant and impractical. To counter this we added a programming project that produces working code for a vending machine, an obviously practical problem. The project is based on state machine automata implemented with the SEI's PACC starter kit, which directly maps state machine models, represented in a domain specific language, into executable code. This allows the student to see a direct and obvious mapping between a state machine based design and a functioning product. &copy;2009 ACM.},
key = {Teaching},
keywords = {Contour followers;Curricula;Education computing;Machine design;Robots;Spontaneous emission;Students;Translation (languages);},
note = {Automata;Domain specific languages;Executable codes;Practical problems;Programming projects;State machine;State machine models;},
URL = {http://dx.doi.org/10.1145/1566445.1566500},
} 


@inproceedings{20102513025884 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A reconfiguration language for virtualized grid infrastructures},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Pottier, Remy and Leger, Marc and Menaud, Jean-Marc},
volume = {6115 LNCS},
year = {2010},
pages = {42 - 55},
issn = {03029743},
address = {Amsterdam, Netherlands},
abstract = {The growing needs in computational power to answer to the increasing number of on-line services and the complexity of applications makes it mandatory to build corresponding hardware infrastructures and to share several distributed hardware and software resources thanks to grid computing. To help with optimizing resource utilization, system virtualization is a more and more adopted technique in data centers. However, this software layer adds to the administration complexity of servers and it requires specific management tools to deal with hypervisor functionalities like live migration. To address this problem, we propose VMScript, a domain specific language for administration of virtualized grid infrastructures. This language relies on set manipulation and is used to introspect physical and virtual grid architectures thanks to query expressions and notably to modify VM placement on machines. &copy; 2010 Springer-Verlag Berlin Heidelberg.},
key = {Linguistics},
keywords = {Computer hardware;Computer software;Grid computing;},
note = {Administration complexity;Computational power;Data centers;Distributed hardware;Domain specific languages;Grid infrastructures;Hypervisor;Management tool;On-line service;On-machines;Query expression;Resource utilizations;Virtual grids;Virtualizations;},
URL = {http://dx.doi.org/10.1007/978-3-642-13645-0_4},
} 


@inproceedings{20113814352300 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Comprehensive two-level analysis of static and dynamic RBAC constraints with UML and OCL},
journal = {Proceedings - 2011 5th International Conference on Secure Software Integration and Reliability Improvement, SSIRI 2011},
author = {Kuhlmann, Mirco and Sohr, Karsten and Gogolla, Martin},
year = {2011},
pages = {108 - 117},
address = {Jeju Island, Korea, Republic of},
abstract = {Organizations with stringent security requirements like banks or hospitals frequently adopt role-based access control (RBAC) principles to simplify their internal permission management. Authorization constraints represent a fundamental advanced RBAC concept enabling precise restrictions on access rights. Thereby the complexity of the resulting security policies increases so that tool support for comfortable creation and adequate validation is required. We propose a new approach to developing and analyzing RBAC policies using UML for modeling RBAC core concepts and OCL to realize authorization constraints. Dynamic (i. e., time-dependent) constraints their visual representation in UML and their analysis are of special interest. The approach results in a domain-specific language for RBAC which is highly configurable and extendable with respect to new RBAC concepts and classes of authorization constraints and allows the developer to validate RBAC policies in an effective way. The approach is supported by a UML and OCL validation tool. &copy; 2011 IEEE.},
key = {Reliability analysis},
keywords = {Access control;Computer aided software engineering;Models;Problem oriented languages;Reliability;},
note = {Access rights;Analysis;Authorization constraints;Configurable;Domain specific languages;RBAC;RBAC policy;Role-based Access Control;Security;Security policy;Security requirements;Static and dynamic;Time-dependent;Tool support;UML/OCL;Validation tools;Visual representations;},
URL = {http://dx.doi.org/10.1109/SSIRI.2011.18},
} 


@inproceedings{20101812901384 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A situation-aware approach for dealing with uncertain context-aware paradigm},
journal = {GLOBECOM - IEEE Global Telecommunications Conference},
author = {Lin, Xiangtao and Cheng, Bo and Chen, Junliang},
year = {2009},
address = {Honolulu, HI, United states},
abstract = {Context-aware paradigm is intended to make decisions proactively for users to adapt to contexts changes in a pervasive environment so as to improve users' work efficiency. However, this commitment deduces because of the intrinsic uncertainty i.e. incompleteness, inaccuracy and inconsistency of context-aware paradigm. We bring forward a situation-aware approach, supported by Bayesian Networks, ontology and Domain Specific Language techniques, for dealing with uncertain contextaware paradigm. Situation, a description of logically combined contexts, is high-level abstract contexts; hence, it can shield the trivialness and inconstancy of low-level contexts. BN mapping contexts to situations is good at dealing with incomplete, inaccurate and erroneous low-level contexts; ontology is referred to eliminate inconsistencies among situations and contexts. Besides, DSL can offer flexibilities for its easy readability and good reusability. Also, interruption ratio, precision and efficiency are evaluated to validate the effectiveness of our approach w.r.t. a situation-aware multimedia conference application.},
key = {Ontology},
keywords = {Bayesian networks;Inference engines;Reusability;},
note = {Context-Aware;Domain specific languages;Multimedia conferences;Pervasive environments;Situation-aware;Work efficiency;},
URL = {http://dx.doi.org/10.1109/GLOCOM.2009.5425910},
} 


@inproceedings{20113914374487 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Parallel Computing Technologies - 11th International Conference, PaCT 2011, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {6873 LNCS},
year = {2011},
pages = {Russian Academy of Sciences; Kazan Federal University; Academy of Sciences of the Republic of Tatarstan; Russian Fund for Basic Research; Lufthansa Official Airlines - },
issn = {03029743},
address = {Kazan, Russia},
abstract = {The proceedings contain 44 papers. The topics discussed include: classical and quantum parallelism in the quantum fingerprinting method; OpenMP parallelization of a CFD code for multicore computers: analysis and comparison; LuNA fragmented programming system, main functions and peculiarities of run-time subsystem; grid computing for sensitivity analysis of stochastic biological models; looking for efficient implementations of concurrent objects; cache efficiency and scalability on multi-core architectures; symbolic algorithm for generation Bu&die;chi automata from LTL formulas; Sisal 3.2 language features overview; a cellular automata based model for pedestrian and group dynamics: motivations and first experiments; using multi core computers for implementing cellular automata systems; efficient minimal routing in the triangular grid with six channels; and domain specific language and translator for cellular automata models of physico-chemical processes.},
} 


@inproceedings{20062910004780 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Ruler: Programming type rules},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Dijkstra, Atze and Doaitse Swierstra, S.},
volume = {3945 LNCS},
year = {2006},
pages = {30 - 46},
issn = {03029743},
address = {Fuji-Susono, Japan},
abstract = {Some type systems are first described formally, to be sometimes followed by an implementation. Other type systems are first implemented as language extensions, to be sometimes retrofitted with a formal description. In neither case it is an easy task to keep both artefacts consistent. In this paper we introduce Ruler, a domain specific language for describing type rules. Type rules can be incrementally described, thus providing a means for building complex type systems on top of simpler ones. Besides checking well-formedness of Ruler programs we use them to generate (1) a visual L<sup>A</sup>T <inf>E</inf>X rendering, suitable for use in the presentation of formal aspects, and (2) an attribute grammar based implementation. Combining these two aspects in Ruler contributes to bridging the gap between theory and practice: mutually consistent representations can be generated for use in both theoretical and practical settings. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Computer programming},
keywords = {Computational complexity;Computer programming languages;Computer science;Formal languages;Information science;Theorem proving;},
note = {Domain specific languages;Formal description;Grammar based implementation;Language extensions;},
URL = {http://dx.doi.org/10.1007/11737414_4},
} 


@inproceedings{20091512021629 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Anima: A Ada derived programming language for real-time embedded software development},
journal = {Proceedings of the ACM SIGAda Annual International Conference; SIGAda},
author = {Doran, Steven},
year = {2008},
pages = {121 - 132},
issn = {10943641},
address = {Portland, OR, United states},
abstract = {Currently, embedded programs are written in a variety of programming languages. None were specifically designed for the real-time environment. The use of a general purpose language for embedded systems can lead to inefficient applications which are more likely to fail to meet timing and execution requirements, or experience run-time errors that prove catastrophic for safety-critical systems. A domain specific language, in which real-time constructs are part of the language proper rather than hosted in a library, is likely to lessen the risks of implementation of tasks with strict real-time requirements. This paper outlines a Ada derived programming language called Anima that directly addresses many of the challenging issues of real-time embedded software development. Copyright 2008 ACM.},
key = {Ada (programming language)},
keywords = {C (programming language);Computers;Embedded software;Embedded systems;Integrated circuits;Linguistics;Query languages;Software design;},
note = {Domain-specific languages;Embedded;General purpose languages;Programming languages;Real-time;Real-time embedded softwares;Real-time environments;Real-time requirements;Run-time errors;Safety-critical systems;},
URL = {http://dx.doi.org/10.1145/1454474.1454494},
} 


@inproceedings{20084811750741 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MDD4SOA: Model-driven service orchestration},
journal = {Proceedings - 12th IEEE International Enterprise Distributed Object Computing Conference, EDOC 2008},
author = {Mayer, Philip and Schroeder, Andreas and Koch, Nora},
year = {2008},
pages = {203 - 212},
address = {Munich, Germany},
abstract = {Service-Oriented Architectures (SOAs) have become an important cornerstone of the development of enterprise-scale software applications. Although a range of domain-specific languages and standards are available for dealing with such architectures, model-driven approaches starting from models written in an established modelling language like UML and including the ability for model transformation (in particular, for code generation) are still in their infancy. In this paper, we show (1) how our UML-based domain-specific language for working with SOA artefacts, UML4SOA, can be used for modelling service orchestrations, and (2) how to exploit so-designed models in the MDD4SOA approach to generate code in multiple languages, among them BPEL and WSDL, Java, and the formal language Jolie. We use a case study for illustrating this approach. Our main contributions are an easy-to-use, conservative extension to the UML2 for modelling service orchestrations on a high level of abstraction, and a fully automated, model-driven approach for transforming these orchestrations down to code. &copy; 2008 IEEE.},
key = {Java programming language},
keywords = {Codes (symbols);Computer programming languages;Formal languages;Graphical user interfaces;Information services;Linguistics;Query languages;Systems analysis;Unified Modeling Language;},
note = {Case studies;Code generations;Conservative extensions;Designed models;Do-mains;High level of abstractions;Model transformations;Multiple languages;Service orchestrations;Service-oriented architectures;Software applications;Specific languages;},
URL = {http://dx.doi.org/10.1109/EDOC.2008.55},
} 


@inproceedings{20112414050072 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Testing policy-based systems with scenarios},
journal = {Proceedings of the 10th IASTED International Conference on Software Engineering, SE 2011},
author = {Strembeck, Mark},
year = {2011},
pages = {64 - 71},
address = {Innsbruck, Austria},
abstract = {Policy-based systems consist of interacting software artifacts and, at first glance, can be tested as any other software system. In a policy-based system, however, the behavior of system entities may change dynamically and frequently, depending on the policy rules governing this behavior. Therefore, policy-based systems demand for a testing approach that especially allows for the testing of dynamically changing system behavior. Thus, testing of policy rules has to check if the behavior that is actually enforced by a set of policies, conforms to the intended behavior of the corresponding system entities. Scenarios are an important means to specify behavior of software entities. In this paper, we introduce an approach to test policy-based systems with scenarios, and present an (embedded) domain-specific language for scenario-based testing.},
key = {Software testing},
keywords = {Computer aided software engineering;Embedded systems;Problem oriented languages;},
note = {Domain specific languages;Interacting softwares;Policy rules;Policy-based systems;Scenario-based testing;Software entities;Software systems;System behaviors;},
URL = {http://dx.doi.org/10.2316/P.2011.720-021},
} 


@inproceedings{20102913087652 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Programming assistance based on contracts and modular verification in the automation domain},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Hurnaus, Dominik and Prahofer, Herbert},
year = {2010},
pages = {2544 - 2551},
address = {Sierre, Switzerland},
abstract = {In industrial automation, control software often has to get changed and adapted by domain experts and end users who have no or only limited software development expertise. This results in high demands on programming environments with respect to supporting, guiding, and supervising the programming tasks. In this paper we present an approach based on model checking and artificial intelligence techniques to guide domain experts in building control software which is guaranteed to obey specified contracts and constraints. The work is based on Monaco which is a domain-specific language for programming automation solutions. As Monaco employs a hierarchical component approach, the verification is done hierarchically where an upper component is verified against the contracts of its subcomponents. The verification approach is leveraged in different programming support systems which give immediate feedback about valid and invalid programs in an integrated development environment. &copy; 2010 ACM.},
key = {Computer software selection and evaluation},
keywords = {Artificial intelligence;Automation;Computer programming;Hierarchical systems;Linguistics;Model checking;Problem oriented languages;Software design;Web services;},
note = {Artificial intelligence techniques;Automation domain;Automation software;Automation solutions;Control software;Domain experts;Domain specific languages;End user programming;End users;Hierarchical components;High demand;In-buildings;Industrial automation;Integrated development environment;Modular verification;Programming environment;Programming support;Programming tasks;Software development;},
URL = {http://dx.doi.org/10.1145/1774088.1774614},
} 


@inproceedings{20112514077186 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Integrating design and runtime variability support into a system ADL},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Ludwig, Marie and Farcet, Nicolas and Babau, Jean-Philippe and Champeau, Joel},
volume = {6698 LNCS},
year = {2011},
pages = {270 - 281},
issn = {03029743},
address = {Birmingham, United kingdom},
abstract = {As the complexity of modern large systems or System of Systems increases, it becomes challenging to capture their whole dimension and to identify their key aspects. Architecture models provide a legible description of the system, and help describing its properties in a representation shared and understood by most stakeholders. In our case, we intend to evaluate system architectures through model execution. Since evolutionary design and configuration are key challenges of such systems, variability needs a way to be expressed in architecture models. Variability can be solved either at design time (derive a system from the family), or at runtime (reconfigure the system). This paper presents our experience in integrating variability aspects in a system architecture description Domain-Specific Language. &copy; 2011 Springer-Verlag.},
key = {Design},
keywords = {Architecture;Problem oriented languages;Systems engineering;},
note = {Architecture models;Design time;Domain specific languages;Evolutionary design;Integrating design;Large system;Model executions;Runtimes;System architectures;System of systems;Systems of Systems;variability;},
URL = {http://dx.doi.org/10.1007/978-3-642-21470-7_19},
} 


@inproceedings{20083211436801 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a full implementation of a robust solution of a Domain Specific Visual Query Language for HEP Physics analysis},
journal = {IEEE Nuclear Science Symposium Conference Record},
author = {Sousa, Vasco and Amaral, Vasco and Barroca, Bruno},
volume = {1},
year = {2007},
pages = {910 - 917},
issn = {10957863},
address = {Honolulu, HI, United states},
abstract = {We focus our research on developing the right methodology and gathering the adequate re-usable methodology and toolset in order to design a domain specific language for High Energy Physics (HEP) data analysis. We aim at a framework that from a specification model using a simple high level abstraction language (Domain Specific Visual Query Language - commonly known as DSL) we generate automatically the target source code in some General Purpose Language (GPL, at the level of the analysis framework) which exactly expresses the querys modeled by the physicist. This source code can then be compiled and run against the analysis framework of a specific HEP experiment. In this communication we will focus on methodological issues, although presenting the conclusions on the latest survey done on domain specific languages (DSL) development tools. &copy; 2007 IEEE.},
key = {Query languages},
keywords = {DSL;High energy physics;Linguistics;Medical imaging;Modems;Telecommunication lines;},
note = {Data analysis;Development tools;Domain specifics;HEP experiments;Physics analyses;Robust solutions;Source codes;Specification models;Target sources;Toolset;},
URL = {http://dx.doi.org/10.1109/NSSMIC.2007.4436475},
} 


@inproceedings{20091311992836 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the IASTED international conference on software engineering, SE 2008},
journal = {Proceedings of the IASTED International Conference on Software Engineering, SE 2008},
year = {2008},
address = {Innsbruck, Austria},
abstract = {The proceedings contain 54 papers. The topics discussed include: establishing a knowledge base for problem management, part II; attaching transactional requirements to business process specifications; data constraints for validation of real-time software; using concept maps to produce sequence diagrams; a proposed extension to the SysML requirements diagram; refactoring merging environment supported by graph transformations; guidelines for modeling language independent integration of dynamic schemata; a domain specific language for the definition of extended queuing network models; intersection of software methodologies and ITIL V3; a generic assistance system of software process; a measurement framework for the parameterization of performance models for SOA-based systems; balancing supporting software development by dedicated infrastructure elements; and a transformation approach for security enhanced business process.},
} 


@inproceedings{20112013985113 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A novel network platform for secure and efficient malware collection based on reconfigurable hardware logic},
journal = {World Congress on Internet Security, WorldCIS-2011},
author = {Muhlbach, Sascha and Koch, Andreas},
year = {2011},
pages = {9 - 14},
address = {London, United kingdom},
abstract = {With the growing diversity of malware, researchers must be able to quickly collect many representative samples for study. This can be done, e.g., by using honeypots. As an alternative to software-based honeypots, we propose a singlechip honeypot appliance that is entirely hardware-based and thus significantly more resilient against compromising attacks. Additionally, it can easily keep up with network speeds of 10+ Gb/s and emulate thousands of vulnerable hosts. As base technology, we employ reconfigurable hardware devices whose functionality is not fixed by the manufacturing process. We present improvements to the platform, aiming to simplify management and updates. To this end, we introduce the domain-specific language VEDL, which can be used to describe the honeypot behavior in a highlevel manner by security experts not proficient in hardware design. &copy; 2011 WorldCIS.},
key = {Reconfigurable hardware},
keywords = {Computer crime;Computer hardware;Internet;Manufacture;Problem oriented languages;Security of data;Telecommunication networks;},
note = {Domain specific languages;Hardware design;Honeypots;Malwares;Manufacturing process;Network platforms;Network speed;Reconfigurable hardware devices;Representative sample;Security experts;Single-chip;Software-based;},
} 


@inproceedings{20114014396080 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Enterprise and Organizational Modeling and Simulation - 7th International Workshop, EOMAS 2011, Held at CAiSE 2011, Selected Papers},
journal = {Lecture Notes in Business Information Processing},
volume = {88 LNBIP},
year = {2011},
pages = {Spec. Interest Group Model. Simul. Assoc. Inf. Syst. (SIGMAS); Spec. Interest Group Simul. Assoc. Comput. Mach. (SIGSIM); Int. Conf. Adv. Inf. Syst. Eng. (CAiSE); Delft University of Technology Department of Systems Engineering - },
issn = {18651348},
address = {London, United kingdom},
abstract = {The proceedings contain 14 papers. The topics discussed include: efficient routing of mobile agents for agent-based integrated enterprise management: a general acceleration technique; a framework of views on service networks models; system dynamics in integration of supply chain management; modeling and simulating organizations; simulation, games and challenges: from schools to enterprises; using a controlled vocabulary to support business process design; a quality-oriented business process meta-model; performance improvement in healthcare processes; supporting enterprise is modeling using ontological analysis; instance-level modeling and simulation using lambda-calculus and object-oriented environments; conceptual normalization formalized; modeling and prototyping of business applications based on multilevel domain-specific language; and building towards a software based innovation modeling tool.},
} 


@inproceedings{20102913080528 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {KStruct: Preserving consistency through C annotations},
journal = {Proceedings of the 5th Workshop on Programming Languages and Operating Systems, PLOS 2009, in Conjunction with the 22nd ACM Symposium on Operating Systems Principles, SOSP 2009},
author = {Schmidt, Alexander and Von Lowis, Martin and Polze, Andreas},
year = {2009},
pages = {Assoc. Comput. Mach., Spec. Interest Group Oper.; Syst. (ACM SIGOPS) - },
address = {Big Sky, MT, United states},
abstract = {Debuggers and instrumentation tools have been proven valuable for understanding the inner workings of software systems. Although these tools are essential for various people, e.g., system administrators, developers, or teachers, they have one major drawback, especially in multi-threaded environments: They completely ignore data races. Within this paper, we present KStruct, a holistic approach for inspecting state information of a system while running. We therefore use a multi-level approach: First KStruct Access, our domain-specific language, can be used to model lock dependencies. Second, based on that model, we generate an access driver that dynamically attaches to the system under investigation and leverages that model to access state information. Our proposed approach can therefore improve quality in two dimensions: The code by making locking first-class primitives, and second the retrieved data is more reliable to be consistent. &copy; 2010 ACM.},
key = {Computer operating systems},
keywords = {Inspection;Linguistics;Problem oriented languages;Program debugging;Query languages;Software architecture;},
note = {Consistency model;consistency models;Data races;Debuggers;Domain specific languages;Holistic approach;Instrumentation tools;Model driven architectures;Multi-level;Multithreaded environments;Software systems;State information;System administrators;Two-dimension;},
URL = {http://dx.doi.org/10.1145/1745438.1745447},
} 


@inproceedings{20113514280120 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {IEEE SSCI 2011 - Symposium Series on Computational Intelligence - CISched 2011: 2011 IEEE Symposium on Computational Intelligence in Scheduling},
journal = {IEEE SSCI 2011 - Symposium Series on Computational Intelligence - CISched 2011: 2011 IEEE Symposium on Computational Intelligence in Scheduling},
year = {2011},
pages = {IEEE Computational Intelligence Society - },
address = {Paris, France},
abstract = {The proceedings contain 9 papers. The topics discussed include: using metaheuristics and queueing models to optimize schedules in the academic enterprise; combining basic heuristics for solving multi-objective scheduling problems; optimization of task assignment to collaborating agents; lower bounds for single machine subproblems occurring in weighted tardiness oriented shifting bottleneck procedures; quantum inspired evolutionary algorithm for joint user selection and power allocation for uplink cognitive MIMO systems; a heuristic algorithm for nurse scheduling with balanced preference satisfaction; scheduling a triple round robin tournament for the Finnish national ice hockey league for players under 20; sports scheduling with generalized breaks; and TEMPLE - a domain specific language for modeling and solving staff scheduling problems.},
} 


@inproceedings{20080411047092 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-oriented, model-based approach for construction and verification of railway control systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Haxthausen, Anne E. and Peleska, Jan},
volume = {4700 LNCS},
year = {2007},
pages = {320 - 348},
issn = {03029743},
address = {Macao, China},
abstract = {This paper describes a complete model-based development and verification approach for railway control systems. For each control system to be generated, the user makes a description of the application-specific parameters in a domain-specific language. This description is automatically transformed into an executable control system model expressed in SystemC. This model is then compiled into object code. Verification is performed using four main methods applied to different levels: (0) The domain-specific description is validated wrt. internal consistency by static analysis. (1) The crucial safety properties are verified for the SystemC model by means of bounded model checking. (2) The object code is verified to be I/O behavioural equivalent to the SystemC model from which it was compiled. (3) The correctness of the hardware/software integration is checked by automated testing. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Control systems},
keywords = {Automatic programming;Computer software;Railroad transportation;User interfaces;Verification;},
note = {Domain engineering;Railway control systems;},
} 


@inproceedings{20084811751671 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {WebWorkFlow: An object-oriented workflow modeling language for Web applications},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Hemel, Zef and Verhaaf, Ruben and Visser, Eelco},
volume = {5301 LNCS},
year = {2008},
pages = {113 - 127},
issn = {03029743},
address = {Toulouse, France},
abstract = {Workflow languages are designed for the high-level description of processes and are typically not suitable for the generation of complete applications. In this paper, we present WebWorkFlow, an object-oriented workflow modeling language for the high-level description of workflows in web applications. Workflow descriptions define procedures operating on domain objects. Procedures are composed using sequential and concurrent process combinators. WebWorkFlow is an embedded language, extending WebDSL, a domain-specific language for web application development, with workflow abstractions. The extension is implemented by means of model-to-model transformations. Rather than providing an exclusive workflow language, WebWorkFlow supports interaction with the underlying WebDSL language. WebWorkFlow supports most of the basic workflow control patterns. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {High level languages},
keywords = {Applications;Computer programming languages;Linguistics;Management;Models;Object oriented programming;Query languages;World Wide Web;},
note = {Combinators;Concurrent processes;Do-mains;Embedded Languages;Model transformations;Modeling languages;Object-oriented;Specific languages;Web application developments;WEB applications;Workflow controls;Workflow languages;Workflows;},
URL = {http://dx.doi.org/10.1007/978-3-540-87875-9_8},
} 


@inproceedings{20093812307947 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {IEEE International Conference on Software Testing, Verification, and Validation Workshops, ICSTW 2009},
journal = {IEEE International Conference on Software Testing, Verification, and Validation Workshops, ICSTW 2009},
year = {2009},
pages = {IEEE Computer Society; Microsoft; IEEE; FedEx Institute of Technology; IBM Research - },
address = {Denver, CO, United states},
abstract = {The proceedings contain 38 papers. The topics discussed include: automated evaluation of runtime object states against model-level states for state-based test execution; IPO-s: incremental generation of combinatorial interaction test data based on symmetries of covering arrays; a model for the measurement of the runtime testability of component-based systems; generating system models for a highly configurable train control system using a domain-specific language: a case study; checking sequence generation using state distinguishing subsequences; test case generation using model checking for software components deployed into new environments; formal correctness of a passive testing approach for timed systems; evolutionary white-box software test with the evotest framework: a progress report; and signal generation for search-based testing of continuous systems.},
} 


@inproceedings{20095112548835 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {White-box evaluation of computer vision algorithms through explicit decision-making},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Zanibbi, Richard and Blostein, Dorothea and Cordy, James R.},
volume = {5815 LNCS},
year = {2009},
pages = {295 - 304},
issn = {03029743},
address = {Liege, Belgium},
abstract = {Traditionally computer vision and pattern recognition algorithms are evaluated by measuring differences between final interpretations and ground truth. These black-box evaluations ignore intermediate results, making it difficult to use intermediate results in diagnosing errors and optimization. We propose "opening the box," representing vision algorithms as sequences of decision points where recognition results are selected from a set of alternatives. For this purpose, we present a domain-specific language for pattern recognition tasks, the Recognition Strategy Language (RSL). At run-time, an RSL interpreter records a complete history of decisions made during recognition, as it applies them to a set of interpretations maintained for the algorithm. Decision histories provide a rich new source of information: recognition errors may be traced back to the specific decisions that caused them, and intermediate interpretations may be recovered and displayed. This additional information also permits new evaluation metrics that include false negatives (correct hypotheses that the algorithm generates and later rejects), such as the percentage of ground truth hypotheses generated (historical recall), and the percentage of generated hypotheses that are correct(historical precision). We illustrate the approach through an analysis of cell detection in two published table recognition algorithms. &copy; 2009 Springer-Verlag Berlin Heidelberg.},
key = {Linguistics},
keywords = {Algorithms;Computer vision;Decision making;Error detection;Graphical user interfaces;Problem oriented languages;Query languages;},
note = {Black boxes;Cell detection;Computer vision algorithms;Decision points;Document recognition;Domain specific languages;Evaluation metrics;False negatives;Ground truth;Intermediate results;New sources;Pattern recognition algorithms;Performance evaluation;Recognition algorithm;Recognition error;Recognition strategies;Runtimes;Scripting languages;Vision algorithms;},
URL = {http://dx.doi.org/10.1007/978-3-642-04667-4_30},
} 


@inproceedings{20110113544294 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {COPAL: An adaptive approach to context provisioning},
journal = {2010 IEEE 6th International Conference on Wireless and Mobile Computing, Networking and Communications, WiMob'2010},
author = {Li, Fei and Sehic, Sanjin and Dustdar, Schahram},
year = {2010},
pages = {286 - 293},
address = {Niagara Falls, ON, Canada},
abstract = {Context-aware services need to acquire context information from heterogeneous context sources. The diversity of service requirements posts challenges on context provisioning systems as well as their programming models. This paper proposes COPAL (COntext Provisioning for ALI) - an adaptive approach to context provisioning. COPAL is at first a runtime middleware, which provides loose-coupling between context and its processing. The component architecture of COPAL ensures that new context processing functions can be added dynamically. A set of context processing patterns are proposed to customize context attributes and compose context provisioning schemes. The COPAL components and models are reflected in a Domain Specific Language (DSL), which can further reduce the development efforts of context provisioning using automatic code generation. A motivating scenario is used throughout the paper to illustrate COPAL approach. &copy; 2010 IEEE.},
key = {Wireless networks},
keywords = {Automatic programming;Information services;Middleware;Mobile computing;},
note = {Adaptive approach;Automatic code generations;Component architectures;Context attributes;Context aware services;Context information;Context processing;Context provisioning;Domain specific languages;Programming models;Run-time middleware;Service requirements;},
URL = {http://dx.doi.org/10.1109/WIMOB.2010.5645051},
} 


@inproceedings{20074810951329 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {DSAL'07: Second Workshop on Domain-Specific Aspect Languages},
journal = {DSAL'07: Second Workshop on Domain-Specific Aspect Languages},
year = {2007},
address = {Vancouver, BC, Canada},
abstract = {The proceedings contain 5 papers. The topics discussed include: ERTSAL: A prototype of a domain-specific aspect language for analysis of embedded real-time systems; a distribution definition language for the automated distribution of Java; ReLAx: implementing KALA over the reflex AOP kernel; ALPH: a domain-specific language for crosscutting pervasive healthcare; and aspect oriented DSLs for business process implementation.},
key = {Java programming language},
keywords = {Real time systems;Software prototyping;Ubiquitous computing;},
note = {Automated distributions;Crosscutting pervasive;Domain Specific Aspect Languages;Pervasive healthcare;},
} 


@article{2006129766437 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using ATL for checking models},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Bezivin, Jean and Jouault, Frederic},
volume = {152},
number = {1-2},
year = {2006},
pages = {69 - 81},
issn = {15710661},
abstract = {Working with models often requires the ability to assert the compliance of a given model to a given set of constraints. Some tools are able to check OCL invariants on UML models. However, there are very few tools able to do the same for any metamodel. This is quite penalizing for the DSL (Domain Specific Language) approach to model engineering. In this paper we propose a metamodel-independent solution to this problem that uses ATL (Atlas Transformation Language). This solution has been implemented as an Eclipse-based plugin. &copy; 2006 Elsevier B.V. All rights reserved.},
key = {Computer programming languages},
keywords = {Computer aided software engineering;Computer hardware description languages;Constraint theory;Mathematical models;Metadata;Object oriented programming;Problem solving;},
note = {Atlas Transformation Language (ATL);Checking models;Model Engineering;OCL;},
URL = {http://dx.doi.org/10.1016/j.entcs.2006.01.015},
} 


@inproceedings{20101812897629 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {SCOPES 2009 - Proceedings of the 12th International Workshop on Software and Compilers for Embedded Systems},
journal = {ACM International Conference Proceeding Series},
volume = {320},
year = {2009},
pages = {ACM SIGBED; ArtistDesign European NoE; European Design and Automation Association, EDAA; PREDATOR European FP7 Project - },
address = {Nice, France},
abstract = {The proceedings contain 8 papers. The topics discussed include: separate compilation for synchronous programs; accelerating WCET-driven optimizations by the invariant path paradigm - a case study of loop unswitching; register allocation deconstructed; the prompt design principles for predictable multi-core architectures; implementing AUTOSAR scheduling and resource management on an embedded SMT processor; a design flow based on a domain specific language to concurrent development of device drivers and device controller simulation models; certifying deadlock-freedom for BIP models; and precise simulation of interrupts using a rollback mechanism.},
} 


@inproceedings{20091311989024 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A MDA Approach for semi automatic Grid services workflows composition},
journal = {2008 IEEE International Conference on Industrial Engineering and Engineering Management, IEEM 2008},
author = {Hlaoui, Y. Bendaly and Benayed, L. Jemni},
year = {2008},
pages = {1433 - 1437},
address = {Singapore, Singapore},
abstract = {In this paper, we propose a Model-Driven Approach (MDA) for developing workflow applications from existing Grid services. We focus on how to model and compose workflow applications of Grid services without considering lower level description of the Grid environment. The workflows are built on an abstract level using UML activity diagram language with semantic and syntactic descriptions of services available on the Grid. Also, we define a Domain Specific Language using the extension of the UML activity diagram notation. This extension deals with additional information allowing an automatic composition of workflows and containing appropriate data to describe a Grid service. These data are useful for the execution of the resulting. &copy; 2008 IEEE.},
key = {Grid computing},
keywords = {Industrial engineering;Information theory;Linguistics;Management;Systems analysis;},
note = {Grid services;Mda approach;Systematic composition;Uml activity diagrams;Workflows;},
URL = {http://dx.doi.org/10.1109/IEEM.2008.4738107},
} 


@inproceedings{2005339294874 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An agent-based domain specific framework for rapid prototyping of applications in evolutionary biology},
journal = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
author = {Son, Tran Cao and Pontelli, Enrico and Ranjan, Desh and Milligan, Brook and Gupta, Gopal},
volume = {2990},
year = {2004},
pages = {76 - 96},
issn = {03029743},
address = {Melbourne, Australia},
abstract = {In this paper we present a brief overview of the &Phi;LOG project, aimed at the development of a domain specific framework for the rapid prototyping of applications in evolutionary biology. This includes the development of a domain specific language, called &Phi;LOG, and an agent-based implementation for the monitoring and execution of &Phi;LOG's programs. A &Phi;LOG program - representing an intended application from an evolutionary biologist - is a specification of what to do to achieve her/his goal. The execution and monitoring component of our system will automatically figure out how to do it. We achieve that by viewing the available bioinformatic tools and data repositories as web services and casting the problem of execution of a sequence of bioinformatic services (possibly with loops, branches, and conditionals, specified by biologists) as the web services composition problem. &copy; Springer-Verlag Berlin Heidelberg 2004.},
key = {Software agents},
keywords = {Computer programming;Database systems;DNA;Genes;Project management;Rapid prototyping;World Wide Web;},
note = {Data repositories;Evolutionary biology;Nucleotides;Web services;},
} 


@inproceedings{20092612146195 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A Model Driven Approach to Generate Service Creation Environments},
journal = {GLOBECOM - IEEE Global Telecommunications Conference},
author = {Achilleos, A. and Yang, K. and Georgalas, N.},
year = {2008},
pages = {1673 - 1678},
address = {New Orleans, LA, United states},
abstract = {The creation of services is a complex activity that involves several tasks. Furthermore this complexity is augmented by the fact that supporting service creation environments are technology-specific. Consequently a technology-independent approach and framework are required to generate service creation environments and drive service creation. In this paper we present such an approach and a generic framework for supporting service creation. The approach realizes service creation via the phases of: (i) domain specific language definition, (ii) model definition and validation, (iii) model-to-model transformation and (iv) model-to-code generation. Each phase maps to a corresponding phase in service creation starting from service analysis to service implementation. The applicability of the approach and its accompanying framework is demonstrated via an example scenario that illustrates the automatic generation of a service creation environment for an online survey system. &copy; 2008 IEEE.},
note = {Automatic Generation;Code Generation;Complex activity;Domain specific languages;Domain specific modelling;Generic frameworks;Model driven approach;Model driven development;Model to model transformation;Online surveys;Phase maps;Service analysis;Service creation;Service creation environment;},
URL = {http://dx.doi.org/10.1109/GLOCOM.2008.ECP.325},
} 


@inproceedings{20090911921122 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Temporal-awareness in SLAs: Why should we be concerned?},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Muller, C. and Ruiz-Cortes, A. and Fernandez, P.},
volume = {4907 LNCS},
year = {2009},
pages = {165 - 173},
issn = {03029743},
address = {Vienna, Austria},
abstract = {Traditionally, Service Level Agreements have been decomposed in two sets of properties: functionals (what) and non-functionals (how). However, in our opinion, there has been a third key element that has had a minor attention from academy: temporal awareness (when). We believe temporality is a main concern that should be addressed in realistic scenarios. In doing so, this position paper discuss our experience in extending the specification WS-Agreement with a temporal Domain Specific Language; importantly, main aim of the paper is to provoke a debate about the importance of temporality in SLAs. &copy; 2009 Springer Berlin Heidelberg.},
key = {Quality of service},
keywords = {Distributed computer systems;},
note = {Domain-specific languages;Functionals;Key elements;Position papers;Realistic scenarios;Service-level agreements;Ws agreements;},
URL = {http://dx.doi.org/10.1007/978-3-540-93851-4_16},
} 


@inproceedings{20094612441798 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Recursive modeling for completed code generation},
journal = {ACM International Conference Proceeding Series},
author = {Sulistyo, Selo and Prinz, Andreas},
year = {2009},
pages = {6 - },
address = {Enschede, Netherlands},
abstract = {Model-Driven Development is promising to software development because it can reduce the complexity and cost of developing large software systems. The basic idea is the use of different kinds of models during the software development process, transformations between them, and automatic code generation at the end of the development. But unlike the structural parts, fully-automated code generation from the behavior parts is still hard, if it works at all, restricted to specific application areas using a domain specific language, DSL. This paper proposes an approach to model the behavior parts of a system and to embed them into the structural models. The underlying idea is recursive refinements of activity elements in an activity diagram. With this, the detail generated code depends on the depth at which the refinements are done, i.e. if the lowest level of activities is mapped into activities executors, the completed code can be obtained. &copy; 2009 ACM.},
key = {Mathematical models},
keywords = {Automatic programming;Computational complexity;Computer control systems;Computer software;Cost reduction;Model structures;Network components;Recursive functions;Software design;Systems analysis;},
note = {Activity diagram;Activity executor;Application area;Automated code generation;Automatic code generations;Basic idea;Code generation;Domain specific languages;Large software systems;MDD;Model driven development;Recursive modeling;Software development;Software development process;Structural models;Structural parts;},
URL = {http://dx.doi.org/10.1145/1555852.1555858},
} 


@inproceedings{20101712895199 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Language models learning for domain-specific natural language user interaction},
journal = {2009 IEEE International Conference on Robotics and Biomimetics, ROBIO 2009},
author = {Bai, Shuanhu and Huang, Chien-Lin and Tan, Yeow-Kee and Ma, Bin},
year = {2009},
pages = {2480 - 2485},
address = {Guilin, China},
abstract = {Natural language interface is an important research topic in the area of natural language processing (NLP). Natural language interaction with robot could be the most natural and efficient way. In order to build speech enabled human language interface of robots, our research goal is to study the problems in this area and develop technologies that can potentially improve human-robot interaction. In particular, we present a learning method for building domain-specific language models (LM) for natural language user interfaces. This method is aimed to use small amount of domain-specific data as seeds to tap domain-specific resources residing in larger amount of general-domain data with the help of topic modeling technologies. The proposed algorithm first performs topic decomposition (TD) on the combined dataset of domain-specific and general-domain data using probabilistic latent semantic analysis (PLSA). Then it derives weighted domain-specific word n-gram counts with mixture modeling scheme of PLSA. Finally, it uses traditional n-gram modeling approach to construct domain-specific LMs from the domain-specific word n-gram counts. Experimental results show that this approach can outperform both stat-of-the-art methods and traditional supervised learning method. In addition, the semi-supervised learning method can achieve better performance even with very small amount of domain-specific data. &copy; 2009 IEEE.},
key = {Human robot interaction},
keywords = {Algorithms;Biomimetics;Computational linguistics;Graphical user interfaces;Human computer interaction;Industrial research;Natural language processing systems;Problem oriented languages;Robotics;Supervised learning;},
note = {Data sets;Domain specific;Domain specific languages;Human language;Human robot interactions;Language model;Learning methods;Mixture modeling;Modeling technology;N-gram modeling;Natural language interaction;Natural language interfaces;Natural language processing;Natural languages;Probabilistic latent semantic analysis;Research goals;Research topics;Semi-supervised learning methods;Supervised learning methods;User interaction;},
URL = {http://dx.doi.org/10.1109/ROBIO.2009.5420442},
} 


@inproceedings{20113814352293 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Runtime verification of domain-specific models of physical characteristics in control software},
journal = {Proceedings - 2011 5th International Conference on Secure Software Integration and Reliability Improvement, SSIRI 2011},
author = {De Roo, Arjan and Sozer, Hasan and Aksit, Mehmet},
year = {2011},
pages = {41 - 50},
address = {Jeju Island, Korea, Republic of},
abstract = {Control logic of embedded systems is nowadays largely implemented in software. Such control software implements among others models of physical characteristics like heat exchange among system components. Due to evolution of system properties and increasing complexity faults can be left undetected in these models. Therefore their accuracy must be verified at runtime. Traditional runtime verification techniques that are based on states and events in software execution are inadequate in this case. The behavior suggested by models of physical characteristics cannot be mapped to behavioral properties of software. Moreover implementation in a general-purpose programming language makes these models hard to locate and verify. This paper presents a novel approach to explicitly specify models of physical characteristics using a domain-specific language to define monitors for inconsistencies by detecting and exploiting redundancy in these models and to realize these monitors using an aspect-oriented approach. The approach is applied to two industrial case studies. &copy; 2011 IEEE.},
key = {Models},
keywords = {Computer aided software engineering;Embedded software;Embedded systems;Problem oriented languages;Software reliability;Verification;},
note = {Aspect-oriented;Behavioral properties;Control logic;Control software;Domain specific;Domain specific languages;General-purpose programming language;Heat exchange;In-control;Industrial case study;Physical characteristics;Run-time verification;Runtimes;Software execution;States and events;System components;System property;},
URL = {http://dx.doi.org/10.1109/SSIRI.2011.14},
} 


@inproceedings{20092812179052 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards composition as a service - a quality of service driven approach},
journal = {Proceedings - International Conference on Data Engineering},
author = {Rosenberg, Florian and Leitner, Philipp and Michlmayr, Anton and Celikovic, Predrag and Dustdar, Schahram},
year = {2009},
pages = {1733 - 1740},
issn = {10844627},
address = {Shanghai, China},
abstract = {Software as a Service (SaaS) and the possibility to compose Web services provisioned over the Internet are important assets for a service-oriented architecture (SOA). However, the complexity and time for developing and provisioning a composite service is very high and it is generally an error-prone task. In this paper we address these issues by describing a semi-automated "Composition as a Service" (CAAS) approach combined with a domain-specific language called VCL (Vienna Composition Language). The proposed approach facilitates rapid development and provisioning of composite services by specifying what to compose in a constraint-hierarchy based way using VCL. Invoking the composition service triggers the composition process and upon success the newly composed service is immediately deployed and available. This solution requires no client-side composition infrastructure because it is transparently encapsulated in the CAAS infrastructure. &copy; 2008 IEEE.},
key = {Service oriented architecture (SOA)},
keywords = {Information services;Linguistics;Quality of service;Software architecture;Web services;},
note = {Composite services;Composition languages;Domain specific languages;Error prone;Rapid development;Semi-automated;Software as a service;},
URL = {http://dx.doi.org/10.1109/ICDE.2009.153},
} 


@inproceedings{20062910004791 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Typed contracts for functional programming},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Hinze, Ralf and Jeuring, Johan and Loh, Andres},
volume = {3945 LNCS},
year = {2006},
pages = {208 - 225},
issn = {03029743},
address = {Fuji-Susono, Japan},
abstract = {A robust software component fulfills a contract: it expects data satisfying a certain property and promises to return data satisfying another property. The object-oriented community uses the design-by-contract approach extensively. Proposals for language extensions that add contracts to higher-order functional programming have appeared recently. In this paper we propose an embedded domain-specific language for typed, higher-order and first-class contracts, which is both more expressive than previous proposals, and allows for a more informative blame assignment. We take some first steps towards an algebra of contracts, and we show how to define a generic contract combinator for arbitrary algebraic data types. The contract language is implemented as a library in Haskell using the concept of generalised algebraic data types. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Mathematical programming},
keywords = {Algebra;Computer programming languages;Computer software;Data reduction;Embedded systems;Functions;Robustness (control systems);},
note = {Data types;Domain-specific languages;Functional programming;Robust software;},
URL = {http://dx.doi.org/10.1007/11737414_15},
} 


@inproceedings{2002377091203 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Navigation of HTML tables, frames, and XML fragments},
journal = {Annual ACM Conference on Assistive Technologies, Proceedings},
author = {Pontelli, E. and Gillan, D. and Xiong, W. and Saad, E. and Gupta, G. and Karshmer, Arthur I.},
year = {2002},
pages = {25 - 32},
address = {Edinburgh, United kingdom},
abstract = {A progress report on the development of technology to support the non-visual navigation of complex HTML and XML structures was presented. Semantic structures adopted were refined to describe the navigational semantics of complex HTML components. A domain specific language dedicated to the navigation of semantic descriptions was validated in the contexts of navigation of tables and frames. Different components were interfaced and integrated to make the system operational.},
key = {HTML},
keywords = {Computer software;Decision making;Interfaces (computer);Semantics;Software agents;Systems analysis;Vision aids;Web browsers;XML;},
note = {System interfaces;},
URL = {http://dx.doi.org/10.1145/638249.638256},
} 


@inproceedings{20064710255019 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {On contracting different behavioral properties in component-based systems},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Collet, Philippe and Ozanne, Alain and Rivierre, Nicolas},
volume = {2},
year = {2006},
pages = {1798 - 1799},
address = {Dijon, France},
abstract = {Using different specification formalisms together is necessary to leverage better reliability on component-based systems. The ConFract system provides a contracting system for hierarchical software components, but currently, only executable assertions are supported. In this paper, we describe how to integrate other kinds of formalism in ConFract. We propose a domain specific language and integration tools that enable designers to describe the observations needed to appropriately verify their specifications. Copyright 2006 ACM.},
key = {Contracts},
keywords = {Computer hardware description languages;Computer software;Integration;Network components;Reliability;},
note = {Component-based systems;ConFract;Hierarchical software components;Integration tools;},
} 


@inproceedings{20111113738540 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A language to define multi-touch interactions},
journal = {ACM International Conference on Interactive Tabletops and Surfaces, ITS 2010},
author = {Huq Khandkar, Shahedul and Maurer, Frank},
year = {2010},
pages = {269 - 270},
address = {Saarbrucken, Germany},
abstract = {Touch has become a common interface for human computer interaction. From portable hand held devices like smart phones to tabletops, large displays and even devices that project on arbitrary surfaces support touch interface. However, at the end, it is the applications that bring meaning for these technologies to people. Incorporating a touch interface in application requires translating meaningful touches into system recognizable events. This process often involves complex implementations that are sometimes hard to fine tune. Due to the lack of higher-level frameworks, developers often end up writing code from scratch to implement touch interactions in their application. To address this, we present a domain-specific language to define multi-touch interaction that hides the low level implementation complexities from application developers. This allows them to focus on designing touch interactions that are natural and meaningful to the application context without worrying about implementation complexities. &copy; 2010 ACM.},
key = {Human computer interaction},
keywords = {Display devices;Interactive devices;Interfaces (computer);Problem oriented languages;},
note = {Application contexts;Application developers;Arbitrary surfaces;Domain specific languages;Gesture;Hand held device;Implementation complexity;Large displays;Low level;Multi-touch;Smart phones;Touch interaction;Touch interfaces;Writing codes;},
URL = {http://dx.doi.org/10.1145/1936652.1936710},
} 


@article{20110413607357 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using the semantic web to define a language for modelling controlled flexibility in software processes},
journal = {IET Software},
author = {Martinho, R. and Varajao, J. and Domingos, D.},
volume = {4},
number = {6},
year = {2010},
pages = {396 - 406},
issn = {17518806},
address = {Six Hills Way, Stevenage, SG1 2AY, United Kingdom},
abstract = {Software processes and corresponding models are dynamic entities that must evolve to cope with changes occurred in the enacting process, the software development organisation, the market and the methodologies used to produce software. However, in the everyday practice, software team members do not want total flexibility. They rather prefer to learn about and follow previously defined controlled flexibility, that is, advices on which, where, how and by whom process models and related instances can change/adapt. Process engineers can express these advices within a process model with a domain-specific language (DSL), which complements the core process modelling language with additional controlled flexibility information. Then, software team members can browse and learn on this information in process models and instances, and be guided when performing changes. In this study, the authors propose the use of the semantic web and associated ontology-based technologies to develop and evolve their controlled flexibility DSL for software processes. They use an ontology-based format to define the controlled flexibility-related concepts, descriptions and axioms that specify the formal semantics of their DSL. In addition, the authors provide concrete mappings between these ontology concepts and a unified modelling language class-based DSL metamodel and describe how it supports changes made in the ontology. &copy; 2010 The Institution of Engineering and Technology.},
key = {Process control},
keywords = {Formal methods;Ontology;Problem oriented languages;Semantic Web;Semantics;Software design;},
note = {Class-based;Domain specific languages;Formal Semantics;In-process;Meta model;Ontology concepts;Ontology-based;Process engineer;Process model;Process modelling;Software development;Software process;Software teams;Unified modelling language;},
URL = {http://dx.doi.org/10.1049/iet-sen.2010.0045},
} 


@inproceedings{20105213530632 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a model driven approach for development of visualization applications in industrial automation},
journal = {Proceedings of the 15th IEEE International Conference on Emerging Technologies and Factory Automation, ETFA 2010},
author = {Hennig, Stefan and Braune, Annerose and Koycheva, Evelina},
year = {2010},
pages = {IEEE Industrial Electronics Society - },
address = {Bilbao, Spain},
abstract = {The eXtensible Visualization Components Markup Language (XVCML) was developed in order to ensure the sustainability of visualization solutions. Therefore, XVCML follows the Model-Driven Software Development (MDSD) approach: It enables technology independent modeling of visualization solutions whereas those models are compliant to a formal metamodel. XVCML was enhanced by a mean to express arbitrary routines using Executable UML. Since we realized the latter aspect only as a first proof of concept, this part of XVCML lacks a formal metamodel - a requirement for MDSD. This paper seizes on this topic so much that a Domain Specific Language, which enables the creation of Executable UML models, will be worked out in the context of MDSD. Therefore, this paper explains the required foundations for the subject matter at hand before it presents the way of proceeding towards a model-driven approach with XVCML. &copy;2010 IEEE.},
key = {Software design},
keywords = {Factory automation;Formal methods;Markup languages;Systems analysis;Unified Modeling Language;Visualization;},
note = {Domain specific languages;Executable UML;Industrial automation;Meta model;Model driven approach;Model-Driven Software Development;Proof of concept;Subject matters;Technology independent;Visualization application;},
URL = {http://dx.doi.org/10.1109/ETFA.2010.5641320},
} 


@inproceedings{20104813446864 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Formalizing high-level service-oriented architectural models using a dynamic ADL},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Lopez-Sanz, Marcos and Cuesta, Carlos E. and Marcos, Esperanza},
volume = {6428 LNCS},
year = {2010},
pages = {57 - 66},
issn = {03029743},
address = {Crete, Greece},
abstract = {Despite the well-known advantages of applying the MDA approach, particularly when applied to the development of SOA-based systems, there are still some gaps in the process that need to be filled. Specifically, when modelling the system at the PIM level, we have an architectural description at a high level of abstraction, as it must only comprise technologically independent models. But this architecture cannot be directly validated, as we must transform it into a PSM version before being able to execute it. In order to solve this issue, we propose to formalize the architectural model using Domain Specific Language, an ADL which supports the description of dynamic, adaptive and evolvable architectures, such as SOA itself. Our choice, &pi;-ADL, allows for the definition of executable versions of the architecture; and therefore providing this specification implies having a prototype of the system at the PIM level. This appears as a perfect way of getting an executable yet completely technology neutral version of the architecture. We illustrate this by discussing a real-world case study, in which a service-oriented messaging system is modelled at the PIM level and then specified using its &pi;-ADL counterpart; the result can then be used to validate the architecture at the right abstraction level. &copy; 2010 Springer-Verlag Berlin Heidelberg.},
key = {Service oriented architecture (SOA)},
keywords = {Abstracting;Architecture;Information services;Internet;Peer to peer networks;Software architecture;Waveguides;},
note = {Abstraction level;Architectural descriptions;Architectural models;Domain specific languages;Evolvable;High level of abstraction;High-level services;Independent model;MDA approach;Messaging system;Model-Driven Architecture;PIM level;PIM-level modelling;Real-world;Service Oriented;SOA-based systems;},
URL = {http://dx.doi.org/10.1007/978-3-642-16961-8_19},
} 


@article{1998344269891 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Little languages: little maintenance?},
journal = {Journal of Software Maintenance},
author = {Van Deursen, A. and Klint, P.},
volume = {10},
number = {2},
year = {1998},
pages = {75 - 92},
issn = {1040550X},
address = {Chichester, United Kingdom},
abstract = {So-called little, or domain-specific languages (DSLs), have the potential to make software maintenance simpler: domain experts can directly use the DSL to make required routine modifications. On the negative side, however, more substantial changes may become more difficult: such changes may involve altering the domain-specific language. This will require compiler technology knowledge, which not every commercial enterprise has easily available. Based on experience taken from industrial practice, we discuss the role of DSLs in software maintenance, the dangers introduced by using them, and techniques for controlling the risks involved.},
key = {Computer programming languages},
keywords = {Computer software;Formal languages;Maintenance;Risk assessment;},
note = {Domain-specific languages;Language prototyping;},
URL = {http://dx.doi.org/10.1002/(SICI)1096-908X(199803/04)10:2<75::AID-SMR168>3.0.CO;2-5},
} 


@inproceedings{20113914360623 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Computer-aided PHA, FTA and FMEA for automotive embedded systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Mader, Roland and Armengaud, Eric and Leitner, Andrea and Kreiner, Christian and Bourrouilh, Quentin and Grienig, Gerhard and Steger, Christian and Wei, Reinhold},
volume = {6894 LNCS},
year = {2011},
pages = {113 - 127},
issn = {03029743},
address = {Naples, Italy},
abstract = {The shift of the automotive industry towards powertrain electrification introduces new automotive sensors, actuators and functions that lead to an increasing complexity of automotive embedded systems. The safety-criticality of these systems demands the application of analysis techniques such as PHA (Preliminary Hazard Analysis), FTA (Fault Tree Analysis) and FMEA (Failure Modes and Effects Analysis) in the development process. The early application of PHA allows to identify and classify hazards and to define top-level safety requirements. Building on this, the application of FTA and FMEA supports the verification of a system architecture defining an embedded system together with connected sensors and controlled actuators. This work presents a modeling framework with automated analysis and synthesis capabilities that supports a safety engineering workflow using the domain-specific language EAST-ADL. The contribution of this work is (1) the definition of properties that indicate the correct application of the workflow using the language. The properties and a model integrating the work products of the workflow are used for the automated detection of errors (property checker) and the automated suggestion and application of corrective measures (model corrector). Furthermore, (2) fault trees and a FMEA table can be automatically synthesized from the same model. The applicability of this computer-aided and tightly integrated approach is evaluated using the case study of a hybrid electric vehicle development. &copy; 2011 Springer-Verlag.},
key = {Embedded systems},
keywords = {Actuators;Automation;Automotive industry;Electric utilities;Electric vehicles;Fault tree analysis;Hazards;Model checking;Plant extracts;Problem oriented languages;Safety factor;Security of data;Sensors;},
note = {Analysis techniques;Automated analysis;Automated detection;Automotive embedded systems;Automotive sensors;Corrective measures;Development process;Domain specific languages;EAST-ADL;Failure modes and effects analysis;Fault-trees;Hybrid electric vehicle;Integrated approach;Modeling frameworks;Preliminary hazard analysis;Safety requirements;System architectures;Work products;},
URL = {http://dx.doi.org/10.1007/978-3-642-24270-0_9},
} 


@inproceedings{2005509540833 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Inferring context-free grammars for domain-specific languages},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Crepinek, Matej and Mernik, Marjan and Bryant, Barrett R. and Javed, Faizan and Sprague, Alan},
volume = {141},
number = {4 SPEC. ISS.},
year = {2005},
pages = {99 - 116},
issn = {15710661},
abstract = {In the area of programming languages, context-free grammars (CFGs) are of special importance since almost all programming languages employ CFG's in their design. Recent approaches to CFG induction are not able to infer context-free grammars for general-purpose programming languages. In this paper it is shown that syntax of a small domain-specific language can be inferred from positive and negative programs provided by domain experts. In our work we are using the genetic programming approach in grammatical inference. Grammar-specific heuristic operators and nonrandom construction of the initial population are proposed to achieve this task. Suitability of the approach is shown by examples where underlying context-free grammars are successfully inferred. &copy; 2005 Elsevier B.V. All rights reserved.},
key = {Context free grammars},
keywords = {Computer programming languages;Genetic algorithms;Heuristic methods;Mathematical operators;},
note = {Exhaustive search;Genetic programming;Grammar induction;Grammar inference;Learning from positive and negative samples;},
URL = {http://dx.doi.org/10.1016/j.entcs.2005.02.055},
} 


@inproceedings{20112514077207 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Operation based model representation: Experiences on inconsistency detection},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Le Noir, Jerome and Delande, Olivier and Exertier, Daniel and Da Silva, Marcos Aurelio Almeida and Blanc, Xavier},
volume = {6698 LNCS},
year = {2011},
pages = {85 - 96},
issn = {03029743},
address = {Birmingham, United kingdom},
abstract = {Keeping the consistency between design models is paramount in complex contexts. It turns out that the underlying Model Representation Strategy has an impact on the inconsistency detection activity. The Operation Based strategy represents models as the sequence of atomic editing actions that lead to its current state. Claims have been made about gains in time and space complexity and in versatility by using this kind of representation when compared to the traditional object based one. However, this hypothesis has never been tested in an industrial context before. In this paper, we detail our experience evaluating an Operation Based consistency engine (Praxis) when compared with a legacy system based on EMF. We evaluated a set of industrial models under inconsistency rules written in both Java (for EMF) and PraxisRules (the DSL - Domain Specific Language - for describing inconsistency rules in Praxis). Our results partially confirm the gains claimed by the Operation Based engines. &copy; 2011 Springer-Verlag.},
key = {Java programming language},
keywords = {Legacy systems;},
note = {Design models;Domain specific languages;Inconsistency detection;Industrial context;Industrial models;Model representation;Object based;Space complexity;},
URL = {http://dx.doi.org/10.1007/978-3-642-21470-7_7},
} 


@inproceedings{20085111787543 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Rule Representation, Interchange and Reasoning on the Web - International Symposium, RuleML 2008, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
editor = {},
volume = {5321 LNCS},
year = {2008},
pages = {VULCAN; Model Systems; STI - INNSBRUCK; ruleCore; JBoss - },
issn = {03029743},
address = {Orlando, FL, United states},
abstract = {The proceedings contain 23 papers. The topics discussed include: abductive workflow mining using binary resolution on task successor rules; a rule-based framework using role patterns for business process compliance; a rule-based notation to specify executable electronic contracts; on extending RuleML for modal defeasible logic; adding uncertainty to a rate-OO inference engine; programming with fuzzy logic by using the FLOPER tool; ruling networks with RDL: a domain-specific language to task wireless sensor networks; local and distributed defeasible reasoning in multi-context systems; personal agents in the rule responder architecture; semi-automatic composition of geospatial Web services using JBoss rules; a RuleML study on integrating geographical and health information; and self-sustained routing for event diffusion in wireless sensor networks.},
} 


@inproceedings{20094912525820 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic Generation of Network Protocol Gateways},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Bromberg, Yerom-David and Reveillere, Laurent and Lawall, Julia L. and Muller, Gilles},
volume = {5896 LNCS},
year = {2009},
pages = {21 - 41},
issn = {03029743},
address = {Urbana, IL, United states},
abstract = {The emergence of networked devices in the home has made it possible to develop applications that control a variety of household functions. However, current devices communicate via a multitude of incompatible protocols, and thus gateways are needed to translate between them. Gateway construction, however, requires an intimate knowledge of the relevant protocols and a substantial understanding of low-level network programming, which can be a challenge for many application programmers. This paper presents a generative approach to gateway construction, z2z, based on a domain-specific language for describing protocol behaviors, message structures, and the gateway logic. Z2z includes a compiler that checks essential correctness properties and produces efficient code. We have used z2z to develop a number of gateways, including SIP to RTSP, SLP to UPnP, and SMTP to SMTP via HTTP, involving a range of issues common to protocols used in the home. Our evaluation of these gateways shows that z2z enables communication between incompatible devices without increasing the overall resource usage or response time. &copy; 2009 Springer-Verlag Berlin Heidelberg.},
key = {Gateways (computer networks)},
keywords = {Internet protocols;Middleware;Network protocols;Problem oriented languages;Telecommunication systems;},
note = {Application programmers;Automatic Generation;Correctness properties;Domain specific languages;Message structures;Network programming;Networked devices;Protocol behavior;Resource usage;Response time;},
URL = {http://dx.doi.org/10.1007/978-3-642-10445-9_2},
} 


@inproceedings{20105013471444 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Declarative mesh subdivision using topological rewriting in MGS},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Spicher, Antoine and Michel, Olivier and Giavitto, Jean-Louis},
volume = {6372 LNCS},
year = {2010},
pages = {298 - 313},
issn = {03029743},
address = {Enschede, Netherlands},
abstract = {Mesh subdivision algorithms are usually specified informally using graphical schemes defining local mesh refinements. These algorithms are then implemented efficiently in an imperative framework. The implementation is cumbersome and implies some tricky indices management. Smith et al. (2004) asks the question of the declarative programming of such algorithms in an index-free way. In this paper, we positively answer this question by presenting a rewriting framework where mesh refinements are described by simple rules. This framework is based on a notion of topological chain rewriting. Topological chains generalize the notion of labeled graph to higher dimensional objects. This framework has been implemented in the domain specific language MGS. The same generic approach has been used to implement Loop as well as Butterfly, Catmull-Clark and Kobbelt subdivision schemes. &copy; 2010 Springer-Verlag.},
key = {Algorithms},
keywords = {Computer programming;Graph theory;},
note = {Declarative Programming;Domain specific languages;Generic approach;Higher-dimensional;Labeled graphs;Local mesh refinement;Mesh refinement;Simple rules;Subdivision algorithms;Subdivision schemes;},
URL = {http://dx.doi.org/10.1007/978-3-642-15928-2_20},
} 


@inproceedings{20064110161834 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Enforcing different contracts in hierarchical component-based systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Collet, Philippe and Ozanne, Alain and Rivierre, Nicolas},
volume = {4089 LNCS},
year = {2006},
pages = {50 - 65},
issn = {03029743},
address = {Vienna, Austria},
abstract = {Using different specification formalisms together is necessary to leverage better reliability on component-based systems. The ConFract system provides a contracting system for hierarchical software components, but currently, only executable assertions are supported. In this paper, we describe how TLA, taken as an instance of behavioral sequence-based formalism, was integrated in ConFract. A domain specific language is proposed in order to enable designers to describe the observations needed to appropriately verify their specifications. These observations are automatically generated for assertions and in the case of TLA, we show what kind of observations must be provided to link the specifications to the concrete application. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Hierarchical systems},
keywords = {Artificial intelligence;Computer programming languages;Computer science;Computer software;Reliability theory;},
note = {Component based systems;ConFract system;Software components;},
} 


@inproceedings{20112214013422 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Whole-function vectorization},
journal = {Proceedings - International Symposium on Code Generation and Optimization, CGO 2011},
author = {Karrenberg, Ralf and Hack, Sebastian},
year = {2011},
pages = {141 - 150},
address = {Chamonix, France},
abstract = {Data-parallel programming languages are an important component in today's parallel computing landscape. Among those are domain-specific languages like shading languages in graphics (HLSL, GLSL, RenderMan, etc.) and "general-purpose" languages like CUDA or OpenCL. Current implementations of those languages on CPUs solely rely on multi-threading to implement parallelism and ignore the additional intra-core parallelism provided by the SIMD instruction set of those processors (like Intel's SSE and the upcoming AVX or Larrabee instruction sets). In this paper, we discuss several aspects of implementing dataparallel languages on machines with SIMD instruction sets. Our main contribution is a language- and platform-independent code transformation that performs whole-function vectorization on low-level intermediate code given by a control flow graph in SSA form. We evaluate our technique in two scenarios: First, incorporated in a compiler for a domain-specific language used in realtime ray tracing. Second, in a stand-alone OpenCL driver. We observe average speedup factors of 3.9 for the ray tracer and factors between 0.6 and 5.2 for different OpenCL kernels. &copy; 2011 IEEE.},
key = {Codes (symbols)},
keywords = {Cosine transforms;Data flow analysis;Graphical user interfaces;Network components;Optimization;Parallel architectures;Parallel programming;Problem oriented languages;Program compilers;},
note = {Code transformation;Control flow graphs;Data parallel;Data-parallel programming;Domain specific languages;Instruction set;Multi-threading;On-machines;Parallel Computing;Real time;RenderMan;Shading languages;SIMD instructions;Speed-up factors;Vectorization;},
URL = {http://dx.doi.org/10.1109/CGO.2011.5764682},
} 


@inproceedings{20110413612788 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven ad hoc data integration in the context of a population-based Cancer Registry},
journal = {ICSOFT 2010 - Proceedings of the 5th International Conference on Software and Data Technologies},
author = {Teiken, Yvette and Rohde, Martin and Appelrath, Hans-Jurgen},
volume = {1},
year = {2010},
pages = {337 - 343},
address = {Athens, Greece},
abstract = {The major task of a population-based Cancer Registry (CR) is the identification of risk groups and factors. This analysis makes use of data about the social background of the population. The integration of that data is not intended for the routine processes at the CR. Therefore, this process must be performed by data warehouse experts that results in high cost. This paper proposes an approach, which allows epidemiologists and physicians at the CR to realize this ad hoc data integration on their own. We use model driven software design (MDSD) with a domain specific language (DSL), which allows the epidemiologists and physicians to describe the data to be integrated in a known language. This description or rather model is used to create an extension of the existing data pool and a web service and web application for data integration. The end user can do the integration on his/her own which results in a very cost-efficient way of ad hoc data integration.},
key = {Data handling},
keywords = {Data warehouses;Diseases;Information management;Integration;Lakes;Population statistics;Software design;Web services;},
note = {Data analysis;Data integration;Data management;MDSD;Model driven software development;},
} 


@inproceedings{20104713411073 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The impact of model driven development on the software architecture process},
journal = {Proceedings - 36th EUROMICRO Conference on Software Engineering and Advanced Applications, SEAA 2010},
author = {Heijstek, Werner and Chaudron, Michel R. V.},
year = {2010},
pages = {333 - 341},
address = {Lille, France},
abstract = {While Model-Driven Development (MDD) is an increasingly popular software development approach, its impact on the development process in large-scale, industrial practice is not yet clear. For this study the application of MDD in a large-scale industrial software development project is analyzed over a period of two years. Applying a grounded theory approach we identified 14 factors which impact the architectural process. We found that scope creep is more likely to occur, late changes can imply more extensive rework and that business engineers need to be more aware of the technical impact of their decisions. In addition, the introduced Domain-Specific Language (DSL) provides a new common idiom that can be used by more team members and will ease communication among team members and with clients. Also, modelers need to be much more explicit and complete in their descriptions. Parallel development of a code generator and defining a proper meta-model require additional time investments. Lastly, the more central role of software architecture design documentation requires more structured, detailed and complete architectural information and consequently, more frequent reviews. &copy; 2010 IEEE.},
key = {Software design},
keywords = {Problem oriented languages;Software architecture;},
note = {Code generators;Development process;Domain specific languages;Grounded theory approach;Industrial practices;Industrial software development;Meta model;Model-driven development;Parallel development;Role of software;Software development approach;Team members;},
URL = {http://dx.doi.org/10.1109/SEAA.2010.63},
} 


@article{20101512843328 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Service-level agreements for electronic services},
journal = {IEEE Transactions on Software Engineering},
author = {Skene, James and Raimondi, Franco and Emmerich, Wolfgang},
volume = {36},
number = {2},
year = {2010},
pages = {288 - 304},
issn = {00985589},
address = {445 Hoes Lane / P.O. Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {The potential of communication networks and middleware to enable the composition of services across organizational boundaries remains incompletely realized. In this paper, we argue that this is in part due to outsourcing risks and describe the possible contribution of Service-Level Agreements (SLAs) to mitigating these risks. For SLAs to be effective, it should be difficult to disregard their original provisions in the event of a dispute between the parties. Properties of understandability, precision, and monitorability ensure that the original intent of an SLA can be recovered and compared to trustworthy accounts of service behavior to resolve disputes fairly and without ambiguity. We describe the design and evaluation of a domain-specific language for SLAs that tend to exhibit these properties and discuss the impact of monitorability requirements on service-provision practices. &copy; 2010 IEEE.},
key = {Contracts},
keywords = {Graphical user interfaces;Linguistics;Middleware;Outsourcing;Problem oriented languages;Query languages;},
note = {Communication networks;Composition of services;Domain specific languages;Electronic services;Model-driven Engineering;Organizational boundaries;Service Level Agreements;Understandability;},
URL = {http://dx.doi.org/10.1109/TSE.2009.55},
} 


@inproceedings{20064110157927 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings Ninth IEEE International EDOC Enterprise Computing Conference},
journal = {Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOC},
year = {2005},
pages = {IEEE Computer Soc. Tech. Committee on Distributed Processing; IEEE Communications Society; CTIT; University of Twente; Telematica Instituut - },
issn = {15417719},
address = {Enschede, Netherlands},
abstract = {The proceedings contain 25 papers. The topics discussed include: bridging the gap between data warehouses and business processes: a business intelligence perspective for event-driven process chain; extending BPEl for run time adaptability; intelligence aggregation of purchase orders in e-procurement; learning, planning, and life cycle of workflow management, dealing with contract violations: formalism and domain specific language, an architecture for flexible web services QoS negotiation; a method for specifying contract mediated interactions; an aspect oriented model driven framework; transaction support using unit of work modeling in the context of MDA; an MDA-oriented .NET metamodel; an approach to related business and application services using ISDL; implementing fair non-repudiable interactions with web services; and integration and analysis of functional and non-functional aspects in model-driven E-services development.},
key = {Data warehouses},
keywords = {Administrative data processing;Artificial intelligence;Computer architecture;Contracts;Electronic commerce;Industrial management;Life cycle;Quality of service;},
note = {Business processes;E-procurements;Intelligence aggregations;Non repudiable interactions;},
} 


@inproceedings{20104913464568 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A tool for modeling form type check constraints},
journal = {Proceedings of the International Multiconference on Computer Science and Information Technology, IMCSIT '09},
author = {Lukovic, Ivan and Popovic, Aleksandar and Mostic, Jovo and Ristic, Sonja},
volume = {4},
year = {2009},
pages = {683 - 690},
address = {Mragowo, Poland},
abstract = {IIS*Case is a software tool that provides information system modeling and generating executable application prototypes. At the level of platform independent model specifications, IIS*Case provides conceptual modeling of database schemas that include specifications of various database constraints, such as domain, not null, key and unique constraints, as well as various kinds of inclusion dependencies. In the paper, we present new concepts and a tool embedded into IIS*Case, that are aimed to support specification of check constraints. We present a domain specific language for specifying check constraints and a tool that enables visually oriented design and parsing check constraints. &copy; 2009 IEEE.},
key = {Specifications},
keywords = {Computer aided software engineering;Computer science;Information technology;Software prototyping;},
note = {Conceptual modeling;Database constraints;Database schemas;Domain specific languages;Inclusion dependencies;Platform independent model;Software tool;},
URL = {http://dx.doi.org/10.1109/IMCSIT.2009.5352764},
} 


@inproceedings{20095012542247 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Smart sensor metamodel for deep sea observatory},
journal = {OCEANS '09 IEEE Bremen: Balancing Technology with Future Needs},
author = {Zein, Oussama Kassem and Champeau, Joel and Kerjean, Dominique and Auffret, Yves},
year = {2009},
address = {Bremen, Germany},
abstract = {Deep sea observatories, based on sensor networks, provide new features to the ocean survey like a continuous observation of the ocean. The sensors used in these observatories provide environment data and also insure new functionalities or services due to the permanent running of this network. The nominal behavior of each sensor must be extended to feet with this concept of deep sea observatory. So in this paper, we present our smart sensor metamodeling approach for deep sea-observatory. This work aims at specifying a Domain Specific Language (DSL) dedicated to smart sensor networks in a goal to model the behavior of the sensor and to produce automaticaly the software which is embedded in the network infrastructure. This DSL includes three modeling levels of smart sensor: static properties, interface and behavior. The sensor interface provides to observers and scientific researchers a set of services dedicated to ocean measures that the sensor can do, based on internal or external event detections. The sensor behavior permits observers to know how the sensor behaves. &copy;2009 IEEE.},
key = {Sensor networks},
keywords = {Buildings;DSL;Embedded software;Modems;Observatories;Oceanography;Smart sensors;Telecommunication lines;},
note = {Continuous observation;Deep sea;Domain specific languages;Environment data;Event detection;Know-how;Meta model;Metamodeling;Network infrastructure;Sensor behavior;Sensor interface;Static properties;},
URL = {http://dx.doi.org/10.1109/OCEANSE.2009.5278105},
} 


@inproceedings{20092812186053 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Bidirectionalization for free! (pearl)},
journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
author = {Voigtlander, Janis},
year = {2009},
pages = {165 - 176},
issn = {07308566},
address = {Savannah, GA, United states},
abstract = {A bidirectional transformation consists of a function get that takes a source (document or value) to a view and a function put that takes an updated view and the original source back to an updated source, governed by certain consistency conditions relating the two functions. Both the database and programming language communities have studied techniques that essentially allow a user to specify only one of get and put and have the other inferred automatically. All approaches so far to this bidirectionalization task have been syntactic in nature, either proposing a domain-specific language with limited expressiveness but built-in (and composable) backward components, or restricting get to a simple syntactic form from which some algorithm can synthesize an appropriate definition for put. Here we present a semantic approach instead. The idea is to take a general-purpose language, Haskell, and write a higher-order function that takes (polymorphic) get-functions as arguments and returns appropriate put-functions. All this on the level of semantic values, without being willing, or even able, to inspect the definition of get, and thus liberated from syntactic restraints. Our solution is inspired by relational parametricity and uses free theorems for proving the consistency conditions. It works beautifully. Copyright&copy; 2009 ACM.},
key = {Linguistics},
keywords = {Computer aided software engineering;Computer software;Problem oriented languages;Query languages;Semantics;Syntactics;Systems analysis;},
note = {Backward components;Bidirectional transformation;Consistency conditions;Domain specific languages;Generic programming;Haskell;Higher-order functions;Program transformation;Programming language;Relational parametricity;Semantic approach;Semantic value;Viewupdate problem;},
URL = {http://dx.doi.org/10.1145/1480881.1480904},
} 


@inproceedings{2005269178242 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the Thirty-sixth SIGCSE Technical Symposium on Computer Science Education, SIGCSE 2005},
journal = {Proceedings of the Thirty-Sixth SIGCSE Technical Symposium on Computer Science Education, SIGCSE 2005},
year = {2005},
pages = {ACM SIGCSE - },
address = {St. Louis, MO, United states},
abstract = {The proceedings contain 131 papers from the Proceedings of the Thirty-sixth SIGCSE Technical Symposium on Computer Science Education, SIGCSE 2005. The topics discussed include: using abstractions to make concepts concrete; building an XQuery interpreter in a compiler construction course; teaching compiler construction using a domain specific language; hide and show - using real compiler code for teaching; accessibility in introductory computer science; integrating science and research in a HCI design course; interpreting Java program runtimes; teaching empirical skills and concepts in computer science using random walks; and design patterns for database pedagogy - a proposal.},
key = {Education computing},
keywords = {Codes (symbols);Computer programming;Computer science;Curricula;Errors;Game theory;Graphical user interfaces;Information technology;Mathematical models;Optimization;Program compilers;Program debugging;Program documentation;Software engineering;Students;Teaching;},
note = {Assistive technology;Blindness;Compiler construction;Debuggers;EiRev;Game programming language (GPL);Mnemonics;Parsing;Program design;Program implementation;},
} 


@inproceedings{20094412412435 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Bidirectionalization for free! (pearl)},
journal = {ACM SIGPLAN Notices},
author = {Voigtlander, Janis},
volume = {44},
number = {1},
year = {2009},
pages = {165 - 176},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {A bidirectional transformation consists of a function get that takes a source (document or value) to a view and a function put that takes an updated view and the original source back to an updated source, governed by certain consistency conditions relating the two functions. Both the database and programming language communities have studied techniques that essentially allow a user to specify only one of get and put and have the other inferred automatically. All approaches so far to this bidirectionalization task have been syntactic in nature, either proposing a domain-specific language with limited expressiveness but built-in (and composable) backward components, or restricting get to a simple syntactic form from which some algorithm can synthesize an appropriate definition for put. Here we present a semantic approach instead. The idea is to take a general-purpose language, Haskell, and write a higher-order function that takes (polymorphic) get-functions as arguments and returns appropriate put-functions. All this on the level of semantic values, without being willing, or even able, to inspect the definition of get, and thus liberated from syntactic restraints. Our solution is inspired by relational parametricity and uses free theorems for proving the consistency conditions. It works beautifully.},
key = {Problem oriented languages},
keywords = {Computer aided software engineering;Linguistics;Semantics;Syntactics;Systems analysis;},
note = {Backward components;Bidirectional transformation;Consistency conditions;Domain specific languages;Generic programming;Haskell;Higher-order functions;Program transformation;Programming language;Relational parametricity;Semantic approach;Semantic value;Viewupdate problem;},
} 


@inproceedings{20093012219895 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Language for advanced protocol analysis automotive networks},
journal = {Proceedings - International Conference on Software Engineering},
author = {Reichert, Tim and Klaus, Edmund and Schoch, Wolfgang and Meroth, Ansgar and Herzberg, Dominikus},
year = {2008},
pages = {593 - 602},
issn = {02705257},
address = {Leipzig, Germany},
abstract = {The increased use and interconnection of electronic components automobiles has made communication behavior in networks drastically more complex task. Both communication at application level and complex communication are often under-specified or out of scope existing analysis techniques. We extend traditional protocol in order to capture communication at the of abstraction that reflects application design and show the same technique can be used to specify, monitor and complex scenarios. We present CFR (Channel Filter) models, a novel approach for the specification of analyzers a domain-specific language that implements this. From CFR models, we can fully generate powerful that extract design intentions, abstract protocol and even complex scenarios from low level communication. We show that three basic concepts (channels, and rules) are sufficient to build such powerful analyzers identify possible areas of application.&copy;right 2008.},
key = {Communication},
keywords = {Abstracting;Automobile parts and equipment;Computer software;Linguistics;Query languages;},
note = {Abstract protocols;Advanced protocols;Analysis techniques;Application design;Application level;Automotive networks;Basic concepts;Channel filters;Communication behavior;Complex task;Design intention;Domain specific languages;Electronic component;In-network;Languages;Low level;},
URL = {http://dx.doi.org/10.1145/1368088.1368171},
} 


@inproceedings{1997083478032 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Specifying code analysis tools},
journal = {Conference on Software Maintenance},
author = {Canfora, G. and Cimitile, A. and De Lucia, A.},
year = {1996},
pages = {95 - 103},
address = {Monterey, CA, USA},
abstract = {Customised code analysis tools for the maintenance and evolution of existing software systems can be created by storing program information into a database, and using an application generator to translate the high level specifications of the analyses the tools are intended to perform. We present a high level domain specific language for the specification of program analysis tools that exploit an algebraic program representation called F(p). The algebraic representation is a compact program view which describes the static composition of the control structures and the set of the resulting potential executions. Operands of the algebraic expression (that represent the program's constructs) are used as indexes to access information stored into a database. The specification language provides facilities for the traversal of the program representation and access to the associated information into the database. The program model and the analyses' results are integrated into a unique conceptual model, thus simplifying the reuse of the results of an analysis and the integration of tools.},
key = {Computer aided software engineering},
keywords = {Algebra;Codes (symbols);Computer hardware description languages;Computer software;Data structures;Database systems;High level languages;},
note = {Algebraic representation;Application generator;Code analysis tools;Software maintenance;},
} 


@inproceedings{20064710254982 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Implementing an embedded GPU language by combining translation and generation},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Lejdfors, Calle and Ohlsson, Lennart},
volume = {2},
year = {2006},
pages = {1610 - 1614},
address = {Dijon, France},
abstract = {Dynamic languages typically allow programs to be written at a very high level of abstraction. But their dynamic nature makes it very hard to compile such languages, meaning that a price has to be paid in terms of performance. However under certain restricted conditions compilation is possible. In this paper we describe how a domain specific language for image processing in Python can be compiled for execution on high speed graphics processing units. Previous work on similar problems have used either translative or generative compilation methods, each of which has its limitations. We propose a strategy which combine these two methods thereby achieving the benefits of both. Copyright 2006 ACM.},
key = {Computer programming languages},
keywords = {Computer graphics;Image processing;Problem solving;Program compilers;Translation (languages);},
note = {Compilation;Dynamic languages;Generative techniques;Graphics processing units (GPU);},
} 


@inproceedings{20102312999057 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {ECQL: A query and action language for model-based applications},
journal = {17th IEEE International Conference and Workshops on the Engineering of Computer-Based Systems, ECBS 2010},
author = {Krenn, Ulrich and Thonhauser, Michael and Kreiner, Christian},
year = {2010},
pages = {286 - 290},
address = {Oxford, United kingdom},
abstract = {Modern distributed computer systems with mobile and embedded devices as first class citizens are formed from heterogeneous platforms. To support this heterogeneity along with adaptation of the system an approach for interpretation of domain specific models at runtime has been proposed with the concept of Model-Based Software Components (MBSC), separating the domain specific functionality from the current technical platform. This is achieved by the usage of different sets of high-level models. These sets are interpreted by a portable, plugin-extensible runtime environment, utilizing several instances of model-based containers (MCC) for models and their corresponding data. In this paper the design of a domain specific language is presented, enabling the specification of accessing and manipulating data entities provided by various MCCs used in the runtime architecture of a MBSC. For demonstration purposes the application of the various language elements is presented using a case study of an exemplary distributed pervasive system running in the business domain of logistics. &copy; 2010 IEEE.},
key = {Distributed computer systems},
keywords = {Embedded systems;Linguistics;},
note = {Action language;Business domain;Data entities;Domain specific;Domain specific languages;Embedded device;Heterogeneous platforms;High-level models;Language elements;Model-based;Pervasive systems;Plug-ins;Running-in;Runtime architecture;Runtime environments;Runtimes;Software component;},
URL = {http://dx.doi.org/10.1109/ECBS.2010.40},
} 


@article{20082111276611 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A language for high-level description of adaptive web systems},
journal = {Journal of Systems and Software},
author = {Sadat-Mohtasham, S. Hossein and Ghorbani, Ali A.},
volume = {81},
number = {7},
year = {2008},
pages = {1196 - 1217},
issn = {01641212},
address = {360 Park Avenue South, New York, NY 10010, United States},
abstract = {Adaptive Web systems (AWS) are Web-based systems that can adapt their features such as, presentation, content, and structure, based on users' behaviour and preferences, device capabilities, and environment attributes. A framework was developed in our research group to provide the necessary components and protocols for the development of adaptive Web systems; however, there were several issues and shortcomings (e.g. low productivity, lack of verification mechanisms, etc.) in using the framework that inspired the development of a domain-specific language for the framework. This paper focuses on the proposal, design, and implementation of AWL, the Adaptive Web Language, which is used to develop adaptive Web systems within our framework. Not only does AWL address the existing issues in the framework, but it also offers mechanisms to increase software quality attributes, especially, reusability. An example application named PENS (a personalized e-News system) is explained and implemented in AWL. AWL has been designed based on the analysis of the adaptive Web domain, having taken into account the principles of reuse-based software engineering (product-lines), domain-specific languages, and aspect-oriented programming. Specially, a novel design decision, inspired by aspect-oriented programming paradigm, allows separate specification of presentation features in an application from its adaptation features. The AWL's design decisions and their benefits are explained. &copy; 2007 Elsevier Inc. All rights reserved.},
key = {High level languages},
keywords = {Adaptive systems;Content based retrieval;Domain decomposition methods;Internet protocols;Software design;},
note = {Adaptive web systems;Aspect-oriented programming;Domain-specific programming language;High-level description;},
URL = {http://dx.doi.org/10.1016/j.jss.2007.08.033},
} 


@inproceedings{20110313598939 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Defining the semantics of it service management models using OWL and SWRL},
journal = {KEOD 2010 - Proceedings of the International Conference on Knowledge Engineering and Ontology Development},
author = {Valiente, Maria-Cruz and Rodriguez, Daniel and Vicente-Chicote, Cristina},
year = {2010},
pages = {378 - 381},
address = {Valencia, Spain},
abstract = {Service management is a set of specialized organizational capabilities that provide value to customers in the form of services. Many organizations are aware of the need to adopt best practices in order to create an effective IT Service Management (ITSM) for enabling Business and IT integration. However, the reuse and interchange of service models is still quite limited in the area of IT service support due to the problems in connecting with natural language. In this context, this paper presents the ITIL-based Service Management Model aimed at capturing ITSM best practices by means of a formal ontology-based business DSL (Domain-Specific Language). We show how this DSL can be formally represented adopting the Web Ontology Language (OWL) and the Semantic Web Rule Language (SWRL). This ontology will precisely define the semantics associated to IT service management models, enabling different tools to interchange them without ambiguities. These models will be defined just in terms of the business logic, without any architectural or platform-specific consideration. That is, according to the OMG's four-layered architecture, the proposed model could be placed at a CIM level.},
key = {Ontology},
keywords = {Information technology;Interchanges;Knowledge representation;Management;Problem oriented languages;Semantic Web;Semantics;},
note = {ITIL;ITSM;OWL;Service process;SWRL;},
} 


@article{20103513198848 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Separation of concerns and linguistic integration in webDSL},
journal = {IEEE Software},
author = {Groenewegen, Danny and Hemel, Zef and Visser, Eelco},
volume = {27},
number = {5},
year = {2010},
pages = {31 - 37},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {Web application development is a complex task, in which developers must address many concerns, such as user interface, data model, access control, data validation, and search. Current technology typically requires multiple languages and programming paradigms to cover these aspects. Using such domain-specific languages improves developer expressivity and lets them separate concerns. However, coupling these technologies is often less than optimal. It results in little or no consistency checking between concerns as well as wildly different language styles and paradigmsfrom XML-style transformation languages like Extensible Style Sheet Language Transformation, to aspect languages like cascading style sheets, to object-oriented languages like Java and Java Script. WebDSL is a domain-specific language for constructing Web information systems. The language comprises sublanguages that address Web application concerns, maintaining separation of concerns, but integrating linguistically to provide consistency checking and reuse of common language concepts consistency checking and reuse of common language concepts between concerns. In this paper we describe the problems in web application development and discuss the WebDSL solution. &copy; 2006 IEEE.},
key = {Java programming language},
keywords = {Access control;Computer system firewalls;Graphical user interfaces;Integration;Linguistics;Object oriented programming;Problem oriented languages;Query languages;World Wide Web;XML;},
note = {Domain specific languages;Separation of concerns;static verification;WEB application;WebDSL;},
URL = {http://dx.doi.org/10.1109/MS.2010.92},
} 


@inproceedings{20103213128314 ,
language = {Russian},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using Microsoft DSL technology to planning of the drug therapy course and diagnostic process},
journal = {2009 5th Central and Eastern European Software Engineering Conference in Russia, CEE-SECR 2009},
author = {Vassiliev, Slava A.},
year = {2009},
pages = {289 - 293},
address = {Moscow, Russia},
abstract = {Medical mistakes at creation of the process of diagnostics and therapy (further-course) can lead to the most fatal consequences for the patient. It is necessary for doctor to keep in mind the wide range of diverse factors in a context of the current status of the patient. In this report the innovative method of creation of the course of drug therapy is presented. The course is considered as the program in Domain-Specific Language. Are described base entities of this language (the Patient, Therapy, Diagnostics) and course engineering process (creation, translation, debug and deployment of the final programs at mobile devices). The integrated development environment has been developed with Microsoft Visual Studio Shell technology. The analysis of compatibility of the medicaments has been implemented by the logic programming (Prolog). Set of predicates is generated from the drug's descriptions. The analysis of efficiency of this approach for elimination of the typical errors is presented. &copy;2009 IEEE.},
key = {Drug therapy},
keywords = {Computer software;Linguistics;Logic programming;Medicine;Mobile devices;Problem oriented languages;Program debugging;Program diagnostics;Program translators;PROLOG (programming language);Web services;},
note = {Current status;Diagnostic process;Domain specific languages;DSL-technologies;Engineering process;Innovative method;Integrated development environment;MicroSoft;Microsoft DSL;Microsoft VSX;Visual studios;},
URL = {http://dx.doi.org/10.1109/CEE-SECR.2009.5501141},
} 


@article{20092512138958 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {We need more than one : Why students need a sophisticated understanding of programming languages},
journal = {ACM SIGPLAN Notices},
author = {Fisher, Kathleen},
volume = {43},
number = {11},
year = {2008},
pages = {62 - 65},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Over the course of their careers, students will need to master a number of diverse programming languages because different languages are best suited to different tasks and because the set of "popular" languages evolves over time. In addition, sometimes the best way to solve a problem is to invent a little language particular to the task. Students need to be able to evaluate which languages to use for which tasks and whether to design a domain-specific language. Consequently, it is critical that students develop a sophisticated understanding of programming languages during their undergraduate studies. &copy; 2008 ACM.},
key = {Query languages},
keywords = {Computer software;Curricula;Linguistics;Students;Teaching;},
note = {Domain specific languages;Programming language;Programming languages curriculum;Undergraduate study;},
} 


@inproceedings{20085111785576 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A DSL approach tor object memory management ot small devices},
journal = {Proceedings of the 4th Workshop on Programming Languages and Operating Systems, PLOS 2007},
author = {Marquet, Kevin and Grimaud, Gilles},
year = {2007},
pages = {Assoc. Comput. Mach. Spec. Interest Gr. Operat. Syst. - },
address = {Stevenson, WA, United states},
abstract = {Small devices have a specific hardware configuration. In particular, they usually include several types of memories (typically ROM, internal and external RAM, ROM, Flash memory) different in quantities and properties. We propose an object memory management where the placement of an object in a given generation is based on different properties. This approach is supported by a domain specific language allowing to write powerful and flexible placement policies. These placement policies completely describe the placement, in the different memories, of the objects handled by the virtual machine.Copyright &copy; 2007 ACM.},
key = {Data storage equipment},
keywords = {Computer programming languages;Computer software;Computers;Flash memory;Linguistics;Query languages;Technical presentations;},
note = {Domain specifics;External-;Object memories;Small devices;Specific hardwares;},
URL = {http://dx.doi.org/10.1145/1376789.1376795},
} 


@inproceedings{20111113739827 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Power of clouds in your pocket: An efficient approach for cloud mobile hybrid application development},
journal = {Proceedings - 2nd IEEE International Conference on Cloud Computing Technology and Science, CloudCom 2010},
author = {Manjunatha, Ashwin and Ranabahu, Ajith and Sheth, Amit and Thirunarayan, Krishnaprasad},
year = {2010},
pages = {496 - 503},
address = {Indianapolis, IN, United states},
abstract = {The advancements in computing have resulted in a boom of cheap, ubiquitous, connected mobile devices as well as seemingly unlimited, utility style, pay as you go computing resources, commonly referred to as Cloud computing. However, taking full advantage of this mobile and cloud computing landscape, especially for the data intensive domains has been hampered by the many heterogeneities that exist in the mobile space as well as the Cloud space. Our research focuses on exploiting the capabilities of the mobile and cloud landscape by defining a new class of applications called cloud mobile hybrid (CMH) applications and a Domain Specific Language (DSL) based methodology to develop these applications. We define Cloud-mobile hybrid as a collective application that has a Cloud based back-end and a mobile device front-end. Using a single DSL script, our toolkit is capable of generating a variety of CMH applications. These applications are composed of multiple combinations of native Cloud and mobile applications. Our approach not only reduces the learning curve but also shields developers from the complexities of the target platforms. We provide a detailed description of our language and present the results obtained using our prototype generator implementation. We also present a list of extensions that will enhance the various aspects of this platform. &copy; 2010 IEEE.},
key = {Cloud computing},
keywords = {Computer systems;Mobile devices;Portable equipment;Ubiquitous computing;},
note = {Computing resource;Data intensive;Domain specific languages;Hybrid applications;Learning curves;Mobile applications;Pay as you go;},
URL = {http://dx.doi.org/10.1109/CloudCom.2010.78},
} 


@article{20110813689430 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based kinematics generation for modular mechatronic toolkits},
journal = {ACM SIGPLAN Notices},
author = {Bordignon, Mirko and Schultz, Ulrik P. and Stoy, Kasper},
volume = {46},
number = {2},
year = {2011},
pages = {157 - 166},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Modular robots are mechatronic devices that enable the construction of highly versatile and flexible robotic systems whose mechanical structure can be dynamically modified. The key feature that enables this dynamic modification is the capability of the individual modules to connect to each other in multiple ways and thus generate a number of different mechanical systems, in contrast with the monolithic, fixed structure of conventional robots. The mechatronic flexibility, however, complicates the development of models and programming abstractions for modular robots, since manually describing and enumerating the full set of possible interconnections is tedious and error-prone for real-world robots. In order to allow for a general formulation of spatial abstractions for modular robots and to ensure correct and streamlined generation of code dependent on mechanical properties, we have developed the Modular Mechatronics Modelling Language (M3L). M3L is a domain-specific language, which can model the kinematic structure of individual robot modules and declaratively describe their possible interconnections, rather than requiring the user to enumerate them in their entirety. From this description, the M3L compiler generates the code that is needed to simulate the resulting robots within Webots, a widely used commercial robot simulator, and the software component needed for spatial structure computations by a virtual machine-based runtime system, which we have developed and used for programming physical modular robots. Copyright &copy; 2010 ACM.},
key = {Robot programming},
keywords = {Abstracting;Computer software;Graphical user interfaces;Kinematics;Mechanical properties;Mechatronics;Modular robots;Network components;Problem oriented languages;Program compilers;Robotics;},
note = {Code Generation;Commercial robots;Conventional robots;Domain-specific languages;Dynamic modifications;Error prones;Fixed structure;Flexible robotics;Key feature;Kinematic structures;Mechanical structures;Mechanical systems;Mechatronic devices;Model-based;Modelling language;Programming abstractions;Real-world;Runtime systems;Software component;Spatial abstractions;Spatial structure;Virtual machines;},
URL = {http://dx.doi.org/10.1145/1942788.1868318},
} 


@inproceedings{20102913090233 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Search computing: A model-driven perspective},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Brambilla, Marco and Ceri, Stefano and Tisi, Massimo},
volume = {6142 LNCS},
year = {2010},
pages = {1 - 15},
issn = {03029743},
address = {Malaga, Spain},
abstract = {Search Computing is a novel discipline that focuses on exploratory search of multi-domain Web queries like "Where can I attend an interesting conference in my field close to a sunny beach?". The approach is based on the interaction between cooperating search services, using ranking and joining of results as the dominant factors for service composition. This paper sketches the main characteristics of search computing and discusses how software engineering and model-driven engineering are challenged by the search computing problems. We present Search Computing applications from a model-driven perspective, in terms of (1) the models describing the objects of interest, (2) the specification of applications through model transformations, and (3) the definition of a domain specific language (DSL) defined for the specification of search query plans. This work provides a first exploration of MDE approaches applied to search computing and poses a set of challenges to the model transformation community. &copy; 2010 Springer-Verlag.},
key = {Models},
keywords = {Information retrieval;Search engines;Software engineering;Specifications;World Wide Web;},
note = {Computing applications;Conceptual model;conceptual models;Domain specific languages;Dominant factor;Exploratory search;Main characteristics;MDD;Model transformation;Model-driven;Model-driven Engineering;Multi domains;Search queries;Search services;Service compositions;},
URL = {http://dx.doi.org/10.1007/978-3-642-13688-7_1},
} 


@inproceedings{20100312649633 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Concurrent programming method for digital signal processing},
journal = {SISY 2009 - 7th International Symposium on Intelligent Systems and Informatics},
author = {Sabo, Anita and Schramm, Norbert},
year = {2009},
pages = {267 - 271},
address = {Subotica, Serbia},
abstract = {The task of programming concurrent systems is substantially more difficult than the task of programming sequential systems with respect to both correctness and efficiency. The tendency in development of embedded, DSP systems and processors are shifting to multi core and multiprocessor setups as well. The problem of easy concurrency and algorithm development is an important for embedded and DSP systems as well. The goal of this paper is to define and present a high level language that allows description and development of signal processing algorithms. With the usage of a domain specific language, we can create compact and easy to understand definition of algorithms. In the paper the authors present the advantages granted by DSL for DSP applications. The created definitions are hardware independent can be executed and functionally verified. Efficient code can be generated for various targets without porting. The design of the presented DSL allows code generation for multi-core targets in case of computing-intensive algorithms, code generation for multiple streams, threads. Code reuse is supported by merging, re-grouping, and splitting of algorithms and groups of algorithms. &copy; 2009 IEEE.},
key = {Embedded systems},
keywords = {Algorithms;Computation theory;Computer programming;Digital signal processors;DSL;Intelligent systems;Linguistics;Modems;Network components;Signal processing;Telecommunication lines;},
note = {Algorithm development;Code Generation;Code reuse;Concurrent programming;Concurrent systems;Domain specific languages;DSP application;DSP system;Hardware independent;Multi core;Multiple streams;Programming sequential systems;Signal processing algorithms;},
URL = {http://dx.doi.org/10.1109/SISY.2009.5291151},
} 


@inproceedings{20073210748773 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Development of a Hungarian medical dictation system},
journal = {Informatica (Ljubljana)},
author = {Banhalmi, Andras and Paczolay, Denes and Toth, Laszo and Kocsor, Andras},
volume = {31},
number = {2},
year = {2007},
pages = {241 - 246},
issn = {03505596},
address = {Jamova 39, Ljubljana, 61000, Slovenia},
abstract = {This paper reviews the current state of a Hungarian project which seeks to create a speech recognition system for the dictation of thyroid gland medical reports. First, we present the MRBA speech corpus that was assembled to support the training of general-purpose Hungarian speech recognition systems. Then we describe the processing of medical reports that were collected to help the creation of domain-specific language models. At the acoustic modelling level we experimented with two techniques - a conventional HMM one and an ANN-based solution - which are both briefly described in the paper. Finally, we present the language modelling methodology currently applied in the system, and round off with recognition results on test data taken from four speakers. The scores show that on a somewhat restricted sub-domain of the task we are able to produce word accuracies well over 95%.},
key = {Speech recognition},
keywords = {Computer programming languages;Computer simulation;Data processing;Medical computing;Neural networks;},
note = {2D-cepstrum;Acoustic modeling;Dictation systems;},
} 


@inproceedings{20072110606129 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {METAWSL and meta-transformations in the FermaT transformation system},
journal = {Proceedings - International Computer Software and Applications Conference},
author = {Ward, Martin and Zedan, Hussein},
volume = {1},
year = {2005},
pages = {233 - 238},
issn = {07303157},
address = {Edinburgh, Scotland, United kingdom},
abstract = {A program transformation is an operation which can be applied to any program (satisfying the transformations applicability conditions) and returns a semantically equivalent program. In the FermaT transformation system program transformations are carried out in a wide spectrum language, called WSL, and the transformations themselves are written in an extension of WSL called METAWSL which was specifically designed to be a domain-specific language for writing program transformations. As a result, FermdT is capable of transforming its own source code via metatransformations. This paper introduces METAWSL and describes some applications of meta-transformations in the FermaT system. &copy; 2005 IEEE.},
key = {Metadata},
keywords = {Computer programming;Semantics;Software engineering;},
note = {FermaT transformation system;Wide spectrum language (WSL);},
URL = {http://dx.doi.org/10.1109/COMPSAC.2005.107},
} 


@inproceedings{20113514267958 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A computer-aided approach to preliminary hazard analysis for automotive embedded systems},
journal = {Proceedings - 18th IEEE International Conference and Workshops on Engineering of Computer-Based Systems, ECBS 2011},
author = {Mader, Roland and Grienig, Gerhard and Leitner, Andrea and Kreiner, Christian and Bourrouilh, Quentin and Armengaud, Eric and Steger, Christian and Wei, Reinhold},
year = {2011},
pages = {169 - 178},
address = {Las Vegas, NV, United states},
abstract = {Powertrain electrification of automobiles leads to a higher number of sensors, actuators and control functions, which in turn increases the complexity of automotive embedded systems. The safety-criticality of the system requires the application of Preliminary Hazard Analysis early in the development process. This is a necessary first step for the development of an automotive embedded system that is acceptably safe. Goal of this activity is the identification and classification of hazards and the definition of top level safety requirements that are the basis for designing a safety-critical embedded system that is able to control or mitigate the identified hazards. A computer-aided framework to support Preliminary Hazard Analysis for automotive embedded systems is presented in this work. The contribution consists of (1) an enhancement for Preliminary Hazard Analysis to the domain-specific language EAST-ADL, as well as (2) the identification of properties that indicate the correct application of Preliminary Hazard Analysis using the language. These properties and an analysis model reflecting the results of the Preliminary Hazard Analysis are used for the automated detection of an erroneously applied Preliminary Hazard Analysis (property checker) and the automated suggestion and application of corrective measures (model corrector). The applicability of the approach is evaluated by the case study of hybrid electric vehicle development. &copy; 2011 IEEE.},
key = {Embedded systems},
keywords = {Computer aided analysis;Computer control systems;Electric utilities;Electric vehicles;Hazards;Identification (control systems);Model checking;Problem oriented languages;Technical presentations;},
note = {Automotive embedded systems;Functional Safety;ISO 26262;Preliminary hazard analysis;Safety goal;},
URL = {http://dx.doi.org/10.1109/ECBS.2011.43},
} 


@inproceedings{20084511677497 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A service oriented architecture for CAX concurrent collaboration},
journal = {4th IEEE Conference on Automation Science and Engineering, CASE 2008},
author = {Khaled, A. and Ma, Y. and Miller, J.},
year = {2008},
pages = {650 - 655},
address = {Washington, DC, United states},
abstract = {The competitive and open market nature demands different vendors to collaborate during the product life cycle and to reduce the product's time to market. In this paper, we propose an infrastructure to enable the concurrent collaboration of heterogeneous CAX tools at the feature level using a Service Oriented Architecture (SOA) approach. A Feature Markup Language (FML) is proposed as the modeling language for feature representation and exchange which can be independent to operating system and programming language. How to employ the concept of software factory to leverage FML as a Domain Specific Language (DSL) is discussed for the process of feature development and distribution. Moreover, the underlying architecture is described to enable CAX information sharing in real-time preserving the semantics and consistency of CAX models. &copy;2008 IEEE.},
key = {Markup languages},
keywords = {Computer programming languages;Concurrent engineering;Information services;Information theory;Life cycle;Linguistics;},
note = {CAX tools;Domain specifics;Feature developments;Feature levels;Feature representations;Heterogeneous;Information sharing;Infra-structure;Modeling languages;Open markets;Operating systems;Product life cycles;Programming languages;Service-Oriented architectures;Software factories;Time-to-market;},
URL = {http://dx.doi.org/10.1109/COASE.2008.4626451},
} 


@inproceedings{20071710565321 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {JunGL: A scripting language for refactoring},
journal = {Proceedings - International Conference on Software Engineering},
author = {Verbaere, Mathieu and Ettinger, Ran and De Moor, Oege},
volume = {2006},
year = {2006},
pages = {172 - 181},
issn = {02705257},
address = {Shanghai, China},
abstract = {Refactorings are behaviour-preserving program transformations, typically for improving the structure of existing code. A few of these transformations have been mechanised in interactive development environments. Many more refactorings have been proposed, and it would be desirable for programmers to script their own refactorings. Implementing such source-to-source transformations, however, is quite complex: even the most sophisticated development environments contain significant bugs in their refactoring tools. We present a domain-specific language for refactoring, named JunGL. It manipulates a graph representation of the program: all information about the program, including ASTs for its compilation units, variable binding, control flow and so on is represented in a uniform graph format. The language is a hybrid of a functional language (in the style of ML) and a logic query language (akin to Datalog). JunGL furthermore has a notion of demand-driven evaluation for constructing computed information in the graph, such as control flow edges. Borrowing from earlier work on the specification of compiler optimisations, JunGL uses socalled 'path queries' to express dataflow properties. We motivate the design of JunGL via a number of nontrivial refactorings, and describe its implementation on the .NET platform. Copyright 2006 ACM.},
key = {Formal languages},
keywords = {Codes (symbols);Data structures;Graph theory;Program compilers;Query languages;Software engineering;},
note = {Language workbenches;Program transformations;Scripting languages;Source code transformations;},
} 


@inproceedings{20100412655159 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {On the implementation of tools for domain specific process modelling},
journal = {ENASE 2009 - 4th International Conference on Evaluation of Novel Approaches to Software Engineering, Proceedings},
author = {Jablonski, Stefan and Volz, Bernhard and Dornstauder, Sebastian},
year = {2009},
pages = {109 - 120},
address = {Milan, Italy},
abstract = {Business process modelling becomes more productive when modellers can use process modelling languages which optimally fit to the application domain. Domain specific modelling is the discipline that deals with the proliferation of domain specific modelling languages. The general tenor is that the more a modelling language fits to an application domain, the more efficient and effective an application can be modelled. In this paper we address the issue of providing domain specific languages in a systematic and structural way without having to implement modelling tools for each domain specific language separately. Our approach is based on a two dimensional meta modelling stack.},
key = {Linguistics},
keywords = {Computer software;Query languages;},
note = {Application domains;Business process modelling;Domain specific;Domain specific languages;Domain-specific modelling;Meta-modelling;Modelling language;Modelling tools;Process modelling;},
} 


@inproceedings{20103013092005 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A MDE-based optimisation process for Real-Time systems},
journal = {ISORC 2010 - 2010 13th IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing},
author = {Gilles, Olivier and Hugues, Jerome},
volume = {1},
year = {2010},
pages = {50 - 57},
address = {Carmona, Sevilla, Spain},
abstract = {The design and implementation of Real-Time Embedded Systems is now heavily relying on Model-Driven Engineering (MDE) as a central place to define and then analyze or implement a system. MDE toolchains are taking a key role as to gather most of functional and not functional properties in a central framework, and then exploit this information. Such toolchain is based on both 1) a modeling notation, and 2) companion tools to transform or analyse models. In this paper, we present a MDE-based process for system optimisation based on an architectural description. We first define a generic evaluation pipeline, define a library of elementary transformations and then shows how to use it through Domain-Specific Language to evaluate and then transform models. We illustrate this process on an AADL case study modeling a Generic Avionics Platform. &copy; 2010 IEEE.},
key = {Real time systems},
keywords = {Computer aided software engineering;Distributed computer systems;Embedded systems;Optimization;Problem oriented languages;Wavelet transforms;},
note = {Architectural descriptions;Domain specific languages;Elementary transformation;Functional properties;Generic evaluation;Model-driven engineering;Modeling notation;Optimisations;Real-time embedded systems;Transform models;},
URL = {http://dx.doi.org/10.1109/ISORC.2010.38},
} 


@inproceedings{20095312600277 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A DSL framework for policy-based security of distributed systems},
journal = {SSIRI 2009 - 3rd IEEE International Conference on Secure Software Integration Reliability Improvement},
author = {Hamdi, Hedi and Mosbah, Mohamed},
year = {2009},
pages = {150 - 158},
address = {Shanghai, China},
abstract = {Securing distributed systems remains a significant challenge for several reasons. First, the security features required in an application may depend on the environment in which the application is operating, the type of data exchanged, and the capability of the end-points of communication. Second, the security mechanisms deployed could apply to both communication and application layers in the system, making it difficult to understand and manage overall system security. This paper presents a policy-based approach to meeting these needs. We propose a framework based on a Domain-Specific Language for the specification, verification and implementation of security policies for distributed systems. Based on a set of abstractions, this framework allows to develop modular security policies and independent of the underlying system. Thus, security policies can be developed by a developer who is not necessarily computer security expert. &copy; 2009 IEEE.},
key = {Network security},
keywords = {Computer aided software engineering;DSL;Modems;Problem oriented languages;Security systems;Software reliability;Specifications;Telecommunication lines;},
note = {Application layers;Computer security;Distributed systems;Domain specific languages;End-points;Implementation;Policy-based approaches;Security features;Security mechanism;Security policy;System security;Underlying systems;},
URL = {http://dx.doi.org/10.1109/SSIRI.2009.43},
} 


@inproceedings{20105013487712 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the Joint ERCIM Workshop on Software Evolution, EVOL 2010 and International Workshop on Principles of Software Evolution, IWPSE 2010, Held in Conjunction with the 25th IEEE/ACM International Conference on Automated Software Engineering, ASE'10},
journal = {ACM International Conference Proceeding Series},
year = {2010},
pages = {Eur. Res. Consort. Informatics Math. (ERCIM); Belgian Policy of the Belgian State; F.R.S.-FNRS/FRFC Research Center on Software Adaptability - },
address = {Antwerp, Belgium},
abstract = {The proceedings contain 13 papers. The topics discussed include: do metrics help to identify refactoring?; recording finer-grained software evolution with IDE: an annotation-based approach; replaying past changes in multi-developer projects; identifying cross-cutting concerns using software repository mining; redocumentation of a legacy banking system; a framework for analysing and visualising open source software ecosystems; an exercise in iterative domain-specific language design; an automated hint generation approach for supporting the evolution of requirements specifications; an empirical study of the evolution of eclipse third-party plug-ins; is duplicate code more frequently modified than non-duplicate code in software evolution?: an empirical study on open source software; evolutional analysis of licenses in FOSS; multi-tenant SaaS applications: maintenance dream or nightmare?; and feature oriented evolutions for context-aware adaptive systems.},
} 


@inproceedings{20085211801901 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Incorporating semantic algebra in the MDA framework},
journal = {ICSOFT 2008 - Proceedings of the 3rd International Conference on Software and Data Technologies},
author = {Barbosa, Paulo E.S. and Ramalho, Franklin and De Figueiredo, Jorge C.A. and Junior, Antonio D. Dos S.},
volume = {SE},
number = {GSDCA/M/-},
year = {2008},
pages = {330 - 336},
address = {Porto, Portugal},
abstract = {Denotational semantics is commonly used to precisely define the meaning of a programming language. This meaning is given by functions that map syntactic elements to mathematically well defined sets called semantic algebra. Models in semantic algebra need to be processed through reductions towards a normal-form in order to allow the verification of semantics properties. MDA is a current trend that shifts the focus and effort from implementation to models, metamodels and transformations during the development process. In order to put forward denotational semantics in the MDA vision, we turn semantic algebra into an useful domain-specific language. In this context, this paper describes our proposed MOF metamodel and ATL reductions between the generated models. The metamodel serves as abstract syntax for semantic algebra. It is useful for static semantics verifications. The reductions enable processing towards a normal-form to compare semantics. This process can be guided by using some rewrite system.},
key = {Formal methods},
keywords = {Algebra;Computer aided software engineering;Fourier transforms;Information theory;Linguistics;Programming theory;Semantics;Syntactics;},
note = {Abstract syntaxes;Current trends;Denotational semantics;Development process;Domain-Specific Languages;Formal methods and MDA;Metamodels;Programming languages;Rewrite systems;Static semantics;},
} 


@inproceedings{20085111784545 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A language for advanced protocol analysis in automotive networks},
journal = {Proceedings - International Conference on Software Engineering},
author = {Reichert, Tim and Klaus, Edmund and Schoch, Wolfgang and Meroth, Ansgar and Herzberg, Dominikus},
year = {2008},
pages = {593 - 602},
issn = {02705257},
address = {Leipzig, Germany},
abstract = {The increased use and interconnection of electronic components in automobiles has made communication behavior in automotive networks drastically more complex. Both communication designs at application level and complex communication scenarios are often under-specified or out of scope of existing analysis techniques. We extend traditional protocol analyzers in order to capture communication at the level of abstraction that reflects application design and show that the same technique can be used to specify, monitor and test complex scenarios. We present CFR (Channel Filter Rule) models, a novel approach for the specification of analyzers and a domain-specific language that implements this approach. From CFR models, we can fully generate powerful analyzers that extract design intentions, abstract protocol layers and even complex scenarios from low level communication data. We show that three basic concepts (channels, filters and rules) are sufficient to build such powerful analyzers and identify possible areas of application. Copyright 2008 ACM.},
key = {Communication},
keywords = {Abstracting;Applications;Automobile parts and equipment;Linguistics;Software engineering;Specifications;Systems engineering;},
note = {Abstract protocols;Advanced protocols;Analysis techniques;Application designs;Application levels;Automotive networks;Automotive systems engineering;Basic concepts;Communication behaviors;Communication datum;Communication designs;Design intentions;Domain-Specific Languages;Electronic components;Level of abstractions;Low levels;Protocol analysis;Protocol analyzers;Protocol specifications;},
URL = {http://dx.doi.org/10.1145/1368088.1368171},
} 


@inproceedings{20112114004827 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Bridging the gap between legacy services and web services},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Bissyande, Tegawende F. and Reveillere, Laurent and Bromberg, Yerom-David and Lawall, Julia L. and Muller, Gilles},
volume = {6452 LNCS},
year = {2010},
pages = {273 - 292},
issn = {03029743},
address = {Bangalore, India},
abstract = {Web Services is an increasingly used instantiation of Service-Oriented Architectures (SOA) that relies on standard Internet protocols to produce services that are highly interoperable. Other types of services, relying on legacy application layer protocols, however, cannot be composed directly. A promising solution is to implement wrappers to translate between the application layer protocols and the WS protocol. Doing so manually, however, requires a high level of expertise, in the relevant application layer protocols, in low-level network and system programming, and in the Web Service paradigm itself. In this paper, we introduce a generative language based approach for constructing wrappers to facilitate the migration of legacy service functionalities to Web Services. To this end, we have designed the Janus domain-specific language, which provides developers with a high-level way to describe the operations that are required to encapsulate legacy service functionalities. We have successfully used Janus to develop a number of wrappers, including wrappers for IMAP and SMTP servers, for a RTSP-compliant media server and for UPnP service discovery. Preliminary experiments show that Janus-based WS wrappers have performance comparable to manually written wrappers. &copy; IFIP International Federation for Information Processing 2010.},
key = {Web services},
keywords = {Computer systems programming;Information services;Internet protocols;Interoperability;Middleware;Network architecture;Problem oriented languages;Servers;Service oriented architecture (SOA);User interfaces;},
note = {Application layer protocols;Domain specific languages;Legacy applications;Legacy services;Media servers;Service discovery;Service Oriented;Service paradigm;WS protocols;},
URL = {http://dx.doi.org/10.1007/978-3-642-16955-7_14},
} 


@inproceedings{20101812898232 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Integration of data validation and user interface concerns in a DSL for web applications},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Groenewegen, Danny M. and Visser, Eelco},
volume = {5969 LNCS},
year = {2010},
pages = {164 - 173},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {Data validation rules constitute the constraints that data input and processing must adhere to in addition to the structural constraints imposed by a data model. Web modeling tools do not address data validation concerns explicitly, hampering full code generation and model expressivity. Web application frameworks do not offer a consistent interface for data validation. In this paper, we present a solution for the integration of declarative data validation rules with user interface models in the domain of web applications, unifying syntax, mechanisms for error handling, and semantics of validation checks, and covering value well-formedness, data invariants, input assertions, and action assertions. We have implemented the approach in WebDSL, a domain-specific language for the definition of web applications. &copy; 2010 Springer-Verlag.},
key = {Data processing},
keywords = {Computer software;Linguistics;Problem oriented languages;Semantic Web;User interfaces;World Wide Web;XML;},
note = {Code Generation;Data input;Data models;Data validation;Domain specific languages;Error handling;Structural constraints;Validation checks;WEB application;Web modeling;},
URL = {http://dx.doi.org/10.1007/978-3-642-12107-4_13},
} 


@article{20072610677474 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {WebML modelling in UML},
journal = {IET Software},
author = {Moreno, N. and Fraternali, P. and Vallecillo, A.},
volume = {1},
number = {3},
year = {2007},
pages = {67 - 80},
issn = {17518806},
address = {Six Hills Way, Stevenage, SG1 2AY, United Kingdom},
abstract = {In recent years, we have witnessed how the Web Engineering community has started using the standard unified modelling language (UML) notation, techniques and supporting tools for modelling Web systems, which has led to the adaptation to UML of several existing modelling languages, notations and development processes. This interest for being MOF and UML-compliant arises from the increasing need to interoperate with other notations and tools, and to exchange data and models, thus facilitating reuse. WebML, like any other domain-specific language, allows one to express in a precise and natural way the concepts and mechanisms of its domain of reference. However, it cannot fully interoperate with other notations, nor be integrated with other model-based tools. As a solution to these requirements, a UML 2.0 profile for WebML which allows WebML models to be used in conjunction with other notations and modelling tools has been described. The paper also evaluates UML 2.0 as a platform for Web modelling and identifies some key requirements for making this version of the standard more usable. &copy; The Institution of Engineering and Technology 2007.},
key = {Web services},
keywords = {Computer aided software engineering;Computer simulation languages;Electronic data interchange;Mathematical models;Unified Modeling Language;},
note = {Web Engineering;Web modelling;WebML models;},
URL = {http://dx.doi.org/10.1049/iet-sen:20060067},
} 


@inproceedings{20103413181674 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using state machines for a model driven development of web service-based sensor network applications},
journal = {Proceedings - International Conference on Software Engineering},
author = {Glombitza, Nils and Pfisterer, Dennis and Fischer, Stefan},
year = {2010},
pages = {2 - 7},
issn = {02705257},
address = {Cape Town, South africa},
abstract = {In the Internet of Things, all kinds of devices will extend the Internet to the physical world. In that vision, even extremely resource constrained sensor nodes can be triggered by as well as trigger business processes and are not limited to sense-and-send anymore. Despite the large potential, due to the time consuming, inflexible, and error prone development of sensor network applications, sensor networks are rarely integrated into today's enterprise IT. In this paper, we present an approach using state machines for a Model Driven Development of Web Service-based sensor network applications. We show how Web Services can be realized on sensor nodes and present a domain-specific language called State Machine for Resource Constrained Devices (SM4RCD) to orchestrate these services. &copy; 2010 ACM.},
key = {Network architecture},
keywords = {Contour followers;Information services;Internet;Problem oriented languages;Sensor networks;Sensor nodes;Service oriented architecture (SOA);Software design;Technical presentations;Telecommunication equipment;Web services;},
note = {Business Process;Domain specific languages;Enterprise IT;Error prones;Internet of things;Model driven development;model driven software development;Physical world;Resource-constrained;Resourceconstrained devices;Sensor network applications;Service-based;State machine;},
URL = {http://dx.doi.org/10.1145/1809111.1809115},
} 


@inproceedings{2005359335233 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {UML Modeling Languages and Applications - UML 2004 Satellite Activities},
journal = {Lecture Notes in Computer Science},
editor = {Nunes, N.J.;Selic, B.;Silva, A.R.;Alvarez, A.T.;},
volume = {3297},
year = {2005},
pages = {SINFIC; Springer Verlag; Mentor Graphics; IBM France - },
issn = {03029743},
address = {Lisbon, Portugal},
abstract = {The proceedings contain 34 papers from the conference on UML Modeling Languages and Applications - UML 2004 Satellite Activities. The topics discussed include: consistency problems in UML-based software development; software architecture description and UML; open issues in industrial use case modeling; OCL and model driven engineering; supporting the building and analysis of an infrastructure portfolio using UML deployment diagrams; system-on-chip verification process using UML; experiences in modeling for a domain specific language; six lessons learned using MDA; applying MDA and UML in the development of a healthcare system; and towards a platform for debugging executed UML-models in embedded systems.},
key = {Satellites},
keywords = {Computer architecture;Computer programming languages;Computer simulation;Health care;Identification (control systems);Program debugging;Software engineering;},
note = {Deployment diagrams;Software architecture;System-on-chip;UML modeling languages;},
} 


@inproceedings{20105113497607 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion, SPLASH '10},
journal = {Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion, SPLASH '10},
year = {2010},
pages = {ACM SIGPLAN; SIGSOFT - },
address = {Reno/Tahoe, NV, United states},
abstract = {The proceedings contain 77 papers. The topics discussed include: emergent feature modularization; harnessing emergence for manycore programming: early experience integrating ensembles, adverbs, and object-based inheritance; collaborative model merging; sonifying performance data to facilitate tuning of complex systems: performance tuning: music to my ears; a recommender for conflict resolution support in optimistic model versioning; inferring arbitrary distributions for data and computation; object-oriented software considerations in airborne systems and equipment certification; migrating a large modeling environment from XML/UML to Xtext/GMF; software evolution in agile development: a case study; application frameworks: how they become your enemy; MDSD for the iPhone: developing a domain-specific language and IDE tooling to produce real world applications for mobile devices; and stop the software architecture erosion: building better software systems.},
} 


@article{20100812722041 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {DECOR: A method for the specification and detection of code and design smells},
journal = {IEEE Transactions on Software Engineering},
author = {Moha, Naouel and Gueheneuc, Yann-Gael and Duchien, Laurence and Le Meur, Anne-Francoise},
volume = {36},
number = {1},
year = {2010},
pages = {20 - 36},
issn = {00985589},
address = {445 Hoes Lane / P.O. Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {Code and design smells are poor solutions to recurring implementation and design problems. They may hinder the evolution of a system by making it hard for software engineers to carry out changes. We propose three contributions to the research field related to code and design smells: 1) Decor, a method that embodies and defines all the steps necessary for the specification and detection of code and design smells, 2) Detex, a detection technique that instantiates this method, and 3) an empirical validation in terms of precision and recall of Detex. The originality of Detex stems from the ability for software engineers to specify smells at a high level of abstraction using a consistent vocabulary and domain-specific language for automatically generating detection algorithms. Using Detex, we specify four well-known design smells: the antipatterns Blob, Functional Decomposition, Spaghetti Code, and Swiss Army Knife, and their 15 underlying code smells, and we automatically generate their detection algorithms. We apply and validate the detection algorithms in terms of precision and recall on Xerces v2.7.0, and discuss the precision of these algorithms on 11 open-source systems. &copy; 2010 IEEE.},
key = {Odors},
keywords = {Algorithms;Computer software;Design;Problem oriented languages;Signal detection;Specifications;},
note = {Anti-patterns;Code smell;Code smells;Detection;Metamodeling;},
URL = {http://dx.doi.org/10.1109/TSE.2009.50},
} 


@article{20091011939183 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {FPath and FScript: Language support for navigation and reliable reconfiguration of Fractal architectures},
journal = {Annales des Telecommunications/Annals of Telecommunications},
author = {David, Pierre-Charles and Ledoux, Thomas and Leger, Marc and Coupaye, Thierry},
volume = {64},
number = {1-2},
year = {2009},
pages = {45 - 63},
issn = {00034347},
address = {1 rue Paul Cezanne, Paris, 75008, France},
abstract = {Component-based systems must support dynamic reconfigurations to adapt to their execution context, but not at the cost of reliability. Fractal provides intrinsic support for dynamic reconfiguration, but its definition in terms of low-level APIs makes it complex to write reconfigurations and to ensure their reliability. This article presents a language-based approach to solve these issues: direct and focused language support for architecture navigation and reconfiguration make it easier both to write the reconfigurations and to ensure their reliability. Concretely, this article presents two languages: (1) FPath, a domain-specific language that provides a concise yet powerful notation to navigate inside and query Fractal architectures, and (2) FScript, a scripting language that embeds FPath and supports the definition of complex reconfigurations. FScript ensures the reliability of these reconfigurations thanks to sophisticated run-time control, which provides transactional semantics (ACID properties) to the reconfigurations. &copy; 2008 Institut TELECOM and Springer-Verlag.},
key = {Query languages},
keywords = {Dynamic models;Fractals;Information theory;Linguistics;Navigation;Reliability;},
note = {ACID properties;Component-based systems;Domain-specific languages;Dynamic reconfigurations;Execution contexts;FPath;Fractal architectures;FScript;Language support;Run-time;Scripting languages;},
URL = {http://dx.doi.org/10.1007/s12243-008-0073-y},
} 


@inproceedings{20093512277608 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A MuDDy experience-ML bindings to a BDD library},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Larsen, Ken Friis},
volume = {5658 LNCS},
year = {2009},
pages = {45 - 57},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {Binary Decision Diagrams (BDDs) are a data structure used to efficiently represent boolean expressions on canonical form. BDDs are often the core data structure in model checkers. MuDDy is an ML interface (both for Standard ML and Objective Caml) to the BDD package BuDDy that is written in C. This combination of an ML interface to a high-performance C library is surprisingly fruitful. ML allows you to quickly experiment with high-level symbolic algorithms before handing over the grunt work to the C library. I show how, with a relatively little effort, you can make a domain specific language for concurrent finite state-machines embedded in Standard ML and then write various custom model-checking algorithms for this domain specific embedded language (DSEL). &copy; IFIP International Federation for Information Processing 2009.},
key = {Model checking},
keywords = {Binary decision diagrams;DSL;Linguistics;Modems;Object oriented programming;Query languages;Telecommunication lines;},
note = {Boolean expressions;Canonical form;Custom models;Domain specific;Domain specific languages;Embedded Languages;Finite state;Model checker;Standard ML;Symbolic algorithms;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_3},
} 


@inproceedings{20090111836578 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {QoS policies for business processes in Service Oriented Architectures},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Baligand, Fabien and Rivierre, Nicolas and Ledoux, Thomas},
volume = {5364 LNCS},
year = {2008},
pages = {483 - 497},
issn = {03029743},
address = {Sydney, Australia},
abstract = {The advent of Service Oriented Architectures tends to promote a new kind of software architecture where services, exposing features accessible through highly standardized protocols, are composed in a loose coupling way. In such a context, where services are likely to be replaced or used by a large number of clients, the notion of Quality of Service (QoS), which focuses on the quality of the relationship between a service and its customers, becomes a key challenge. This paper aims to ease QoS management in service compositions through a better separation of concerns. For this purpose, we designed QoSL4BP, a domain-specific language which allows QoS policies specification for business processes. More specifically, the QoSL4BP language is designed to allow an architect to specify QoS constraints and mechanisms over parts of BPEL compositions. This language is executed by our ORQOS platform which cooperates in a non-intrusive way with orchestration engines. At pre-deployment time, ORQOS platform performs service planning depending on services QoS offers and on the QoS requirements in QoSL4BP policies. At runtime, QoSL4BP policies allow to react to QoS variations and to enact QoS management related mechanisms. &copy; 2008 Springer Berlin Heidelberg.},
key = {Quality of service},
keywords = {Architectural design;Decentralized control;Distributed computer systems;Information services;Linguistics;Network architecture;Software architecture;},
note = {Business processes;Deployment times;Do-mains;In services;Loose couplings;Qos constraints;QoS managements;QoS policies;Separation of concerns;Service oriented;Specific languages;},
URL = {http://dx.doi.org/10.1007/978-3-540-89652-4-36},
} 


@inproceedings{20102513027687 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Incremental dynamic update for Java-based smart cards},
journal = {5th International Conference on Systems, ICONS 2010},
author = {Noubissi, Agnes C. and Iguchi-Cartigny, Julien and Lanet, Jean-Louis},
year = {2010},
pages = {110 - 113},
address = {Menuires, France},
abstract = {One of the most appealing feature for multiapplication smart cards is their ability to dynamically download or delete applications once the card has been issued. Applications can be updated by deleting old versions and loading the new ones. Nevertheless, for system components, the update is sligthly more complex because the systems never stop. Indeed, for smart cards based on Java called JavaCard, the virtual machine has a life cycle similar to the card because persistent objects are preserved after the communication sessions with the reader have expired. We present in this paper, our research in dynamic system components updating of JavaCard. Our technique requires a lot of off-card and on-card mechanisms. Our approach uses control flow graph to determine change between versions, a domain specific language to represent the change for minimization of the download overhead throughout the communication link with the card. &copy; 2010 IEEE.},
key = {Smart cards},
keywords = {Dynamical systems;},
note = {Communication links;Communication sessions;Control flow graphs;Domain specific languages;Dynamic system components;Dynamic update;E-passport;Hotswup;JAVA card;Multiapplication smart cards;System components;Virtual machines;},
URL = {http://dx.doi.org/10.1109/ICONS.2010.27},
} 


@inproceedings{20064410207028 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A plugin-based language to experiment with model transformation},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Cuadrado, Jesus Sanchez and Molina, Jesus Garcia},
volume = {4199 LNCS},
year = {2006},
pages = {336 - 350},
issn = {03029743},
address = {Genova, Italy},
abstract = {Model transformation is a key technology of model driven software development approaches. Several transformation languages have appeared in the last few years, but more research is still needed for an in-depth understanding of the nature of model transformations and to discover desirable features of transformation languages. Research interest is primarily focused on experimentation with languages by writing transformations for real problems. RubyTL is a hybrid transformation language defined as a Ruby internal domain specific language, and is designed as an extensible language: a plugin mechanism allows new features to be added to core features. In this paper, we describe this plugin mechanism, devised to facilitate the experimentation with possible features of RubyTL. Through an example, we show how to add a new language feature, specifically we will develop a plugin to organize a transformation in several phases. Finally, we discuss the advantages of this extensible language design. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Computer programming languages},
keywords = {Computational methods;Mathematical models;Software engineering;XML;},
note = {Domain specific languages;Model transformation;Transformation languages;},
} 


@article{20080211012521 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A de-identifier for medical discharge summaries},
journal = {Artificial Intelligence in Medicine},
author = {Uzuner, Ozlem and Sibanda, Tawanda C. and Luo, Yuan and Szolovits, Peter},
volume = {42},
number = {1},
year = {2008},
pages = {13 - 35},
issn = {09333657},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Objective: Clinical records contain significant medical information that can be useful to researchers in various disciplines. However, these records also contain personal health information (PHI) whose presence limits the use of the records outside of hospitals. The goal of de-identification is to remove all PHI from clinical records. This is a challenging task because many records contain foreign and misspelled PHI; they also contain PHI that are ambiguous with non-PHI. These complications are compounded by the linguistic characteristics of clinical records. For example, medical discharge summaries, which are studied in this paper, are characterized by fragmented, incomplete utterances and domain-specific language; they cannot be fully processed by tools designed for lay language. Methods and results: In this paper, we show that we can de-identify medical discharge summaries using a de-identifier, Stat De-id, based on support vector machines and local context (F-measure = 97% on PHI). Our representation of local context aids de-identification even when PHI include out-of-vocabulary words and even when PHI are ambiguous with non-PHI within the same corpus. Comparison of Stat De-id with a rule-based approach shows that local context contributes more to de-identification than dictionaries combined with hand-tailored heuristics (F-measure = 85%). Comparison with two well-known named entity recognition (NER) systems, SNoW (F-measure = 94%) and IdentiFinder (F-measure = 36%), on five representative corpora show that when the language of documents is fragmented, a system with a relatively thorough representation of local context can be a more effective de-identifier than systems that combine (relatively simpler) local context with global context. Comparison with a Conditional Random Field De-identifier (CRFD), which utilizes global context in addition to the local context of Stat De-id, confirms this finding (F-measure = 88%) and establishes that strengthening the representation of local context may be more beneficial for de-identification than complementing local with global context. &copy; 2007 Elsevier B.V. All rights reserved.},
key = {Hospital data processing},
keywords = {Computational linguistics;Glossaries;Health care;Information analysis;Random processes;Support vector machines;},
note = {Automatic de-identification of narrative patient records;Local lexical context;Local syntactic context;Sentential global context;Syntactic information for de-identification;},
URL = {http://dx.doi.org/10.1016/j.artmed.2007.10.001},
} 


@inproceedings{20083511496982 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {International Conference on Field Programmable Technology},
journal = {ICFPT 2007 - International Conference on Field Programmable Technology},
editor = {},
year = {2007},
pages = {IEICE-ISS; Technical Committee on RECONF; City of Kitakyushu - },
address = {Kitakyushu, Japan},
abstract = {The proceedings contain 67 papers. The topics discussed include: FPGA cluster computing in the ETA radio telescope; FPGA-based accelerator design for RankBoost in Web search engines; asymmetric multi-processor architecture for reconfigurable system-on-chip and operating system abstractions; design and implementation of an FPGA architecture for high-speed network feature extraction; architect hard crossbars on FPGAs and increasing their area-efficiency with shadow clusters; reconfigurable functional units for scientific superscalar processors; instrumented multi-stage word-length Optimization; A Domain specific language for reconfigurable path-based Monte Carlo simulations; fused-arithmetic unit generation for reconfigurable devices using common subgraph extraction; and unifying FPGA hardware development.},
} 


@inproceedings{20085011772894 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative and Transformational Techniques in Software Engineering II - International Summer School, GTTSE 2007, Revised Papers},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
editor = {},
volume = {5235 LNCS},
year = {2008},
pages = {Centro de Ciencias e Tecnologias de Computacao; Luso-American Foundation; Software Improvement Group - },
issn = {03029743},
address = {Braga, Portugal},
abstract = {The proceedings contain 16 papers. The topics discussed include: a landscape of bidirectional model transformations; evolving a DSL implementation; adding dimension analysis to Java as a composable language extension; model transformations for the compilation of multi-processor systems-on-chip; implementation of a fine state machine with active libraries in C++; automated merging of feature models using graph transformations; software reuse beyond components with XVCL; QL: object-oriented queries made easy; transforming data by calculation; how to write fast numerical code: a small introduction; webDSL: a case study in domain-specific language engineering; model-driven engineering of rules for web services; and an introduction to context-oriented programming with contextS.},
} 


@article{IP51064166 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Integration of data validation and user interface concerns in a DSL for web applications},
journal = {Software and Systems Modeling},
author = {Groenewegen, Danny M. and Visser, Eelco},
year = {2010},
pages = {1 - 18},
issn = {16191366},
abstract = {Data validation rules constitute the constraints that data input and processing must adhere to in addition to the structural constraints imposed by a data model. Web modeling tools do not make all types of data validation explicit in their models, hampering full code generation and model expressivity. Web application frameworks do not offer a consistent interface for data validation. In this paper, we present a solution for the integration of declarative data validation rules with user interface models in the domain of web applications, unifying syntax, mechanisms for error handling, and semantics of validation checks, and covering value well-formedness, data invariants, input assertions, and action assertions. We have implemented the approach in WebDSL, a domain-specific language for the definition of web applications. &copy; 2010 The Author(s).},
key = {Data processing},
keywords = {Problem oriented languages;Semantic Web;User interfaces;World Wide Web;XML;},
note = {Code Generation;Data input;Data models;Data validation;Domain specific languages;Error handling;Structural constraints;User interface models;Validation checks;WEB application;Web modeling;},
URL = {http://dx.doi.org/10.1007/s10270-010-0173-9},
} 


@article{2005379362594 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {On the role of metadata in visual language reuse and reverse engineering - An industrial case},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Karaila, Mika and Systa, Tarja},
volume = {137},
number = {3},
year = {2005},
pages = {29 - 41},
issn = {15710661},
abstract = {Collecting metadata on a family of programs is useful not only for generating statistical data on the programs but also for future re-engineering and reuse purposes. In this paper we discuss an industrial case where a project library is used to store visual programs and a database to store the metadata on these programs. The visual language in question is a domain-specific language, Function Block Language (FBL) that is used in Metso Automation for writing automation control programs. For reuse, program analysis and re-engineering activities and various data and program analysis methods are applied to study the FBL programs. Metadata stored in a database is used to provide advanced program analysis support; from the large amount of programs, the metadata allows focusing the analysis to certain kinds of programs. In this paper, we discuss the role and usage of the metadata in program analysis techniques applied to FBL programs. &copy; 2005 Elsevier B.V. All rights reserved.},
key = {Metadata},
keywords = {Automation;Computer programming languages;Data acquisition;Reverse engineering;Statistical methods;},
note = {Domain-specific languages;Metadata-driven program analysis;Reuse;Visual languages;},
URL = {http://dx.doi.org/10.1016/j.entcs.2005.07.003},
} 


@inproceedings{20094812515323 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Attribute grammars fly first-class how to do aspect oriented programming in Haskell},
journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
author = {Viera, Marcos and Swierstra, S. Doaitse and Swierstra, Wouter},
year = {2009},
pages = {245 - 256},
address = {Edinburgh, United kingdom},
abstract = {Attribute Grammars (AGs), a general-purpose formalism for describing recursive computations over data types, avoid the trade-off which arises when building software incrementally: should it be easy to add new data types and data type alternatives or to add new operations on existing data types? However, AGs are usually implemented as a pre-processor, leaving e.g. type checking to later processing phases and making interactive development, proper error reporting and debugging difficult. Embedding AG into Haskell as a combinator library solves these problems. Previous attempts at embedding AGs as a domain-specific language were based on extensible records and thus exploiting Haskell's type system to check the well-formedness of the AG, but fell short in compactness and the possibility to abstract over oft occurring AG patterns. Other attempts used a very generic mapping for which the AG well-formedness could not be statically checked. We present a typed embedding of AG in Haskell satisfying all these requirements. The key lies in using HList-like typed heterogeneous collections (extensible polymorphic records) and expressing AG well-formedness conditions as type-level predicates (i.e., typeclass constraints). By further type-level programming we can also express common programming patterns, corresponding to the typical use cases of monads such as Reader, Writer and State. The paper presents a realistic example of type-class-based type-level programming in Haskell. Copyright &copy; 2009 ACM.},
key = {Computer software selection and evaluation},
keywords = {Computer systems programming;Context sensitive grammars;Functional programming;Java programming language;Problem oriented languages;Query languages;},
note = {Aspect-Oriented Programming;Attribute grammars;Building softwares;Class-based;Combinator library;Data type;Domain specific languages;Extensible records;Generic mapping;Haskell;Heterogeneous collections;Interactive development;Lazy evaluation;Preprocessors;Programming patterns;Recursive computation;Type systems;Typechecking;},
URL = {http://dx.doi.org/10.1145/1596550.1596586},
} 


@inproceedings{20074410892707 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards model-driven development of staged participatory multimedia events},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Van Den Bergh, Jan and Huypens, Steven and Coninx, Karin},
volume = {4323 LNCS},
year = {2007},
pages = {81 - 94},
issn = {03029743},
address = {Dublin, Ireland},
abstract = {The industry nowadays is showing an increasing interest towards an extended interactive television experience, called participation television. This increasing interactivity brings the creation of such television events closer to the creation of regular software as we know it for personal computers and mobile devices. In this paper we report on our work in model-driven development of one kind of such interactive television shows, staged participatory multimedia events. More specifically, this work reports on the domain-specific language we created to model these events and the generation of abstract prototypes. These interactive prototypes are built using web-languages and can be used to perform early evaluation. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Multimedia systems},
keywords = {Abstracting;Computer simulation;Computer software;Mobile devices;Personal computers;Software prototyping;Video on demand;},
note = {Abstract prototypes;Interactive prototypes;Web-languages;},
} 


@inproceedings{20094512424373 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Attribute grammars fly first-class: How to do aspect oriented programming in haskell},
journal = {ACM SIGPLAN Notices},
author = {Viera, Marcos and Swierstra, S. Doaitse and Swierstra, Wouter},
volume = {44},
number = {9},
year = {2009},
pages = {245 - 256},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Attribute Grammars (AGs), a general-purpose formalism for describing recursive computations over data types, avoid the trade-off which arises when building software incrementally: should it be easy to add new data types and data type alternatives or to add new operations on existing data types? However, AGs are usually implemented as a pre-processor, leaving e.g. type checking to later processing phases and making interactive development, proper error reporting and debugging difficult. Embedding AG into Haskell as a combinator library solves these problems. Previous attempts at embedding AGs as a domain-specific language were based on extensible records and thus exploiting Haskell's type system to check the well-formedness of the AG, but fell short in compactness and the possibility to abstract over oft occurring AG patterns. Other attempts used a very generic mapping for which the AG well-formedness could not be statically checked. We present a typed embedding of AG in Haskell satisfying all these requirements. The key lies in using HList-like typed heterogeneous collections (extensible polymorphic records) and expressing AG well-formedness conditions as type-level predicates (i.e., typeclass constraints). By further type-level programming we can also express common programming patterns, corresponding to the typical use cases of monads such as Reader, Writer and State. The paper presents a realistic example of type-class-based type-level programming in Haskell. &copy;2009 ACM.},
key = {Computer software selection and evaluation},
keywords = {Computer systems programming;Context sensitive grammars;Java programming language;Query languages;},
note = {Attribute grammars;Class system;Haskell;Hlist;Lazy evaluation;Type-level programming;},
} 


@inproceedings{2002527291596 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using the architecture description language metah for designing and prototyping an embedded reconfigurable sliding mode flight controller},
journal = {AIAA/IEEE Digital Avionics Systems Conference - Proceedings},
author = {McDuffie, James H.},
volume = {2},
year = {2002},
pages = {8B11 - 8B17},
address = {Irvine, CA, United states},
abstract = {Performance evaluation and rapid prototyping of novel, advanced, and potentially complex modern control methodologies in an embedded environment remain a challenge in today's engineering environment. This work utilizes an integrated tool set consisting of the Domain Specific Language Simulink, The BEACON code generator, and the Architecture Description Language MetaH to prototype a new method for reconfiguring control systems. The model system selected is a simplified model of a derivative F-16 aircraft flying at 10,000 ft. at math 0.7. Sliding mode controller design consists of two steps. First, a suitable hypersurface is selected such that linear tracking error behavior with desired eigenvalues placement is achieved on the surface. Then the control is found in order to guarantee the hypersurface is reached in finite time and is maintained thereafter. This guarantees the desired decoupled tracking response in sliding mode and insensitivity to external disturbances and parametric uncertainties. Smoothing of the control input is achieved via the saturation function and reconfiguration of the controller is accomplished by dynamically varying the boundary layer thickness. For normal flight control the boundary layer is static, while for post damage flight control the boundary layer is allowed to dynamically vary according to a predetermined protocol. A model of the controller and aircraft are created using Simulink. The BEACON code generator is then used to generate code packages describing the aircraft and controller systems. MetaH is used to create a software architecture for integration of the controller and aircraft subsystems, to simplify software module integration, to create an executable for the embedded target, and to switch flight controller modes to enable the reconfigured controller. Additionally, MetaH provides a simple mechanism to modify process execution rates, supports hybrid time systems, and provides scheduling analysis of process execution times.},
key = {Flight dynamics},
keywords = {Computer architecture;Computer programming languages;Embedded systems;Sliding mode control;Software prototyping;},
note = {Architechture description languages (ADL);},
URL = {http://dx.doi.org/10.1109/DASC.2002.1052937},
} 


@inproceedings{20103113108249 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A generic traceability framework for facet-based traceability data extraction in Model-Driven Software development},
journal = {ACM International Conference Proceeding Series},
author = {Grammel, Birgit and Kastenholz, Stefan},
year = {2010},
pages = {7 - 14},
address = {Paris, France},
abstract = {Traceability of artefacts induces the means of understanding the complexity of logical relations existing among artefacts, that are created during software development. In turn, this provides the necessary knowledge for reasoning about the quality of software. With the inception of Model-Driven Software Engineering, the advantage of generating traceability information automatically, eases the problem of creating and maintaining trace links, which is a labor intensive task, when done manually. Yet, there is still a wide range of open challenges in existing traceability solutions and a need to consolidate traceability domain knowledge. This paper proposes a generic traceability framework for augmenting arbitrary model transformation approaches with a traceability mechanism. Essentially, this augmentation is based on a domain-specific language for traceability, accounting for facet-based data extraction. Copyright &copy; 2010 ACM.},
key = {Software design},
keywords = {Computer software;Data mining;Problem oriented languages;},
note = {Arbitrary models;Data extraction;Domain knowledge;Domain specific languages;Labor intensive;Logical relations;Model-driven;Model-Driven Software Development;Quality of softwares;Software development;Traceability information;},
URL = {http://dx.doi.org/10.1145/1814392.1814394},
} 


@inproceedings{20073610797956 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A static aspect language for checking design rules},
journal = {ACM International Conference Proceeding Series},
author = {Morgan, Clint and De Volder, Kris and Wohlstadter, Eric},
volume = {208},
year = {2007},
pages = {63 - 72},
address = {Vancouver, BC, Canada},
abstract = {Design rules express constraints on the behavior and structure of a program. These rules can help ensure that a program follows a set of established practices, and avoids certain classes of errors.Design rules often crosscut program structure and enforcing them is emerging as an important application domain for Aspect Oriented Programming. For many interesting design rules, current general purpose AOP languages lack the expressiveness to characterize them statically and enforce them at compile time.We have developed a domain specific language called Program Description Logic (PDL). PDL allows succinct declarative definitions of programmatic structures which correspond to design rule violations. PDL is based on a fully static and expressive pointcut language. PDL pointcuts allow characterizing a wide range of design rules without sacrificing static verification.We evaluate PDL by comparing it to FxCop, an industrial strength tool for checking design rules. Copyright 2007 ACM.},
key = {Computer programming languages},
keywords = {Error analysis;Program compilers;Software design;Static analysis;},
note = {Aspect Oriented Programming;Design rule;Program Description Logic (PDL);},
URL = {http://dx.doi.org/10.1145/1218563.1218571},
} 


@inproceedings{2001526779386 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using the architecture description language MetaH for designing and prototyping an embedded spacecraft attitude control system},
journal = {AIAA/IEEE Digital Avionics Systems Conference - Proceedings},
author = {McDuffie, J.H.},
volume = {2},
year = {2001},
pages = {8E31 - 8E39},
address = {Daytona Beach, FL, United states},
abstract = {Performance evaluation and rapid prototyping of novel, advanced, and potentially complex modern control methodologies in an embedded environment remain a challenge in today's software engineering environment. This work utilizes an integrated tool set consisting of the Domain Specific Language Simulink, The BEACON code generator, and the Architecture Description Language MetaH to prototype a new, embedded, decoupling, sliding mode controller for spacecraft attitude tracking maneuvers and regulation. Sliding mode controller design consists of two steps. First, a suitable hypersurface is selected such that linear tracking error behavior with desired eigenvalues placement is achieved on the surface. Then the control is found in order to guarantee the hypersurface is reached in finite time and is maintained thereafter. This guarantees the desired decoupled tracking response in sliding mode and insensitivity to disturbances and uncertainties. Smoothing of the control input is achieved via the saturation function. For regulation maneuvers the initial phase is accomplished using a quaternion feedback regulator for eigenaxis rotations. The sliding mode controller is engaged to maintain the spacecraft attitude in the presence of parametric uncertainties and external disturbances. A model of the controller and spacecraft are created using Simulink. The BEACON code generator is then used to generate code packages describing the spacecraft and controller systems. MetaH is used to create a software architecture for integration of the controller and spacecraft subsystems, to simplify software module integration, and to create an executable for the embedded target. Additionally, MetaH provides a simple mechanism to modify process execution rates, supports hybrid time systems, and provides scheduling analysis of process execution times.},
key = {Rapid prototyping},
keywords = {Codes (symbols);Computer aided software engineering;Computer programming languages;Embedded systems;Error detection;Mathematical models;Sliding mode control;Space applications;Spacecraft;},
note = {Spacecraft attitude control systems;},
URL = {http://dx.doi.org/10.1109/DASC.2001.964241},
} 


@inproceedings{20112614102405 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic generation of executable communication specifications from parallel applications},
journal = {Proceedings of the International Conference on Supercomputing},
author = {Wu, Xing and Mueller, Frank and Pakin, Scott},
year = {2011},
pages = {12 - 21},
address = {Tucson, AZ, United states},
abstract = {Portable parallel benchmarks are widely used and highly effective for (a) the evaluation, analysis and procurement of high-performance computing (HPC) systems and (b) quantifying the potential benefits of porting applications for new hardware platforms. Yet, past techniques to synthetically parametrized hand-coded HPC benchmarks prove insufficient for today's rapidly-evolving scientific codes particularly when subject to multi-scale science modeling or when utilizing domain-specific libraries. To address these problems, this work contributes novel methods to automatically generate highly portable and customizable communication benchmarks from HPC applications. We utilize ScalaTrace, a lossless, yet scalable, parallel application tracing framework to collect selected aspects of the run-time behavior of HPC applications, including communication operations and execution time, while abstracting away the details of the computation proper. We subsequently generate benchmarks with identical run-time behavior from the collected traces. A unique feature of our approach is that we generate benchmarks in CONCEPTUAL, a domain-specific language that enables the expression of sophisticated communication patterns using a rich and easily understandable grammar yet compiles to ordinary C+MPI. Experimental results demonstrate that the generated benchmarks are able to preserve the run-time behavior - including both the communication pattern and the execution time - -of the original applications. Such automated benchmark generation is particularly valuable for proprietary, export-controlled, or classified application codes: when supplied to a third party, our auto-generated benchmarks ensure performance fidelity but without the risks associated with releasing the original code. This ability to automatically generate performance-accurate benchmarks from parallel applications is novel and without any precedence, to our knowledge. &copy; 2011 ACM.},
key = {Benchmarking},
keywords = {C (programming language);Communication;Computer software selection and evaluation;Graphical user interfaces;Intelligent control;Problem oriented languages;},
note = {application-specific benchmark generation;conceptual;Domain specific languages;performance;scalatrace;Trace compression;},
URL = {http://dx.doi.org/10.1145/1995896.1995901},
} 


@inproceedings{20073110729605 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A UML 2.0 profile for WebML modeling},
journal = {ACM International Conference Proceeding Series},
author = {Moreno, Nathalie and Fraternalli, Piero and Vallecillo, Antonio},
volume = {155},
year = {2006},
address = {Palo Alto, CA, United states},
abstract = {In recent years, we have witnessed how the Web Engineering community considers the use of standard UML notation, techniques and supporting tools for modeling Web systems, including the adaptation of their own modeling languages, representation diagrams and development processes to UML. This interest for being MOF and UML-compliant arises from the increasing need to be able to interoperate with other notations and tools, and to exchange data and models, thus facilitating and improving reuse. WebML, like any other Domain Specific Language (DSL), allows to express in a precise and natural way the concepts and mechanisms of its domain of reference. However, it cannot fully interoperate with other notations, nor can it be integrated with other tools. As a solution to these requirements, in this paper we describe a UML 2.0 profile for WebML which allows WebML models to be used in conjunction with other notations and modeling tools.},
key = {Unified Modeling Language},
keywords = {Electronic document exchange;Interoperability;Mathematical models;Web services;},
note = {Domain Specific Languages (DSL);Metamodels;Modeling languages;Web Engineering;},
URL = {http://dx.doi.org/10.1145/1149993.1149998},
} 


@inproceedings{2005529621798 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {HAIL: A language for easy and correct device access},
journal = {Proceedings of the 5th ACM International Conference on Embedded Software, EMSOFT 2005},
author = {Sun, Jun and Yuan, Wanghong and Kallahalla, Mahesh and Islam, Nayeem},
year = {2005},
pages = {1 - 9},
address = {Jersey City, NJ, United states},
abstract = {It is difficult to write device drivers. One factor is that writing low-level code for accessing devices and manipulating their registers is tedious and error-prone. For many system-on-chip based systems, buggy hardware, imprecise documentation, and code reuse worsen the situation further. This paper presents HAIL (Hardware Access Interface Language), a language-based approach to simplify device access programming and generate error checking code against bugs in software, hardware, and documentation. HAIL is a domain-specific language that specifies all aspects of a device's programming interface and the access methods in a particular system and OS. A compiler automatically checks the specification and translates it into C code for device access, with optional debugging code. The generated code can be included directly into device driver code. In the paper, we argue that HAIL lowers development effort, incurs minimal runtime overhead, and reduces device access related bugs. We also show that the HAIL specification can be reused for different operating systems, thereby reducing porting costs. Copyright 2005 ACM.},
key = {Computer software},
keywords = {Computer debugging;Computer hardware;Computer networks;Computer operating systems;Computer programming;Embedded systems;Networks (circuits);},
note = {Automatic code generation;Device drivers;Domain-specific languages;Invariant specification and verification;Register access;Software reuse;System-on-chip;},
} 


@inproceedings{20110413625463 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Metamodel recovery from multi-tiered domains using extended MARS},
journal = {Proceedings - International Computer Software and Applications Conference},
author = {Liu, Qichao and Bryant, Barrett R. and Mernik, Marjan},
year = {2010},
pages = {279 - 288},
issn = {07303157},
address = {Seoul, Korea, Republic of},
abstract = {With the rapid development of model-driven engineering (MDE), domain-specific modeling has become a widely used software development technique. In MDE, metamodels represent a schema definition of the syntax and static semantics to which an instance model conforms (i.e., a model conforms to its metamodel in a similar manner to how a program conforms to a grammar). However, in order to address new feature requests of the domain and language, the metamodel often undergoes frequent evolution that may result in the inability of users to load and view previous model instances. MARS is a metamodel recovery system to address the problems of metamodel evolution. This paper presents our extensions to MARS to infer models for multi-tiered domains. A new XSLT translator has been developed to generate a domain-specific language (DSL) called MRL (model representation language) for the XML representation of domain instances. The metamodel inference engine has been revised to translate the MRL back into a metamodel. &copy; 2010 IEEE.},
key = {Software design},
keywords = {Computer applications;Computer software;Problem oriented languages;Semantics;Translation (languages);},
note = {Domain specific languages;Domain specific modeling;Feature requests;Grammar inference;Meta model;Model representation;Model-driven engineering;Multi-tiered;Rapid development;Recovery systems;Software development techniques;Static semantics;XML representation;},
URL = {http://dx.doi.org/10.1109/COMPSAC.2010.35},
} 


@inproceedings{20080311025485 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Data dependence analysis for the parallelization of numerical tree codes},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Zumbusch, Gerhard},
volume = {4699 LNCS},
year = {2007},
pages = {890 - 899},
issn = {03029743},
address = {Umea, Sweden},
abstract = {Data dependence analysis for automatic parallelization of sequential tree codes is discussed. Hierarchical numerical algorithms often use tree data structures for unbalanced, adaptively and dynamically created trees. Moreover, such codes often do not follow a strict divide and conquer concept, but introduce some geometric neighborhood data dependence in addition to parent-children dependencies. Hence, recognition mechanisms and hierarchical partition strategies of trees are not sufficient for automatic parallelization. Generic tree traversal operators are proposed as a domain specific language. Additional geometric data dependence can be specified by code annotation. A code transformation system with data dependence analysis is implemented, which generates several versions of parallel codes for different programming models. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Data processing},
keywords = {Algorithms;Codes (symbols);Hierarchical systems;Numerical methods;Parallel processing systems;Trees (mathematics);},
note = {Automatic parallelization;Hierarchical partition strategies;Numerical tree codes;},
} 


@inproceedings{20100412654598 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a generic traceability framework for model-driven software engineering},
journal = {Future Trends of Model-Driven Development - Proceedings of the 1st International Workshop on Future Trends of Model-Driven Development - FTMDD 2009 In Conjunction with ICEIS 2009},
author = {Grammel, Birgit},
year = {2009},
pages = {44 - 47},
address = {Milan, Italy},
abstract = {With the inception of Model-Driven Software Engineering (MDSD) the need for traceability is raised to understand the complexity of model transformations and overall to improve the quality of MDSD. Using the advantage of generating traceability information automatically in MDSD, eases the problem of creating and maintaining trace links, which is a labor intensive task, when done manually. Yet, there is still a wide range of open challenges in existing traceability solutions and a need to consolidate traceability domain knowledge. This paper proposes a generic framework for augmenting arbitrary model transformation approaches with a traceability mechanism. Essentially, this augmentation is based on a domain-specific language for traceability providing the formalization on integration conditions needed for implementing traceability. The paper is of positional nature and outlines work currently in progress.},
key = {Computer software},
keywords = {Problem oriented languages;},
note = {Arbitrary models;Domain knowledge;Domain specific languages;Generic frameworks;Labor intensive;Model transformation;Model-driven;Traceability information;},
} 


@inproceedings{20080411043594 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Experience with safe dynamic reconfigurations in component-based embedded systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Polakovic, Juraj and Mazare, Sebastien and Stefani, Jean-Bernard and David, Pierre-Charles},
volume = {4608 LNCS},
year = {2007},
pages = {242 - 257},
issn = {03029743},
address = {Medford, MA, United states},
abstract = {Supporting dynamic reconfiguration is required even in highly constrained embedded systems, to allow software patches and updates, and to allow adaptations to changes in environmental and operating conditions without service interruption. Dynamic reconfiguration, however, is a complex and error prone process. In this paper we report our experience in implementing safe dynamic reconfigurations in embedded devices with limited resources. Our approach relies on a component-based framework for building reconfigurable operating systems, and the use of a domain specific language (DSL) for reconfiguration. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Embedded systems},
keywords = {Computer operating systems;Computer programming languages;Constraint theory;Error analysis;},
note = {Dynamic reconfiguration;Error prone process;},
} 


@article{2005068832596 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A data-modelling approach to web application synthesis},
journal = {International Journal of Web Engineering and Technology},
author = {Di Ruscio, Davide and Muccini, Henry and Pierantonio, Alfonso},
volume = {1},
number = {3},
year = {2004},
pages = {320 - 337},
issn = {14761289},
abstract = {Most web applications are data-intensive, i.e. they rely heavily on dynamic contents usually stored in databases. Website design and maintenance can greatly benefit from conceptual descriptions of both data and hypermedia aspects, i.e. those design dimensions which distinguish this application class: the data upon which the content is based, the way dynamic contents are composed together to form pages, and how pages are linked together in order to move across the application content. The paper proposes Webile, a visual Domain-Specific Language based on UML, which enables a model-driven approach to high-level specification of web applications. In contrast with other approaches, Webile exploits the UML meta-model architecture by serialising the specifications in the XMI interchange format. This representation provides interoperability amongst different operative platforms and enables an XSL transformation-based automatic generation of the applications that are being designed.},
key = {World Wide Web},
keywords = {Database systems;Electronic document exchange;Hypermedia systems;Information management;Interoperability;Metadata;Software engineering;},
note = {Conceptual modeling;Data-intensive web applications;Development;Modelling methodologies;UML;Web application design;},
} 


@inproceedings{20094812502668 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Computer generation of fast Fourier transforms for the cell broadband engine},
journal = {Proceedings of the International Conference on Supercomputing},
author = {Chellappa, Srinivas and Franchetti, Franz and Puschel, Markus},
year = {2009},
pages = {26 - 35},
address = {Yorktown Heights, NY, United states},
abstract = {The Cell BE is a multicore processor with eight vector accelerators (called SPEs) that implement explicit cache management through direct memory access engines. While the Cell has an impressive floating point peak performance, programming and optimizing for it is difficult as it requires explicit memory management, multi-threading, streaming, and vectorization. We address this problem for the discrete Fourier transform (DFT) by extending Spiral, a program generation system, to automatically generate highly optimized implementations for the Cell. The extensions include multi-SPE parallelization and explicit memory streaming, both performed at a high abstraction level using rewriting systems operating on Spiral's internal domain-specific language. Further, we support latency and throughput optimizations, single and double precision, and different data formats. The performance of Spiral's computer generated code is comparable with and sometimes better than existing DFT implementations, where available. Copyright 2009 ACM.},
key = {Automatic programming},
keywords = {Cache memory;Discrete Fourier transforms;Intelligent control;Mathematical transformations;Probability density function;Problem oriented languages;Signal receivers;Tuning;},
note = {Automatic performance tuning;Multi core;Multibuffering;Parallelizations;Program generation;},
URL = {http://dx.doi.org/10.1145/1542275.1542285},
} 


@inproceedings{20113914381381 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Design and validation of feature-based process model tailoring - A sample implementation of PDE},
journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
author = {Costache, Daniela and Kalus, Georg and Kuhrmann, Marco},
year = {2011},
pages = {464 - 467},
address = {Szeged, Hungary},
abstract = {A comprehensive software development process needs some adjustment before it can be used: It needs to be tailored to the particular organization's and project's setting. The definition of an appropriate tailoring model is a critical task. Process users need tailoring that enables them to trim the process to reflect the actual needs. Process engineers need a method and a tool to define a valid model. The SE Book of T-Systems contains a feature model to describe variable parts of the process model and relations and constraints between these parts. The notation and semantics of feature models can be used to visually author a consistent and valid tailoring model. In this paper we present a tool for visual modeling and validation of process model tailoring based on feature models using the SE Book of T-Systems as an example. The tool is based on a domain-specific language that represents the process model. It leverages the semantics of feature models to provide an easy-to-use editor for tailoring-enabled process models. &copy; 2011 ACM.},
key = {Software design},
keywords = {Problem oriented languages;Semantics;},
note = {Critical tasks;Development process;Domain specific languages;Feature models;Feature-based;Feature-model;Process engineer;Process model;Software development process;T-Systems;Visual modeling;},
URL = {http://dx.doi.org/10.1145/2025113.2025192},
} 


@inproceedings{20094712473337 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {AFPL2, an abstract language for firewall ACLs with NAT support},
journal = {Proceedings - 2009 2nd International Conference on Dependability, DEPEND 2009},
author = {Pozo, S. and Varela-Vaca, A.J. and Gasca, R.M.},
year = {2009},
pages = {52 - 59},
address = {Athens, Glyfada, Greece},
abstract = {The design and management of firewall ACLs is a very hard and error-prone task. Part of this complexity comes from the fact that each firewall platform has its own low-level language with a different functionality, syntax, and development environment. Although high-level languages have been proposed to model firewall ACLs, none of them has been widely adopted by the industry due to a combination of factors: high complexity, no support of important features of firewalls, etc. In this paper the most important access control policy languages are reviewed, with special focus on the development of firewall ACLs. Based on this analysis, a new domain specific language for firewall ACLs (AFPL2) is proposed, supporting more features that other languages do not cover (e.g. NAT). As the result of our design methodology, AFPL2 is very lightweight and easy to use. AFPL2 can be translated to existing low-level firewall languages, or be directly interpreted by firewall platforms, and is an extension to a previously developed language. &copy; 2009 IEEE.},
key = {High level languages},
keywords = {Access control;Computer system firewalls;Linguistics;Query languages;},
note = {Abstract languages;Access control policy languages;Acl;Design Methodology;Development environment;Domain specific languages;Error prones;Firewall;Language;Low-level language;Nat;},
URL = {http://dx.doi.org/10.1109/DEPEND.2009.14},
} 


@article{IP51424635 ,
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Incorporating the Ontology Paradigm Into Software Engineering: Enhancing Domain-Driven Programming in Clojure/Java},
journal = {IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews},
author = {Djuric, Dragan and Devedzic, Vladan},
year = {2011},
issn = {10946977},
abstract = {There is a notable overlap of the challenges with which the semantic technologies and software engineering deal. They can also complement and mutually improve each other. Current efforts mostly focus on improving software tools around the resource description framework (RDF) and Web Ontology Language (OWL) Web-oriented ecosystem that helps ontology engineers but is alien to software engineers. This paper presents an opposite approach taken from the software developer's viewpoint---an incorporation of the ontology paradigm into a general-purpose programming language, in a simple and agile way, on a small scale, and in an unpretentious manner. The objective is to help programmers write simple domain-driven code with richer semantics. The means to achieve this objective relies on metaprogramming to internalize the ontology modeling paradigm into a mainstream programming environment based on the Java ecosystem, in a lightweight manner suitable for small teams. An embedded meta domain-specific language (DSL), which is called Magic Potion, is implemented in Clojure and blends ontology, functional, object-oriented, and concurrent paradigms. An example from the technology enhanced learning (TEL) domain is used to illustrate Magic Potion in action.},
key = {Ontology},
keywords = {Computer aided software engineering;Computer programming;Ecosystems;Engineers;Java programming language;Problem oriented languages;Semantic Web;Semantics;User interfaces;},
note = {Domain specific languages;General-purpose programming language;Meta Programming;Object oriented;Ontology modeling;Programming environment;Resource description framework;Semantic technologies;Small scale;Software developer;Software engineers;Software tool;Technology enhanced learning;Web ontology language;},
URL = {http://dx.doi.org/10.1109/TSMCC.2011.2140316},
} 


@inproceedings{20095212580972 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GaussianScriptEditor: An editor for Gaussian scripting language for grid environment},
journal = {8th International Conference on Grid and Cooperative Computing, GCC 2009},
author = {Wei, Tongming and Zhang, Ruisheng and Su, Xianrong and Chen, Shilin and Li, Lian},
year = {2009},
pages = {39 - 44},
address = {Lanzhou, Gansu, China},
abstract = {More and more chemists carry out scientific research using computation. In this process, computational chemistry software has played a very important role. Among these computational chemistry software, Gaussian is very prominent. The most essential user interface of Gaussian is scripting language, but software-oriented scripting language is a great burden to chemists. Meanwhile, chemists are increasingly using grid environment to do scientific research. So, it is significant to build a user-friendly and chemist-oriented Gaussian scripting language editing environment in grid. In this paper, we introduce GaussianScriptEditor to solve these problems. GaussianScriptEditor is on the basis of grid platform and its implementation is related to Domain Specific Language (DSL), knowledge in computational chemistry, technology of compiling, ANTLR and DLTK. &copy; 2009 IEEE.},
key = {Grid computing},
keywords = {Computer science;Computer software;Linguistics;User interfaces;},
note = {Computational chemistry;Computational chemistry software;Domain specific languages;Gaussians;Grid environments;Grid platform;Scientific researches;Scripting languages;Virtualizations;},
URL = {http://dx.doi.org/10.1109/GCC.2009.49},
} 


@inproceedings{20110313586772 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Steering model-driven development of enterprise information system through responsibilities},
journal = {Proceedings of the Joint Workshop on Web Services and Model-Driven Enterprise Information Services, WSMDEIS 2005, in Conjunction with ICEIS 2005},
author = {Huang, Ming-Jen and Katayama, Takuya},
year = {2005},
pages = {165 - 170},
address = {Miami, FL, United states},
abstract = {OMG proposes the MDA that promotes the ideas of modeling in UML and transforming UML models to code. But UML is not universal for every domain and the direct translation approach of the MDA is not adequate. In this paper, we introduce REST, an idea of using responsibilities as contextual information to instruct machines to generate software systems. First, we give an overview of RESTDA - a software development architecture for business based on the concept of REST. Then we describe a domain-specific language Business Models. It helps developers to describe a business from a documentprocessing perspective. We also introduce a rule-based validation of consistency within Business Models. Finally, we describe the transformation mechanism of RESTDA. Our approach provides machines higher intelligence to generate source code for different contexts.},
key = {Web services},
keywords = {Industry;Information retrieval;Information services;Information systems;Problem oriented languages;Software architecture;Software design;Unified Modeling Language;},
note = {Business models;Contextual information;Document-processing;Domain specific languages;Enterprise information system;Model driven development;Rule based;Software development;Software systems;Source codes;Transformation mechanisms;UML Model;},
} 


@inproceedings{20063110040445 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {RubyTL: A practical, extensible transformation language},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Cuadrado, Jesus Sanchez and Molina, Jesus Garcia and Tortosa, Marcos Menarguez},
volume = {4066 LNCS},
year = {2006},
pages = {158 - 172},
issn = {03029743},
address = {Bilbao, Spain},
abstract = {Model transformation is a key technology of model driven development approaches. A lot of research therefore is being carried out to understand the nature of model transformations and find out desirable characteristics of transformation languages. In recent years, several transformation languages have been proposed. We present the RubyTL transformation language which has been designed as an extensible language - a set of core features along with an extension mechanism. RubyTL provides a framework for experimenting with features of hybrid transformation languages. In addition, RubyTL has been created as a domain specific language embedded in the Ruby programming language. In this paper we show the core features of the language through a simple example and explain how the language can be extended to provide more features. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Computer programming languages},
keywords = {Computer science;Computer software;Embedded systems;Software engineering;},
note = {Hybrid transformation;Model transformations;Transformation languages;},
URL = {http://dx.doi.org/10.1007/11787044_13},
} 


@inproceedings{2005038792012 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Plugging Haskell in},
journal = {Proceedings of the ACM SIGPLAN 2004 Haskell Workshop, Haskell'04},
author = {Pang, Andre and Stewart, Don and Seefried, Sean and Chakravarty, Manuel M. T.},
year = {2004},
pages = {10 - 21},
address = {Snowbird, UT, United states},
abstract = {Extension languages enable users to expand the functionality of an application without touching its source code. Commonly, these languages are dynamically typed languages, such as Lisp, Python, or domain-specific languages, which support runtime plugins via dynamic loading of components. We show that Haskell can be comfortably used as a statically typed extension language for both Haskell and foreign-language applications supported by the Haskell FFI, and that it can perform type-safe dynamic loading of plugins using dynamic types. Moreover, we discuss how plugin support is especially useful to applications where Haskell is used as an embedded domain-specific language (EDSL). We explain how to realise type-safe plugins using dynamic types, runtime compilation, and dynamic linking, exploiting infrastructure provided by the Glasgow Haskell Compiler. We demonstrate the practicability of our approach with several applications that serve as running examples.},
key = {Computer programming languages},
keywords = {Distributed computer systems;Dynamic programming;Embedded systems;Interfaces (computer);Program compilers;Syntactics;},
note = {Dynamic loading;Dynamic typing;Extension languages;Functional programming;Plugins;Staged type inference;},
URL = {http://dx.doi.org/10.1145/1017472.1017478},
} 


@inproceedings{20105013485969 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {TASTY: Tool for automating secure two-party computations},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
author = {Henecka, Wilko and Kogl, Stefan and Sadeghi, Ahmad-Reza and Schneider, Thomas and Wehrenberg, Immo},
year = {2010},
pages = {451 - 462},
issn = {15437221},
address = {Chicago, IL, United states},
abstract = {Secure two-party computation allows two untrusting parties to jointly compute an arbitrary function on their respective private inputs while revealing no information beyond the outcome. Existing cryptographic compilers can automatically generate secure computation protocols from high-level specifications, but are often limited in their use and efficiency of generated protocols as they are based on either garbled circuits or (additively) homomorphic encryption only. In this paper we present TASTY, a novel tool for automating, i.e., describing, generating, executing, benchmarking, and comparing, efficient secure two-party computation protocols. TASTY is a new compiler that can generate protocols based on homomorphic encryption and efficient garbled circuits as well as combinations of both, which often yields the most efficient protocols available today. The user provides a high-level description of the computations to be performed on encrypted data in a domain-specific language. This is automatically transformed into a protocol. TASTY provides most recent techniques and optimizations for practical secure two-party computation with low online latency. Moreover, it allows to efficiently evaluate circuits generated by the well-known Fairplay compiler. We use TASTY to compare protocols for secure multiplication based on homomorphic encryption with those based on garbled circuits and highly efficient Karatsuba multiplication. Further, we show how TASTY improves the online latency for securely evaluating the AES functionality by an order of magnitude compared to previous software implementations. TASTY allows to automatically generate efficient secure protocols for many privacy-preserving applications where we consider the use cases for private set intersection and face recognition protocols. Copyright 2010 ACM.},
key = {Cryptography},
keywords = {Computation theory;Face recognition;Function evaluation;Image quality;Network protocols;Network security;Problem oriented languages;Program compilers;},
note = {Arbitrary functions;Compiler;Domain specific languages;Encrypted data;Garbled circuits;High level description;High level specification;Homomorphic-encryptions;Karatsuba multiplication;Order of magnitude;Privacy preserving;Secure computation;Secure function evaluation;Secure protocols;Secure two-party computations;Set intersection;Software implementation;},
URL = {http://dx.doi.org/10.1145/1866307.1866358},
} 


@inproceedings{20105113498030 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based kinematics generation for modular mechatronic toolkits},
journal = {GPCE'10 - Proceedings of the 2010 Conference on Generative Programming and Component Engineering},
author = {Bordignon, Mirko and Schultz, Ulrik P. and Stoy, Kasper},
year = {2010},
pages = {157 - 166},
address = {Eindhoven, Netherlands},
abstract = {Modular robots are mechatronic devices that enable the construction of highly versatile and flexible robotic systems whose mechanical structure can be dynamically modified. The key feature that enables this dynamic modification is the capability of the individual modules to connect to each other in multiple ways and thus generate a number of different mechanical systems, in contrast with the monolithic, fixed structure of conventional robots. The mechatronic flexibility, however, complicates the development of models and programming abstractions for modular robots, since manually describing and enumerating the full set of possible interconnections is tedious and error-prone for real-world robots. In order to allow for a general formulation of spatial abstractions for modular robots and to ensure correct and streamlined generation of code dependent on mechanical properties, we have developed the Modular Mechatronics Modelling Language (M3L). M3L is a domain-specific language, which can model the kinematic structure of individual robot modules and declaratively describe their possible interconnections, rather than requiring the user to enumerate them in their entirety. From this description, the M3L compiler generates the code that is needed to simulate the resulting robots within Webots, a widely used commercial robot simulator, and the software component needed for spatial structure computations by a virtual machine-based runtime system, which we have developed and used for programming physical modular robots. &copy; 2010 ACM.},
key = {Robot programming},
keywords = {Abstracting;Automatic programming;Computer software;Graphical user interfaces;Kinematics;Mechanical properties;Mechatronics;Modular robots;Network components;Problem oriented languages;Program compilers;Robotics;},
note = {Code Generation;Commercial robots;Conventional robots;Domain specific languages;Dynamic modifications;Error prones;Fixed structure;Flexible robotics;Key feature;Kinematic structures;Mechanical structures;Mechanical systems;Mechatronic devices;Model-based;Modelling language;Programming abstractions;Real-world;Runtime systems;Software component;Spatial abstractions;Spatial structure;Virtual machines;},
URL = {http://dx.doi.org/10.1145/1868294.1868318},
} 


@inproceedings{20071410525543 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Unsupervised adaptation of a stochastic language model using a Japanese raw corpus},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
author = {Kurata, Gakuto and Mori, Shinsuke and Nishimura, Masafumi},
volume = {1},
year = {2006},
pages = {I1037 - I1040},
issn = {15206149},
address = {Toulouse, France},
abstract = {The target uses of Large Vocabulary Continuous Speech Recognition (LVCSR) systems are spreading. It takes a lot of time to build a good LVCSR system specialized for the target domain because experts need to manually segment the corpus of the target domain, which is a labor-intensive task. In this paper, we propose a new method to adapt an LVCSR system to a new domain. In our method, we stochastically segment a Japanese raw corpus of the target domain. Then a domain-specific Language Model (LM) is built based on this corpus. All of the domain-specific words can be added to the lexicon for LVCSR. Most importantly, the proposed method is fully automatic. Therefore, we can reduce the time for introducing an LVCSR system drastically. In addition, the proposed method yielded a comparable or even superior performance to use of expensive manual segmentation. &copy; 2006 IEEE.},
key = {Speech recognition},
keywords = {Natural language processing systems;Stochastic models;Vocabulary control;},
note = {Large Vocabulary Continuous Speech Recognition (LVCSR);Manual segmentation;Stochastic language model;Target domains;},
} 


@inproceedings{20081011128668 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model driven development with NORMA},
journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
author = {Curland, Matthew and Halpin, Terry},
year = {2007},
issn = {15301605},
address = {Big Island, HI, United states},
abstract = {Object-role Modeling (ORM) is a fact-oriented approach for specifying, transforming, and querying information at a conceptual level. Unlike EntityRelationship (ER) modeling and Unified Modeling Language (UML) class diagrams, ORM is attributefree, treating all elementary facts as relationships. For information modeling, fact-oriented graphical notations are typically far more expressive than other notations. Based on extensive industrial feedback, a second generation ORM (ORM 2) was recently specified. This paper provides a detailed discussion of NORMA (Neumont ORM Architect), a software tool that facilitates entry, validation, and mapping of ORM 2 models. Building on Microsoft's Domain Specific Language (DSL) technology, NORMA is implemented as an open-source plug-in to Visual Studio .NET. As well as supporting ORM 2, with automated verbalization and live error-handling, NORMA automatically generates code for relational database models, object models, and XML schemas. &copy; 2007 IEEE.},
key = {Query processing},
keywords = {Computer aided software engineering;Error analysis;Graphic methods;Mathematical models;Unified Modeling Language;XML;},
note = {Class diagrams;Domain Specific Languages;Object role Modeling (ORM);Querying information;},
URL = {http://dx.doi.org/10.1109/HICSS.2007.384},
} 


@inproceedings{20102312984830 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Safe compositional network sketches: Formal framework},
journal = {HSCC'10 - Proceedings of the 13th ACM International Conference on Hybrid Systems: Computation and Control},
author = {Bestavros, Azer and Kfoury, Assaf and Lapets, Andrei and Ocean, Michael J.},
year = {2010},
pages = {231 - 241},
address = {Stockholm, Sweden},
abstract = {NetSketch is a tool for the specification of constrained-flow applications and the certification of desirable safety properties imposed thereon. NetSketch assists system integrators in two types of activities: modeling and design. As a modeling tool, it enables the abstraction of an existing system while retaining sufficient information about it to carry out future analysis of safety properties. As a design tool, NetSketch enables the exploration of alternative safe designs as well as the identification of minimal requirements for out-sourced subsystems. NetSketch embodies a lightweight formal verification philosophy, whereby the power (but not the heavy machinery) of a rigorous formalism is made accessible to users via a friendly interface. NetSketch does so by exposing tradeoffs between exactness of analysis and scalability, and by combining traditional whole-system analysis with a more flexible compositional analysis. The compositional analysis is based on a strongly-typed Domain-Specific Language (DSL) for describing and reasoning about constrained-flow networks at various levels of sketchiness along with invariants that need to be enforced thereupon. In this paper, we define the formal system underlying the operation of NetSketch, in particular the DSL behind NetSketch's userinterface when used in "sketch mode", and prove its soundness relative to appropriately-defined notions of validity. In a companion paper [7], we overview NetSketch, highlight its salient features, and illustrate how it could be used in applications that include: the management/shaping of traffic flows in a vehicular network (as a proxy for cyber-physical systems (CPS) applications) and a streaming media network (as a proxy for Internet applications). &copy; 2010 ACM.},
key = {Design},
keywords = {Electric grounding;Hybrid computers;Hybrid systems;Machinery;Media streaming;Modems;Philosophical aspects;Problem oriented languages;Telecommunication lines;Traffic surveys;},
note = {Compositional analysis;Compositionality;Cyber-physical systems;Design modeling;Design tool;Domain specific languages;Existing systems;Flow network;Formal framework;Formal systems;Formal verifications;Heavy machinery;Internet application;Modeling tool;Safe designs;Safety property;Salient features;Streaming media;System integrators;Traffic flow;Vehicular networks;Whole-system analysis;},
URL = {http://dx.doi.org/10.1145/1755952.1755985},
} 


@inproceedings{20083811577311 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Constructing advanced web-based dialog components with stakeholders - A DSL approach},
journal = {Proceedings - 8th International Conference on Web Engineering, ICWE 2008},
author = {Freudenstein, Patrick and Nussbaumer, Martin},
year = {2008},
pages = {38 - 44},
address = {Yorktown Heights, NY, United states},
abstract = {Complex dialogs with comprehensive underlying data models are gaining increasing importance in today's Web applications. This in turn accelerates the need for highly dynamic dialogs offering guidance to the users and reducing cognitive overload. Beyond that, requirements from the fields of Web accessibility, platform-independence and Web service integration arise. Considering the resulting complexity, a systematic engineering approach becomes important. Besides addressing the specific characteristics of these dialogs, key success factors from a communication perspective like strong user involvement and clear business objectives must be taken into account. To this end, we present an evolutionary, extensible approach for the model-driven construction of advanced dialogs which is based on a Domain-specific Language (DSL). We introduce a modeling notation based on Petri net constructs and XForms as well as a supporting Web-based editor, both focusing on simplicity and fostering communications. The technical framework allows for quick prototyping and flexible changes. In conclusion, complex, device-independent dialogs with rich behavior and appearance can be constructed and evolved with intense stakeholder collaboration. &copy; 2008 IEEE.},
key = {Mathematical models},
keywords = {DSL;Graph theory;Information services;Modems;Petri nets;Telecommunication lines;},
note = {International conferences;Web engineering;Web service integration;},
URL = {http://dx.doi.org/10.1109/ICWE.2008.39},
} 


@inproceedings{20094512418045 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Type checking evolving languages with MSOS},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Van Den Brand, M.G.J. and Van Der Meer, A.P. and Serebrenik, A.},
volume = {5700 LNCS},
year = {2009},
pages = {207 - 226},
issn = {03029743},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {Evolution of programming languages requires co-evolution of static analysis tools designed for these languages. Traditional approaches to static analysis, e.g., those based on Structural Operational Semantics (SOS), assume, however, that the syntax and the semantics of the programming language under consideration are fixed. Language modification is, therefore, likely to cause redevelopment of the analysis techniques and tools. Moreover, the redevelopment cost can discourage the language engineers from improving the language design. To address the co-evolution problem we suggest to base static analyses on modular structural operational semantics (MSOS). By using an intrinsically modular formalism, type rules can be added, removed or modified easily. We illustrate our approach by developing an MSOS-based type analysis technique for Chi, a domain specific language for hybrid systems engineering. &copy; 2009 Springer Berlin Heidelberg.},
key = {Linguistics},
keywords = {Computer software;Hybrid systems;Object oriented programming;Query languages;Semantics;Static analysis;Systems engineering;},
note = {Analysis techniques and tools;Co-evolution;Domain specific languages;Language design;Programming language;Redevelopment costs;Structural operational semantics;Type analysis;Typechecking;},
URL = {http://dx.doi.org/10.1007/978-3-642-04164-8_11},
} 


@inproceedings{20064410207024 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a MOF/QVT-based domain architecture for model driven security},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Hafner, Michael and Alam, Muhammad and Breu, Ruth},
volume = {4199 LNCS},
year = {2006},
pages = {275 - 290},
issn = {03029743},
address = {Genova, Italy},
abstract = {The SECTET-framework realizes an extensible domain architecture for the collaborative development and management of security-critical, inter-organizational workflows. Models integrate security requirements at the abstract level and are rendered in a visual language based on UML 2.0. The models form the input for a chain of integrated tools that transform them into artefacts configuring security components of a Web services-based architecture. Based on findings of various projects, this contribution has three objectives. First, we detail the MOF based metamodels defining a domain specific language for the design of inter-organizational workflows. The language supports various categories of security patterns. We then specify model-to-model transformations based on the MDA standard MOF-QVT. The mappings translate platform independent models into platform specific artefacts targeting the reference architecture. Third, we exemplarily show how model-to-code transformation could be implemented with an MDA-framework like OPEN ARCHITECTUREWARE. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Computer supported cooperative work},
keywords = {Computer architecture;Computer software;Mathematical models;Project management;Security of data;Software engineering;},
note = {Code transformation;Collaborative development;Domain architecture;Security requirements;},
} 


@inproceedings{20102613048152 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {From a domain analysis to the specification and detection of code and design smells},
journal = {Formal Aspects of Computing},
author = {Moha, Naouel and Gueheneuc, Yann-Gael and Le Meur, Anne-Francoise and Duchien, Laurence and Tiberghien, Alban},
volume = {22},
number = {3-4},
year = {2010},
pages = {345 - 361},
issn = {09345043},
address = {The Guildway, Old Portsmouth Road, Artington, Guildford, GU3 1LP, United Kingdom},
abstract = {Code and design smells are recurring design problems in software systems that must be identified to avoid their possible negative consequences on development and maintenance. Consequently, several smell detection approaches and tools have been proposed in the literature. However, so far, they allow the detection of predefined smells but the detection of new smells or smells adapted to the context of the analysed systems is possible only by implementing new detection algorithms manually. Moreover, previous approaches do not explain the transition from specifications of smells to their detection. Finally, the validation of the existing approaches and tools has been limited on few proprietary systems and on a reduced number of smells. In this paper, we introduce an approach to automate the generation of detection algorithms from specifications written using a domain-specific language. This language is defined from a thorough domain analysis. It allows the specification of smells using high-level domain-related abstractions. It allows the adaptation of the specifications of smells to the context of the analysed systems.We specify 10 smells, generate automatically their detection algorithms using templates, and validate the algorithms in terms of precision and recall on Xerces v2.7.0 and GanttProject v1.10.2, two open-source object-oriented systems.We also compare the detection results with those of a previous approach, iPlasma. BCS &copy; 2010.},
key = {Odors},
keywords = {Algorithms;Design;Java programming language;Linguistics;Problem oriented languages;Signal detection;Specifications;},
note = {Anti-patterns;Code smell;Code smells;Detection;Domain specific languages;},
URL = {http://dx.doi.org/10.1007/s00165-009-0115-x},
} 


@inproceedings{2003427684469 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Static Reasoning about Programs and Queries},
journal = {Principles of Computing and Knowledge: Paris C. Kanellakis Memorial Workshop},
author = {Millsteln, Todd},
year = {2003},
pages = {28 - 34},
address = {San Diego, CA, United states},
abstract = {In this paper, I survey three projects that are loosely related by the aim to statically understand important properties of a computation. First I describe an extension to mainstream programming languages that solves some common expressiveness limitations while preserving the ability to perform static typechecking modularly. Second I describe a notion of query containment that is appropriate for data integration systems and investigate the complexity of the problem. Finally I describe a domain-specific language for writing compiler optimizations and a strategy for automatically proving the correctness of optimizations written in this language. These three projects explore themes that are prevalent in the work of Paris Kanellakis, including object orientation, type theory, database theory, and declarative languages. I was first exposed to many of these topics through my interaction with Paris.},
key = {Computer programming languages},
keywords = {Optimization;Problem solving;Program compilers;Query languages;},
note = {Static reasoning;},
} 


@inproceedings{20102012927723 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Melange: Creating a "functional" internet},
journal = {Operating Systems Review (ACM)},
author = {Madhavapeddy, Anil and Ho, Alex and Deegan, Tim and Scott, David and Sohan, Ripduman},
volume = {41},
number = {3},
year = {2007},
pages = {101 - 114},
issn = {01635980},
address = {Lisbon, Portugal},
abstract = {Most implementations of critical Internet protocols are written in type-unsafe languages such as C or C++ and are regularly vulnerable to serious security and reliability problems. Type-safe languages eliminate many errors but are not used to due to the perceived performance overheads. We combine two techniques to eliminate this performance penalty in a practical fashion: strong static typing and generative meta-programming. Static typing eliminates run-time type information by checking safety at compile-time and minimises dynamic checks. Meta-programming uses a single specification to abstract the low-level code required to transmit and receive packets. Our domain-specific language, MPL, describes Internet packet protocols and compiles into fast, zero-copy code for both parsing and creating these packets. MPL is designed for implementing quirky Internet protocols ranging from the low-level: Ethernet, IPv4, ICMP and TCP; to the complex application-level: SSH, DNS and BGP; and even file-system protocols such as 9P. We report on fully-featured SSH and DNS servers constructed using MPL and our OCaml framework Melange, and measure greater throughput, lower latency, better flexibility and more succinct source code than their C equivalents OpenSSH and BIND. Our quantitative analysis shows that the benefits of MPL-generated code overcomes the additional overheads of automatic garbage collection and dynamic bounds checking. Qualitatively, the flexibility of our approach shows that dramatic optimisations are easily possible. Copyright 2007 ACM.},
key = {Internet protocols},
keywords = {Internet;Linguistics;Network protocols;Network security;Problem oriented languages;Query languages;Refuse collection;Servers;Transmission control protocol;Waste disposal;},
note = {Automatic garbage collection;Compile time;Complex applications;DNS server;Domain specific languages;Internet packets;Meta Programming;Optimisations;Performance penalties;Quantitative analysis;Reliability problems;Run-time types;Source codes;Static typing;Type-safe languages;Zero-copy;},
URL = {http://dx.doi.org/10.1145/1272998.1273009},
} 


@article{20110913711994 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Patrol routing expression, execution, evaluation, and engagement},
journal = {IEEE Transactions on Intelligent Transportation Systems},
author = {Steil, Dana A. and Pate, Jeremy R. and Kraft, Nicholas A. and Smith, Randy K. and Dixon, Brandon and Ding, Li and Parrish, Allen},
volume = {12},
number = {1},
year = {2011},
pages = {58 - 72},
issn = {15249050},
address = {445 Hoes Lane / P.O. Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {Recommended patrol routes can be used by organizations such as police agencies, emergency medical responders, and taxi services whose agents patrol roadway segments at proper times to assist or deter their target events. The creation of optimal complementary patrol routes for multiple agents targeting temporal event hotspots and minimizing travel distance is an NP-hard combinatorial problem that belongs to a class of problems known as the vehicle routing problem with time windows (VRPTW). Traffic safety patrol routing problems share many characteristics of VRPTW problems but differ in ways that prevent the application of existing solutions. In our approach, nondeterministic patrol routing algorithms are used to specify the movements of simulated mobile agents on a roadway system. Nondeterminism is critical in the traffic safety patrol routing domain, as rigidity and predictability can negatively impact the effectiveness of law enforcement agents' efforts.This paper addresses the problem of expressing, executing, evaluating, and engaging patrol routing algorithms that target event hotspots on roadways. The patrol algorithms are first expressed using Turn, which is our extensible domain-specific language (DSL) created for this purpose. Algorithms specified using Turn syntax are then executed in a custom simulation environment. Utilizing predefined metrics, users evaluate the resulting patrol routes to ensure that the criteria of interest in a given patrol context are met. Acceptable patrol routes are then engaged by end users via a web-based geographic information system (GIS) portal. To demonstrate the applicability and efficacy of our approach, we present two illustrative case studies. &copy; 2010 IEEE.},
key = {Military vehicles},
keywords = {Accident prevention;Geographic information systems;Law enforcement;Mobile agents;Motor transportation;Optimization;Problem oriented languages;Routing algorithms;Taxicabs;Vehicle routing;},
note = {Combinatorial problem;Domain specific languages;End users;Hotspots;Multiple agents;Non-determinism;NP-hard;Patrol algorithms;patrol routing algorithm;patrol simulation;Roadway systems;Routing problems;Simulation environment;Taxi services;Traffic safety;Travel distance;Vehicle routing problem with time windows;},
URL = {http://dx.doi.org/10.1109/TITS.2010.2065224},
} 


@inproceedings{20073410780776 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Melange: Creating a "functional" internet},
journal = {Operating Systems Review (ACM)},
author = {Madhavapeddy, Anil and Ho, Alex and Deegan, Tim and Scott, David and Sohan, Ripduman},
year = {2007},
pages = {101 - 114},
issn = {01635980},
address = {Lisbon, Portugal},
abstract = {Most implementations of critical Internet protocols are written in type-unsafe languages such as C or C++ and are regularly vulnerable to serious security and reliability problems. Type-safe languages eliminate many errors but are not used to due to the perceived performance overheads. We combine two techniques to eliminate this performance penalty in a practical fashion: strong static typing and generative meta-programming. Static typing eliminates run-time type information by checking safety at compile-time and minimises dynamic checks. Meta-programming uses a single specification to abstract the low-level code required to transmit and receive packets. Our domain-specific language, MPL, describes Internet packet protocols and compiles into fast, zero-copy code for both parsing and creating these packets. MPL is designed for implementing quirky Internet protocols ranging from the low-level: Ethernet, IPv4, ICMP and TCP; to the complex application-level: SSH, DNS and BGP; and even file-system protocols such as 9P. We report on fully-featured SSH and DNS servers constructed using MPL and our OCaml framework Melange, and measure greater throughput, lower latency, better flexibility and more succinct source code than their C equivalents OpenSSH and BIND. Our quantitative analysis shows that the benefits of MPL-generated code overcomes the additional overheads of automatic garbage collection and dynamic bounds checking. Qualitatively, the flexibility of our approach shows that dramatic optimisations are easily possible. Copyright 2007 ACM.},
key = {Internet protocols},
keywords = {C (programming language);Dynamic programming;Metadata;Object oriented programming;Reliability theory;Security of data;},
note = {Meta-programming;Type-safe languages;},
URL = {http://dx.doi.org/10.1145/1272996.1273009},
} 


@inproceedings{20102613042034 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {AADL modeling and analysis of hierarchical schedulers},
journal = {Proceedings of the ACM SIGAda Annual International Conference; SIGAda},
author = {Singhoff, Frank and Plantec, Alain},
year = {2007},
pages = {41 - 49},
issn = {10943641},
address = {Fairfax, VA, United states},
abstract = {A system based on a hierarchical scheduler is a system in which the processor is shared between several collaborative schedulers. Such schedulers exist since 1960 and they are becoming more and more investigated and proposed in real-life applications. For example, the ARINC 653 international standard which defines an Ada interface for avionic real time operating systems provides such a kind of collaborative schedulers. This article focuses on the modeling and the performance analysis of hierarchical schedulers. We investigate the modeling of hierarchical schedulers with AADL. Hierarchical scheduler timing and synchronization relationships are expressed with a domain specific language based on timed automata: the Cheddar language. With the meta CASE tool Platypus, we generate Ada packages implementing the Cheddar language. These Ada packages are part of Cheddar, a real time scheduling simulator. With these Ada packages, Cheddar is able to perform analysis by scheduling simulation of AADL systems composed of hierarchical schedulers. An AADL model of the ARINC 653 hierarchical scheduling is described as an illustration. Copyright 2007 ACM.},
key = {Scheduling},
keywords = {Automata theory;Computer operating systems;Hierarchical systems;Linguistics;Real time systems;Robots;Translation (languages);},
note = {ARINC 653;Domain specific languages;Hierarchical scheduling;International standards;Meta-CASE;Modeling and analysis;Performance analysis;Real time operating system;Real time scheduling;Real-life applications;Scheduling simulation;System-based;Timed Automata;Timing and synchronization;},
URL = {http://dx.doi.org/10.1145/1315580.1315593},
} 


@inproceedings{20100412654194 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A model driven approach for generating code from security requirements},
journal = {Security in Information Systems - Proceedings of the 7th International Workshop on Security in Information Systems - WOSIS 2009 In Conjunction with ICEIS 2009},
author = {Sanchez, Oscar and Molina, Fernando and Molina, Jesus Garcia and Toval, Ambrosio},
year = {2009},
pages = {119 - 126},
address = {Milan, Italy},
abstract = {Nowadays, Information Systems are present in numerous areas and they usually contain data with special security requirements. However, these requirements do not often receive the attention that they deserve and, on many occasions, they are not considered or are only considered when the system development has finished. On the other hand, the use of model driven approaches has recently demonstrated to offer numerous benefits. This paper tries to align the use of a model driven development paradigm with the consideration of security requirements from early stages of software development (such as requirements elicitation). With this aim, a security requirements metamodel that formalizes the definition of this kind of requirements is proposed. Based on this metamodel, a Domain Specific Language (DSL) has been built which allows both the construction of requirements models with security features and the automatic generation of other software artefacts from them. An application example that illustrates the approach is also shown.},
key = {Network security},
keywords = {Computer software;Information systems;},
note = {Application examples;Automatic Generation;Domain specific languages;Meta model;Model driven approach;Model driven development;Requirements elicitation;Requirements Models;Security features;Security requirements;Software artefacts;Software development;System development;},
} 


@article{2001426691055 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Formal analysis of a space-craft controller using SPIN},
journal = {IEEE Transactions on Software Engineering},
author = {Havelund, K. and Lowry, M. and Penix, J.},
volume = {27},
number = {8},
year = {2001},
pages = {749 - 765},
issn = {00985589},
abstract = {This paper documents an application of the finite state model checker SPIN to formally analyze a multithreaded plan execution module. The plan execution module is one component of NASA's New Millennium Remote Agent, an artificial intelligence-based space-craft control system architecture which launched in October of 1998 as part of the DEEP SPACE 1 mission. The bottom layer of the plan execution module architecture is a domain specific language, named ESL (Executive Support Language), implemented as an extension to multithreaded COMMON LISP. ESL supports the construction of reactive control mechanisms for autonomous robots and space-craft. For this case study, we translated the ESL services for managing interacting parallel goal-and-event driven processes into the PROMELA input language of SPIN. A total of five previously undiscovered concurrency errors were identified within the implementation of ESL. According to the Remote Agent programming team, the effort has had a major impact, locating errors that would not have been located otherwise and, in one case, identifying a major design flaw. In fact, in a different part of the system, a concurrency bug identical to one discovered by this study escaped testing and caused a deadlock during an in-flight experiment 96 million kilometers from earth. The work additionally motivated the introduction of procedural abstraction in terms of inline procedures into SPIN.},
key = {Computer control},
keywords = {Artificial intelligence;Computer aided software engineering;Computer hardware description languages;Computer simulation;Concurrency control;Error detection;Intelligent robots;Mathematical models;Microcontrollers;Multitasking;Parallel algorithms;Remote consoles;Spacecraft;Supervisory and executive programs;},
note = {Concurrency errors;Verification systems;},
URL = {http://dx.doi.org/10.1109/32.940728},
} 


@inproceedings{20103713223229 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Application middleware for convergence of IP Multimedia system and Web Services},
journal = {MIPRO 2010 - 33rd International Convention on Information and Communication Technology, Electronics and Microelectronics, Proceedings},
author = {Budiselic, Ivan and Zuzak, Ivan and Benc, Ivan},
year = {2010},
pages = {507 - 512},
address = {Opatija, Croatia},
abstract = {Current network applications are typically created for one of two worlds. Communication applications targeting mobile devices usually communicate using the SIP protocol and are integrated into IP Multimedia systems of mobile network operators. On the other hand, applications targeting the enterprise market typically adhere to the SOAP protocol and integrate with Web Services exposed on the Internet. However, existing and future applications would benefit from access to services exposed by both of these protocols in both the mobile network and the Internet. In this paper we present the architecture of an application middleware that acts as a bidirectional gateway among IP Multimedia and Web Services systems. The middleware provides infrastructure for SIP and SOAP message handling, and session and network resource management. The middleware exposes interfaces for defining application specific rules for communication between protocol domains. Lastly, we outline a domain specific language that simplifies definition of such rules.},
key = {Internet protocols},
keywords = {Gateways (computer networks);Information technology;Internet;Microelectronics;Middleware;Mobile devices;Multimedia services;Multimedia systems;Web services;Wireless networks;},
note = {Application specific;Communication application;Domain specific languages;Enterprise market;Future applications;IP multimedia system;Mobile network operators;Mobile networks;Network applications;Network resource management;SIP protocol;SOAP messages;SOAP protocol;},
} 


@inproceedings{20085011773765 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {30th Internationa Conference on Software Engineering, ICSE 2008 Co-located Workshops - Proceedings of the 4th Internationa Workshop on End-user Software Engineering, WEUSE IV},
journal = {Proceedings - International Conference on Software Engineering},
editor = {},
year = {2008},
issn = {02705257},
address = {Leipzig, Germany},
abstract = {The proceedings contain 20 papers. The topics discussed include: using topes to validate and reform data in end-user programming tools; EUD for enterprise process and information management; opportunistic programming: how rapid ideation and prototyping occur in practice; gender in end-user software engineering; test-driven development: can it work for spreadsheets?; more natural end-user software engineering; teaching software engineering to end-users; using two heads in practice; end-user programming and the intrinsic complexity of networked artifacts; software design using UML for empowering end-users with an external domain specific language; spreadsheet debugging behaviour of expert and novice end-users; towards end-user programming with wikis; end users as unwitting software developers; software support for building end-user programming environments in the automation domain; and towards a user-oriented environment for web services composition.},
} 


@inproceedings{20084911761673 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Visualization, simulation and analysis of reconfigurable systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Ermel, Claudia and Ehrig, Karsten},
volume = {5088 LNCS},
year = {2008},
pages = {265 - 280},
issn = {03029743},
address = {Kassel, Germany},
abstract = {Meta-modeling is well known to define the basic concepts of domain-specific languages in an object-oriented way. Based on graph transformation, an abstract meta-model may be enhanced with information on concrete visualization of objects and relations, and the language syntax is defined by a graph grammar. Moreover, graph transformation can also formalize the semantic aspects of models, thus providing a basis for model validation by simulation. Apart from editing and simulating the behavior of a system, there may be necessary reconfiguration operations which change the underlying system structure at runtime. In this paper, we focus on the interrelation of simulation and reconfiguration operations using formal verification techniques based on graph transformation. Our approach is demonstrated by the definition of a domain-specific language for building, simulating and reconfiguring small railway systems, using the Tiger tool environment. For further verification, we define a model transformation from the railway domain to Petri nets. &copy; 2008 Springer Berlin Heidelberg.},
key = {Graph theory},
keywords = {Computer aided software engineering;Computer programming languages;Formal languages;Graphical user interfaces;Information theory;Linguistics;Marine biology;Object oriented programming;Petri nets;Query languages;Railroads;Semantics;Visualization;},
note = {Analysis;Graph transformation;Model transformation;Reconfigurable system;Simulation;},
URL = {http://dx.doi.org/10.1007/978-3-540-89020-1-19},
} 


@inproceedings{20104013271218 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A pattern-driven generation of security policies for Service-oriented Architectures},
journal = {ICWS 2010 - 2010 IEEE 8th International Conference on Web Services},
author = {Menzel, Michael and Warschofsky, Robert and Meinel, Christoph},
year = {2010},
pages = {243 - 250},
address = {Miami, FL, United states},
abstract = {Service-oriented Architectures support the provision, discovery, and usage of services in different application contexts. The Web Service specifications provide a technical foundation to implement this paradigm. Moreover, mechanisms are provided to face the new security challenges raised by SOA. To enable the seamless usage of services, security requirements can be expressed as security policies (e.g. WS-Policy and WSSecurityPolicy) that enable the negotiation of these requirements between clients and services. However, the codification of security policies is a difficult and error-prone task due to the complexity of the Web Service specifications. In this paper, we introduce our model-driven approach that facilitates the transformation of architecture models annotated with simple security intentions to security policies. This transformation is driven by security configuration patterns that provide expert knowledge on Web Service security. Therefore, we will introduce a formalised pattern structure and a domain-specific language to specify these patterns. &copy; 2010 IEEE.},
key = {Web services},
keywords = {Architecture;Information services;Problem oriented languages;Security systems;Specifications;},
note = {Application contexts;Architecture models;Domain specific languages;Error prones;Expert knowledge;Model driven approach;Pattern structure;Security challenges;Security policy;Security requirements;Service specifications;Web service security;WS-policy;WS-SecurityPolicy;},
URL = {http://dx.doi.org/10.1109/ICWS.2010.25},
} 


@inproceedings{20104713402173 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Embedded software development with projectional language workbenches},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Voelter, Markus},
volume = {6395 LNCS},
number = {PART 2},
year = {2010},
pages = {32 - 46},
issn = {03029743},
address = {Oslo, Norway},
abstract = {This paper describes a novel approach to embedded software development. Instead of using a combination of C code and modeling tools, we propose an approach where modeling and programming is unified using projectional language workbenches. These allow the incremental, domain-specific extension of C and a seamless integration between the various concerns of an embedded system. The paper does not propose specific extensions to C in the hope that everybody will use them; rather, the paper illustrates the benefits of domain specific extension using projectional editors. In the paper we describe the problems with the traditional approach to embedded software development and how the proposed approach can solve them. The main part of the paper describes our modular embedded language, a proof-of-concept implementation of the approach based on JetBrains MPS. We implemented a set of language extensions for embedded programming, such as state machines, tasks, type system extensions as well as a domain specific language (DSL) for robot control. The language modules are seamlessly integrated, leading to a very efficient way for implementing embedded software. &copy; 2010 Springer-Verlag.},
key = {Embedded systems},
keywords = {Embedded software;Models;Network components;Problem oriented languages;Robot programming;Software design;Unified Modeling Language;},
note = {C codes;Code Generation;Domain specific;Domain specific languages;Embedded Languages;Embedded programming;Embedded software development;Language extensions;Language workbenches;Modeling tool;projectional editing;Proof of concept;Robot controls;Seamless integration;State machine;Type systems;},
URL = {http://dx.doi.org/10.1007/978-3-642-16129-2_4},
} 


@inproceedings{20080311039829 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A language for quality of service requirements specification in web services orchestrations},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Baligand, Fabien and Botlan, Didier Le and Ledoux, Thomas and Combes, Pierre},
volume = {4652 LNCS},
year = {2007},
pages = {38 - 49},
issn = {03029743},
address = {Chicago, IL, United states},
abstract = {Service Oriented Architectures industry aims to deliver agile service infrastructures. In this context, solutions to specify service compositions (mostly BPEL language) and Quality of Service (QoS) of individual services have emerged. However, architects still lack adapted means to specify and implement QoS in service compositions. Typically, they use ad-hoc technical solutions that significantly reduce flexibility and require cost-effective development. Our approach aims to overcome this shortcoming by introducing both a new language and tool for QoS specification and implementation in service compositions. More specifically, our language is a declarative domain-specific language that allows the architect to specify QoS constraints and mechanisms in Web Service orchestrations. Our tool is responsible for the QoS constraints processing and for QoS mechanisms injection into the orchestration. A key property of our approach is to preserve compatibility with existing languages and standards. In this paper, we present our language and tool, as well as an illustrative scenario dealing with multiple QoS concerns. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Web services},
keywords = {Constraint theory;Cost effectiveness;Formal languages;Problem solving;Quality of service;},
note = {QoS specification;Service compositions;Service Oriented Architectures;Services orchestrations;},
} 


@inproceedings{2003097373334 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards dynamic meta modeling of UML extensions: An extensible semantics for UML sequence diagrams},
journal = {2001 IEEE Symposium on Human-Centric Computing},
author = {Hausmann, Jan Hendrik and Heckel, Reiko and Sauer, Stefan},
year = {2001},
pages = {80 - 87},
address = {Stresa, Italy},
abstract = {The Unified Modeling Language (UML) still lacks a formal and commonly agreed specification of its semantics that also accounts for UML's built-in semantic variation points and extension mechanisms. The semantics specification of such extensions must be formally integrated and consistent with the standard UML semantics without changing the latter Feasible semantics approaches must thus allow advanced UML modelers to define domain-specific language extensions in a precise, yet usable manner. We have proposed dynamic meta modeling for specifying operational semantics of UML behavioral diagrams based on UML collaboration diagrams that are interpreted as graph transformation rules. Herein we show how this approach can be advanced to specify the semantics of UML extensions. As a case study we specify the operational semantics of UML sequence diagrams and extend this specification to include features for modeling multimedia applications.},
key = {Computer programming},
keywords = {Graph theory;Mathematical transformations;Multimedia systems;Real time systems;Semantics;},
note = {Dynamic meta modeling;},
URL = {http://dx.doi.org/10.1109/HCC.2001.995242},
} 


@article{2002467198027 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Einstein summation for multidimensional arrays},
journal = {Computers and Mathematics with Applications},
author = {Ahlander, K.},
volume = {44},
number = {8-9},
year = {2002},
pages = {1007 - 1017},
issn = {08981221},
abstract = {One of the most common data structures, at least in scientific computing, is the multidimensional array. Some numerical algorithms may conveniently be expressed as a generalized matrix multiplication, which computes a multidimensional array from two other multidimensional arrays. By adopting index notation with the Einstein summation convention, an elegant tool for expressing generalized matrix multiplications is obtained. Index notation is the succinct and compact notation primarily used in tensor calculus. In this paper, we develop computer support for index notation as a domain specific language. Grammar and semantics are proposed, yielding an unambiguous interpretation algorithm. An object-oriented implementation of a C++ library that supports index notation is described. A key advantage with computer support of index notation is that the notational gap between a mathematical index notation algorithm and its implementation in a computer language is avoided. This facilitates program construction as well as program understanding. Program examples that demonstrate the close resemblance between code and the original mathematical formulation are presented. &copy; 2002 Elsevier Science Ltd. All rights reserved.},
key = {Data structures},
keywords = {Algorithms;C (programming language);Codes (symbols);Computational grammars;Computer simulation;Computer software;Matrix algebra;Semantics;Tensors;},
note = {Index notations;Multidimensional arrays;},
URL = {http://dx.doi.org/10.1016/S0898-1221(02)00210-9},
} 


@inproceedings{20113914361195 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Opening tel systems for teachers : A domain-specific modeling  model-driven engineering approach},
journal = {CSEDU 2011 - Proceedings of the 3rd International Conference on Computer Supported Education},
author = {Ouraiba, El Amine and Choquet, Christophe and Cottier, Philippe},
volume = {1},
year = {2011},
pages = {312 - 317},
address = {Noordwijkerhout, Netherlands},
abstract = {Despite their quality, few TEL systems are actually adopted in educational institutions. These educational technologies have not always the necessary flexibility for use in real educational contexts that often requiring the rapid adaptations to new and often unexpected events (Cottier et al., 2008). Indeed, TEL environements should be designed as "open" in which the teacher himself is able to lead the adaptation and reengineering of learning system at an abstract level. In our work, we consider that opening of pedagogical scenario allows for the opening of TEL system. This article focuses on an approach based on the Domain- Specific Modeling and Model-driven Engineering for supporting practitioner teachers in their activities through the instructional design process. In order to verify our proposal we took Hop3x as experimentation field. Our objective is to open this TEL system for its users by providing them a user-friendly editor which allows the design and adaptation of learning sessions at a high-level of abstraction. We illustrate the development process of Hop3x's Domain-Specific Language and specific editor.},
key = {Teaching},
keywords = {Abstracting;Design;Learning systems;Problem oriented languages;},
note = {Domain specific modeling;Instructional designs;Learning sessions;Model-driven Engineering;Open technology;Pedagogical scenarios;},
} 


@article{2006269957438 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Dynamic optimization for functional reactive programming using Generalized Algebraic Data Types},
journal = {ACM SIGPLAN Notices},
author = {Nilsson, Henrik},
volume = {40},
number = {9},
year = {2005},
pages = {54 - 65},
issn = {03621340},
abstract = {A limited form of dependent types, called Generalized Algebraic Data Types (GADTs), has recently been added to the list of Haskell extensions supported by the Glasgow Haskell Compiler. Despite not being full-fledged dependent types, GADTs still offer considerably enlarged scope for enforcing important code and data invariants statically. Moreover, GADTs offer the tantalizing possibility of writing more efficient programs since capturing invariants statically through the type system sometimes obviates entire layers of dynamic tests and associated data markup. This paper is a case study on the applications of GADTs in the context of Yampa, a domain-specific language for Functional Reactive Programming in the form of a self-optimizing, arrow-based Haskell combinator library. The paper has two aims. Firstly, to explore what kind of optimizations GADTs make possible in this context. Much of that should also be relevant for other domain-specific embedded language implementations, in particular arrow-based ones. Secondly, as the actual performance impact of the GADT-based optimizations is not obvious, to quantify this impact, both on tailored micro benchmarks, to establish the effectiveness of individual optimizations, and on two fairly large, realistic applications, to gauge the overall impact. The performance gains for the micro benchmarks are substantial. This implies that the Yampa API could be simplified as a number of "pre-composed" primitives that were there mainly for performance reasons are no longer needed. As to the applications, a worthwhile performance gain was obtained in one case whereas the performance was more or less unchanged in the other. Copyright &copy; 2005ACM.},
key = {Structured programming},
keywords = {Database systems;Dynamic programming;Embedded systems;Optimization;Program compilers;},
note = {Arrows;Combinator library;Domain specific languages;FRP;Functional programming;GADT;Haskell;Synchronous dataflow languages;Yampa;},
URL = {http://dx.doi.org/10.1145/1090189.1086374},
} 


@inproceedings{1996323214956 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Teapot: language support for writing memory coherence protocols},
journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
author = {Chandra, Satish and Richards, Brad and Larus, James R.},
year = {1996},
pages = {237 - 248},
address = {Philadelphia, PA, USA},
abstract = {Recent shared-memory parallel computer systems offer the exciting possibility of customizing memory coherence protocols to fit an application's semantics and sharing patterns. Custom protocols have been used to achieve message-passing performance - while retaining the convenient programming model of a global address space - and to implement high-level language constructs. Unfortunately, coherence protocols written in a conventional language such as C are difficult to write, debug, understand, or modify. This paper describes Teapot, a small, domain-specific language for writing coherence protocols. Teapot uses continuations to help reduce the complexity of writing protocols. Simple static analysis in the Teapot compiler eliminates much of the overhead of continuations and results in protocols that run nearly as fast as hand-written C code. A Teapot specification can be compiled both to an executable coherence protocol and to input for a model checking system, which permits the specification to be verified. We report our experiences coding and verifying several protocols written in Teapot, along with measurements of the overhead incurred by writing a protocol in a higher-level language.},
key = {Computer hardware description languages},
keywords = {C (programming language);Computer systems programming;Data storage equipment;Encoding (symbols);Error detection;High level languages;Network protocols;Parallel processing systems;Program compilers;Program debugging;},
note = {Memory coherence protocols;Model checking system;Programming model;Teapot programming language;},
} 


@article{20063210048557 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards an insider threat prediction specification language},
journal = {Information Management and Computer Security},
author = {Magklaras, G.B. and Furnell, S.M. and Brooke, P.J.},
volume = {14},
number = {4},
year = {2006},
pages = {361 - 381},
issn = {09685227},
abstract = {Purpose - This paper presents the process of constructing a language tailored to describing insider threat incidents, for the purposes of mitigating threats originating from legitimate users in an IT infrastructure. Design/methodology/approach - Various information security surveys indicate that misuse by legitimate (insider) users has serious implications for the health of IT environments. A brief discussion of survey data and insider threat concepts is followed by an overviewof existing research efforts to mitigate this particular problem. None of the existing insider threat mitigation frameworks provide facilities for systematically describing the elements of misuse incidents, and thus all threat mitigation frameworks could benefit from the existence of a domain specific language for describing legitimate user actions. Findings - The paper presents a language development methodology which centres upon ways to abstract the insider threat domain and approaches to encode the abstracted information into language semantics. The language construction methodology is based upon observed information security survey trends and the study of existing insider threat and intrusion specification frameworks. Originality/value - This paper summarizes the picture of the insider threat in IT infrastructures and provides a useful reference for insider threat modeling researchers by indicating ways to abstract insider threats.},
key = {Security of data},
keywords = {Computer hardware description languages;Information technology;Semantics;},
note = {Information security survay;Information systems;Language semantics;Mitigation frameworks;},
URL = {http://dx.doi.org/10.1108/09685220610690826},
} 


@inproceedings{20110813676801 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Adopting software engineering practices to network processor devices: Introducing the domain specific modeling paradigm to the ForCES framework},
journal = {Proceedings of the 2010 International Conference on Network and Service Management, CNSM 2010},
author = {Haleplidis, Evangelos and Tranoris, Christos and Denazis, Spyros and Koufopavlou, Odysseas},
year = {2010},
pages = {366 - 369},
address = {Niagara Falls, ON, Canada},
abstract = {IETF's new Forwarding and Control Element Separation (ForCES) architecture specifies the ForCES model providing an accurate description of the Forwarding Plane in an Object-Oriented fashion. However, the model is described totally in an XML Schema Definition (XSD): it is well-defined but purely machine oriented, being readable and usable, thus not human-friendly and difficult extending itself in the future. We argue that the ForCES model is actually a meta-model that is used to model ForCES components, e.g. Logical Function Blocks (LFBs), that later are used in ForCES applications. This paper presents a methodology based on a case study on how to automate the process of configuring the forwarding plane of network devices using state-of-the-art model-driven techniques in a tangible way while specifying a tool supported by a Domain Specific Language (DSL) for ForCES. We first consider describing the ForCES XSD based meta-model to a more manageable Ecore (MOF) based meta-model and then we create a DSL based on this Ecore meta-model. Then we target to transform automatically a Platform Independent ForCES model specified in the DSL to an executable target source code (Platform Specific: XML-ForCES compliant, C++, Java) able to communicate with the ForCES protocol. &copy; 2010 IEEE.},
key = {Network management},
keywords = {Arts computing;Mathematical models;Software engineering;XML;},
note = {ART model;Domain specific languages;Domain specific modeling;Ecore;ForCES model;Forwarding and control element separations;Human-friendly;Logical functions;Meta model;Meta-modelling;Network devices;Network processor;Object oriented;Platform independent;Software engineering practices;Target source;Xml schema definitions;},
URL = {http://dx.doi.org/10.1109/CNSM.2010.5691237},
} 


@inproceedings{20095212579642 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The anti-goldilocks debugger: Helping the average bear debug transparently transformed programs},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Song, Myoungkyu and Tilevich, Eli},
year = {2009},
pages = {811 - 812},
address = {Orlando, FL, United states},
abstract = {The practice of enhancing the bytecode of Plain Old Java Objects (POJOs) with additional capabilities, including persistence, distribution, and security, has become an indispensable part of enterprise software development. The resulting transparently-applied, large-scale structural changes to the bytecode significantly complicate symbolic debugging. This demonstration will showcase the Anti-Goldilocks Java (AGJ) debugger, which enables the programmer to trace and debug transparently transformed programs, without the distraction of the bytecode-level enhancements obfuscating the program's source code. AGJ executes a structurally-enhanced program, while dynamically reinterpreting the debugging output (e.g., 'step', 'print variable', etc.) to display program information as pertaining to the original version of the code. AGJ is based on a new debugging architecture that leverages our domain-specific language for describing enhancements. A paper in the main technical program of OOPSLA 2009 [5] describes the design rationale and implementation details of AGJ. This demonstration will showcase the functionality of our reference implementation by using it to locate bugs in a framework-based enterprise application from the financial industry. Using the domain of transparent persistence, this demonstration will compare AGJ to the standard JDK debugger, thereby highlighting the capabilities of AGJ to cut through the morass of transparent bytecode enhancements in order to find obscure bugs.},
key = {Program debugging},
keywords = {Computer software;Computer systems programming;Demonstrations;Java programming language;Linguistics;Object oriented programming;Problem oriented languages;Query languages;},
note = {Bytecodes;Cut-through;Debuggers;Design rationale;Domain specific languages;Enterprise applications;Enterprise software;Financial industry;Java objects;Program transformations;Reference implementation;Source codes;Structural change;Technical programs;},
URL = {http://dx.doi.org/10.1145/1639950.1640027},
} 


@inproceedings{20072010600698 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based DSL frameworks},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Kurtev, Ivan and Bezivin, Jean and Jouault, Frederic and Valduriez, Patrick},
volume = {2006},
year = {2006},
pages = {602 - 615},
address = {Portland, OR, United states},
abstract = {More than five years ago, the OMG proposed the Model Driven Architecture (MDA) approach to deal with the separation of platform dependent and independent aspects in information systems. Since then, the initial idea of MDA evolved and Model Driven Engineering (MDE) is being increasingly promoted to handle separation and combination of various kinds of concerns in software or data engineering. MDE is more general than the set of standards and practices recommended by the OMG's MDA proposal. In MDE the concept of model designates not only OMG models but a lot of other artifacts like XML documents, Java programs, RDBMS data, etc. Today we observe another evolutionary step. A convergence between MDE and DSL (Domain Specific Language) engineering is rapidly appearing. In the same way as MDE is a generalization of MDA, the DSL engineering may be viewed as a generalization of MDE. One of the goals of this paper is to explore the potential of this important evolution of engineering practices. In order to anchor the discussion on practical grounds, we present a set of typical problems that could be solved by classical (object-oriented and others), MDE, or DSL-based techniques. Solutions to these problems will be based on current platforms (EMF, AMMA, GME, etc.). This paper illustrates how powerful model-based frameworks, allowing to use and build a variety of DSLs, may help to solve complex problems in a more efficient way.},
key = {Computer architecture},
keywords = {Information retrieval systems;Java programming language;Problem solving;XML;},
note = {DSL engineering;Model-driven engineering;Tool-based approaches;},
URL = {http://dx.doi.org/10.1145/1176617.1176632},
} 


@article{1999484835274 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Adapting distributed applications using extensible networks},
journal = {Proceedings - International Conference on Distributed Computing Systems},
author = {Thibault, Scott and Marant, Jerome and Muller, Gilles},
year = {1999},
pages = {234 - 243},
address = {Austin, TX, USA},
abstract = {Active networks have been proposed to allow the dynamic extension of network behavior by downloading application-specific protocols (ASPs) into network routers. In this paper, we demonstrate feasibility of the use of ASPs in an active network for the adaptation of distributed software components. We have implemented three examples which show that ASPs can be used to easily extend distributed applications, and furthermore, that such adaptation can be safe, portable and efficient. Safety and efficiency is obtained by implementing the ASPs in PLAN-P, a domain-specific language and run-time system for active networking. The presented examples illustrate three different applications: (i) audio broadcasting with bandwidth adaptation in routers, (ii) an extensible HTTP server with load-balancing facilities, (iii) a multipoint MPEG server derived from a point-to-point server.},
key = {Computer networks},
keywords = {Bandwidth;Client server computer systems;Computer programming languages;Computer software;Computer software reusability;Information theory;Network protocols;Security of data;},
note = {Application specific protocols;Distributed software components;},
} 


@inproceedings{2001436705741 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {High-level adaptive program optimization with ADAPT},
journal = {Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPOPP},
author = {Voss, M.J. and Eigenmann, R.},
year = {2001},
pages = {93 - 102},
address = {Snowbird, UT, United states},
abstract = {Compile-time optimization is often limited by a lack of target machine and input data set knowledge. Without this information, compilers may be forced to make conservative assumptions to preserve correctness and to avoid performance degradation. In order to cope with this lack of information at compile-time, adaptive and dynamic systems can be used to perform optimization at runtime when complete knowledge of input and machine parameters is available. This paper presents a compiler-supported high-level adaptive optimization system. Users describe, in a domain specific language, optimizations performed by stand-alone optimization tools and backend compiler flags, as well as heuristics for applying these optimizations dynamically at runtime. The ADAPT compiler reads these descriptions and generates application-specific runtime systems to apply the heuristics. To facilitate the usage of existing tools and compilers, overheads are minimized by decoupling optimization from execution. Our system, ADAPT, suppor ts a range of paradigms proposed recently, including dynamic compilation, parameterization and runtime sampling. We demonstrate our system by applying several optimization techniques to a suite of benchmarks on two target machines. ADAPT is shown to consistently outperform statically generated executables, improving performance by as much as 70%.},
key = {High level languages},
keywords = {Benchmarking;Computer operating systems;Database systems;Optimization;Program compilers;},
note = {Compile-time optimization;},
URL = {http://dx.doi.org/10.1145/379539.379583},
} 


@article{20113214209692 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Zebu: A language-based approach for network protocol message processing},
journal = {IEEE Transactions on Software Engineering},
author = {Burgy, Laurent and Reveillere, Laurent and Lawall, Julia and Muller, Gilles},
volume = {37},
number = {4},
year = {2011},
pages = {575 - 591},
issn = {00985589},
address = {445 Hoes Lane / P.O. Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {A network application communicates with other applications according to a set of rules known as a protocol. This communication is managed by the part of the application known as the protocol-handling layer, which enables the manipulation of protocol messages. The protocol-handling layer is a critical component of a network application since it represents the interface between the application and the outside world. It must thus satisfy two constraints: It must be efficient to be able to treat a large number of messages and it must be robust to face various attacks targeting the application itself or the underlying platform. Despite these constraints, the development process of this layer still remains rudimentary and requires a high level of expertise. It includes translating the protocol specification written in a high-level formalism such as ABNF toward low-level code such as C. The gap between these abstraction levels can entail many errors. This paper proposes a new language-based approach to developing protocol-handling layers, to improve their robustness without compromising their performance. Our approach is based on the use of a domain-specific language, Zebu, to specify the protocol-handling layer of network applications that use textual HTTP-like application protocols. The Zebu syntax is very close to that of ABNF, facilitating the adoption of Zebu by domain experts. By annotating the original ABNF specification of a protocol, the Zebu user can dedicate the protocol-handling layer to the needs of a given application. The Zebu compiler first checks the annotated specification for inconsistencies, and then generates a protocol-handling layer according to the annotations. This protocol-handling layer is made up of a set of data structures that represent a message, a parser that fills in these data structures, and various stub functions to access these data structures or drive the parsing of a message. &copy; 2006 IEEE.},
key = {Hypertext systems},
keywords = {Data structures;Graphical user interfaces;Network layers;Network protocols;Problem oriented languages;Specifications;},
note = {Abstraction level;Application protocols;Critical component;Development process;Domain experts;Domain specific languages;message composing;message parsing;Network applications;Other applications;Protocol message;Protocol specifications;Set of rules;Various attacks;},
URL = {http://dx.doi.org/10.1109/TSE.2010.64},
} 


@inproceedings{2001436705826 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Facile: A language and compiler for high-performance processor simulators},
journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
author = {Schnarr, E.C. and Hill, M.D. and Larus, J.R.},
year = {2001},
pages = {321 - 331},
address = {Snowbird, UT, United states},
abstract = {Architectural simulators are essential tools for computer architecture and systems research and development. Simulators, however, are becoming frustratingly slow, because they must now model increasingly complex micro-architectures running realistic workloads. Previously, we developed a technique called fast-forwarding, which applied partial evaluation and memoization to improve the performance of detailed architectural simulations by as much as an order of magnitude. While writing a detailed processor simulator is difficult, implementing fast-forwarding is even more complex. This paper describes Facile, a domain-specific language for writing detailed, accurate micro-architecture simulators. Architectural descriptions written in Facile can be compiled, using partial evaluation techniques, into fast-forwarding simulators that achieve significant performance improvements with far less programmer effort. Facile and its compiler make this performance-enhancing technique accessible to computer architects.},
key = {Program compilers},
keywords = {Computer architecture;Computer programming languages;Computer simulation;Program processors;},
note = {High-performance processor simulators;},
URL = {http://dx.doi.org/10.1145/378795.378864},
} 


@inproceedings{20110413607594 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Defining and observing the compliance of service level agreements: A model driven approach},
journal = {Proceedings - 7th International Conference on the Quality of Information and Communications Technology, QUATIC 2010},
author = {Correia, Anacleto and E Abreu, Fernando Brito},
year = {2010},
pages = {165 - 170},
address = {Porto, Portugal},
abstract = {IT Service Management (ITSM) is the set of processes that allow planning, organizing, directing and controlling the provisioning of IT services. Among the concerns of ITSM, namely within the service level management process, are the requirements for services availability, performance, accuracy, capacity and security, which are specified in terms of service-level agreements (SLA). SLA definition and monitoring are open issues within the ITSM domain. This paper overviews an ongoing research initiative concerned with three specific problems in this context: (1) SLAs in the context of ITSM are informally specified in natural language; (2) SLAs specifications are not grounded on models of ITSM processes; (3) SLAs compliance verification in IT services is not performed at the same level of abstraction as service design. To mitigate those problems, we propose a model-based approach to IT services SLA specification and compliance verification. The specification part will be based on a SLA language - a domain specific language (DSL) for defining quality attributes as non functional requirements (NFRs) in the context of ITSM. Its metamodel will be an extension of the metamodel of the adopted process modeling language. As such, it will be possible to ground SLA definition on the corresponding IT service model constructs. SLA monitoring and compliance validation will occur at the same abstraction level as service specification, therefore being understood by all stakeholders. &copy; 2010 IEEE.},
key = {Information technology},
keywords = {Abstracting;Access control;Planning;Software architecture;Specifications;},
note = {BPMN;Domain specific languages;IT service management;ITIL;MDA;Meta model;Process model;Service Level Agreements;Service level management;},
URL = {http://dx.doi.org/10.1109/QUATIC.2010.32},
} 


@inproceedings{20104513356379 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {End-user visual design of web-based interactive applications making use of geographical information: The WINDMash approach},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Luong, The Nhan and Etcheverry, Patrick and Nodenot, Thierry and Marquesuzaa, Christophe and Lopisteguy, Philippe},
volume = {6383 LNCS},
year = {2010},
pages = {536 - 541},
issn = {03029743},
address = {Barcelona, Spain},
abstract = {Visual instructional design languages currently provide notations for representing the intermediate and final results of a knowledge engineering process. This paper reports on a visual framework (called WIND - Web INteraction Design) that focuses on both designers' creativity and model executability. It only addresses Active Reading Learning Scenarios making use of localized documents (travel stories, travel guides). Our research challenge is to enable the teachers to design by themselves interaction scenarios for such a domain, avoiding any programmer intervention. The WIND framework provides a conceptual model and its associated Application Programming Interface (API). The WIND interaction scenarios are encoded as XML documents which are automatically transformed into code thanks to the provided API, thus providing designers with a real application that they can immediately assess and modify (prototyping techniques). The WIND conceptual model only provides designers with an abstract syntax and a semantics. Users of such a Domain Specific Language (DSL) need a concrete syntax. Our choice is to produce a Web-Based Mashup Environment providing designers with visual functionality. &copy; 2010 Springer-Verlag Berlin Heidelberg.},
key = {Design},
keywords = {Application programming interfaces (API);Innovation;Knowledge engineering;Semantic Web;Syntactics;Technology;},
note = {Abstract syntax;Active reading;Conceptual model;Concrete syntax;Domain specific languages;End users;Geographical information;Interaction design;Interactive applications;Learning scenarios;Mash-up;Prototyping;Real applications;Research challenges;Visual design;Visual instructional design language;Web interactions;},
URL = {http://dx.doi.org/10.1007/978-3-642-16020-2_50},
} 


@inproceedings{2003187452402 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Quick Piping: A fast, high-level model for describing processor pipelines},
journal = {Joint COnference on Languages, Compilers and Tools for Embedded Systems and Software and Compilers for Embedded Systems},
author = {Milner, Christopher W. and Davidson, Jack W.},
year = {2002},
pages = {175 - 184},
address = {Berlin, Germany},
abstract = {Responding to marketplace needs, today's embedded processors must feature a flexible core that allows easy modification with fast time to market. In this environment, embedded processors are increasingly reliant on flexible support tools. This paper presents one such tool, called Quick Piping, a new, high-level formalism for modeling processor pipelines. Quick Piping consists of three primary components that together provide an easy-to-build, reusable processor description: Pipeline graphs - a new high-level formalism for modeling processor pipelines, pipe - a companion domain-specific language for specifying a pipeline graph, pipe miner - a compiler specification generator for pipe descriptions, pipe miner processes a pipe description and produces a compiler specification that is used to build a compiler that reads the corresponding machine's instruction set and automatically generates resource vectors. Despite their ubiquity and importance in achieving high performance in modern processors, pipelines - and improving the mechanisms for specifying their operation - have received little attention. Until now, handwritten resource vectors have served to specify information about a processor's pipeline and encode relevant information about each instruction's resource usage. Describing the complete set of resource vectors for a machine can be quite tedious and error prone, since it commonly must be developed by hand on an instruction-by-instruction basis. With its use of pipeline graphs, the pipe language, and the pipe miner compiler specification generator, Quick Piping gives the embedded processor architect and compiler writer an intuitive high-level abstraction of pipelines, a language for specifying a pipeline, and a tool for automatically producing pipeline resource vectors. The resulting specifications are quick to develop, easy to understand, simple to modify and maintain, and can be automatically processed to produce the low-level information required by processor control units and instruction schedulers.},
key = {Program processors},
keywords = {Computer aided software engineering;Computer architecture;Data mining;Embedded systems;},
note = {Processor pipelines;},
URL = {http://dx.doi.org/10.1145/513829.513859},
} 


@inproceedings{20073510784500 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Interactive, scalable, declarative program analysis: From prototype to implementation},
journal = {PPDP'07: Proceedings of the 9th International ACM SIGPLAN Conference on Principles and Practice of Declarative Programming},
author = {Benton, William C. and Fischer, Charles N.},
year = {2007},
pages = {13 - 24},
address = {Wroclaw, Poland},
abstract = {Static analyses provide the semantic foundation for tools ranging from optimizing compilers to refactoring browsers and advanced debuggers. Unfortunately, developing new analysis specifications and implementations is often difficult and error-prone. Since analysis specifications are generally written in a declarative style, logic programming presents an attractive model for producing executable specifications of analyses. However, prior work on using logic programming for program analysis has focused exclusively on solving constraints derived from program texts by an external preprocessor. In this paper, we present DIMPLE, an analysis framework for Java bytecodes implemented in the Yap Prolog system [8]. DIMPLE provides both a representation of Java bytecodes in a database of relations and a declarative domain-specific language for specifying new analyses as queries over this database. DIMPLE thus enables researchers to use logic programming for every step of the analysis development process, from specification to prototype to implementation. We demonstrate that our approach facilitates rapid prototyping of new program analyses and produces executable analysis implementations that are speed-competitive with specialized analysis toolkits. Copyright &copy; 2007 ACM.},
key = {Program compilers},
keywords = {Codes (symbols);Interactive computer systems;Java programming language;Logic programming;Semantics;Software prototyping;},
note = {Bytecodes;Program analysis;Tabled prolog;},
URL = {http://dx.doi.org/10.1145/1273920.1273923},
} 


@inproceedings{20111113743219 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {On instance-model querying and meta-model transformation},
journal = {Proceedings of the International MultiConference of Engineers and Computer Scientists 2010, IMECS 2010},
author = {Nguyen, Viet Cuong and Qafmolla, Xhevi},
year = {2010},
pages = {710 - 715},
address = {Kowloon, Hong kong},
abstract = {In today's market environment, change is an integral part of all projects. As such, its proper management is a crucial task when it comes to reducing both time and cost of development. The classical modeling approach can improve the situation up to a proper extent but it is not enough, because the process is usually variable and complex. Therefore it is necessary to introduce different level of abstractions for modeling. Each of these levels should serve at a certain phase for a certain purpose in the process. In the early stages several elements are grouped together and aggregated at the higher level, in an abstract model. Throughout time, granularity becomes smaller while understanding of the concepts becomes clearer and clearer and we need to see already working prototypes. In this situation, the approaches on instance- and meta-modeling techniques promise to bring productivity and efficiency to the process. This paper outlines practices from both approaches. We introduce the approach of using Object Constraint Language (OCL) with a Domain Specific Language (DSL) for instance-level model querying, illustrating this method with some examples. We analyze OCL from the broad perspective discussing its advantages and pointing out some its limitations. Moving to a higher level of abstraction, we also present the usage of Kermeta - an extension to the meta-data language with an action language for specifying semantics and behavior of meta-models. We show how Kermeta provides the possibility of automated meta-model transformations.},
key = {Mathematical models},
keywords = {Abstracting;Engineers;Semantics;},
note = {Domain specific languages;Instance-model;Kermeta;Meta model;Model driven development;OCL;},
} 


@article{20104213305954 ,
language = {Portuguese},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proposal of a new architecture for using the dynamic object model},
title = {Proposta de uma nova arquitetura para utilizacao do modelo de objetos dinamicos},
journal = {IEEE Latin America Transactions},
author = {Cardoso, Paulo Eduardo and Ferreira, Mauricio Goncalves Vieira},
volume = {5},
number = {3},
year = {2007},
pages = {177 - 184},
issn = {15480992},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {The National Institute for Space Research (INPE) has always developed satellite control systems with architectures that may be used as much as possible by future satellites. The present challenge is to build an Adaptive Satellite Control System, using the technology of the Dynamic Object Model, so as to comply with later requirements without having to make significant changes in the code. According to this technology, object structures and their behavior are mapped onto a database, so end-users can modify them by using configuration tools and, possibly, a domain specific language. This paper proposes a Dynamic Object System, using an architecture that facilitates its long term use by the satellite control systems. The paper also presents a new approach for representing Dynamic Objects, based on a tree of entities and properties. &copy; Copyright 2010 IEEE - All Rights Reserved.},
key = {Adaptive control systems},
keywords = {Architecture;Control theory;Satellites;Space research;},
note = {Domain specific languages;Dynamic object models;Dynamic objects;End-users;Long term;New approaches;Object structure;Satellite control systems;},
URL = {http://dx.doi.org/10.1109/TLA.2007.4378502},
} 


@inproceedings{20083811547657 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {IDEA: A new intrusion detection data source},
journal = {Proceedings of the 2nd International Conference on Information Security and Assurance, ISA 2008},
author = {Mahoney, William and Sousan, William},
year = {2008},
pages = {15 - 19},
address = {Busan, Korea, Republic of},
abstract = {In the context of computer systems, an intrusion is generally considered to be a harmful endeavor to prevent others from legitimate use of that system, to obtain data which is not normally available to the intruder, or to plant data or disrupt data already existent on the machines. Traditionally intrusion detection has relied on two data sources: various log flies which record user's activity, and network traffic which contains potential threats. This research presents a system which we call IDEA; the Intrusion DEtection Automata system. We utilize a third source of data for intrusion detection in the form of an instrumented process. Open source software is recompiled using a modified compiler we have created, and the resulting executable program generates the data as it runs. An external monitoring facility then checks the behavior of the program against known good execution paths. These paths are specified either using a domain specific language and hand-written rules, or by running the software in a learning mode and capturing the normal behavior for later comparison. &copy; 2008 IEEE.},
key = {Intrusion detection},
keywords = {Computer networks;Computer systems;Information services;Internet;Open systems;Program compilers;},
note = {Data sourcing;Information security;International conferences;},
URL = {http://dx.doi.org/10.1109/ISA.2008.32},
} 


@inproceedings{20080411049021 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Easying MR development with eclipse and InTml},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Figueroa, Pablo and Florez, Camilo},
volume = {4842 LNCS},
number = {PART 2},
year = {2007},
pages = {760 - 769},
issn = {03029743},
address = {Lake Tahoe, NV, United states},
abstract = {This paper shows our work in progress towards an easy to use development environment for Mixed Reality (MR) Applications. We argue that development of MR applications is a collaboration between interaction designers who know about user requirements, and expert developers who know the intricacies of MR development. This collaboration should be supported by tools that aid both roles and ease their communication. We also argue that real MR development should allow easy migration from one hardware setup to another, since hardware greatly varies in these type of applications, and it is important to fit a solution to the particular user's requirements and context. We show the foundational concepts in our work and current Integrated Development Environment (IDE) implementation. This work is based on InTmI, a domain specific language for MR applications, and Eclipse, an open source, general purpose IDE. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Interactive computer systems},
keywords = {Computer programming languages;Computer supported cooperative work;},
note = {Mixed Reality (MR) Applications;User requirements;},
} 


@inproceedings{2002116884912 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {KelpIO: A telescope-ready domain-specific I/O library for irregular block-structured applications},
journal = {Future Generation Computer Systems},
author = {Broom, Bradley and Fowler, Rob and Kennedy, Ken},
volume = {18},
number = {4},
year = {2002},
pages = {449 - 460},
issn = {0167739X},
address = {Brisbane, Australia},
abstract = {To ameliorate the need to spend significant programmer time modifying parallel programs to achieve high-performance, while maintaining compact, comprehensible source codes, this paper advocates the use of telescoping languages technology to automatically apply, during the normal compilation process, high-level performance enhancing transformations to applications using a high-level domain-specific I/O library. We believe that this approach will be more acceptable to application developers than new language extensions, but will be just as amenable to optimization by advanced compilers, effectively making it a domain-specific language extension for I/O. The paper describes a domain-specific I/O library for irregular block-structured applications based on the KeLP library, describes high-level transformations of the library primitives for improving performance, and describes how a high-level domain-specific optimizer for applying these transformations could be constructed using the telescoping languages framework. &copy; 2002 Published by Elsevier Science B.V.},
key = {Digital libraries},
keywords = {High level languages;Input output programs;Mathematical transformations;Optimization;Parallel processing systems;Program compilers;Structured programming;},
note = {Block-structured applications;Domain-specific languages;},
URL = {http://dx.doi.org/10.1016/S0167-739X(01)00072-3},
} 


@inproceedings{20084411664201 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Code generation by model transformation a case study in transformation modularity},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Hemel, Zef and Kats, Lennart C. L. and Visser, Eelco},
volume = {5063 LNCS},
year = {2008},
pages = {183 - 198},
issn = {03029743},
address = {Zurich, Switzerland},
abstract = {The realization of model-driven software development requires effective techniques for implementing code generators. In this paper, we present a case study of code generation by model transformation with Stratego, a high-level transformation language based on the paradigm of rewrite rules with programmable strategies that integrates model-to-model, model-to-code, and code-to-code transformations. The use of concrete object syntax guarantees syntactic correctness of code patterns, and enables the subsequent transformation of generated code. The composability of strategies supports two dimensions of transformation modularity. Vertical modularity is achieved by designing a generator as a pipeline of model-to-model transformations that gradually transforms a high-level input model to an implementation. Horizontal modularity is achieved by supporting the definition of plugins which implement all aspects of a language feature. We discuss the application of these techniques in the implementation of WebDSL, a domain-specific language for dynamic web applications with a rich data model. &copy; Springer-Verlag Berlin Heidelberg 2008.},
key = {Mathematical models},
keywords = {Codes (symbols);Cosine transforms;High level languages;Linguistics;Network components;Pipelines;Syntactics;},
note = {Case studies;Code generations;Code generators;Code patterns;Code transformations;Composability;Concrete Object syntaxes;Data models;Dynamic web applications;Implementing;Input models;Language features;Level transformations;Model transformations;Model-driven software developments;Modularity;Plugins;Rewrite rules;Specific languages;Stratego;Syntactic;Two dimensions;},
URL = {http://dx.doi.org/10.1007/978-3-540-69927-9_13},
} 


@inproceedings{2001316601363 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A language for software subsystem composition},
journal = {Proceedings of the Hawaii International Conference on System Sciences},
author = {Buffenbarger, J. and Gruell, K.},
year = {2001},
pages = {292 - },
issn = {10603425},
address = {Maui, HI, United states},
abstract = {A software system often consists of thousands of source files, which must be translated into thousands of intermediate files, which eventually must be translated into some small number of library and executable files. Collectively, these steps compose its build process. A large software system can be difficult to build. The steps can be numerous and complex. Of course, there are a variety of tools to assist us (e.g., Make), but their languages emphasize the specification of low-level details (e.g., compiler names and options), rather than high-level attributes (e.g., host/target platforms and required subsystems). This paper describes a new domain-specific language for specifying the composition and construction of a software system, where the emphasis is on high-level attributes. A specification is processed by a pipeline of fairly simple tools to produce a set of makefiles, which are then processed by Make in the usual way.},
key = {Computer software},
keywords = {Computer aided software engineering;Computer programming languages;Digital libraries;},
note = {Source files;},
} 


@article{1999424775344 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Machine-independent debugger - revisited},
journal = {Software - Practice and Experience},
author = {Hanson, David R.},
volume = {29},
number = {10},
year = {1999},
pages = {849 - 862},
issn = {00380644},
address = {Chichester, United Kingdom},
abstract = {Most debuggers are notoriously machine-dependent, but some recent research prototypes achieve varying degrees of machine-independence with novel designs. Cdb, a simple source-level debugger for C, is completely independent of its target architecture. This independence is achieved by embedding symbol tables and debugging code in the target program, which costs both time and space. This paper describes a revised design and implementation of cdb that reduces the space cost by nearly one-half and the time cost by 13 per cent by storing symbol tables in external files. A symbol table is defined by a 31-line grammar in the Abstract Syntax Description Language (ASDL). ASDL is a domain-specific language for specifying tree data structures. The ASDL tools accept an ASDL grammar and generate code to construct, read, and write these data structures. Using ASDL automates implementing parts of the debugger, and the grammar documents the symbol table concisely. Using ASDL also suggested simplifications to the interface between the debugger and the target program. Perhaps most important, ASDL emphasizes that symbol tables are data structures, not file formats. Many of the pitfalls of working with low-level file formats can be avoided by focusing instead on high-level data structures and automating the implementation details.},
key = {Program debugging},
keywords = {Automation;Codes (symbols);Computational grammars;Computer programming languages;Data structures;Interfaces (computer);Program compilers;},
note = {Abstract syntax description language;Domain-specific languages;},
URL = {http://dx.doi.org/10.1002/(SICI)1097-024X(199908)29:10<849::AID-SPE260>3.0.CO;2-T},
} 


@inproceedings{2005229130896 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {LPS: A language prototyping system using modular monadic semantics},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Labra Gayo, J.E. and Luengo Diez, M.C. and Cueva Lovelle, J.M. and Cernuda Del Rio, A.},
volume = {44},
number = {2},
year = {2001},
pages = {115 - 136},
issn = {15710661},
address = {Genova, Italy},
abstract = {This paper describes LPS, a Language Prototyping System that facilitates the modular development of interpreters from semantic building blocks. The system is based on the integration of ideas from Modular Monadic Semantics and Generic Programming. To define a new programming language, the abstract syntax is described as the fixpoint of non-recursive pattern functors. For each functor an algebra is defined whose carrier is the computational monad obtained from the application of several monad transformers to a base monad. The interpreter is automatically generated by a catamorphism or, in some special cases, a monadic catamorphism. The system has been implemented as a domain-specific language embedded in Haskell and we have also implemented an interactive framework for language testing. &copy;2001 Published by Elsevier Science B.V.},
key = {Computer programming languages},
keywords = {Computational methods;Graphical user interfaces;Object oriented programming;Problem solving;Program interpreters;Semantics;},
note = {Generic programming;Language testing;Meta-language;Monads;},
URL = {http://dx.doi.org/10.1016/S1571-0661(04)80923-X},
} 


@inproceedings{20103713226563 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific languages for composable editor plugins},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Kats, Lennart C.L. and Kalleberg, Karl T. and Visser, Eelco},
volume = {253},
number = {7},
year = {2010},
pages = {149 - 163},
issn = {15710661},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Modern IDEs increase developer productivity by incorporating many different kinds of editor services. These can be purely syntactic, such as syntax highlighting, code folding, and an outline for navigation; or they can be based on the language semantics, such as in-line type error reporting and resolving identifier declarations. Building all these services from scratch requires both the extensive knowledge of the sometimes complicated and highly interdependent APIs and extension mechanisms of an IDE framework, and an in-depth understanding of the structure and semantics of the targeted language. This paper describes Spoofax/IMP, a meta-tooling suite that provides high-level domain-specific languages for describing editor services, relieving editor developers from much of the framework-specific programming. Editor services are defined as composable modules of rules coupled to a modular SDF grammar. The composability provided by the SGLR parser and the declaratively defined services allows embedded languages and language extensions to be easily formulated as additional rules extending an existing language definition. The service definitions are used to generate Eclipse editor plugins. We discuss two examples: an editor plugin for WebDSL, a domain-specific language for web applications, and the embedding of WebDSL in Stratego, used for expressing the (static) semantic rules of WebDSL. &copy; 2010 Elsevier B.V. All rights reserved.},
key = {Linguistics},
keywords = {Graphical user interfaces;Object oriented programming;Problem oriented languages;Query languages;Semantic Web;Semantics;Syntactics;Web services;XML;},
note = {Composability;Domain specific languages;editor plugin;Embedded Languages;High-level domain;In-depth understanding;In-line;Integrated development environment;Language extensions;Language semantics;Plug-ins;Semantic rules;Service definition;Stratego;Type errors;WEB application;},
URL = {http://dx.doi.org/10.1016/j.entcs.2010.08.038},
} 


@inproceedings{20085111785597 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A service-oriented middleware for context-aware applications},
journal = {Proceedings of the 5th International Workshop on Middleware for Pervasive and Ad-hoc Computing, MPAC 2007 held at the ACM/IFIP/USENIX 8th International Middleware Conference},
author = {Da Silva Santos, Luiz Olavo Bonino and Van Wijnen, Remco Poortinga and Vink, Peter},
year = {2007},
pages = {37 - 42},
address = {Newport Beach, CA, United states},
abstract = {Context awareness has emerged as an important element in distributed computing. It offers mechanisms that allow applications to be aware of their environment and enable these applications to adjust their behavior to the current context. Considering the dynamic nature of context, the data flow of relevant contextual information can be significant. In order to keep track of this information flow, a flexible service mechanism should be available for the client applications. In this document we present a service-oriented middleware for context-aware applications. This middleware provides support to leverage the development of context-aware applications by providing a scripting-like approach for context-aware application development; allowing the subscription of rules containing context-based events and conditions and a notification to be sent when the specified context holds. Moreover, a domain-specific language has been developed to express these context-based rules. Copyright 2007 ACM.},
key = {Computer software},
keywords = {Ad hoc networks;Applications;Distributed computer systems;Human engineering;Middleware;Technical presentations;},
note = {Application developments;Client applications;Context awarenesses;Context-aware;Contextual informations;Data flows;Distributed computing;Do-mains;Dynamic natures;Experimentation;Flexible services;Human factors;Information flows;Specific languages;},
URL = {http://dx.doi.org/10.1145/1376866.1376873},
} 


@inproceedings{20074310881174 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Concoqtion: Indexed types now!},
journal = {Proceedings of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation},
author = {Fogarty, Seth and Pasalic, Emir and Siek, Jeremy and Taha, Walid},
year = {2007},
pages = {112 - 121},
address = {Nice, France},
abstract = {Almost twenty years after the pioneering efforts of Cardelli, the programming languages community is vigorously pursuing ways to incorporate F-style indexed types into programming languages. This paper advocates Concoqtion, a practical approach to adding such highly expressive types to full-fledged programming languages. The approach is applied to MetaOCaml using the Coq proof checker to conservatively extend Hindley-Milner type inference. The implementation of MetaOCaml Concoqtion requires minimal modifications to the syntax, the type checker, and the compiler; and yields a language comparable in notation to the leading proposals. The resulting language provides unlimited expressiveness in the type system while maintaining decidability. Furthermore, programmers can take advantage of a wide range of libraries not only for the programming language but also for the indexed types. Programming in MetaOCaml Concoqtion is illustrated with small examples and a case study implementing a statically-typed domain-specific language. Copyright &copy; 2007 ACM.},
key = {Computer programming languages},
keywords = {Computability and decidability;Inference engines;Metadata;Optimization;Static analysis;Syntactics;},
note = {Domain-specific languages;Indexed types;MetaOCaml Concoqtion;},
URL = {http://dx.doi.org/10.1145/1244381.1244400},
} 


@article{20093312256222 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Effective use of ontologies in software measurement},
journal = {Knowledge Engineering Review},
author = {Garcia, Felix and Ruiz, Francisco and Calero, Coral and Bertoa, Manuel F. and Vallecillo, Antonio and Mora, Beatriz and Piattini, Mario},
volume = {24},
number = {1},
year = {2009},
pages = {23 - 40},
issn = {02698889},
address = {40 West 20th Street, New York, NY 10011-4211, United States},
abstract = {Ontologies are frequently used in the context of software and technology engineering. These can be grouped into two main categories, depending on whether they are used to describe the knowledge of a domain (domain ontologies) or whether they are used as software artifacts in software development processes. This paper presents some experiences and lessons learnt from the effective use of an ontology for Software Measurement, called software measurement ontology (SMO). The SMO was developed some years ago as a result of a thorough analysis of the software measurement domain. Its use as a domain ontology is presented first, a description of how the SMO can serve as a conceptual basis for comparing international standards related to software measurement. Second, the paper describes several examples of the applications of SMO as a software artifact. In particular, we show how the SMO can be instantiated to define a data quality model for Web portals, and also how it can be used to define a Domain-Specific Language (DSL) for measuring software entities. These examples show the significant role that ontologies can play as software artifacts in the realm of model-driven engineering and domain-specific modeling. &copy; 2009 Copyright Cambridge University Press.},
key = {Ontology},
keywords = {Computer software;},
note = {Data quality;Domain ontologies;Domain specific languages;Domain specific modeling;International standards;Model-driven Engineering;Software artifacts;Software development process;Software entities;Software Measurement;Web portal;},
URL = {http://dx.doi.org/10.1017/S0269888909000125},
} 


@inproceedings{20092812186037 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the 22nd Annual ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA'07},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
year = {2007},
pages = {ACM SIGPLAN - },
address = {Montreal, QC, Canada},
abstract = {The proceedings contain 39 papers. The topics discussed include: the JastAdd extensible Java compiler; jeannie: granting Java native interface developers their wishes; ILEA: inter-language analysis across Java and C; statistically rigorous Java performance evaluation; MicroPhase: an approach to proactively invoking garbage collection for improved performance; variant path types for scalable extensibility; component NextGen: a sound and expressive component framework for Java; User-changeable visibility: resolving unanticipated name clashes in traits; transactions with isolation and cooperation; streamflex: high-throughput stream programming in Java; can programming be liberated from the two-level style? multi-level programming with DeepJava; notation and representation in collaborative object-oriented design: an observational study; and WebRB: evaluating a visual domain-specific language for building relational web-applications.},
} 


@article{1995252570254 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Service management in the picture processing and painting system having extensible functions},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Hirai, Ikuo and Miyamoto, Yasuhide and Murao, Yo and Enomoto, Hajime},
volume = {2308},
number = {p 2},
year = {1994},
pages = {736 - 747},
issn = {0277786X},
address = {Chicago, IL, USA},
abstract = {An excellent system environment is required for realizing various services for picture processing and painting like geometrical feature processing and modification processing with susceptible constraints. Service management will play important roles in the system environment in order to integrate processing and painting of many kinds of pictures including moving picture. Integration of service management is inevitable to realize interactive process such as our Extensible WELL (Window-based ELaboration Language). Our system can handle all kinds of domain specific language by using concept of common platform including object network and of communication manager. Every object network specifies consecutive process, and communication manager controls cooperation between a client and several servers.},
key = {Interactive computer graphics},
keywords = {Animation;Image communication systems;Object oriented programming;Procedure oriented languages;},
note = {Interactive painting;Moving pictures;Picture painting;},
} 


@inproceedings{20093712300997 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {High performance synthetic aperture radar image formation on commodity multicore architectures},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {McFarlin, Daniel S. and Franchetti, Franz and Puuschel, Markus and Moura, Jose M.F.},
volume = {7337},
year = {2009},
pages = {The International Society for Optical Engineering (SPIE) - },
issn = {0277786X},
address = {Orlando, FL, United states},
abstract = {Synthetic Aperture Radar (SAR) image processing platforms have to process increasingly large datasets under and hard real-time deadlines. Upgrading these platforms is expensive. An attractive solution to this problem is to couple high performance, general-purpose Commercial-Off-The-Shelf (COTS) architectures such as IBM's Cell BE and Intel's Core with software implementations of SAR algorithms. While this approach provides great flexibility, achieving the requisite performance is difficult and time-consuming. The reason is the highly parallel nature and general complexity of modern COTS microarchitectures. To achieve the best performance, developers have to interweave of various complex optimizations including multithreading, the use of SIMD vector extensions, and careful tuning to the memory hierarchy. In this paper, we demonstrate the computer generation of high performance code for SAR implementations on Intel's multicore platforms based on the Spiral framework and system. The key is to express SAR and its building blocks in Spiral's formal domain-specific language to enable automatic vectorization, parallelization, and memory hierarchy tuning through rewriting at a high abstraction level and automatic exploration of choices. We show that Spiral produces code for the latest Intel quadcore platforms that surpasses competing hand-tuned implementations on the Cell Blade, an architecture with twice as many cores and three times the memory bandwidth. Specifically, we show an average performance of 39 Gigaflops/sec for 16-Megapixel and 100-Megapixel SAR images with runtimes of 0.56 and 3.76 seconds respectively. &copy; 2009 SPIE.},
key = {Synthetic aperture radar},
keywords = {Architectural design;Automatic programming;Cell membranes;Economic analysis;Image classification;Image processing;Imaging systems;Multitasking;Photoacoustic effect;Radar;Radar antennas;Radar imaging;Software architecture;Synthetic apertures;Tracking radar;Tuning;},
note = {Abstraction level;Attractive solutions;Automatic vectorization;Building blockes;Commercial-off-the-shelf;Complex optimization;Computer generation;Domain specific languages;Hard real-time;High performance codes;Large datasets;Many core;Mega-pixel;Memory bandwidths;Memory hierarchy;Micro architectures;Multi core;Multicore architectures;Multithreading;Parallel processing;Parallelizations;Processing platform;Program generation;Runtimes;SAR Images;SIMD vectorization;Software implementation;Synthetic aperture radar images;},
URL = {http://dx.doi.org/10.1117/12.818399},
} 


@inproceedings{2005429422125 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Empirical performance-model driven data layout optimization},
journal = {Lecture Notes in Computer Science},
author = {Lu, Qingda and Gao, Xiaoyang and Krishnamoorthy, Sriram and Baumgartner, Gerald and Ramanujam, J. and Sadayappan, P.},
volume = {3602},
year = {2005},
pages = {72 - 86},
issn = {03029743},
address = {West Lafayette, IN, United states},
abstract = {Empirical optimizers like ATLAS have been very effective in optimizing computational kernels in libraries. The best choice of parameters such as tile size and degree of loop unrolling is determined by executing different versions of the computation. In contrast, optimizing compilers use a model-driven approach to program transformation. While the model-driven approach of optimizing compilers is generally orders of magnitude faster than ATLAS-like library generators, its effectiveness can be limited by the accuracy of the performance models used. In this paper, we describe an approach where a class of computations is modeled in terms of constituent operations that are empirically measured, thereby allowing modeling of the overall execution time. The performance model with empirically determined cost components is used to perform data layout optimization in the context of the Tensor Contraction Engine, a compiler for a high-level domain-specific language for expressing computational models in quantum chemistry. The effectiveness of the approach is demonstrated through experimental measurements on some representative computations from quantum chemistry. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Optimization},
keywords = {Computation theory;Data reduction;Digital libraries;Mathematical models;Parameter estimation;Program compilers;Quantum optics;},
note = {Computational kernels;Data layout optimization;Quantum chemistry;Tile size;},
} 


@inproceedings{1998444365312 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Producing BT's yellow pages with Formation},
journal = {Innovative Applications of Artificial Intelligence - Conference Proceedings},
author = {Anderson, Gail and Mont, Andrew Casson-du and Macintosh, Ann and Rae, Robert and Gleeson, Barry},
year = {1998},
pages = {1020 - 1026},
address = {Madison, WI, USA},
abstract = {This case study illustrates how the adoption of AI technology can benefit smaller companies as well as major corporations. Pindar Set is a small UK company which has originated the Yellow Pages directories for British Telecommunications plc since 1979. AIAI is a technology transfer organization which has delivered innovative solutions to industrial clients since 1984. Together, AIAI and Pindar have developed a next-generation layout system, Formation. Formation is fast, easy to use and flexible, and had already delivered benefits through marketing trials before being successfully deployed in production of the Yellow Pages in December 1997. The heart of Formation is a 2D layout engine which formats input data according to styles written in LSSL, a domain-specific language developed at AIAI. Through representing the layout knowledge in Formation explicitly in LSSL styles, and ensuring that it can easily be modified, Pindar has enabled itself to respond far better to its customer's present and future needs.},
key = {Knowledge representation},
keywords = {Computer systems programming;Data reduction;Data structures;},
note = {Software package Formation;},
} 


@inproceedings{20094612442703 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Enhancing source-level programming tools with an awareness of transparent program transformations},
journal = {ACM SIGPLAN Notices},
author = {Song, Myoungkyu and Tilevich, Eli},
volume = {44},
number = {10},
year = {2009},
pages = {301 - 319},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Programs written in managed languages are compiled to a platform-independent intermediate representation, such as Java bytecode. The relative high level of Java bytecode has engendered a widespread practice of changing the bytecode directly, without modifying the maintained version of the source code. This practice, called bytecode engineering or enhancement, has become indispensable in transparently introducing various concerns, including persistence, distribution, and security. For example, transparent persistence architectures help avoid the entanglement of business and persistence logic in the source code by changing the bytecode directly to synchronize objects with stable storage. With functionality added directly at the bytecode level, the source code reflects only partial semantics of the program. Specifically, the programmer can neither ascertain the program's runtime behavior by browsing its source code, nor map the runtime behavior back to the original source code. This paper presents an approach that improves the utility of source-level programming tools by providing enhancement specifications written in a domain-specific language. By interpreting the specifications, a source-level programming tool can gain an awareness of the bytecode enhancements and improve its precision and usability. We demonstrate the applicability of our approach by making a source code editor and a symbolic debugger enhancements-aware. &copy; 2009 ACM.},
key = {Java programming language},
keywords = {Computer software;Graphical user interfaces;Linguistics;Problem oriented languages;Program debugging;Query languages;Specifications;},
note = {Bytecode engineering;Debugging;Domain-specific languages;Enhancement;Program transformation;},
} 


@inproceedings{20095212578449 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Enhancing source-level programming tools with an awareness of transparent program transformations},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Song, Myoungkyu and Tilevich, Eli},
year = {2009},
pages = {301 - 319},
address = {Orlando, FL, United states},
abstract = {Programs written in managed languages are compiled to a platform-independent intermediate representation, such as Java bytecode. The relative high level of Java bytecode has engendered a widespread practice of changing the bytecode directly, without modifying the maintained version of the source code. This practice, called bytecode engineering or enhancement, has become indispensable in introducing various concerns, including persistence, distribution, and security, transparently. For example, transparent persistence architectures help avoid the entanglement of business and persistence logic in the source code by changing the bytecode directly to synchronize objects with stable storage. With functionality added directly at the bytecode level, the source code reflects only partial semantics of the program. Specifically, the programmer can neither ascertain the program's runtime behavior by browsing its source code, nor map the runtime behavior back to the original source code. This paper presents an approach that improves the utility of source-level programming tools by providing enhancement specifications written in a domain-specific language. By interpreting the specifications, a source-level programming tool can gain an awareness of the bytecode enhancements and improve its precision and usability. We demonstrate the applicability of our approach by making a source code editor and a symbolic debugger enhancements-aware. Copyright &copy; 2009 ACM.},
key = {Java programming language},
keywords = {Computer software;Computer systems programming;Graphical user interfaces;Linguistics;Object oriented programming;Problem oriented languages;Program debugging;Query languages;Specifications;},
note = {Bytecode engineering;Bytecodes;Debuggers;Domain specific languages;Intermediate representations;Java byte codes;Program transformations;Programming tools;Runtimes;Source codes;Stable storage;},
URL = {http://dx.doi.org/10.1145/1640089.1640112},
} 


@inproceedings{20063710112880 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Optimizing code-copying JIT compilers for virtual stack machines},
journal = {Concurrency Computation Practice and Experience},
author = {Gregg, David and Ertl, M. Anton},
volume = {18},
number = {11},
year = {2006},
pages = {1465 - 1484},
issn = {15320626},
abstract = {Just-in-time (JIT) compilers are widely used to implement stack-based virtual machines, such as the Java and .NET virtual machines. One disadvantage of most JIT compilers is that they are importable; much of the back-end is specific to the target machine. An alternative to machine-specific code generation methods is to define a routine in a high-level language for each virtual machine instruction. These can be compiled to native code using a normal C compiler. The native code for these routines can then be strung together, allowing very simple, unoptimized code to be produced just in time. In this paper we present such a system based on an existing implementation of the Forth language. We present a novel system of optimizations for the system based on exploiting common sequences of virtual machine instructions. We use a small domain specific language and tool to generate stack-optimized code for sequences of virtual machine instructions, and for choosing the most useful sequences for a code-copying compiler. By measuring the length of the resulting executable code, we allow machine-specific sequences to be chosen without any machine-dependent code in our system. Experimental results show that best (average) speedups of 47.2% (15.75%) are possible on a Pentium 4 machine, and even higher an a PowerPC based machine. Furthermore, our optimizations allow the size of the generated code to be reduced by an average of 17.9% on the Pentium 4, and 20.5% on the PowerPC over a wide range of programs. Copyright &copy; 2006 John Wiley &amp; Sons, Ltd.},
key = {Program compilers},
keywords = {C (programming language);Codes (symbols);Java programming language;Just in time production;Optimization;Virtual reality;},
note = {Interpreter;Just-in-time (JIT) compilers;Machine-specific code generation;Virtual machine;},
URL = {http://dx.doi.org/10.1002/cpe.1016},
} 


@inproceedings{20102613042478 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven HMI development - Can meta-case tools relieve the pain?},
journal = {ICSOFT 2006 - 1st International Conference on Software and Data Technologies, Proceedings},
author = {Bock, Carsten and Zuehlke, Detlef},
volume = {2},
year = {2006},
pages = {312 - 319},
address = {Setubal, Portugal},
abstract = {Today metamodeling and domain-specific languages represent many promising beginnings to create nongeneric tool support for individual modelling tasks. Due to the inherent complexity and numerous variants of human-machine interfaces (HMIs) model-driven development becomes increasingly interesting for manufacturers and suppliers in the automtive industry. Particularly, the development of powerful user interfaces requires appropriate development processes as well as easy-to-use software tools. Since suitable tool kits are missing in the field of HMI development this paper describes the utilization of visual domain-specific languages for model-driven useware engineering in general and model-based specification of automotive HMIs in special. Moreover, results from a survey among developers are presented revealing the requirements for HMI specific tool support. Additionally, experiences with using current meta-CASE tools as well as standard office applications for creating a visual domain-specific language are presented. Based on these experiences requirements for future meta-CASE tools are derived.},
key = {Computer aided software engineering},
keywords = {Computer software;Graphical user interfaces;Linguistics;Problem oriented languages;Query languages;Specifications;},
note = {Development process;Domain specific languages;HMI development;Human Machine Interface;Inherent complexity;Meta-CASE;Metamodeling;Model driven development;Model-based specifications;Model-driven;Office applications;Software tool;Specific tool;Specification models;Tool kits;Tool support;Useware engineering;},
} 


@inproceedings{20081011128672 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven HMI development: Can meta-CASE tools do the job?},
journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
author = {Bock, Carsten},
year = {2007},
issn = {15301605},
address = {Big Island, HI, United states},
abstract = {Today metamodeling and domain-specific languages represent many promising beginnings to create non-generic tool support for project specific modeling tasks. Due to the inherent complexity and numerous variants of human-machine interfaces (HMIs) model-driven development becomes increasingly interesting for manufacturers and suppliers in the automobile industry. Particularly, the development of powerful user interfaces requires appropriate development processes as well as easy-to-use software tools. Since suitable tool kits are missing in the field of HMI development this paper describes the utilization of visual domain-specific languages for model-driven useware engineering in general and model-based specification of automotive HMIs in special. Moreover, results from a survey among developers are presented revealing the requirements for HMI specific tool support. Additionally, experiences with using current meta-CASE tools as well as standard office applications for creating a visual domain-specific language are presented. Based on these experiences requirements for future meta-CASE tools are derived. &copy; 2007 IEEE.},
key = {Human computer interaction},
keywords = {Automotive industry;Computer programming languages;Mathematical models;Project management;Specification languages;User interfaces;},
note = {Domain specific languages;Model driven useware engineering;},
URL = {http://dx.doi.org/10.1109/HICSS.2007.385},
} 


@inproceedings{20102012943402 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Alpaca: Extensible authorization for distributed services},
journal = {Proceedings of the ACM Conference on Computer and Communications Security},
author = {Lesniewski-Laas, Chris and Ford, Bryan and Strauss, Jacob and Morris, Robert and Kaashoek, M. Frans},
year = {2007},
pages = {432 - 444},
issn = {15437221},
address = {Alexandria, VA, United states},
abstract = {Traditional Public Key Infrastructures (PKI) have not lived up to their promise because there are too many ways to define PKIs, too many cryptographic primitives to build them with, and too many administrative domains with incompatible roots of trust. Alpaca is an authentication and authorization framework that embraces PKI diversity by enabling one PKI to "plug in" another PKI's credentials and cryptographic algorithms, allowing users of the latter to authenticate themselves to services using the former using their existing, unmodified certificates. Alpaca builds on Proof-Carrying Authorization (PCA), expressing a credential as an explicit proof of a logical claim. Alpaca generalizes PCA to express not only delegation policies but also the cryptographic primitives, credential formats, and namespace structures needed to use foreign credentials directly. To achieve this goal, Alpaca introduces a method of creating and naming new principals which behave according to arbitrary rules, a modular approach to logical axioms, and a domain-specific language specialized for reasoning about authentication. We have implemented Alpaca as a Python module that assists applications in generating proofs (e.g., in a client requesting access to a resource), and in verifying those proofs via a compact 800-line TCB (e.g., in a server providing that resource). We present examples demonstrating Alpaca's extensibility in scenarios involving inter-organization PKI interoperability and secure remote PKI upgrade. Copyright 2007 ACM.},
key = {Theorem proving},
keywords = {Authentication;Problem oriented languages;Public key cryptography;},
note = {Authentication and authorization;Cryptographic algorithms;Cryptographic primitives;Distributed service;Domain specific languages;Inter-organization;Logical axioms;Modular approach;Namespaces;Plug-ins;Public-key infrastructure;Security theorem;},
URL = {http://dx.doi.org/10.1145/1315245.1315299},
} 


@article{2006279982831 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Combining partial evaluation and staged interpretation in the implementation of domain-specific languages},
journal = {Science of Computer Programming},
author = {Herrmann, Christoph A. and Langhammer, Tobias},
volume = {62},
number = {1},
year = {2006},
pages = {47 - 65},
issn = {01676423},
abstract = {We propose a combination of partial evaluation and staged interpretation with MetaOCaml for rapid prototyping of domain-specific languages. Interpretation is an easy way to implement such languages. MetaOCaml can eliminate the overhead of interpretation at run-time, if the interpreter is written in a staged form, i.e., takes the source program separate from the input data in a first stage. Partial evaluation of the source program with values known at compile time can further improve the target code performance. Additional aggressive optimizations are possible due to the absence of general recursion. Algebraic simplifications can even achieve binding-time improvements during the online partial evaluation. Our approach both saves the application programmer completely from binding-time considerations and exploits staged interpretation with MetaOCaml for target code generation. The example domain presented in this paper is image processing, in which the domain-specific language permits the specification of convolution matrices, summations, case distinctions and non-local pixel accesses. All expressions known at compile time are simplified and all remaining expressions are turned into MetaOCaml code parts, which are combined to form the compiled application program. The example specifications deal with filtering by convolution and iterations in a series of images for wave effects and temperature distribution. The experimental results show significant speed-ups if online partial evaluation with algebraic simplifications is used for the elimination of interpretation overhead and optimization of code expressions. &copy; 2006 Elsevier B.V. All rights reserved.},
key = {Computer programming languages},
keywords = {Codes (symbols);Computer software;Data processing;Linear algebra;Matrix algebra;Optimization;Rapid prototyping;Specifications;},
note = {Binding-time improvement;Compilation;Domain-specific languages;Meta-programming;Partial evaluation;Staged interpretation;},
URL = {http://dx.doi.org/10.1016/j.scico.2006.02.002},
} 


@inproceedings{2005269186659 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Telescoping languages: A system for automatic generation of domain languages},
journal = {Proceedings of the IEEE},
author = {Kennedy, Ken and Broom, Bradley and Chauhan, Arun and Fowler, Robert J. and Garvin, John and Koelbel, Charles and Mccosh, Cheryl and Mellor-Crummey, John},
volume = {93},
number = {2},
year = {2005},
pages = {387 - 408},
issn = {00189219},
abstract = {The software gap - the discrepancy between the need for new software and the aggregate capacity of the workforce to produce it - is a serious problem for scientific software. Although users appreciate the convenience (and, thus, improved productivity) of using relatively high-level scripting languages, the slow execution speeds of these languages remain a problem. Lower level languages, such as C and Fortran, provide better performance for production applications, but at the cost of tedious programming and optimization by experts. If applications written in scripting languages could be routinely compiled into highly optimized machine code, a huge productivity advantage would be possible. It is not enough, however, to simply develop excellent compiler technologies for scripting languages (as a number of projects have succeeded in doing for MATLAB). In practice, scientists typically extend these languages with their own domain-centric components, such as the MATLAB signal processing toolbox. Doing so effectively defines a new domain-specific language. If we are to address efficiency problems for such extended languages, we must develop a framework for automatically generating optimizing compilers for them. To accomplish this goal, we have been pursuing an innovative strategy that we call telescoping languages. Our approach calls for using a library-preprocessing phase to extensively analyze and optimize collections of libraries that define an extended language. Results of this analysis are collected into annotated libraries and used to generate a library-aware optimizer. The generated library-aware optimizer uses the knowledge gathered during preprocessing to carry out fast and effective optimization of high-level scripts. This enables script optimization to benefit from the intense analysis performed during preprocessing without repaying its price. Since library preprocessing is performed only at infrequent "language-generation" times, its cost is amortized over many compilations of individual scripts that use the library. We call this strategy "telescoping languages" because it merges knowledge of a hierarchy of extended languages into a single library-aware optimizer. In this paper, we present our vision and plans for compiler frameworks based on telescoping languages and report on the preliminary research that has established the effectiveness of this approach. &copy; 2005 IEEE.},
key = {Computer programming languages},
keywords = {Computer software;Computer systems;Data storage equipment;Optimization;Program compilers;Signal processing;},
note = {Compiler optimization;Component integration system;Domain-specific languages implementation;High performance computing;Library generation;MATLAB compilers;Type analysis;},
URL = {http://dx.doi.org/10.1109/JPROC.2004.840447},
} 


@inproceedings{2000265169947 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Randomizing the knowledge acquisition bottleneck},
journal = {Proceedings of the IEEE International Conference on Systems, Man and Cybernetics},
author = {Rubin, Stuart H. and Smith, Michael H. and Trajkovic, Ljiljana},
volume = {5},
year = {1999},
pages = {V - 790 - V-795},
issn = {08843627},
address = {Tokyo, Jpn},
abstract = {This paper addresses the knowledge acquisition bottleneck. It first takes an information-theoretic view of knowledge acquisition as having a basis in randomization theory and subsequently gives practical examples. The examples are taken from the field of expert compiler technology. Such technology can be used to effect the realization of fourth generation languages. These languages have been shown to be among software engineering's greatest success stories. Expert compilers have the advantage of being easily maintainable and extensible. They randomize translational information in the form of rules. The capture of domain-specific knowledge allows for the construction of context-sensitive languages that are easy to work with. Of course, such languages are necessarily domain-specific; but even here expert compilers lend their advantage of promoting rapid prototyping within similar domains. It follows that if one builds a text-oriented domain-specific language that one can build a more complex expert compiler and so on. Clearly, randomization has application to not just the data, but to the representation of the data as well.},
key = {Knowledge acquisition},
keywords = {Computer software maintenance;Context sensitive languages;Information technology;Information theory;Program compilers;Query languages;Random processes;Rapid prototyping;Software engineering;},
note = {Expert compiler technology;Randomization theory;},
URL = {http://dx.doi.org/10.1109/ICSMC.1999.815652},
} 


@inproceedings{20090211850166 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A case study on the transformation of context-aware domain data onto XML schemas},
journal = {Proceedings of the 3rd International Workshop on Model-Driven Enterprise Information Systems - MDEIS 2007; In Conjunction with ICEIS 2007},
author = {De Farias, Clever R. G. and Pires, Luis Ferreira and Van Sinderen, Marten},
year = {2007},
pages = {63 - 72},
address = {Funchal, Madeira, Portugal},
abstract = {In order to accelerate the development of context-aware applications, it would be convenient to have a smooth path between the context models and the automated services that support these models. This paper discusses how MDA technology (metamodelling and the QVT standard) can support the transformation of high-level models of context-aware services onto the implementation of these services using web services. The total transformation process from context-aware services onto web services involves the following aspects: 1. service signatures, which should be translated onto WSDL definitions; 2. contextaware domain data used as input and output data in service operations, which should be translated onto XML schemas; and 3. service behaviours, which should be used to generate the service implementation. This paper concentrates on the modelling and transformation of the context-aware domain data. The results of this paper are generally applicable to the transformation of elements of any domain-specific language expressed in terms of a metamodel onto XML Schema data.},
key = {Information systems},
keywords = {Information services;Markup languages;Paper;Systems analysis;Technical presentations;Web services;World Wide Web;XML;},
note = {Automated services;Case studies;Context models;Context-aware;Do-mains;In service operations;Input and outputs;Level models;Metamodelling;Schemas;Specific languages;Transformation processes;},
} 


@inproceedings{20074310883247 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A software factory for air traffic data},
journal = {Proceedings of the 2007 Integrated Communications, Navigation and Surveillance Conference, 7th ICNS Conference 2007},
author = {Comitz, Paul H.},
year = {2007},
address = {Herndon, VA, United states},
abstract = {Modern information systems require a flexible, scalable, and upgradeable infrastructure that allows communication, and subsequently collaboration, between heterogeneous information processing and computing environments. Heterogeneous systems often use different data representations for the same data items, limiting collaboration and increasing the cost and complexity of system integration. Although this problem is conceptually straightforward, the process of data conversion is error prone, often dramatically underestimated, and surprisingly complex. The complexity is often the result of the non-standard data representations that are used by computing systems in the aviation domain. This paper describes work that is being done to address this challenge. A prototype software factory for air traffic data is being built and evaluated. The software factory provides the capability to create data and interface models for use in the air traffic domain. The model will allow the user to specify entities such as data items, scaling, units, headers and footers, representation, and coding. The factory automatically creates a machine usable data representation. A prototype for a Domain Specific Language to assist in this task is being developed. This paper describes the scope of the work and the overall approach. &copy; 2007 IEEE.},
key = {Air traffic control},
keywords = {Cost effectiveness;Information systems;Mathematical models;Software engineering;Telecommunication services;},
note = {Air traffic data;Heterogeneous information processing;},
URL = {http://dx.doi.org/10.1109/ICNSURV.2007.384149},
} 


@article{2004188137611 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Hancock: A language for analyzing transactional data streams},
journal = {ACM Transactions on Programming Languages and Systems},
author = {Cortes, Corinna and Fisher, Kathleen and Pregibon, Daryl and Rogers, Anne and Smith, Frederick},
volume = {26},
number = {2},
year = {2004},
pages = {301 - 338},
issn = {01640925},
abstract = {Massive transaction streams present a number of opportunities for data mining techniques. The transactions in such streams might represent calls on a telephone network, commercial credit card purchases, stock market trades, or HTTP requests to a web server. While historically such data have been collected for billing or security purposes, they are now being used to discover how the transactors, for example, credit-card number or IP addresses, uses the associated services. Over the past 5 years, we have computed evolving profiles (called signatures) of transactors in several very large data streams. The signature for each transactor captures the salient features of his or her behavior through time. Programs for processing signatures must be highly optimized because of the size of the data stream (several gigabytes per day) and the number of signatures to maintain (hundreds of millions). Originally, we wrote such programs directly in C, but because these programs often sacrificed readability for performance, they were difficult to verify and maintain. Hancock is a domain-specific language we created to express computationally efficient signature programs cleanly. In this paper, we describe the obstacles to computing signatures from massive streams and explain how Hancock addresses these problems. For expository purpose, we present Hancock using a running example from the telecommunications industry; however, the language itself is general and applies equally well to other data sources.},
key = {Computer programming languages},
keywords = {Computer architecture;Computer simulation;Data mining;Database systems;Pattern recognition;Statistical methods;},
note = {Domain-specific languages;Statistical models;},
URL = {http://dx.doi.org/10.1145/973097.973100},
} 


@article{20102413013618 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Code generation by model transformation: A case study in transformation modularity},
journal = {Software and Systems Modeling},
author = {Hemel, Zef and Kats, Lennart C.L. and Groenewegen, Danny M. and Visser, Eelco},
volume = {9},
number = {3},
year = {2010},
pages = {375 - 402},
issn = {16191366},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {The realization of model-driven software development requires effective techniques for implementing code generators for domain-specific languages. This paper identifies techniques for improving separation of concerns in the implementation of generators. The core technique is code generation by model transformation, that is, the generation of a structured representation (model) of the target program instead of plain text. This approach enables the transformation of code after generation, which in turn enables the extension of the target language with features that allow better modularity in code generation rules. The technique can also be applied to 'internal code generation' for the translation of high-level extensions of a DSL to lower-level constructs within the same DSL using model-to-model transformations. This paper refines our earlier description of code generation by model transformation with an improved architecture for the composition of model-to-model normalization rules, solving the problem of combining type analysis and transformation. Instead of coarse-grained stages that alternate between normalization and type analysis, we have developed a new style of type analysis that can be integrated with normalizing transformations in a fine-grained manner. The normalization strategy has a simple extension interface and integrates non-local, context-sensitive transformation rules. We have applied the techniques in a realistic case study of domain-specific language engineering, i. e. the code generator for WebDSL, using Stratego, a high-level transformation language that integrates model-to-model, model-to-code, and code-to-code transformations. &copy; 2009 The Author(s).},
key = {Network components},
keywords = {Automatic programming;Cosine transforms;Graphical user interfaces;Linguistics;Problem oriented languages;Program compilers;Query languages;Software design;},
note = {Coarse-grained;Code Generation;Code generators;Code transformation;Combination of analysis and transformation;Context-sensitive;Domain specific languages;High-level transformations;Model to model transformation;Model transformation;Model-Driven Software Development;Nonlocal;Normalization strategies;Normalizing transformation;Plain text;Separation of concerns;Stratego;Target language;Term rewriting;Transformation rules;Type analysis;},
URL = {http://dx.doi.org/10.1007/s10270-009-0136-1},
} 


@article{1998334253301 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Implementing generalized operator overloading},
journal = {Software - Practice and Experience},
author = {Miles, William S. and Johnson, Leroy F.},
volume = {28},
number = {6},
year = {1998},
pages = {593 - 610},
issn = {00380644},
address = {Chichester, United Kingdom},
abstract = {This paper presents a practical method of adding problem-specific notation to an established computer language. Our idea is to use unrestricted operator overloading as a tool to map the problem domain notation directly into an existing programming language. Our method introduces new operator symbols and function names into a host language by overloading existing usage. We extend the host programming language syntax to an augmented language which is mapped to the host language by a programmable preprocessor. The preprocessor uses a programmer-modifiable symbolic language grammar to translate an augmented program into a standard program. This process gives a natural extension to any computer language without modifying the host language. Direct use of problem notation can improve program legibility and code comprehension within the problem domain. The preprocessor provides a useful research tool for exploring language issues without the need to write a compiler for a new language. It can also be used to provide a domain specific language for a programming group at lower cost than new language development. This paper presents several working examples which illustrate our work. We redefine many of the standard C operators to alleviate some of the more common programming errors, thus creating a `cleaner' C. As a more esoteric example, we encode a subset of APL vector operators as an algebraic extension to the C language. A curious application of our method shows its success in an arbitrary problem domain by compiling and executing poetry. Our final example introduces standard symbolic logic notation into C for tautology verification.},
key = {Computer programming languages},
keywords = {Codes (symbols);Computational grammars;Program compilers;Program debugging;Program translators;},
note = {Generalized operator overloading;Programmer modifiable symbolic language grammar;},
URL = {http://dx.doi.org/10.1002/(SICI)1097-024X(199805)28:6<593::AID-SPE161>3.0.CO;2-S},
} 


@inproceedings{2001496752891 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Charting patterns on price history},
journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
author = {Anand, S. and Chin, W.-N. and Khoo, S.-C.},
year = {2001},
pages = {134 - 145},
address = {Florence, Italy},
abstract = {It is an established notion among financial analysts that price moves in patterns and these patterns can be used to forecast future price. As the definitions of these patterns are often subjective, every analyst has a need to define and search meaningful patterns from historical time series quickly and efficiently. However, such discovery process can be extremely laborious and technically challenging in the absence of a high level pattern definition language. In this paper, we propose a chart-pattern language (CPL for short) to facilitate pattern discovery process. Our language enables financial analysts to (1) define patterns with subjective criteria, through introduction of fuzzy constraints, and (2) incrementally compose complex patterns from simpler patterns. We demonstrate through an array of examples how real life patterns can be expressed in CPL. In short, CPL provides a high-level platform upon which analysts can define and search patterns easily and without any programming expertise. CPL is a domain-specific language embedded in Haskell. We show how various features of a functional language, such as pattern matching, higher-order functions, lazy evaluation, facilitate pattern definitions and implementation. Furthermore, Haskell's type system frees the programmers from annotating the programs with types.},
key = {High level languages},
keywords = {Computer hardware description languages;Constraint theory;Database systems;Finance;Forecasting;Fuzzy sets;Graphical user interfaces;Sales;Semantics;},
note = {Chart pattern language;Fuzzy constraints;Haskell;},
URL = {http://dx.doi.org/10.1145/507635.507653},
} 


@inproceedings{2003087364647 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Hancock: A language for extracting signatures from data streams},
journal = {Proceeding of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
author = {Cortes, Corinna and Fisher, Kathleen and Pregibon, Daryl and Rogers, Anne and Smith, Frederick},
year = {2000},
pages = {9 - 17},
address = {Boston, MA, United states},
abstract = {Massive transaction streams present a number of opportunities for data mining techniques. Transactions might represent calls on a telephone network, commercial credit card purchases, stock market trades, or HTTP requests to a web server. While historically such data have been collected for billing or security purposes, they are now being used to discover how customers or their intermediaries (called transactors) use the underlying services. For several years, we have computed evolving profiles (called signatures) of the transactors in large data streams using handwritten C code. The signature for each transactor captures the salient features of his transactions through time. Programs for processing signatures must be highly optimized because of the size of the data stream (several gigabytes per day) and the number of signatures to maintain (hundreds of millions). C programs to compute signatures often sacrificed readability for performance. Consequently, they are difficult to verify and maintain. Hancock is a domain-specific language created to express computationally efficient signature programs cleanly. In this paper, we describe the obstacles to computing signatures from massive streams and explain how Hancock addresses these problems. For expository purposes, we present Hancock using a running example from the telecommunications industry; however, the language itself is general and applies equally well to other data sources.},
key = {Data mining},
keywords = {C (programming language);Computer programming;Customer satisfaction;Data acquisition;Telecommunication industry;},
note = {Domain-specific languages;},
} 


@inproceedings{2003517785208 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Ad Hoc Software Interfacing: Enterprise Application Integration (EAI) when Middleware is Overkill},
journal = {Proceedings - IEEE Computer Society's International Computer Software and Applications Conference},
author = {Reyes, Arthur A. and Espino, Jose R. and Mohan, Vijai and Nadkar, Monica},
year = {2003},
pages = {570 - 575},
issn = {07303157},
address = {Dallas, TX, United states},
abstract = {Enterprise application integration (EAI) is cooperation of disparate systems and components to implement business rules in a distributed environment. "Systems and components" can be computer-aided design (CAD) or software engineering (CASE) tools, enterprise databases, COTS applications, or in-house software. Ad hoc software interfacing (AHSI) is a special kind of EAI. A tradeoff analysis classifies an EAI problem as an AHSI problem when middleware solutions are seen as heavy-handed. I.e., the planned EAI is not expected to become broad enough to justify the generality of a middleware solution or the client is unwilling to pay for a unified data model. AHSI seeks to "wire" extant software applications as components in new, larger software applications. We call applications-as-components "appliponents". AHSI seeks to minimize appliponent modification to the greatest extent possible. We demonstrate solutions to AHSI problems using XML toolkits, domain-specific language toolkits, and Microsoft BizTalk Server.},
key = {Middleware},
keywords = {Computer aided design;Computer aided software engineering;Computer programming languages;Data transfer;Database systems;Interfaces (computer);Interoperability;Servers;Societies and institutions;XML;},
note = {Enterprise application integration (EAI);Software interfacing;},
URL = {http://dx.doi.org/10.1109/CMPSAC.2003.1245397},
} 


@article{2002046836489 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Unix tools as visual programming components in a GUI-builder environment},
journal = {Software - Practice and Experience},
author = {Spinellis, Diomidis},
volume = {32},
number = {1},
year = {2002},
pages = {57 - 71},
issn = {00380644},
abstract = {Development environments based on ActiveX controls and JavaBeans are marketed as 'visual programming' platforms; in practice their visual dimension is limited to the design and implementation of an application's graphical user interface (GUI). The availability of sophisticated GUI development environments and visual component development frameworks is now providing viable platforms for implementing visual programming within general-purpose platforms, i.e. for the specification of non GUI program functionality using visual representations. We describe how specially designed reflective components can be used in an industry-standard visual programming environment to graphically specify sophisticated data transformation pipelines that interact with GUI elements. The components are based on Unix-style filters repackaged as ActiveX controls. Their visual layout on the development environment canvas is used to specify the connection topology of the resultant pipeline. The process of converting filter style programs into visual controls is automated using a domain-specific language. We demonstrate the approach through the design and the visual implementation of a GUI-based spell-checker. Copyright &copy; 2001 John Wiley &amp; Sons, Ltd.},
key = {Software engineering},
keywords = {Data transfer;Graphical user interfaces;Java programming language;Specifications;UNIX;},
note = {Visual programming;},
URL = {http://dx.doi.org/10.1002/spe.428},
} 


@inproceedings{2002387092608 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Distributing MPEG movies over the Internet using programmable networks},
journal = {Proceedings - International Conference on Distributed Computing Systems},
author = {He, Dan and Muller, Gilles and Lawall, Julia L.},
year = {2002},
pages = {161 - 170},
address = {Vienna, Austria},
abstract = {Distributing video over the Internet is an increasingly important application. Nevertheless, the real-time and high bandwidth requirements of video make video distribution over today's Internet a challenge. Adaptive approaches can be used to respond to changes in bandwidth availability while limiting the effect of such changes on perceptual quality and resource consumption. Nevertheless, most existing adaptation mechanisms have limited scalability and do not effectively exploit the heterogeneity of the Internet. In this paper, we describe the design and implementation of a MPEG video broadcasting service based on active networks. In an active network, routers can be programmed to make routing decisions based on local conditions. Because decisions are made locally, adaptation reacts rapidly to changing conditions and is unaffected by conditions elsewhere in the network. Programmability allows the adaptation policy to be tuned to the structure of the transmitted data, and to the properties of local clients. We use the PLAN-P domain-specific language for programming active routers; this language provides high-level abstractions and safety guarantees that allow complex protocols to be developed rapidly and reliably. Our experiments show that our approach to video distribution permits the decoding of up to 9 times as many frames in a heavily loaded network as distribution using standard routers.},
key = {Video on demand},
keywords = {Bandwidth;Broadcasting;Computer programming languages;Motion pictures;Routers;World Wide Web;},
note = {Programmable networks;},
URL = {http://dx.doi.org/10.1109/ICDCS.2002.1022253},
} 


@article{20110413626932 ,
language = {Japanese},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A proposal of Ajax framework for web-based supervisory and control systems},
journal = {IEEJ Transactions on Electronics, Information and Systems},
author = {Yanagihara, Shintaro and Ishihara, Akira and Ishii, Toshinao and Kitsuki, Junichi and Seo, Kazuo},
volume = {130},
number = {12},
year = {2010},
pages = {2276 - 2285+23},
issn = {03854221},
address = {1-12-1 Yurakucho, Chiyoda-ku, Tokyo, 100, Japan},
abstract = {In recent years, with spread of Web application and performance gain of Web browsers, the demand of the web-based supervisory and control(WSCADA) systems based on RIA(Rich Internet Application) is increased. To develop CRUD operations(Create, Read, Update, Delete which corresponds to the basic database operations) of RIA-based web applications, various frameworks and libraries are being provided. However, to develop behavior operations, a lot of program must be written manually. The typical operations of WSCADA are behavior operations, so even if RIA frameworks and libraries are used to develop WSCADA, the productivity of development doesn't improve. Although conceptual models and development environment have been proposed for typical web applications consisted mostly of CRUD operations, those for WSCADA is still the unsolved problem. This paper proposes the user interface model and the development environment for the monitoring user interface program of WSCADA. We focus on the productivity enhancement of the WSCADA development, and propose the Monitoring User Interface Model(MUM) extended Model-View-Controller(MVC) model. We design the Ajax framework and the development environment based on our model. We define the Displayltem as the advanced View and the Monitoringltem as the advanced Model, and classify the Controller into the Interaction and the Behavior. Our Ajax framework based on web browser's standard technologies, provides the mapping between conceptual model elements. We define the domain specific language for writing the mapping. We design development environment for auto-generating Behavior program from the mapping. In this paper, we evaluate our model and development environment through the experimental development of the typical WSCADA. As a result, the development cost of the WSCADA based on our framework is only one fifth of that based on the typical Ajax library. &copy; 2010 The Institute of Electrical Engineers of Japan.},
key = {Web browsers},
keywords = {Controllers;Libraries;Mapping;Monitoring;Productivity;User interfaces;World Wide Web;},
note = {Ajax;Auto-generating;Conceptual model;Design development;Development costs;Development environment;Domain specific languages;Experimental development;Extended model;Framework;Interface program;Monitoring systems;Performance Gain;Productivity enhancement;RIA;Rich Internet Applications;Standard technology;Unsolved problems;User interface models;WEB application;},
URL = {http://dx.doi.org/10.1541/ieejeiss.130.2276},
} 


@inproceedings{20101412829650 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic synthesis of high performance mathematical programs},
journal = {Proceedings of the International Symposium on Symbolic and Algebraic Computation, ISSAC},
author = {Puschel, Markus},
year = {2009},
pages = {5 - 6},
address = {Seoul, Korea, Republic of},
abstract = {The evolution of computing platforms is at a historic inflection point. CPU frequency has stalled (in 2004 at about 3GHz), which means future performance gains will only be achievable due to increasing parallelism in the form of multiple cores and vector instructions sets. The impact on the developers of high performance libraries implementing important mathematical functionality such as matrix-multiplication, linear transforms, and many others is profound. Traditionally, an algorithm developer ensures correctness and minimizes the operations count. A software engineer then performs the actual implementation (in a compilable language like C) and performance optimization. However, on modern platforms, two implementations with the exact same operations count may differ by 10, 100, or even 1000x in runtime: instead, the structure of an algorithm becomes a major factor and determines how well it can be parallelized, vectorized, and matched to the memory hierarchy. Ideally, a compiler would perform all these tasks, but the current state of knowledge suggest that this may be inherently impossible for many types of code. The reason may be two-fold. First, many transformations, in particular for parallelism, require domain-knowledge that the compiler simply does possess. Second, often there are simply too many choices of transformations that the compiler cannot or does not know how to explore. As a consequence, the development of high performance libraries for mathematical functions becomes extraordinarily difficult, since the developer needs to have a good understanding of available algorithms, the target microarchitecture, and implementation techniques such as threading and vector instruction set such as SSE on Intel. To make things worse, optimal code is often platform specific, that is, code that runs very fast on one platform can be suboptimal on another. This means that if highest performance is desired, library developers are constantly forced to reimplement and reoptimize the same functionality. A commercial example following this model are Intel's IPP and MKL libraries, which provide a very broad set of mathematical functions needed in scientific computing, signal and image processing, communication, and security applications. An attractive solution would be to automate the library development, which means let the computer write the code and rewrite it for every new platforms. There are several challenges involved with this proposal. First, for a given desired function (such as multiplying matrices or computing a discrete Fourier transform), the existing algorithm knowledge has to be encoded into a form or language that is suitable for computer representation. Second, structural algorithm transformations for parallelism or locality that are typically performed by the programmer also have to be encoded into this form. Third, available choices have to be explored systematically and efficiently. As we will show for a specific domain, techniques from symbolic computation provide the answers. In this talk we present Spiral [6, 1], a domain-specific program generation system for important mathematical functionality such as linear transforms, filters, Viterbi decoders, and basic linear algebra routines. Spiral completely replaces the human programmer. For a desired function, Spiral generates alternative algorithms, optimizes them, compiles them into programs, and "intelligently"' searches for the best match to the computing platform. The main idea behind Spiral is a mathematical, symbolic, declarative, domain-specific language to represent algorithms and the use of rewriting systems to generate and structurally optimize algorithms at a high level of abstraction. Optimization includes parallelization, vectorization, and locality improvement for the memory hierarchy [3, 4, 5, 7, 2]. Experimental results show that the code generated by Spiral competes with, and sometimes outperforms, the best available human-written code.},
key = {Mathematical transformations},
keywords = {Algebra;Automatic programming;Computational efficiency;Discrete Fourier transforms;Function evaluation;Image processing;Knowledge representation;Libraries;Linguistics;Matrix algebra;Optimal systems;Optimization;Problem oriented languages;Program compilers;Viterbi algorithm;XML;},
note = {Automation domain;Parallelizations;Performance matrices;Program generation;Vectorization;},
URL = {http://dx.doi.org/10.1145/1576702.1576705},
} 


@article{1996363242457 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Prototype of an expert system for the selection of high-speed steels for cutting tools},
journal = {Journal of Materials Processing Technology},
author = {Dobrzanski, L.A. and Madejski, J. and Malina, W. and Sitek, W.},
volume = {56},
number = {1-4},
year = {1996},
pages = {873 - 881},
issn = {09240136},
address = {Dublin, Irel},
abstract = {Experience gained by a team of researchers developing a database system designed as an aid for engineers and students who work out the tools made from the high-speed steels shows that this sort of system needs a flexible yet powerful user interface. To solve this task a front-end expert system module is being designed. Present design parameters assume that the intelligent add-on shall consist of some 500 &divide; 1000 rules enabling the user to compare the characteristic properties of various high-speed steels in respect to given applications, more, the technology generating module shall include the what-if option. To make all these new features as user friendly as possible it has been decided that the work should start with development of the linguistic task-oriented processor to enable the user to contact with the system in a subset of the natural language. To this end a prototype of a user interface was written in PROLOG and is presently being tested. In order to set the limits to the above mentioned task the dictionary was developed including all the necessary nouns, verbs, adjectives, numerals and sentence structures that are allowed to appear in the interface domain specific language.},
key = {Steel},
keywords = {Computer aided design;Cutting tools;Database systems;Expert systems;Natural language processing systems;PROLOG (programming language);User interfaces;},
note = {Design parameters;Intelligent add on;User friendly;What if option;},
URL = {http://dx.doi.org/10.1016/0924-0136(96)85119-3},
} 


@article{2000365258693 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Functional polytypic programming},
journal = {Doktorsavhandlingar vid Chalmers Tekniska Hogskola},
author = {Jansson, Patrik},
number = {1584},
year = {2000},
pages = {1 - 180},
issn = {0346718X},
address = {Goteborg, Sweden},
abstract = {Many algorithms have to be implemented over and over again for different datatypes, either because datatypes change during the development of programs, or because the same algorithm is used for several datatypes. Examples of such algorithms are equality tests, pretty printers, and pattern matchers, and polytypic programming is a paradigm for expressing such algorithms. This dissertation introduces polytypic programming for functional programming languages, shows how to construct and prove properties of polytypic algorithms, presents the language extension PolyP for implementing polytypic algorithms in a type safe way, and presents a number of applications of polytypic programming. The applications include a library of basic polytypic building blocks, PolyLib, and two larger applications of polytypic programming: rewriting and data conversion. PolyP extends a functional language (a subset of Haskell) with a construct for defining polytypic functions by induction on the structure of user-defined datatypes. Programs in the extended language are translated to Haskell. PolyLib contains powerful structured recursion operators like catamorphisms, maps and traversals, as well as polytypic versions of a number of standard functions from functional programming: sum, length, zip, (= =), (&le), etc. Both the specification of the library and a PolyP implementation are presented. The first larger application is a framework for polytypic programming on terms. We show that an interface of four functions is sufficient to express polytypic functions for pattern matching, unification and term rewriting. Using this framework, a term rewriting function is specified and transformed into an efficient and correct implementation. In the second application, a number of functions for polytypic data conversion are implemented and proved correct. The conversions considered include pretty printing, parsing, packing and unpacking of structured data. The conversion functions are expressed in an embedded domain specific language for data conversion (a hierarchy of Haskell's constructor classes).},
key = {Computer programming languages},
keywords = {Algebra;Algorithms;Data structures;Functions;Interfaces (computer);Mathematical operators;},
note = {Algebraic datatypes;Functional programming;Generic programming;Polytypic programming;},
} 


@inproceedings{20110913701935 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A UML-based domain specific modeling language for the availability management framework},
journal = {Proceedings of IEEE International Symposium on High Assurance Systems Engineering},
author = {Salehi, P. and Hamou-Lhadj, A. and Colombo, P. and Khendek, F. and Toeroe, M.},
year = {2010},
pages = {35 - 44},
issn = {15302059},
address = {San Jose, CA, United states},
abstract = {The Service Availability Forum (SA Forum) is a consortium of several telecommunications and computing companies that defines standard solutions for high availability platforms. One of the most important SA Forum services is the Availability Management Framework (AMF) which is responsible for managing the availability of an application running under its control. To achieve this, AMF requires a complete configuration, which consists of several entities organized according to AMF rules and constraints. In this paper, we argue that AMF concepts form a domain for which a domain-specific modeling language can greatly facilitate the generation, analysis and the management of AMF configurations. We define such a language by extending UML through its profiling mechanism and we implement it. More important, we discuss the challenges and the lessons learned in the course of this project. &copy; 2010 IEEE.},
key = {Unified Modeling Language},
keywords = {High level languages;Systems engineering;},
note = {Availability management frameworks;Domain specific modeling languages;Domain-specific modeling language;High availability;Service availability forum;Standard solutions;UML profiles;},
URL = {http://dx.doi.org/10.1109/HASE.2010.21},
} 


@inproceedings{20104113278014 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A generative programming approach to developing pervasive computing systems},
journal = {ACM SIGPLAN Notices},
author = {Cassou, Damien and Bertran, Benjamin and Loriant, Nicolas and Consel, Charles},
volume = {45},
number = {2},
year = {2010},
pages = {137 - 146},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Developing pervasive computing applications is a difficult task because it requires to deal with a wide range of issues: heterogeneous devices, entity distribution, entity coordination, low-level hardware knowledge &mellip; Besides requiring various areas of expertise, programming such applications involves writing a lot of administrative code to glue technologies together and to interface with both hardware and software components. This paper proposes a generative programming approach to providing programming, execution and simulation support dedicated to the pervasive computing domain. This approach relies on a domain-specific language, named DiaSpec, dedicated to the description of pervasive computing systems. Our generative approach factors out features of distributed systems technologies, making DiaSpec-specified software systems portable. The DiaSpec compiler is implemented and has been used to generate dedicated programming frameworks for a variety of pervasive computing applications, including detailed ones to manage the building of an engineering school. Copyright &copy; 2009 ACM.},
key = {Ubiquitous computing},
keywords = {Problem oriented languages;},
note = {Distributed systems;Domain specific languages;Engineering schools;Generative programming;Hardware and software components;Heterogeneous devices;Pervasive computing;Pervasive computing applications;Pervasive computing systems;Programming framework;Software systems;},
URL = {http://dx.doi.org/10.1145/1837852.1621629},
} 


@inproceedings{20094812518489 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A generative programming approach to developing pervasive computing systems},
journal = {GPCE'09 - Proceedings of the 8th International ACM SIGPLAN Conference on Generative Programming and Component Engineering},
author = {Cassou, Damien and Bertran, Benjamin and Loriant, Nicolas and Consel, Charles},
year = {2009},
pages = {137 - 146},
address = {Denver, CO, United states},
abstract = {Developing pervasive computing applications is a difficult task because it requires to deal with a wide range of issues: heterogeneous devices, entity distribution, entity coordination, low-level hardware knowledge. Besides requiring various areas of expertise, programming such applications involves writing a lot of administrative code to glue technologies together and to interface with both hardware and software components. This paper proposes a generative programming approach to providing programming, execution and simulation support dedicated to the pervasive computing domain. This approach relies on a domain-specific language, named DiaSpec, dedicated to the description of pervasive computing systems. Our generative approach factors out features of distributed systems technologies, making DiaSpec-specified software systems portable. The DiaSpec compiler is implemented and has been used to generate dedicated programming frameworks for a variety of pervasive computing applications, including detailed ones to manage the building of an engineering school. Copyright &copy; 2009 ACM.},
key = {Computer science},
keywords = {Computer software;DSL;Modems;Problem oriented languages;Telecommunication lines;},
note = {Distributed systems;Domain specific languages;Engineering schools;Generative programming;Hardware and software components;Heterogeneous devices;Pervasive computing;Pervasive computing applications;Pervasive computing systems;Programming framework;Software systems;},
URL = {http://dx.doi.org/10.1145/1621607.1621629},
} 


@inproceedings{20110813694024 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific modeling language for scientific data composition and interoperability},
journal = {Proceedings of the Annual Southeast Conference},
author = {Cho, Hyun and Gray, Jeff},
year = {2010},
address = {Oxford, MS, United states},
abstract = {Domain-Specific Modeling Languages (DSMLs) can offer assistance to domain experts, who may not be computer scientists, by providing notations and semantic constructs that align with abstractions from a particular domain. In this paper, we describe our design and application of a DSML in the area of data composition and interoperability. In particular, we introduce our recent effort to design a DSML to assist with interoperability issues across scientific software applications (e.g., composing scientific data in different file structures and integrating scientific data with data gathering devices). Currently, several different scientific data file specifications have been proposed (e.g., CID, netCDF, and HDF). Each file specification is optimized to manage a specific data type efficiently. Thus, each file specification has evolved with slightly different notions and implementation technologies. These differences led to the need for an environment that provides interoperability among the different specification formats. In this paper, we introduce our framework, supported by a DSML, that provides functionality to visually model the data composition and integration concepts independent from a particular data file specification. Copyright &copy; 2010 ACM.},
key = {Data handling},
keywords = {Data visualization;High level languages;Integration;Interoperability;Semantics;Specifications;},
note = {Data composition;Data integration;Domain-Specific modeling language (DSML);File format;Metamodeling;},
URL = {http://dx.doi.org/10.1145/1900008.1900146},
} 


@inproceedings{20093712304362 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using UML as a domain-specific modeling language: A proposal for automatic generation of UML profiles},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Giachetti, Giovanni and Marin, Beatriz and Pastor, Oscar},
volume = {5565 LNCS},
year = {2009},
pages = {110 - 124},
issn = {03029743},
address = {Amsterdam, Netherlands},
abstract = {Nowadays, there are several MDD approaches that have defined Domain-Specific Modeling Languages (DSML) that are oriented to representing their particular semantics. However, since UML is the standard language for software modeling, many of these MDD approaches are trying to integrate their semantics into UML in order to use UML as DSML. The use of UML profiles is a recommended strategy to perform this integration allowing, among other benefits, the use of the existent UML modeling tools. However, in the literature related to UML profile construction; it is not possible to find a standardized UML profile generation process. Therefore, a process that integrates a DSML into UML through the automatic generation of a UML profile is presented in this paper. This process facilitates the correct use of UML in a MDD context and provides a solution to take advantage of the benefits of UML and DSMLs. &copy; 2009 Springer Berlin Heidelberg.},
key = {Markup languages},
keywords = {High level languages;Information systems;Linguistics;Query languages;Semantics;Systems engineering;},
note = {Automatic Generation;Domain-specific modeling language;DSML;Generation process;MDD;Software modeling;UML;UML modeling tools;UML Profile;UML profiles;},
URL = {http://dx.doi.org/10.1007/978-3-642-02144-2_13},
} 


@inproceedings{2006189858306 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative Programming and Component Engineering - 4th International Conference, GPCE 2005, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {3676 LNCS},
year = {2005},
pages = {ACM SIGPLAN; ACM SIGSOFT; Utrecht University - },
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {The proceedings contain 30 papers. The topics discussed include: object-oriented reengineering patterns - an overview; certifiable program generation; efficient code generation for a domain specific language; Bossa Nova: introducing modularity into the Bossa domain-specific language; model compiler construction based on aspect-oriented mechanisms; shadow programming: reasoning about programs using Lexical join point information; generalized type-based disambiguation of meta programs with concrete object syntax; semi-inversion of guarded equations; a generative programming approach to interactive information retrieval: insights and experiences; and optimizing marshalling by run-time program generation.},
key = {Technical presentations},
keywords = {Computer programming;Information retrieval;Mathematical models;Metadata;Object oriented programming;Program compilers;},
note = {Bossa domain-specific language;Lexical join point information;Run-time program generation;},
} 


@inproceedings{2004037822060 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative programming for space applications},
journal = {European Space Agency, (Special Publication) ESA SP},
author = {Cechticky, V. and Pasetti, A.},
number = {532},
year = {2003},
pages = {19 - 30},
issn = {03796566},
address = {Prague, Czech republic},
abstract = {Generative programming is a software engineering paradigm that, given a particular requirements specification, allows an application implementing those requirements to be automatically generated by configuring and customizing the components and the architecture provided by a software framework. Generative programming raises the level of abstraction at which an application is defined and implemented. It can potentially increase the ease of development and the reliability of the final application and is therefore of interest to domains - like space - where there is a need to contain costs while maintaining or enhancing overall quality. This paper is divided into two parts. The first part introduces the generative programming paradigm in general. The second part presents the results of a study done by the authors for ESA-Estec (contract number 15753/02/NL/LvH) to apply generative programming techniques to automate the instantiation of the AOCS Framework. The AOCS Framework is a prototype framework for on-board control applications.},
key = {Space research},
keywords = {Computer architecture;Computer programming;Computer programming languages;Computer software;Project management;Space applications;},
note = {Domain-specific languages (DSL);Generative programming environment;},
} 


@inproceedings{2004408382473 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Performance of generative programming based protocol implementation},
journal = {Proceedings - Second Annual Conference on Communication Networks and Services Research},
author = {Li, Zheyin and Barbeau, Michel},
year = {2004},
pages = {113 - 120},
address = {Fredericton, NB, Canada},
abstract = {Protocol Implementation Framework for Linux (PIX) is a protocol development tool using generative programming. It aims at capturing the similarities in behaviors among different layers of protocols and grouping solutions to cross-cutting concerns of communication systems. It achieves a high degree of configurability by providing several combinations which could be chosen to generate desired protocols. This paper addresses the following open question. How does the performance of generative programming based protocol implementation compare with traditional protocol implementation techniques? This paper provides an answer to this question. A benchmark is developed to give a thorough performance analysis of PIX to contrast it with other protocol development frameworks. The benchmark compares the performance of bulk data transfer. The file transfer protocol (FTP) is used for comparison purposes. Latency, throughput and resource usage measurements are provided in order to compare the performance of FIX and generative programming with NcFTP, which uses structured programming, and x-Kernel, which uses structured and object-based programming.},
key = {Network protocols},
keywords = {Benchmarking;Communication systems;Computer programming;Data transfer;Mathematical models;UNIX;},
note = {File transfer protocol (FTP);Generative programming;Latency;Protocol Implementation Frameowrk for Linux (PIX);},
} 


@inproceedings{20082211277244 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GP-pro: The generative programming protocol generator for routing in mobile ad hoc networks},
journal = {2006 2nd IEEE Workshop on Wireless Mesh Networks, WiMESH 2006},
author = {Villanueva-Pena, Pedro E. and Kunz, Thomas},
year = {2007},
pages = {129 - 131},
address = {Reston, VA, United states},
abstract = {Routing in mobile ad hoc networks (MANETs) where network topology is highly dynamic is not a trivial task. Routing protocols have been profoundly researched but only three of them have reached the RFC status (AODV[7], OLSR[5] and TBPRF[O]). On the other hand, the constantly increasing network requirements in terms of bandwidth, robustness, reliability and quality of service for a broad range of multiplatform scenarios demand for fast development and implementation of routing protocols that satisfy specific user and network requirements. However, current practices for protocol development and implementation are costly error-prone and time-consuming, especially when existing knowledge is not properly reused. Generative Programming is an attractive solution that makes use of reusable components and is also empowered with the knowledge to automatically assemble them. This paper discusses the design and development of the GP-Pro protocol generator (based on generative programming), for automatic generation of ad hoc routing protocols, according to user requirements expressed by means of a specification language. GP-Pro is designed to be extensible, with the explicit goal of generating a large number of different protocols by different component combinations. GP-Pro addresses the generation of proactive, reactive and position-based routing protocols. &copy; 2006 IEEE.},
key = {Routing protocols},
keywords = {Ad hoc networks;Bandwidth;Computer programming;Mobile telecommunication systems;Quality of service;},
note = {Automatic generation;Domain engineering;Generative programming;Mobile ad hoc networks (MANET);},
URL = {http://dx.doi.org/10.1109/WIMESH.2006.288628},
} 


@inproceedings{20102813070563 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A generative programming approach for game development},
journal = {SBGAMES2009 - 8th Brazilian Symposium on Games and Digital Entertainment},
author = {Sarinho, Victor T. and Apolinario, Antonio L.},
year = {2009},
pages = {83 - 92},
address = {Rio de Janeiro, Brazil},
abstract = {Nowadays, due to the great distance between design and implementation worlds, different skills are necessary to create a game system. To solve this problem, a lot of strategies for game development, trying to increase the abstraction level necessary for the game production, were proposed. In this way, a lot of game engines, game frameworks and others, in most cases without any compatibility or reuse criteria between them, were developed. This paper presents a new generative programming approach, able to increase the production of a digital game by the integration of different game development artifacts, following a system family strategy focused on variable and common aspects of a computer game. As result, high level abstractions of games, based on a common language, can be used to configure metaprogramming transformations during the game production, providing a great compatibility level between game domain and game implementation artifacts. &copy; 2009 IEEE.},
key = {Computer systems programming},
keywords = {Abstracting;Linguistics;Specification languages;Specifications;Strategic planning;},
note = {Abstraction level;Common languages;Compatibility levels;Computer game;Digital games;Feature models;Game development;Game Engine;Game specifications;Game system;Generative programming;High-level abstraction;Meta Programming;System families;},
URL = {http://dx.doi.org/10.1109/SBGAMES.2009.18},
} 


@inproceedings{20070910459570 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative programming for programmable logic controllers},
journal = {IEEE Symposium on Emerging Technologies and Factory Automation, ETFA},
author = {Cote, Daniel and St-Denis, Richard and Kerjean, Sylvain},
volume = {2 2 OF 2 VOL},
year = {2005},
pages = {741 - 748},
address = {Catania, Italy},
abstract = {Many attempts have been made to implement supervisors derived by synthesis procedures peculiar to the Supervisory Control Theory (SCT), most adopting the event-based supervisory control paradigm. However, when considering code generation schemata for programmable logic controllers (PLCs), hardware resources are limited and event tracking is hard to realize satisfactorily. Moreover, previous work has highlighted differences between the abstract model adopted by SCT and realistic process control situations. Inappropriate solutions to these issues may result in code generation schemata that produce unreliable PLC code. A generative programming approach for PLCs based on a dual paradigm, the state-based supervisory control paradigm, is investigated in this paper. Such cm approach exhibits interesting properties. For instance, the maximum depth of the PLC stack as well as PLC cycle, timing evaluations become possible. Furthermore, well-known code optimization techniques can be used to obtain more efficient code. &copy; 2005 IEEE.},
key = {Logic programming},
keywords = {Codes (symbols);Computer hardware;Control theory;Mathematical models;Optimization;},
note = {Code generation schemata;Generative programming;Logic controllers;Supervisory Control Theory (SCT);},
} 


@inproceedings{2005429419764 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative programming from a post object-oriented programming viewpoint},
journal = {Lecture Notes in Computer Science},
author = {Chiba, Shigeru},
volume = {3566},
year = {2005},
pages = {355 - 366},
issn = {03029743},
address = {Le Mont Saint Michel, France},
abstract = {This paper presents an application of generative programming to reduce the complications of the protocol for using an application framework written in an object-oriented language. It proposes that a programmable program translator could allow framework users to write a simple program, which is automatically translated by the translator into a program that fits the framework protocol. Then it mentions the author's experience with Javassist, which is a translator toolkit for Java, and discusses a research issue for applying this idea to real-world software development. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Computer programming},
keywords = {Computer programming languages;Computer science;Java programming language;Network protocols;Program translators;},
note = {Application framework;Framework protocol;Generative programming;Translator toolkit;},
} 


@article{2006269957464 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative programming for C#},
journal = {ACM SIGPLAN Notices},
author = {Draheim, Dirk and Lutteroth, Christof and Weber, Gerald},
volume = {40},
number = {8},
year = {2005},
pages = {29 - 33},
issn = {03621340},
abstract = {This article describes how we extended the C# language by new constructs that provide means for generative programming. Those constructs make it possible to handle problems like the generation of user interfaces and certain crosscutting concerns in a less error prone and elegant way without affecting the overall language integrity.},
key = {Computer programming},
keywords = {Computer programming languages;Problem solving;User interfaces;},
note = {Generative programming;Genericity;},
URL = {http://dx.doi.org/10.1145/1089851.1089857},
} 


@inproceedings{20080511075913 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative programming approach for building pervasive computing applications},
journal = {Proceedings - ICSE 2007 Workshops: First International Workshop on Software Engineering for Pervasive Computing Applications, Systems, and Environments, SEPCASE'07},
author = {Kulkarni, Devdatta and Tripathi, Anand},
year = {2007},
address = {Minneapolis, MN, United states},
abstract = {In this paper we present a generative programming approach for building context-aware applications. In this approach, a context-aware application is programmed using high-level specification constructs provided in our programming framework. The runtime environment of the application is generated from this specification by a middleware. We demonstrate the utility of this approach by presenting an example case-study. &copy; 2007 IEEE.},
key = {Ubiquitous computing},
keywords = {Computer programming;Middleware;},
note = {Context aware application;Generative programming;},
URL = {http://dx.doi.org/10.1109/SEPCASE.2007.8},
} 


@inproceedings{20094312391552 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Developing scientific applications using generative programming},
journal = {Proceedings of the 2009 ICSE Workshop on Software Engineering for Computational Science and Engineering, SECSE 2009},
author = {Arora, Ritu and Bangalore, Purushotham and Mernik, Marjan},
year = {2009},
pages = {51 - 58},
address = {Vancouver, BC, Canada},
abstract = {Scientific applications usually involve large number of distributed and dynamic resources and huge datasets. A mechanism like checkpointing is essential to make these applications resilient to failures. Using checkpointing as an example, this paper presents an approach for integrating the latest software engineering techniques with the development of scientific software. Generative programming is used in this research to achieve the goals of non-intrusive reengineering of existing applications to insert the checkpointing mechanism and to decouple the checkpointing-specifications from its actual implementation. The end-user specifies the checkpointing details at a higher level of abstraction, using which the necessary code is generated and woven into the application. The lessons learned and the implementation approach presented in this paper can be applied to the development of scientific applications in general. The paper also demonstrates that the generated code does not introduce any inaccuracies and its performance is comparable to the manually inserted code. &copy; 2009 IEEE.},
key = {Engineering},
keywords = {Computer software;},
note = {Check pointing;Data sets;End users;Generative programming;Implementation approach;Lessons learned;Level of abstraction;Non-intrusive;Scientific applications;Scientific softwares;},
URL = {http://dx.doi.org/10.1109/SECSE.2009.5069162},
} 


@inproceedings{2005429418127 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards generative programming},
journal = {Lecture Notes in Computer Science},
author = {Cointe, Pierre},
volume = {3566},
year = {2005},
pages = {315 - 325},
issn = {03029743},
address = {Le Mont Saint Michel, France},
abstract = {Generative Programming (GP) is an attempt to manufacture software components in an automated way by developing programs that synthesize other programs. Our purpose is to introduce the what and the how of the GP approach from a programming language point of view. For the what we discuss the lessons learned from object-oriented languages seen as general purpose languages to develop software factories. For the how we compare a variety of approaches and techniques based on program transformation and generation. On the one hand, we present the evolution of open-ended languages from metalevel programming to aspect-oriented programming. On the other hand, we introduce domain-specific languages as a way to bridge the gap between conceptual models and programming languages. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Automatic programming},
keywords = {Computer programming languages;Computer software;Mathematical models;Object oriented programming;},
note = {Domain-specific languages;Generative programming (GP);Metalevel programming;Program transformation;},
} 


@inproceedings{2004518731762 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Program comprehension in generative programming: A history of grand challenges},
journal = {Program Comprehension, Workshop Proceedings},
author = {Batory, Don},
volume = {12},
year = {2004},
pages = {2 - 11},
issn = {10928138},
address = {Bari, Italy},
abstract = {The communities of Generative Programming (GP) and Program Comprehension (PC) look at similar problems: GP derives a program from a specification, PC derives a specification from a program. A basic difference between the two is GP's use of specific knowledge representations and mental models that are essential for program synthesis. In this paper, I present a historical review of the Grand Challenges, results, and outlook for GP as they pertain to PC.},
key = {Automatic programming},
keywords = {Codes (symbols);Computer programming languages;Computer software;Knowledge acquisition;Mathematical models;Problem solving;Product design;},
note = {Domain-specific languages;Generative Programming (GP);Program Comprehension (PC);Program models;},
} 


@inproceedings{2006079704120 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Visual tool for generative programming},
journal = {ESEC/FSE'05 - Proceedings of the Joint 10th European Software Engineering Conference (ESEC) and 13th ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE-13)},
author = {Grigorenko, Pavel and Saabas, Ando and Tyugu, Enn},
year = {2005},
pages = {249 - 252},
address = {Lisbon, Portugal},
abstract = {A way of combining object-oriented and structural paradigms of software composition is demonstrated in a tool for generative programming. Metaclasses are introduced that are components with specifications called metainterfaces. Automatic code generation is used that is based on structural synthesis of programs. This guarantees that problems of handling data dependencies, order of application of components, usage of higher-order control structures etc are handled automatically. Specifications can be written either in a specification language or given visually on an architectural level. The tool is Java-based and portable. Copyright 2005 ACM.},
key = {Computer aided software engineering},
keywords = {Automatic programming;Binary codes;Computer programming languages;Data handling;Metadata;Object oriented programming;},
note = {Compositional software engineering;Generative programming;Model-based software engineering;},
} 


@inproceedings{2005159032313 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Consistency checking in an infrastructure for large-scale generative programming},
journal = {Proceedings - 19th International Conference on Automated Software Engineering, ASE 2004},
author = {Rauschmayer, Axel and Knapp, Alexander and Wirsing, Martin},
year = {2004},
pages = {238 - 247},
address = {Linz, Austria},
abstract = {Ubiquitous computing increases the pressure on the software industry to produce ever more and error-free code. Two recipes from automated programming are available to meet this challenge: On the one hand, generative programming raises the level of abstraction in software development by describing problems in high-level domain-specific languages and making them executable. On the other hand, in situations where one needs to produce a family of similar programs, product line engineering supports code reuse by composing programs from a set of common assets (or features). AHEAD (Algebraic Hierarchical Equations for Application Design) is a framework for generative programming and product line engineering that achieves additional productivity gains by scaling feature composition up. Our contribution is GRAFT, a calculus that gives a formal foundation to AHEAD and provides several mechanisms for making sure that feature combinations are legal and that features in themselves are consistent. &copy; 2004 IEEE.},
key = {Automatic programming},
keywords = {Boolean algebra;Java programming language;Problem solving;Robustness (control systems);Semantics;Software engineering;Theorem proving;},
note = {Algebraic hierarchical equations for application design (AHEAD);Domain-specific language;Non-monotonicity;Scaling featur ecomposition;},
} 


@inproceedings{20112914152569 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The REA-DSL: A domain specific modeling language for business models},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Sonnenberg, Christian and Huemer, Christian and Hofreiter, Birgit and Mayrhofer, Dieter and Braccini, Alessio},
volume = {6741 LNCS},
year = {2011},
pages = {252 - 266},
issn = {03029743},
address = {London, United kingdom},
abstract = {In the discipline of accounting, the resource-event-agent (REA) ontology is a well accepted conceptual accounting framework to analyze the economic phenomena within and across enterprises. Accordingly, it seems to be appropriate to use REA in the requirements elicitation to develop an information architecture of accounting and enterprise information systems. However, REA has received comparatively less attention in the field of business informatics and computer science. Some of the reasons may be that the REA ontology despite of its well grounded core concepts is (1) sometimes vague in the definition of the relationships between these core concepts, (2) misses a precise language to describe the models, and (3) does not come with an easy to understand graphical notation. Accordingly, we have started developing a domain specific modeling language specifically dedicated to REA models and corresponding tool support to overcome these limitations. In this paper we present our REA DSL which supports the basic set of REA concepts. &copy; 2011 Springer-Verlag.},
key = {Information systems},
keywords = {Information science;Knowledge management;Models;Ontology;Systems engineering;},
note = {Business Models;Conceptual modeling;Domain specific languages;Domain specific modeling languages;Enterprise information system;Graphical notation;Informatics;Information architectures;Requirements elicitation;Tool support;},
URL = {http://dx.doi.org/10.1007/978-3-642-21640-4_20},
} 


@inproceedings{20100912734923 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific modeling language supporting specification, simulation and execution of dynamic adaptive systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Fleurey, Franck and Solberg, Arnor},
volume = {5795 LNCS},
year = {2009},
pages = {606 - 621},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {Constructing and executing distributed systems that can automatically adapt to the dynamic changes of the environment are highly complex tasks. Non-trivial challenges include provisioning of efficient design time and run time representations, system validation to ensure safe adaptation of interdependent components, and scalable solutions to cope with the possible combinatorial explosions of adaptive system artifacts such as configurations, variant dependencies and adaptation rules. These are all challenges where current approaches offer only partial solutions. Furthermore, in current approaches the adaptation logic is typically specified at the code level, tightly coupled with the main system functionality, making it hard to control and maintain. This paper presents a domain specific modeling language (DSML) allowing specification of the adaptation logic at the model level, and separation of the adaptation logic from the main system functionality. It supports model-checking and design-time simulation for early validation of adaptation policies. The model level specifications are used to generate the adaptation logic. The DSML also provides indirection mechanisms to cope with combinatorial explosions of adaptive system artifacts. The proposed approach has been implemented and validated through case studies. &copy; 2009 Springer Berlin Heidelberg.},
key = {Model checking},
keywords = {Adaptive systems;Embedded systems;Linguistics;Models;Query languages;Specifications;},
note = {Adaptation rules;Combinatorial explosion;Complex task;Distributed systems;Domain specific modeling languages;Dynamic changes;Efficient designs;Inter-dependent components;Non-trivial;Runtimes;Scalable solution;System functionality;System validation;Tightly-coupled;Time simulations;},
URL = {http://dx.doi.org/10.1007/978-3-642-04425-0_47},
} 


@inproceedings{20083611524485 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a domain-specific modeling language for customer data integration workflow},
journal = {Proceedings - 3rd International Conference on Grid and Pervasive Computing Symposia/Workshops, GPC 2008},
author = {Deneke, Wesley and Eno, Josh and Li, Wingning and Thompson, Craig and Talburt, John and Loghry, Jonathan and Nash, David and Stires, Jeff},
year = {2008},
pages = {49 - 56},
address = {Kunming, China},
abstract = {This paper describes the workflow specification problem, how workflows are specified today, requirements for improved workflow specification, and begins to sketch a new domain-specific modeling language (DSML) approach for specifying intent that can be used to constructively generate a complete workflow meeting a collection of intent requirements. This is an interim report on work in progress. &copy; 2008 IEEE.},
key = {Grid computing},
keywords = {Integration;Linguistics;Predictive control systems;Specifications;},
note = {Dom-ain-specific modeling languages;International conferences;Pervasive Computing;},
URL = {http://dx.doi.org/10.1109/GPC.WORKSHOPS.2008.49},
} 


@inproceedings{20094712474028 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative programming with support for formal verification},
journal = {Proceedings - 2009 IEEE International Symposium on Industrial Embedded Systems, SIES 2009},
author = {Paka, Marek},
year = {2009},
pages = {58 - 61},
address = {Lausanne, Switzerland},
abstract = {This paper presents a novel approach to software development, mainly useful for embedded devices.Embedded software is described in a programming language with very high level of abstraction.Efficient production code is generated from this description; also code suitable for formal verification is generated.The paper investigates efficiency of both the verifiable and the production code.&copy; 2009 IEEE.},
key = {Embedded systems},
keywords = {Computer software selection and evaluation;Embedded software;Formal methods;Verification;},
note = {Formal verifications;Generative programming;Programming language;Software development;},
URL = {http://dx.doi.org/10.1109/SIES.2009.5196194},
} 


@inproceedings{2006179837292 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative programming driven by user models},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Marinilli, Mauro and Micarelli, Alessandro},
volume = {3538 LNAI},
year = {2005},
pages = {30 - 39},
issn = {03029743},
address = {Edinburgh, Scotland, United kingdom},
abstract = {This paper discusses the automatic generation of programs by adapting the construction process to the user currently interacting with the program. A class of such systems is investigated where such generation process is continuously repeated making the program design and implementation evolve according to user behaviour. By leveraging on existing technologies (software generation facilities, modelling languages, specific and general standard meta-models) an experimental proof of concept system that is able to generate itself while interacting with the user is introduced and tested. The findings are discussed and a general organization for this class of adaptive systems is briefly proposed and compared with existing literature. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Automatic programming},
keywords = {Computer programming;Computer science;Computer simulation;Computer software;Metadata;},
note = {Generative programming;Meta models;Modelling languages;Software generation;},
} 


@inproceedings{2005058812014 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A generative programming framework for adaptive middleware},
journal = {Proceedings of the Hawaii International Conference on System Sciences},
author = {Subramonian, Venkita and Gill, Christopher},
volume = {37},
year = {2004},
pages = {4273 - 4282},
issn = {10603425},
address = {Big Island, HI., United states},
abstract = {Component middleware technologies such as the CORBA Component Model (CCM), J2EE, and .NET, were developed to address many limitations like interdependencies between services and object interfaces, limited re-use, of first-generation middleware technologies such as CORBA 2.x, XML, and SOAP. These component technologies have addressed a wide range of application domains, but unfortunately for distributed real-time and embedded (DRE) systems, the focus of these technologies has been primarily on functional and not quality of service (QoS) properties. Research on QoS-aware component models such as the CIAO project shows that there is a fundamental difference between configuration of functional and QoS properties even within such a unified component model: the dominant decomposition of functional properties is essentially object-oriented, while the dominant decomposition of QoS properties is essentially aspect-oriented. In this paper, we describe how a focus on aspect frameworks for configuring QoS properties both complements and extends QoS-aware component models. This paper makes three main contributions to the state of the art in DRE systems middleware. First, it describes a simple but representative problem for configuring QoS aspects that cut across architectural layers, system and distribution boundaries, which motivates our focus on aspect frameworks. Second, it provides a formalization of that problem using first order logic - Infrastructure Configuration Logic - which both guides the design of aspect configuration infrastructure, and offers a way to connect these techniques with model-integrated computing approaches to further reduce the programming burden on DRE system developers. Third, it describes alternative mechanisms to ensure correct configuration of the aspects involved, and notes the phases of the DRE system lifecycle at which each such configuration mechanism is most appropriate.},
key = {Computer programming languages},
keywords = {Adaptive systems;Computer architecture;Mathematical models;Middleware;Quality of service;XML;},
note = {Adaptive and reflective middleware;First order logic;Generative programming;System aspects;},
} 


@article{20063510090662 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Unifying clones with a generative programming technique: A case study},
journal = {Journal of Software Maintenance and Evolution},
author = {Jarzabek, Stan and Li, Shubiao},
volume = {18},
number = {4},
year = {2006},
pages = {267 - 292},
issn = {1532060X},
abstract = {Software clones - similar program structures repeated in variant forms - increase the risk of update anomalies, blow up the program size and complexity, possibly contributing to high maintenance costs. Yet, programs are often polluted by clones. In this paper, we present a case study of cloning in the Java Buffer library, JDK 1.5. We found that at least 68% of the code in the Buffer library was contained in cloned classes or class methods. Close analysis of program situations that led to cloning revealed difficulties in eliminating clones with conventional program design techniques. As a possible solution, we applied a generative technique of XVCL (XML-based Variant Configuration Language) to represent similar classes and methods in generic, adaptable form. Concrete buffer classes could be automatically produced from the generic structures. We argue, on analytical and empirical grounds, that unifying clones reduced conceptual complexity and enhanced the changeability of the Buffer library at rates proportional to code size reduction (68%). We evaluated our solution in qualitative and quantitative ways, and conducted a controlled experiment to support this claim. The approach presented in the paper can be used to enhance genericity and changeability of any program, independently of an application domain or programming language. As the solution is not without pitfalls, we discuss trade-offs involved in its project application. Copyright &copy; 2006 John Wiley &amp; Sons, Ltd.},
key = {Computer programming},
keywords = {Computer software maintenance;Computer software reusability;Costs;Large scale systems;Project management;Risk assessment;XML;},
note = {Class libraries;Generative programming;Object-oriented methods;},
URL = {http://dx.doi.org/10.1002/smr.333},
} 


@inproceedings{20110813675332 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The power of symmetry: Unifying inheritance and generative programming},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {DeLesley, Hutchins},
year = {2003},
pages = {38 - 52},
address = {Anaheim, CA, United states},
abstract = {I present the Ohmu language, a unified object model which allows a number of "advanced" techniques such as aspects, mixin layers, parametric polymorphism, and generative components to be implemented cleanly using two basic concepts: block structure and inheritance. I argue that conventional ways of defining classes and objects have created artificial distinctions which limit their expressiveness. The Ohmu model unifies functions, classes, instances, templates, and even aspects into a single construct - the structure. Function calls, instantiation, aspect-weaving, and inheritance are likewise unified into a single operation - the structure transformation. This simplification eliminates the distinction between classes and instances, and between compiletime and run-time code. Instead of being compiled, programs are reduced using partial evaluation, during which the interpreter is invoked at compile-time. Within this architecture, standard OO inheritance becomes a natural vehicle for creating meta-programs and automatic code generators - the key to a number of recent domain-driven programming methodologies.},
key = {Object oriented programming},
keywords = {Aspect oriented programming;Automatic programming;Computer systems programming;Java programming language;Network components;Parameter estimation;Polymorphism;Program interpreters;Textile industry;},
note = {Aspect-oriented;Aspects;Code Generation;Covariant;Generative components;Generative programming;Generic types;Join points;Meta Programming;Mixin layers;Mixins;Multiple inheritance;Parametric polymorphism;Partial evaluation;Prototypes;Transformation systems;Virtual class;Virtual types;},
URL = {http://dx.doi.org/10.1145/949344.949350},
} 


@inproceedings{20083311460907 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a rigorous framework for dealing with domain specific language families},
journal = {2008 3rd International Conference on Information and Communication Technologies: From Theory to Applications, ICTTA},
author = {Dib, Ali Abou and Feraud, Louis and Ober, Ileana and Percebois, Christian},
year = {2008},
address = {Damascus, Syria},
abstract = {In this paper we present our approach to rigorously handle variation within a family of languages. Our starting point is a case study that we developed with industrial partners, where a major difficulty arised from the need to work with a set of domain specific languages (DSLs). Our solution is based on using the Category Theory. We consider the category of algebraic specifications implementing the semantics of the DSLs and we calculate the unifying language of the family.},
key = {Query languages},
keywords = {Communication;Information theory;Linguistics;Specifications;Technology;},
note = {Algebraic specifications;Case studies;Category theory;Domain specific language (DSL);Domain specific modeling (DSM);Domain specific modeling language (DSML);Domain-Specific Language;Domain-specific languages;Formal semantics;Incremental verification;Industrial partners;INformation and communication technologies;International conferences;},
URL = {http://dx.doi.org/10.1109/ICTTA.2008.4530342},
} 


@inproceedings{20092912190802 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The formal semantics of the domain specific modeling language for multiagent systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Hahn, Christian and Fischer, Klaus},
volume = {5386},
year = {2009},
pages = {16 - 30},
issn = {03029743},
address = {Estoril, Portugal},
abstract = {Recently, associated with the increasing acceptance of agentbased computing as a novel computing paradigm a lot of research has been addressed to develop mechanisms and methods to support the agent-based development of complex software systems. Especially the idea to define agent-oriented languages on a more abstract level through metamodels is recently often applied. However, the metamodel's opportunity to express the language's semantics are restricted as only concepts and their relationships to each other can be defined within the metamodel. This paper discusses an approach to formalize the semantics of Dsml4mas-a modeling language for multiagent systems-to support the system designer in validating and verifying the generated design.},
key = {Software agents},
keywords = {Formal methods;Linguistics;Multi agent systems;Query languages;Semantics;},
note = {Abstract levels;Agent based;Agent-based computing;Agent-oriented;Complex software systems;Computing paradigm;Domain specific modeling languages;Formal Semantics;Meta model;Modeling languages;System designers;},
URL = {http://dx.doi.org/10.1007/978-3-642-01338-6_2},
} 


@inproceedings{2005058812563 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Framework for domain-specific modeling language development},
journal = {Proceedings of the International Conference on Software Engineering Research and Practice, SERP'04},
author = {Grant, Emanuel S. and Reza, Hassan},
volume = {1},
year = {2004},
pages = {183 - 187},
address = {Las Vegas, NV, United states},
abstract = {The use of general purpose modeling languages (GPMLs) is giving way to the increasing usage of domain-specific modeling languages (DSMLs). Many DSMLs are high level textual programming languages, and offer very little support for modeling at the analysis, and design phases of software development. The objective of this work is to develop semi-formal graphical DSMLs that are used in analyzing and design software systems, within specified domains.},
key = {High level languages},
keywords = {Computer software;Mathematical models;Object oriented programming;Semantics;Software engineering;Syntactics;Systems analysis;},
note = {Domain-specific modeling languages (DSML);General purpose modeling languages (GPML);Rigorous domain specific software engineering (RDSSE);Unified modeling languages (UML);},
} 


@inproceedings{20090911935121 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Specification and implementation of autonomic large-scale system behaviors using domain specific modeling language tools},
journal = {Proceedings of the 2005 International Conference on Software Engineering Research and Practice, SERP'05},
author = {Yao, Di and Neema, Sandeep and Nordstrom, Steve and Ahuja, Shikha and Shetty, Shwetta and Bapty, Ted},
volume = {1},
year = {2005},
pages = {16 - 22},
address = {Las Vegas, NV, United states},
abstract = {Space applications are often highly complex systems composed of a large number of hardware and software components. The harsh environments in which the hardware operates and long mission lifetime make this class of systems susceptible to component failures, jeopardizing the success of space missions. Embedding autonomic fault-mitigation behaviors in the system can greatly increase the chance of mission success and decrease catastrophic consequences. Work at Vanderbilt University has resulted in a tool for designing fault-adaptive, autonomic systems. The tool provides an environment that supports specification of custom fault-adaptive behaviors and automated generation of behavior code. These behaviors are defined to perform application-specific adaptations in response to external and internal fault events. This paper describes the application of the tool in managing faults on large-scale embedded computing clusters for a high-energy physics instrumentation application and how this tool can be extended to space applications.},
key = {Embedded systems},
keywords = {Embedded software;Engineering research;Fault tolerant computer systems;High energy physics;Integrated circuits;Large scale systems;Real time systems;Software engineering;Space applications;Specifications;},
note = {Autonomic systems;Fault tolerant;Large-scale embedded systems;Model integrated computing;Real-time;Software generation;},
} 


@inproceedings{20094812500005 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Algorithmic skeletons within an embedded domain specific language for the cell processor},
journal = {Parallel Architectures and Compilation Techniques - Conference Proceedings, PACT},
author = {Saidani, Tarik and Tadonki, Claude and Lacassagne, Lionel and Falcou, Joel and Etiemble, Daniel},
year = {2009},
pages = {67 - 76},
issn = {1089795X},
address = {Raleigh, NC, United states},
abstract = {Efficiently using the hardware capabilities of the Cell processor, a heterogeneous chip multiprocessor that uses several levels of parallelism to deliver high performance, and being able to reuse legacy code are real challenges for application developers. We propose to use Generative Programming and more precisely template meta-programing to design an Embedded Domain Specific Language using algorithmic skeletons to generate applications based on a high-level mapping description. The method is easy to use by developers and delivers performance close to the performance of optimized hand-written code, as shown on various benchmarks ranging from simple BLAS kernels to image processing applications.},
key = {Algorithmic languages},
keywords = {Algorithms;Benchmarking;Image processing;Linguistics;Parallel architectures;},
note = {Algorithmic skeleton;Application developers;CELL processor;Embedded domain specific languages;Generative programming;Heterogeneous chip multiprocessor;Image processing applications;Legacy code;Level mapping;},
URL = {http://dx.doi.org/10.1109/PACT.2009.21},
} 


@inproceedings{20105113498033 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GPCE'10 - Proceedings of the 2010 Conference on Generative Programming and Component Engineering},
journal = {GPCE'10 - Proceedings of the 2010 Conference on Generative Programming and Component Engineering},
year = {2010},
pages = {ACM SIGPLAN - },
address = {Eindhoven, Netherlands},
abstract = {The proceedings contain 20 papers. The topics discussed include: automatic variation-point identification in function-block-based models; efficient extraction and analysis of preprocessor-based variability; iterative type inference with attribute grammars; automatic and efficient simulation of operation contracts; implicit invocation meets safe, implicit concurrency; a component-based run-time evolution infrastructure for resource-constrained embedded systems; code clones in feature-oriented software product lines; composition of dynamic analysis aspects; applications of enhanced dynamic code evolution for Java in GUI development and dynamic aspect-oriented programming; domain-specific language integration with compile-time parser generator library; ABI compatibility through a customizable language; model-based kinematics generation for modular mechatronic toolkits; and incremental type-checking for type-reflective metaprograms.},
} 


@inproceedings{2006189858290 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A generative programming approach to interactive information retrieval: Insights and experiences},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Perugini, Saverio and Ramakrishnan, Naren},
volume = {3676 LNCS},
year = {2005},
pages = {205 - 220},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {We describe the application of generative programming to a problem in interactive information retrieval. The particular interactive information retrieval problem we study is the support for 'out of turn interaction' with a website - how a user can communicate input to a website when the site is not soliciting such information on the current page, but will do so on a subsequent page. Our solution approach makes generous use of program transformations (partial evaluation, currying, and slicing) to delay the site's current solicitation for input until after the user's out-of-turn input is processed. We illustrate how studying outof-turn interaction through a generative lens leads to several valuable insights: (i) the concept of a web dialog, (ii) an improved understanding of web taxonomies, and (iii) new web interaction techniques and interfaces. These notions allow us to cast the design of interactive (and responsive) websites in terms of the underlying dialog structure and, further, suggest a simple implementation strategy with a clean separation of concerns. We also highlight new research directions opened up by the generative programming approach to interactive information retrieval such as the idea of web interaction axioms. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Information retrieval},
keywords = {Computer programming;Data processing;Interactive computer systems;World Wide Web;},
note = {Dialog structure;Web interaction axioms;Web taxonomies;},
URL = {http://dx.doi.org/10.1007/11561347_15},
} 


@inproceedings{2003517785161 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The XIS Generative Programming Techniques},
journal = {Proceedings - IEEE Computer Society's International Computer Software and Applications Conference},
author = {Da Silva, Alberto Rodrigues and Lemos, Goncalo and Matias, Tiago and Costa, Marco},
year = {2003},
pages = {236 - 241},
issn = {07303157},
address = {Dallas, TX, United states},
abstract = {XIS' is a R&amp;D project which main mission is to analyze, develop and evaluate mechanisms and tools to produce information systems from a more abstract, high-level, efficient and productive way than it is done currently. XIS project is Influenced by MDA reference model, and is mainly based on three principles: namely high-level models specification; generative programming techniques; and it is component-based architecture-centric. XIS is not a conceptual research plan, it is a working on project with concrete results and produced systems. In this paper we detail the generative programming techniques used in the XIS project as well as the discussions and main decisions tackled on. Finally, we present the main conclusions, the relationship between XIS and MDA, and the work that will be handled in the near future.},
key = {Automatic programming},
keywords = {Abstracting;Computer programming languages;Computer software;Information science;Research and development management;},
note = {Generative programing techniques;},
URL = {http://dx.doi.org/10.1109/CMPSAC.2003.1245347},
} 


@inproceedings{2006189858279 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A generative programming approach to developing DSL compilers},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Consel, Charles and Latry, Fabien and Reveillere, Laurent and Cointe, Pierre},
volume = {3676 LNCS},
year = {2005},
pages = {29 - 46},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {Domain-Specific Languages (DSLs) represent a proven approach to raising the abstraction level of programming. They offer high-level constructs and notations dedicated to a domain, structuring program design, easing program writing, masking the intricacies of underlying software layers, and guaranteeing critical properties. On the one hand, DSLs facilitate a straightforward mapping between a conceptual model and a solution expressed in a specific programming language. On the other hand, DSLs complicate the compilation process because of the gap in the abstraction level between the source and target language. The nature of DSLs make their compilation very different from the compilation of common General-Purpose Languages (GPLs). In fact, a DSL compiler generally produces code written in a GPL; low-level compilation is left to the compiler of the target GPL. In essence, a DSL compiler defines some mapping of the high-level information and features of a DSL into the target GPL and underlying layers (e.g., middleware, protocols, objects, ... ). This paper presents a methodology to develop DSL compilers, centered around the use of generative programming tools. Our approach enables the development of a DSL compiler to be structured on facets that represent dimensions of compilation. Each facet can then be implemented in a modular way, using aspects, annotations and specialization. Because these tools are high level, they match the needs of a DSL, facilitating the development of the DSL compiler, and making it modular and re-targetable. We illustrate our approach with a DSL for telephony services. The structure of the DSL compiler is presented, as well as practical uses of generative tools for some compilation facets. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Computer programming},
keywords = {Computer programming languages;Computer software;Program compilers;},
note = {Annotations;DSL compilers;General-Purpose Languages (GPLs);Structuring program design;},
URL = {http://dx.doi.org/10.1007/11561347_4},
} 


@inproceedings{20094912520794 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GPCE'09 - Proceedings of the 8th International ACM SIGPLAN Conference on Generative Programming and Component Engineering},
journal = {GPCE'09 - Proceedings of the 8th International ACM SIGPLAN Conference on Generative Programming and Component Engineering},
year = {2009},
pages = {ACM SIGPLAN - },
address = {Denver, CO, United states},
abstract = {The proceedings contain 19 papers. The topics discussed include: reusable, generic program analyses and transformations; toward foundations for type-reflective metaprogramming; transactional pointcuts: designation reification and advice of interrelated join points; extending aspectJ for separating regions; a language and framework for invariant-driven transformations; JavaGI in the battlefield: practical experience with generalized interfaces; classifying java class transformations for pervasive virtualized access; advanced runtime adaptation for java; hotwave: creating adaptive tools with dynamic aspect-oriented programming in java; generating safe template languages; abstract parsing for two-staged languages with concatenation; synthesis of fast programs for maximum segment sum problems; a generative programming approach to developing pervasive computing systems; and algorithms for user interfaces.},
} 


@inproceedings{20064310192393 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MetaBorg in action: Examples of domain-specific language embedding and assimilation using stratego/XT},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Bravenboer, Martin and De Groot, Rene and Visser, Eelco},
volume = {4143 LNCS},
year = {2006},
pages = {297 - 311},
issn = {03029743},
address = {Braga, Portugal},
abstract = {General-purpose programming languages provide limited facilities for expressing domain-specific concepts in a natural manner. All domain concepts need to be captured using the same generic syntactic and semantic constructs. Generative programming methods and program transformation techniques can be used to overcome this lack of abstraction in general-purpose languages. In this tutorial we describe the METABORG method for embedding domainspecific languages, tailored syntactically and semantically to the application domain at hand, in a general-purpose language. METABORG is based on Stratego/XT, a language and toolset for the implementation of program transformation systems, which is used for the definition of syntactic embeddings and assimilation of the embedded constructs into the surrounding code. We illustrate METABORG with three examples. JavaSwul is a custom designed language for implementing graphical user-interfaces, which provides high-level abstractions for component composition and event-handling. JavaRegex is a new embedding of regular expression matching and string rewriting. JavaJava is an embedding of Java in Java for generating Java code. For these cases we show how Java programs in these domains become dramatically more readable, and we give an impression of the implementation of the language embeddings. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Computer programming languages},
keywords = {Embedded systems;Graphical user interfaces;Program translators;Semantics;Syntactics;},
note = {Domain specific languages;General purpose programming languages;Generative programming methods;Program transformation systems;},
} 


@article{20111113757909 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Special issue on generative programming and component engineering (Selected Papers from GPCE 2004/2005)},
journal = {Science of Computer Programming},
author = {Gluck, Robert and Visser, Eelco},
volume = {76},
number = {5},
year = {2011},
pages = {347 - 348},
issn = {01676423},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
URL = {http://dx.doi.org/10.1016/j.scico.2011.02.001},
} 


@article{20101612855491 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Preface to special issue on Generative Programming and Component Engineering (GPCE 2007)},
journal = {Science of Computer Programming},
author = {Lawall, Julia L.},
volume = {75},
number = {7},
year = {2010},
pages = {471 - 472},
issn = {01676423},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
URL = {http://dx.doi.org/10.1016/j.scico.2010.01.005},
} 


@article{20105113498012 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GPCE'10 - Proceedings of the 2010 Conference on Generative Programming and Component Engineering: Foreword},
journal = {GPCE'10 - Proceedings of the 2010 Conference on Generative Programming and Component Engineering},
author = {Visser, Eelco and Jarvi, Jaakko},
year = {2010},
pages = {iii - iii},
address = {Eindhoven, Netherlands},
} 


@inproceedings{20080711091781 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative programming techniques for Java library migration},
journal = {GPCE'07 - Proceedings of the Sixth International Conference on Generative Programming and Component Engineering},
author = {Winter, Victor L. and Mametjanov, Azamat},
year = {2007},
pages = {185 - 196},
address = {Salzburg, Australia},
abstract = {Embedded systems can be viewed as scaled-down versions of their stand-alone counterparts. In many cases, the software abstractions and libraries for embedded systems can be derived from libraries for stand-alone systems. One such example is the Java library for Java Virtual Machines. An embedded system does not always support all features as in the case of an embedded JVM that does not support floating-point operations. In such cases, an existing library needs to be migrated to the embedded platform. Libraries are large collections of code and manual migration is a daunting task. In this paper, we provide an automated approach to the library migration problem using program transformations. The solution developed in this paper enables rapid adaptation and re-targeting of Java libraries in the presence of evolving libraries and evolving embedded platforms. Copyright &copy; 2007 ACM.},
key = {Computer programming languages},
keywords = {Digital libraries;Embedded systems;Problem solving;Software engineering;},
note = {Manual migration;Program transformation;Strategic programming;},
URL = {http://dx.doi.org/10.1145/1289971.1290001},
} 


@article{20082211278001 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {FIRE/J - Optimizing regular expression searches with generative programming},
journal = {Software - Practice and Experience},
author = {Karakoidas, Vassilios and Spinellis, Diomidis},
volume = {38},
number = {6},
year = {2008},
pages = {557 - 573},
issn = {00380644},
address = {Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom},
abstract = {Regular expressions are a powerful tool for analyzing and manipulating text. Their theoretical background lies within automata theory and formal languages. The FIRE/J (fast implementation of regular expressions for Java) regular expression library is designed to provide maximum execution speed while remaining portable across different machine architectures. To achieve that, FIRE/J transforms each regular expression into a tailor-made class file, which is compiled directly to Java virtual machine (JVM) bytecodes. The library is compatible with the POSIX standard. Copyright &copy; 2007 John Wiley &amp; Sons, Ltd.},
key = {Computer programming},
keywords = {Automata theory;Computer aided software engineering;Formal languages;Java programming language;},
note = {Java virtual machine (JVM);Regular expressions;},
URL = {http://dx.doi.org/10.1002/spe.841},
} 


@inproceedings{1997063689437 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative Programming (GP) with C++},
journal = {Lecture Notes in Computer Science},
author = {Eisenecker, Ulrich W.},
volume = {1204},
year = {1997},
pages = {351 - 351},
issn = {03029743},
address = {Linz, Austria},
} 


@article{20091512018450 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GPCE'08: Proceedings of the ACM SIGPLAN 7th International Conference on Generative Programming and Component Engineering: Foreword},
journal = {GPCE'08: Proceedings of the ACM SIGPLAN 7th International Conference on Generative Programming and Component Engineering},
author = {Smaragdakis, Yannis and Siek, Jeremy},
year = {2008},
pages = {iii - iii},
address = {Nashville, TN, United states},
} 


@inproceedings{20091512018468 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GPCE'08: proceedings of the ACM SIGPLAN 7th international conference on generative programming and component engineering},
journal = {GPCE'08: Proceedings of the ACM SIGPLAN 7th International Conference on Generative Programming and Component Engineering},
year = {2008},
pages = {ACM SIGPLAN - },
address = {Nashville, TN, United states},
abstract = {The proceedings contain 17 papers. The topics discussed include: emerging challenges for large scale systems integration; code generation to support static and dynamic composition of software product lines; efficient compilation techniques for large scale feature models; on the modularity of feature interactions; using modern mathematics as an FOSD modeling language; generating incremental implementations of object-set queries; integrating semantics and compilation; generating customized verifiers for automatically generated code; property models: from incidental algorithms to reusable components; fundamentalist functional programming; feature featherweight Java: a calculus for feature-oriented programming and stepwise refinement; typing communicating component assemblages; and program refactoring using functional aspects.},
} 


@article{20094812518474 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GPCE'09 - Proceedings of the 8th International ACM SIGPLAN Conference on Generative Programming and Component Engineering: Foreword},
journal = {GPCE'09 - Proceedings of the 8th International ACM SIGPLAN Conference on Generative Programming and Component Engineering},
author = {Siek, Jeremy and Fischer, Bernd},
year = {2009},
pages = {iii - iii},
address = {Denver, CO, United states},
} 


@inproceedings{20075010971232 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of the 5th Int. Conf. on Generative Programming and Component Eng., GPCE'06. Co-located with the 21st Int. Conf. on Object-Oriented Programm., Syst., Languages, and Applic.OOPSLA 2006},
journal = {Proceedings of the 5th International Conference on Generative Programming and Component Engineering, GPCE'06},
year = {2006},
pages = {ACM Special Interest Group on Programming Languages - },
address = {Portland, OR, United states},
abstract = {The proceedings contain 31 papers. The topics discussed include: staging static analyses for program generation; a multi-stage language with intentional analysis; assimilating MetaBorg: embedding language tools in languages; creating custom containers with generative techniques; safe component updates; application-specific foreign-interface generation; when to use features and aspects?: a case study; a dynamic aspect-oriented system for OS kernels; concurrent aspects; software extension and integration with type classes; flexible and efficient measurement of dynamic bytecode metrics; patches as better bug reports; feature refactoring a multi-representation program into a product line; refactoring product lines; verifying feature-based model templates against well-formedness OCL constraints; roadmap for enhanced languages and methods to aid verification; semantic reasoning about feature composition via multiple aspect-weavings; and distributed meta-programming.},
key = {Computer programming languages},
keywords = {Computer operating systems;Embedded systems;Semantics;User interfaces;Verification;},
note = {Aspect oriented systems;Program generation;Static analyses;},
} 


@inproceedings{20080711091782 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GPCE'07 - Proceedings of the Sixth International Conference on Generative Programming and Component Engineering},
journal = {GPCE'07 - Proceedings of the Sixth International Conference on Generative Programming and Component Engineering},
year = {2007},
pages = {ACM Special Interest Group on Software Engineering; ACM Special Interest Group on Programming Languages - },
address = {Salzburg, Australia},
abstract = {The proceedings contain 21 papers. The topics discussed include: generative metaprogramming; parsimony principles for software components and metalanguages; debugging macros; lightweight scalable components; constructing language processors with algebra combinators; aspects of availability; refactoring-based support for binary compatibility in evolving frameworks; Repleo: a syntax-safe template engine; preventing injection attacks with syntax embeddings; context-aware scanning for parsing extensible languages; library composition and adaptation using C++ concepts; challenges in generating QoS-constrained software implementations; and safe composition of product lines.},
key = {Computer programming languages},
keywords = {Program processors;Quality of service;Scanning;Security of data;},
note = {Binary compatibility;Generative metaprogramming;},
} 


@inproceedings{2001436705757 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Invited talk sphere packings and generative programming},
journal = {Proceedings of the Annual Symposium on Computational Geometry},
author = {Hales, T.C.},
year = {2001},
pages = {69 - 69},
address = {Medford, MA, United states},
URL = {http://dx.doi.org/10.1145/378583.378624},
} 


@inproceedings{20114014402838 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language for interactive enterprise application development},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Zhou, Jingang and Zhao, Dazhe and Liu, Jiren},
volume = {6988 LNCS},
number = {PART 2},
year = {2011},
pages = {351 - 360},
issn = {03029743},
address = {Taiyuan, China},
abstract = {Web-based enterprise applications (EAs) have become the mainstream for business systems; however, there are enormous challenges for EAs development to meet the software quality and delivery deadline. In this paper, we propose a domain specific language, called WL4EA, which combines components with generative reuse and targets for popular application frameworks (or platform) and supports high interactivity. With WL4EA, an EA can be declaratively specified as some sets of entities, views, business objects, and data access objects. Such language elements will be composed according to known EA architecture and patterns. Such a DSL and code generation can lower the development complexity and error proneness and improve efficiency. &copy; 2011 Springer-Verlag.},
key = {User interfaces},
keywords = {Automatic programming;Computer software selection and evaluation;Industry;Information systems;World Wide Web;},
note = {Application frameworks;Business objects;Business systems;Code Generation;Data access object;Domain specific languages;Enterprise application development;Enterprise applications;Error proneness;Generative programming;Interactivity;Language elements;Software Quality;WEB application;Web-based enterprise;},
URL = {http://dx.doi.org/10.1007/978-3-642-23982-3_43},
} 


@inproceedings{20102513028498 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative approaches for application tailoring of mobile devices},
journal = {Proceedings of the Annual Southeast Conference},
author = {Davis, Victoria and Gray, Jeff and Jones, Joel},
volume = {2},
year = {2005},
pages = {2237 - 2241},
address = {Kennesaw, GA, United states},
abstract = {The popularity of mobile devices has propelled the development of many useful location-aware applications. However, the heterogeneity of mobile devices necessitates that the software be customized and tailored for each device. The research described in this paper demonstrates the possibilities of generative programming applied to application tailoring. This is done in order to assist in porting software to specific devices without manually rewriting code. The Java 2 Micro Edition (J2ME) is an integral part of the application tailoring solution. Many mobile devices are capable of using J2ME, but require the code to be packaged specifically to run in each different mobile environment. J2ME applications alone are not sufficient for porting the code to different mobile devices. The first solution that will be presented uses a specifically structured VoiceXML file as input to an XSL transformation. The transformation produces J2ME source code. Java servlets are used to compile the resulting code and package it with respect to a specific device. This first solution works well for users who have programming experience and are comfortable with editing XML files. However, a different solution is needed to enable users with limited programming experience to specify the essential properties of the mobile application. A second solution to application tailorability uses a metamodeling tool (we use the Generic Modeling Environment - GME) to create a domain-specific modeling language. This environment allows an end-user to capture the essence of a design in a notation that is familiar to the users. From the specified models, an application can be generated directly from a model interpreter. The modeling approach provides a higher-level of abstraction, which removes the user from the accidental complexities regarding the details of the mobile application implementation. A case study is presented that enables a restaurateur to create an online menu for use on several different mobile devices. Copyright 2005 ACM.},
key = {Java programming language},
keywords = {Computer programming;Computer software;Internet telephony;Machinery;Mobile devices;Mobile telecommunication systems;Portable equipment;Program interpreters;},
note = {Domain-specific modeling language;End users;Generative programming;Generic modeling;Integral part;Java 2 micro editions;Java servlets;Level of abstraction;Location-aware application;Metamodeling;Mobile applications;Mobile environments;Model interpreter;Modeling approach;Porting software;Programming experience;Source codes;Tailorability;VoiceXML;XML files;},
URL = {http://dx.doi.org/10.1145/1167253.1167308},
} 


@article{20111913966357 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific language for C4ISR capability analysis},
journal = {Xitong Gongcheng Lilun yu Shijian/System Engineering Theory and Practice},
author = {Dong, Qing-Chao and Wang, Zhi-Xue and Zhu, Wei-Xing and Chen, Jian and Zhang, Ting-Ting},
volume = {31},
number = {3},
year = {2011},
pages = {552 - 560},
issn = {10006788},
address = {Xitong Yanjiusuo, Beijing, 100080, China},
abstract = {The applicability of UML for C4ISR capability requirements analysis is weak. To solve the problem, the paper proposes a construction method of domain-specific language. It discusses the domain conceptualization, suggesting a meta ontology for C4ISR capability conceptualization under which a domain-specific language can be defined to describe the C4ISR capability concepts. The method is supported by taking advantage of the UML Profile mechanism. The model integrity checking is studied through adopting a symbol inference system based on Description Logic. Finally, a case study of C4ISR domain-specific model checking is provided to demonstrate the availability and applicability of the method.},
key = {Model checking},
keywords = {Data description;Formal languages;Ontology;Problem oriented languages;},
note = {Description logic;Domain-specific language;Domain-specific model;Meta ontology for C4ISR capability;SHOIN(D);},
} 


@inproceedings{2006199863656 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using a domain-specific language and custom tools to model a multi-tier service-oriented application - Experiences and challenges},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Vokac, Marek and Glattetre, Jens M.},
volume = {3713 LNCS},
year = {2005},
pages = {492 - 506},
issn = {03029743},
address = {Montego Bay, Jamaica},
abstract = {A commercial Customer Relationship Management application of approx. 1.5 MLOC of C++ code is being reimplemented, in stages, as a service-oriented, multi-tier application in C# on Microsoft NET. We have chosen to use a domain-specific language both to model the external service-oriented interfaces, and to manage the transition to the internal, object-oriented implementation. Generic UML constructs such as class diagrams do not capture enough semantics to model these concepts. By defining a UML Profile that incorporates the concepts we wish to model, we have in effect created a Domain-Specific Language for our application. The models are edited using Rational XDE, but we have substituted our own code generator. This generator is a relatively generic text-substitution engine, which takes a template text and performs substitutions based on the model. The generator uses reflection to convert the UML and Profile concepts into substitution tags, which are in turn used in the template text. In this way, we can translate the semantics of the model into executable code, WSDL or other formats in a flexible way. We have successfully used this approach on a prototype scale, and are now transitioning to full-scale development. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Computer programming languages},
keywords = {Automatic programming;Codes (symbols);Interfaces (computer);Mathematical models;Object oriented programming;Semantics;},
note = {Class diagrams;Code generator;Custom tools;Customer Relationship Management;Domain-specific language;},
} 


@inproceedings{2001276566373 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language framework for non-visual browsing of complex HTML structures},
journal = {Annual ACM Conference on Assistive Technologies, Proceedings},
author = {Pontelli, E. and Xiong, W. and Gupta, G. and Karshmer, A.I.},
year = {2000},
pages = {180 - 187},
address = {Arlington, VA, United states},
abstract = {We present a general framework for navigating complex structures - specifically, tables, frames, and forms - found in web-pages. Our framework is based on an (automatically or manually created) program written in a domain specific language that captures the semantic structure of the table/frame/form as well as specifies the strategy to be used for navigating it. We describe our general framework and the domain specific language we have designed.},
key = {Computer programming languages},
keywords = {HTML;Semantics;Web browsers;Websites;},
note = {Domain specific language;Web accessibility;},
} 


@inproceedings{20083411467893 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Development of a prototype domain-specific language for monitor and control systems},
journal = {IEEE Aerospace Conference Proceedings},
author = {Bennett, Matthew and Borgen, Richard and Havelund, Klaus and Ingham, Michel and Wagner, David},
year = {2008},
issn = {1095323X},
address = {Big Sky, MT, United states},
abstract = {This paper describes the Domain-Specific Language (DSL) prototype developed for the NASA Constellation Launch Control System (LCS) project. A key element of the LCS architecture, the DSL prototype is a specialized monitor and control language composed of constructs for specifying and programming test, checkout, and launch processing applications for flight and ground systems. The principal objectives of the prototyping activity were to perform a proof-of-concept of an approach to ultimately lower the lifecycle costs of application software for the LCS, and to explore mitigations for a number of development risks perceived by the project. The language has been implemented as a library that extends the Python scripting language, and validated in a successful demonstration of capability required for Constellation. &copy;2008 IEEE.},
key = {Software prototyping},
keywords = {Computer programming;Computer programming languages;Computer software;Control systems;DSL;Flight control systems;Launching;Linguistics;Modems;NASA;Telecommunication lines;},
note = {Application softwares;Development risks;Domain-Specific Language;Ground systems;Life-cycle costing;Monitor and control;Processing applications;Proof of concepts;Prototyping;Scripting languages;},
URL = {http://dx.doi.org/10.1109/AERO.2008.4526660},
} 


@inproceedings{20083511482754 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An unsupervised incremental learning algorithm for domain-specific language development},
journal = {Applied Artificial Intelligence},
author = {Javed, Faizan and Mernik, Marjan and Bryant, Barrett R. and Sprague, Alan},
volume = {22},
number = {7-8},
year = {2008},
pages = {707 - 729},
issn = {08839514},
address = {325 Chestnut St, Suite 800, Philadelphia PA, PA 19106, United States},
abstract = {While grammar inference (or grammar induction) has found extensive application in the areas of robotics, computational biology, and speech recognition, its application to problems in programming language and software engineering domains has been limited. We have found a new application area for grammar inference which intends to make domain-specific language development easier for domain experts not well versed in programming language design, and finds a second application in construction of renovation tools for legacy software systems. As a continuation of our previous efforts to infer context-free grammars (CFGs) for domain-specific languages which previously involved a genetic-programming based CFG inference system, we discuss extensions to the inference capabilities of GenInc, an incremental learning algorithm for inferring CFGs. We show that these extensions enable GenInc to infer more comprehensive grammars, discuss the results of applying GenInc to various domain-specific languages and evaluate the results using a comprehensive suite of grammar metrics.},
key = {Computer programming languages},
keywords = {Applications;Automation;BASIC (programming language);Bioinformatics;C (programming language);Computational grammars;Computer aided software engineering;Computer software;Computer systems programming;Computers;Context free languages;Genetic programming;Graphical user interfaces;Inference engines;Learning algorithms;Learning systems;Legacy systems;Linguistics;Query languages;Robot programming;Software design;Software engineering;Speech recognition;Technology;},
note = {Application area;Computational biology;Context-free grammars;Domain Experts;Domain-Specific Language;Domain-Specific Languages;Engineering domains;Grammar induction;Grammar inference;Incremental Learning;Inference systems;Legacy softwares;Programming language design;Programming languages;},
URL = {http://dx.doi.org/10.1080/08839510802164127},
} 


@article{20070310374080 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific language approach to modelling UI architecture of mobile telephony systems},
journal = {IEE Proceedings: Software},
author = {Lee, J.-S. and Chae, H.S.},
volume = {153},
number = {6},
year = {2006},
pages = {231 - 240},
issn = {14625970},
address = {Six Hills Way, Stevenage, SG1 2AY, United Kingdom},
abstract = {Although there has been a considerable increase in the use of embedded software including mobile telephony applications, the development of embedded software has not proved so manageable as compared with conventional software. From the experience of working with mobile telephony systems for over three years, it is the author's belief that the huge amount of variance in application logics, not the diversity of hardware platforms, is the major obstacle to the development of embedded software. A domain specific language (DSL) for modelling the user interface (UI) architecture of embedded software, especially focusing on telephony applications is proposed. With the proposed DSL, developers can describe the UI architecture of applications by the fundamental domain concepts at a higher level of abstraction. The proposed DSL is based on the concept of scene. A scene is proposed as a unit of UI in the UI architecture and UI-related behaviours are associated with scenes. The result of a pilot project conducted in a major company dedicated to developing mobile telephony applications is also described. &copy; The Institution of Engineering and Technology 2006.},
key = {Cellular telephone systems},
keywords = {Computer hardware;Computer programming languages;Embedded systems;User interfaces;},
note = {Domain specific language (DSL);Embedded software;Mobile telephony systems;},
URL = {http://dx.doi.org/10.1049/ip-sen:20060022},
} 


@inproceedings{20094812504979 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automating test case definition using a domain specific language},
journal = {Proceedings of the 46th Annual Southeast Regional Conference on XX, ACM-SE 46},
author = {Im, Kyungsoo and Im, Tacksoo and McGregor, John D.},
year = {2008},
pages = {180 - 185},
address = {Auburn, AL, United states},
abstract = {Effective test cases are critical to the success of a development effort but their creation requires large amounts of critical resources such as domain expertise. This study explores an approach to automating test case definition in the context of applying a model driven approach to the development of a software product line. In this study, test cases are automatically extracted from use cases, which are specified using a domain specific language (DSL). DSLs are easier for domain experts to use than formal specification languages and are more narrowly focused than natural languages making it easier to build tools. The task is further simplified by restricting the DSL to the scope of the software product line under development. The structure of the DSL and proven patterns of test design provide the clues necessary to be able to automatically extract the test cases. A chain of model-driven tools is used to automate the system test process, which begins with a use case model and ends with automatic execution of system tests. Copyright 2008 ACM.},
key = {Testing},
keywords = {Computer software selection and evaluation;DSL;Linguistics;Modems;Ontology;Query languages;Software testing;Specification languages;Spontaneous emission;Telecommunication lines;},
note = {Critical resources;Domain expertise;Domain experts;Domain specific language;Domain specific languages;Formal specification language;Model driven approach;Model-driven;Natural languages;Software Product Line;System test;Test case;Test designs;Use case model;},
URL = {http://dx.doi.org/10.1145/1593105.1593152},
} 


@inproceedings{20101712873433 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Systematic and formal approach to got a domain specific language},
journal = {ITNG 2009 - 6th International Conference on Information Technology: New Generations},
author = {Marcondes, Francisco Supino and Tasinaffo, Paulo Marcelo and Fernandes, Danilo Douradinho and Vega, Italo Santiago and Montini, Denis Avila and Dias, Luiz Alberto Vieira},
year = {2009},
pages = {1447 - 1450},
address = {Las Vegas, NV, United states},
abstract = {This paper presents a systematic approach applied over State Machine (since it is a wide know model and easy to be used to formal specification) to improve the domain analysis procedure, besides been out of scope of this paper, this approach can also helps to improve the enterprise's business process as well. The motivation which leads to the this paper is how to got a Domain Specific Language (DSL) that is completely correspondent to a Domain Analysis sharing both the same business rules. This is a very important property to be achieved since a DSL must be used to help the codding procedure in a specific domain, so, it must be a direct relation over them and this relation is explored in this paper. It has a briefly discussion over the need for formalization procedures concluding that too much formalization can be a problem and lack of it can also be, so, formal transformations can be performed at mark point (as baselines or any other mark that can be defined) bringing important contributions to the rigor of the model improving it. &copy; 2009 IEEE.},
key = {Formal methods},
keywords = {Contour followers;DSL;Information technology;Linguistics;Management science;Modems;Telecommunication lines;},
note = {Business Process;Business rules;Domain analysis;Domain specific language;Domain specific languages;Formal approach;Formal Specification;Formal transformation;State machine;},
URL = {http://dx.doi.org/10.1109/ITNG.2009.265},
} 


@inproceedings{20083111417532 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The domain-specific language Monaco and its visual interactive programming environment},
journal = {Proceedings - IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC 2007},
author = {Prahofer, Herbert and Hurnaus, Dominik and Wirth, Christian and Mossenbock, Hanspeter},
year = {2007},
pages = {104 - 107},
address = {Coeur d'Alene, ID, United states},
abstract = {Monaco is a domain-specific language for machine automation programming. It has been developed with the objective to empower domain experts with limited programming capabilities. Its main language features are an imperative notation for reactive systems, concepts for describing asynchronous event handling in a concise way, and a state-of-the-art component approach. Monaco is a programming language with a Pascal-like syntax, but also comes with a visual programming environment. In this paper we review the language Monaco, show the visual representation scheme, report on the programming environment and compare our visual notation to Statecharts. &copy; 2007 IEEE.},
key = {Pascal (programming language)},
keywords = {Automation;Computer aided software engineering;Computer programming;Computer programming languages;Graphical user interfaces;Linguistics;Query languages;},
note = {Automation control;Domain-specific language;End-user programming;Visual language;Visual programming;},
URL = {http://dx.doi.org/10.1109/VLHCC.2007.53},
} 


@inproceedings{20080411055521 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for Web APIs and services mashups},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Maximilien, E. Michael and Wilkinson, Hernan and Desai, Nirmit and Tai, Stefan},
volume = {4749 LNCS},
year = {2007},
pages = {13 - 26},
issn = {03029743},
address = {Vienna, Austria},
abstract = {Distributed programming has shifted from private networks to the public Internet and from using private and controlled services to increasingly using publicly available heterogeneous Web services (e.g., REST, SOAP, RSS, and Atom). This move enables the creation of innovative end-user-oriented composed services with user interfaces. These services mashups are typically point solutions to specific (specialized) problems; however, what is missing is a programming model that facilitates and accelerates creation and deployment of mashups of diverse services. In this paper we describe a domain-specific language that unifies the most common service models and facilitates service composition and integration into end-user-oriented Web applications. We demonstrate our approach with an implementation that leverages the Ruby on Rails framework. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Computer programming languages},
keywords = {Data structures;Problem solving;User interfaces;Web services;},
note = {Domain-specific language;Programming models;Web applications;},
} 


@inproceedings{20080411045250 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {DirectFlow: A domain-specific language for information-flow systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Lin, Chuan-Kai and Black, Andrew P.},
volume = {4609 LNCS},
year = {2007},
pages = {299 - 322},
issn = {03029743},
address = {Berlin, Germany},
abstract = {Programs that process streams of information are commonly built by assembling reusable information-flow components. In some systems the components must be chosen from a pre-defined set of primitives; in others the programmer can create new custom components using a general-purpose programming language. Neither approach is ideal: restricting programmers to a set of primitive components limits the expressivity of the system, while allowing programmers to define new components in a general-purpose language makes it difficult or impossible to reason about the composite system. We advocate defining information-flow components in a domain-specific language (DSL) that enables us to infer the properties of the components and of the composed system; this provides us with a good compromise between analysability and expressivity. This paper presents DirectFlow, which comprises a DSL, a compiler and a runtime system. The language allows programmers to define objects that implement information-flow components without specifying how messages are sent and received. The compiler generates Java classes by inferring the message sends and methods, while the run-time library constructs information-flow networks by composition of DSL-defined components with standard components. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Specification languages},
keywords = {Computer programming languages;Information fusion;Message passing;},
note = {Domain-specific language (DSL);Information flow;Reusable information;},
} 


@inproceedings{20081711212414 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Extracting a domain specific language from an example a bottom-up method using the ngrease metalanguage},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Oikarinen, Ville T.},
year = {2007},
pages = {850 - 851},
address = {Montreal, QC, Canada},
abstract = {This demonstration shows a lightweight and fast method for creating a tested and working domain specific language. The method is demonstrated using the ngrease metalanguage. The creation of a new language is started by writing a representative example of the final product with a test that tests the transformation from a stub source to the result. The test is made to pass by writing a constant transformer that unconditionally outputs the result. At each step the language is extended by refactoring: Some part of the transformer template is converted from a constant subtree to a reference to data read from the source tree, thus driving additions to the new language. Optionally, each refactoring step can be driven by a new test that demonstrates the lack of parameterization of some part of the final product.},
key = {Object oriented programming},
keywords = {Computer systems programming;Electric transformer testing;Linguistics;Neodymium;Query languages;Testing;Trees (mathematics);},
note = {Bottom-up;Data read;Domain specific language (DSL);final products;international conferences;Languages (traditional);Object-oriented programming;Refactoring;source trees;sub trees;},
URL = {http://dx.doi.org/10.1145/1297846.1297921},
} 


@inproceedings{2004398372074 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Mapping a domain specific language to a platform FPGA},
journal = {Proceedings - Design Automation Conference},
author = {Kulkarni, Chidamber and Brebner, Gordon and Schelle, Graham},
year = {2004},
pages = {924 - 927},
issn = {0738100X},
address = {San Diego, CA, United states},
abstract = {A domain specific language (DSL) enables designers to rapidly specify and implement systems for a particular domain, yielding designs that are easy to understand, reason about, re-use and maintain. However, there is usually a significant overhead in the required infrastructure to map such a DSL on to a programmable logic device. In this paper, we present a mapping of an existing DSL for the networking domain on to a platform FPGA by embedding the DSL into an existing language infrastructure. In particular, we will show that, using few basic concepts, we are able to achieve a successful mapping of the DSL on to a platform FPGA and create a re-usable structure that also makes it easy to extend the DSL. Finally we will present some results of mapping the DSL on to a platform FPGA and comment on the resulting overhead.},
key = {Field programmable gate arrays},
keywords = {Algorithms;Computer networks;Computer programming languages;Costs;Logic design;Mapping;Semantics;Transceivers;},
note = {Domain specific language;Hardware description language (HDL);Network processing;Platform FPGA;},
URL = {http://dx.doi.org/10.1145/996566.996811},
} 


@article{2006179840192 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Research on a domain specific language constructing method based on objects},
journal = {Xi'an Dianzi Keji Daxue Xuebao/Journal of Xidian University},
author = {Hu, Sheng-Ming and Li, Qing-Shan and Chen, Ping},
volume = {33},
number = {1},
year = {2006},
pages = {80 - 84},
issn = {10012400},
abstract = {This paper aims at giving out a guideline for defining a DSL (Domain Specific Language) by presenting a language constructing method based on Objects. DSL semantics is analyzed and decomposed into Domain Specific Semantics and Domain Independent Semantics, and then objects are employed to encapsulate the former. View objects and model objects are used to define and interpret the Domain Specific Semantics, and language tools are used to generate the general features of a language. Then objects and general language features are combined and a DSL is constructed. This method makes the DSL constructing process rapid and clear, and more expandability can be achieved. DSL developers can implement the DSL interpreter by efficiently incorporating this method with language tools.},
key = {Software engineering},
keywords = {Computer programming languages;Object oriented programming;Semantics;},
note = {Domain specific language;DSL semantics;Language constructing method;Object based;},
} 


@inproceedings{20083311451130 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {AGOL: An aspect-oriented domain-specific language for MAS},
journal = {Proceedings - International Conference on Software Engineering},
author = {Amor, Mercedes and Garcia, Alessandro and Fuentes, Lidia},
year = {2007},
pages = {IEEE Computer Society Technical Council on Software Engineering; ACM Special Interest Group on Software Engineering (SIGSOFT) - },
issn = {02705257},
address = {Minneapolis, United states},
abstract = {Specific features of Multi-Agent Systems (MAS), such as autonomy, learning, mobility, coordination, are driving development concerns, which make evident the need for new design abstractions. Up to now, agent-oriented modeling languages have delivered basic MAS design abstractions - such as goals and actions - that explicitly tackle some of these concerns. However, the modularization of a plethora of fundamental MAS features has been hindered throughout the software lifecycle. This paper presents a methodological framework to address enhanced modularity and traceability of such crosscutting concerns in MAS development. Our design framework is mainly rooted at the proposition of a new domain-specific language, called AGOL. In addition, the proposed framework is supported by a bench of transformation rules of AGOL artifacts, which can be effectively used to derive agent implementations in two concrete aspect-oriented implementation platforms, namely AspectT and Malaca. &copy; 2007 IEEE.},
key = {Architectural design},
keywords = {Abstracting;Large scale systems;Linguistics;Modular construction;Multi agent systems;Query languages;Requirements engineering;Software design;Software engineering;},
note = {Agent-oriented modelling;Architecture designs;Aspect-oriented;Crosscutting concerns;Design abstractions;Design framework;Domain specific language (DSL);Early aspects;Implementation platforms;International conferences;Modularization;Multi agent systems (MAS);Multiagent system (MAS) development;New design;Software life cycles;Transformation rules;},
URL = {http://dx.doi.org/10.1109/EARLYASPECTS.2007.3},
} 


@inproceedings{20081711212261 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {WebRB: Evaluating a visual domain-specific language for building relational Web-applications},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Leff, Avraham and Rayfield, James T.},
year = {2007},
pages = {281 - 300},
address = {Montreal, QC, Canada},
abstract = {Many web-applications can be characterized as "relational". In this paper we introduce and evaluate WebRB, a visual domain-specific language for building such applications. WebRB addresses the limitations of the conventional "imperative-embedding" approach typically used to build relational web-applications. We describe the WebRB language, present extended examples of its use, and discuss the WebRB visual editor, libraries, and runtime. We then evaluate WebRB by comparing it to alternative approaches, and demonstrate its effectiveness in building relational webapplications. Copyright &copy; 2007 ACM.},
key = {Object oriented programming},
keywords = {Buildings;Computer programming languages;Computer systems programming;Linguistics;Neodymium;Query languages;},
note = {Domain specific language (DSL);international conferences;Languages (traditional);Object-oriented programming;Run time;Web applications (WA);},
URL = {http://dx.doi.org/10.1145/1297027.1297048},
} 


@inproceedings{2006189858280 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Efficient code generation for a domain specific language},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Moss, Andrew and Muller, Henk},
volume = {3676 LNCS},
year = {2005},
pages = {47 - 62},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {We present a domain-specific-language (DSL) for writing instances of a class of filter programs. The values in the language are symbolic and independent of a concrete precision. Efficient code generation is required to fit the program onto a target device limited in both memory and processing power. We construct an interpreter for the DSL in a language specific to the device which contains the semantics of the target instruction set embedded within a declarative meta-language. The compiler is automatically generated from the interpreter through specialisation. This extension of the instruction set allows the construction of an interpreter for the DSL that is both simple and clear. In particular it allows us to declare static representations of the symbolic values, and have the specialisation of the code produce operate upon these values in the instruction set of the target device. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Computer programming languages},
keywords = {Codes (symbols);Program compilers;Semantics;},
note = {Code generation;Domain-specific-language (DSL);Meta-language;Specialisation;},
URL = {http://dx.doi.org/10.1007/11561347_5},
} 


@inproceedings{2006109739225 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Weaving a debugging aspect into domain-specific language grammars},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Wu, Hui and Gray, Jeff and Roychoudhury, Suman and Mernik, Marjan},
volume = {2},
year = {2005},
pages = {1370 - 1374},
address = {Santa Fe, NM, United states},
abstract = {A common trend in programming language specification is to generate various tools (e.g., compiler, editor, profiler, and debugger) from a grammar. In such a generative approach, it is desirable to have the definition of a programming language be modularized according to specific concerns specified in the grammar. However, it is often the case that the corresponding properties of the generated tools are scattered and tangled across the language specification. In this paper, separation of concerns within a programming language specification is demonstrated by considering debugging support within a domain-specific language (DSL). The paper first describes the use of AspectJ to weave the debugging semantics into the code created by a parser generator. The paper outlines several situations when the use of AspectJ is infeasible at separating language specification properties. To accommodate such situations, a second approach is presented that weaves the debugging support directly into a grammar specification using a program transformation engine. A case study for a simple DSL is presented to highlight the benefits of weaving across language specifications defined by grammars. Copyright 2005 ACM.},
key = {Programming theory},
keywords = {Computer programming languages;File editors;Program compilers;Program debugging;Report generators;Semantics;},
note = {Domain-specific language (DSL);Grammarware;Profilers;Program transformation engines;},
URL = {http://dx.doi.org/10.1145/1066677.1066986},
} 


@article{2003467720128 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language approach to programmable networks},
journal = {IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews},
author = {Muller, Gilles and Lawall, Julia L. and Thibault, Scott and Jensen, Rasmus Erik Voel},
volume = {33},
number = {3},
year = {2003},
pages = {370 - 381},
issn = {10946977},
abstract = {Active networks present significant safety, security, and efficiency challenges. Domain-specific languages, i.e., languages providing only constructs relevant to a particular domain, provide a solution that balances these constraints. Safety and security can be ensured using verification techniques that exploit the restricted nature of such languages. Strategies have been developed for the compilation of domain-specific languages that provide both portability and efficiency. This paper presents a synthesis of work on the PLAN-P domain-specific language for programmable routers. We present the language design, representative experiments that have been carried out using the language, and new compilation strategies. End-to-end performance is typically comparable to that of hand-coded C implementations.},
key = {High level languages},
keywords = {Bandwidth;C (programming language);Computer architecture;Image compression;Image quality;Java programming language;Network protocols;Program compilers;Routers;},
note = {Domain-specific language;Programmable routers;},
URL = {http://dx.doi.org/10.1109/TSMCC.2003.817364},
} 


@article{20084811738421 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain specific language implementation via compile-time meta-programming},
journal = {ACM Transactions on Programming Languages and Systems},
author = {Tratt, Laurence},
volume = {30},
number = {6},
year = {2008},
issn = {01640925},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Domain specific languages (DSLs) are mini-languages that are increasingly seen as being a valuable tool for software developers and non-developers alike. DSLs must currently be created in an ad-hoc fashion, often leading to high development costs and implementations of variable quality. In this article, I show how expressive DSLs can be hygienically embedded in the Converge programming language using its compile-time meta-programming facility, the concept of DSL blocks, and specialised error reporting techniques. By making use of pre-existing facilities, and following a simple methodology, DSL implementation costs can be significantly reduced whilst leading to higher quality DSL implementations. &copy; 2008 ACM.},
key = {Computer software selection and evaluation},
keywords = {Computer programming languages;DSL;Linguistics;Modems;Query languages;Syntactics;Telecommunication lines;},
note = {Compile-time meta-programming;Development costs;Domain specific language implementations;Domain specific languages;Domain specifics;Implementation costs;Meta programmings;Programming languages;Software developers;Syntax extension;},
URL = {http://dx.doi.org/10.1145/1391956.1391958},
} 


@article{20092412117619 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MMC-BPM: A domain-specific language for business processes analysis},
journal = {Lecture Notes in Business Information Processing},
author = {Gonzalez, Oscar and Casallas, Rubby and Deridder, Dirk},
volume = {21 LNBIP},
year = {2009},
pages = {157 - 168},
issn = {18651348},
address = {Poznan, Poland},
abstract = {Business Process Management approaches incorporate an analysis phase as an essential activity to improve business processes. Although business processes are defined at a high-level of abstraction, the actual analysis concerns are specified at the workflow implementation level resulting in a technology-dependent solution, increasing the complexity to evolve them. In this paper we present a language for high-level monitoring, measurement data collection, and control of business processes and an approach to translate these specifications into executable implementations. The approach we present offers process analysts the opportunity to evolve analysis concerns independently of the process implementation. &copy; 2009 Springer Berlin Heidelberg.},
key = {Process control},
keywords = {Enterprise resource management;High level languages;Linguistics;Metallic matrix composites;Monitoring;},
note = {Business Process;Business Process Analysis;Business process management;Domain Specific Language;Domain specific languages;Level of abstraction;Measurement data;Process implementation;},
URL = {http://dx.doi.org/10.1007/978-3-642-01190-0_14},
} 


@article{20083511481484 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Grammar-driven generation of domain-specific language debuggers},
journal = {Software - Practice and Experience},
author = {Wu, Hui and Gray, Jeff and Mernik, Marjan},
volume = {38},
number = {10},
year = {2008},
pages = {1073 - 1103},
issn = {00380644},
address = {Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom},
abstract = {Domain-specific languages (DSLs) assist a software developer (or end-user) in writing a program using idioms that are similar to the abstractions found in a specific problem domain. Tool support for DSLs is lacking when compared with the capabilities provided for standard general-purpose languages (GPLs), such as Java and C++. For example, support for debugging a program written in a DSL is often non-existent. The lack of a debugger at the proper abstraction level limits an end-user's ability to discover and locate faults in a DSL program. This paper describes a grammar-driven technique to build a debugging tool generation framework from existing DSL grammars. The DSL grammars are used to generate the hooks needed to interface with a supporting infrastructure constructed for an integrated development environment that assists in debugging a program written in a DSL. The contribution represents a coordinated approach to bring essential software tools (e.g. debuggers) to different types of DSLs (e.g. imperative, declarative, and hybrid). This approach hides from the end-users the accidental complexities associated with expanding the focus of a language environment to include debuggers. The research described in this paper addresses a long-term goal of empowering end-users with development tools for particular DSL problem domains at the proper level of abstraction without depending on a specific GPL. Copyright &copy; 2007 John Wiley &amp; Sons, Ltd.},
key = {Program debugging},
keywords = {Abstracting;Chlorine compounds;Computer aided software engineering;Computer programming languages;Computer software;DSL;Graphical user interfaces;Java programming language;Linguistics;Modems;Query languages;Research;Standards;Telecommunication lines;Web services;XML;},
note = {Abstraction levels;Debuggers;Debugging;Debugging tools;Development tools;Domain-Specific Language;Domain-specific languages;End-users;GPL;Grammars;Integrated development environment;Language environment;Level of abstraction;Paper addresses;Problem domains;Program environments-integrated environments;Software developers;Software tools;Tool supports;},
URL = {http://dx.doi.org/10.1002/spe.863},
} 


@inproceedings{20085111787532 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Ruling networks with RDL: A domain-specific language to task wireless sensor networks},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Terfloth, Kirsten and Schiller, Jochen},
volume = {5321 LNCS},
year = {2008},
pages = {127 - 134},
issn = {03029743},
address = {Orlando, FL, United states},
abstract = {Events are a fundamental concept in computer science with decades of research contributing to enable precise specification and efficient processing. New as well as evolving application domains nevertheless call for adaptation of successful concepts to meet intrinsic challenges provided by the target environment. A representative of such a new area for application are wireless sensor networks, pushing the need for event handling onto the bare metal of embedded devices. In this paper, we motivate the deployment of reactive rules in wireless sensor networks and describe our rule-based language RDL. Since our goal is to provide a high level of abstraction for node-level tasking, we will especially focus on recent additions to the language that support modularity to achieve a better encapsulation of concerns. &copy; 2008 Springer Berlin Heidelberg.},
key = {Wireless sensor networks},
keywords = {Computer networks;Graphical user interfaces;Hybrid sensors;Industrial research;Interchanges;Intersections;Linguistics;Sensor networks;Sensors;},
note = {Application domains;Do-mains;Domain-specific language;Embedded devices;Event handlings;FACTS;Fundamental concepts;High level of abstractions;RDL;Reactive rules;Specific languages;Target environments;},
URL = {http://dx.doi.org/10.1007/978-3-540-88808-6-15},
} 


@inproceedings{20083511496930 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language for reconfigurable path-based monte carlo simulations},
journal = {ICFPT 2007 - International Conference on Field Programmable Technology},
author = {Thomas, David B. and W., Luk},
year = {2007},
pages = {97 - 104},
address = {Kitakyushu, Japan},
abstract = {FPGAs have been successfully used to accelerate many computationally bound applications, such as high-performance Monte-Carlo simulations, but the amount of programmer effort required in development, testing, and tuning is also very high, requiring a new custom design for each application. This paper presents Contessa, a pure-functional continuation-based language for describing path-based Monte-Carlo simulations, and a completely automated method for turning platform-independent Contessa programs into high-performance hardware implementations. Our approach exploits the large degree of thread-based parallelism available in Monte-Carlo simulations, allowing data-dependent control-flow and loop-carried dependencies to be expressed, while retaining high-performance. The Contessa toolchain is evaluated using five different simulation kernels, in comparison to both software and manually described hardware. When compared to an existing FPGA implementation, Contessa requires a quarter of the Handel-C source-code length, and doubles the clock rate to over 300MHz while requiring a similar number of resources, and also provides a 35 times speedup over a C++ implementation using an Opteron 2.2GHz. &copy; 2007 IEEE.},
key = {Monte Carlo methods},
keywords = {Computer software;Field programmable gate arrays (FPGA);Hardware;Linguistics;Technology;},
note = {Clock rates;Code lengths;Control flows;Custom designed;Domain-Specific Language;FPGA implementations;Handel-C;High-performance hardware;International conferences;Loop-carried dependencies;Monte-Carlo simulations;Opteron;Re-configurable;Simulation kernels;},
URL = {http://dx.doi.org/10.1109/FPT.2007.4439237},
} 


@inproceedings{20064710254839 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for task handlers generation, applying discrete controller synthesis},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Delaval, Gwenael and Rutten, Eric},
volume = {1},
year = {2006},
pages = {901 - 905},
address = {Dijon, France},
abstract = {We propose a simple programming language, called Nemo, specific to the domain of multi-task real-time embedded systems, such as in robotic, automotive or avionics systems. It can be used to specify a set of resources with usage constraints, a set of tasks that consume them according to various modes, and applications sequencing the tasks. We obtain automatically an application-specific task handler that correctly manages the constraints (if there exists one), through a compilation-like process including a phase of discrete controller synthesis. This way, this formal technique contributes to the safety of the designed systems, while being encapsulated in a tool that makes it usable by end-users and application experts. Our approach is based on the synchronous modelling techniques, languages and tools. Copyright 2006 ACM.},
key = {Discrete time control systems},
keywords = {Computer programming languages;Constraint theory;Encapsulation;Mathematical models;Program compilers;Real time systems;},
note = {Discrete control synthesis;Domain specific language;Safe design;Synchronous programming;},
} 


@inproceedings{2006069688835 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {PADS: A domain-specific language for processing Ad hoc data},
journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
author = {Fisher, Kathleen and Gruber, Robert},
year = {2005},
pages = {295 - 304},
address = {Chicago, IL, United states},
abstract = {PADS is a declarative data description language that allows data analysts to describe both the physical layout of ad hoc data sources and semantic properties of that data. From such descriptions, the PADS compiler generates libraries and tools for manipulating the data, including parsing routines, statistical profiling tools, translation programs to produce well-behaved formats such as XML or those required for loading relational databases, and tools for running XQueries over raw PADS data sources. The descriptions are concise enough to serve as "living" documentation while flexible enough to describe most of the ASCII, binary, and Cobol formats that we have seen in practice. The generated parsing library provides for robust, application-specific error handling. Copyright 2005 ACM.},
key = {Formal languages},
keywords = {Computer aided software engineering;Data acquisition;Data processing;Database systems;Semantics;XML;},
note = {Data description language;Domain-specific language;},
} 


@inproceedings{20073110724355 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {SOLj: A domain-specific language (DSL) for secure service-based systems},
journal = {Proceedings of the IEEE Computer Society Workshop on Future Trends of Distributed Computing Systems},
author = {Bharadwaj, Ramesh and Mukhopadhyay, Supratik},
year = {2007},
pages = {173 - 180},
address = {Sedona, AZ, United states},
abstract = {We present SOLj (Secure Operations Language-Java), an event-driven domain-specific synchronous programming extension of Java for developing secure service-based systems. The language has capabilities for handling service invocations asynchronously, includes strong typing for the enforcement of information flow and security policies, and exception handling mechanisms to deal with failures of components or services (both benign and Byzantine). Applications written in SOLj are formally verifiable using static analysis techniques. SOLj programs may be deployed, configured, and run on SINS (Secure Infrastructure for Networked Systems) under development at the Naval Research Laboratory. &copy; 2007 IEEE.},
key = {Java programming language},
keywords = {Computer system recovery;Data processing;Security of data;},
note = {Domain specific language;Exception handling mechanisms;Security policies;Static analysis techniques;},
URL = {http://dx.doi.org/10.1109/FTDCS.2007.32},
} 


@inproceedings{20074810948849 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A systematic approach to domain-specific language design using UML},
journal = {Proceedings - 10th IEEE International Symposium on Object and Component-Oriented Real-Time Distributed Computing, ISORC 2007},
author = {Selic, Bran},
year = {2007},
pages = {2 - 9},
address = {Santorini Island, Greece},
abstract = {UML includes special extensibility mechanisms, which are used to define domain-specific modeling languages that are based on UML. These mechanisms have been significantly improved in the latest versions of UML. Unfortunately, there is currently a dearth of published material on how to best exploit these capabilities and, consequently, many UML profiles are either invalid or of poor quality. In this paper, we first provide an overview of the new extensibility mechanisms of UML 2.1 and then describe a method for defining profiles that greatly increases the likelihood of producing technically correct quality UML profiles. &copy; 2007 IEEE.},
key = {Unified Modeling Language},
keywords = {Computer hardware description languages;Semantics;Technology transfer;},
note = {Domain specific language design;UML profiles;},
URL = {http://dx.doi.org/10.1109/ISORC.2007.10},
} 


@inproceedings{20080511075912 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Addressing dynamic contextual adaptation with a domain-specific language},
journal = {Proceedings - ICSE 2007 Workshops: First International Workshop on Software Engineering for Pervasive Computing Applications, Systems, and Environments, SEPCASE'07},
author = {Fritsch, Serena and Senart, Aline and Clarke, Siobhan},
year = {2007},
address = {Minneapolis, MN, United states},
abstract = {The increasing number of mobile devices and sensors equipped with wireless networking capabilities enable a new generation of pro-active applications. These applications make use of context to adapt their behaviour to better fit their current situation. To support unanticipated changes to application behaviour, mechanisms are needed to specify when and how to adapt an application during its runtime. Many dynamic platforms exist that achieve this to some extent, and that are built on general-purpose languages (GPLs). However, these approaches suffer from standard difficulties of GPLs relating to the lack of semantic expressiveness of their constructs. In this paper, we describe high-level declarative constructs that can be used to specify the adaptation of application behaviour to specific situations. The language is supported by a framework that enables the exchange and merge of behaviours on-the-fly. Our approach is evaluated against application scenarios in the domain of autonomous vehicles. &copy; 2007 IEEE.},
key = {Wireless networks},
keywords = {Computer programming languages;Mobile devices;Sensors;},
note = {Domain specific language;General purpose languages;},
URL = {http://dx.doi.org/10.1109/SEPCASE.2007.1},
} 


@inproceedings{20080511075922 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings - ICSE 2007 Workshops: First International Workshop on Software Engineering for Pervasive Computing Applications, Systems, and Environments, SEPCASE'07},
journal = {Proceedings - ICSE 2007 Workshops: First International Workshop on Software Engineering for Pervasive Computing Applications, Systems, and Environments, SEPCASE'07},
year = {2007},
address = {Minneapolis, MN, United states},
abstract = {The proceedings contain 11 papers. The topics discussed include: the service ecosystem: dynamic self-aggregation of pervasive communication services; addressing dynamic contextual adaptation with a domain-specific language; generative programming approach for building pervasive computing applications; towards aspect-oriented programming for context-aware systems: a comparative study; and aspect-oriented model-driven development for mobile context-aware computing.},
key = {Ubiquitous computing},
keywords = {Computer programming languages;Mathematical models;Object oriented programming;},
note = {Domain specific language;Generative programming;Pervasive communication services;Service ecosystem;},
} 


@article{20105113503132 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Prototyping a domain-specific language for monitor and control systems},
journal = {Journal of Aerospace Computing, Information and Communication},
author = {Bennett, Matthew and Borgen, Richard and Havelund, Klaus and Ingham, Michel and Wagner, David},
volume = {7},
number = {11},
year = {2010},
pages = {338 - 364},
issn = {15429423},
address = {1801 Alexander Bell Drive, Suite 500, Reston, VA 20191-4344, United States},
abstract = {This paper describes a domain-specific language prototype developed for the NASA Constellation launch control system project. A key element of the launch control system architecture, the domain-specific language prototype is a specialized monitor and control language composed of constructs for specifying and programming test, checkout, and launch processing applications for flight and ground systems. The principal objectives of the prototyping activity were to perform a proof-of-concept of an approach to ultimately lower the lifecycle costs of application software for the launch control system, and to explore mitigations for a number of development risks perceived by the project. The language has been implemented as a library that extends the dynamically-typed Python scripting language, and validated in a demonstration of capability required for Constellation. A study of the statically typed Scala programming language as an alternative domain-specific language implementation language is also presented. &copy; 2010 by the American Institute of Aeronautics and Astronautics, Inc.},
key = {Flight control systems},
keywords = {Computer aided software engineering;Computer systems programming;Control theory;Launching;NASA;Problem oriented languages;Remote control;},
note = {Application softwares;Control system architecture;Development risk;Domain specific languages;Ground systems;Key elements;Lifecycle costs;Monitor and control;Processing applications;Programming language;Proof of concept;Prototyping;Scripting languages;},
URL = {http://dx.doi.org/10.2514/1.40331},
} 


@inproceedings{2005359335217 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Experiences in modeling for a domain specific language},
journal = {Lecture Notes in Computer Science},
author = {},
volume = {3297},
year = {2005},
pages = {187 - 197},
issn = {03029743},
address = {Lisbon, Portugal},
abstract = {Building models with a domain specific language enables targeting specific platform and framework functionality. We built a domain specific language for use in modeling applications targeting our business application framework. Such models are used for tasks including generating C# code and producing object-relational mappings for business objects. The paper briefly describes the framework and its accompanying domain specific language and then describes issues we encountered in using an unconstrained UML tool to express our models, solutions we developed to deal with those issues and observations about the suitability of UML for application to such problems. We found that making a general-purpose, extensible modeling language serve the needs of a targeted domain specific language is a lot of work and is only partially successful. We conclude that what is needed is a more general purpose framework for creating domain specific languages and tools for them. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Computer programming languages},
keywords = {Computer simulation;Computer software;Software engineering;},
note = {Building models;Domain specific languages;Modeling applications;Object-relational mappings;},
} 


@article{20080611090234 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A preliminary study on various implementation approaches of domain-specific language},
journal = {Information and Software Technology},
author = {Kosar, Tomaz and Martinez Lopez, Pablo E. and Barrientos, Pablo A. and Mernik, Marjan},
volume = {50},
number = {5},
year = {2008},
pages = {390 - 405},
issn = {09505849},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Various implementation approaches for developing a domain-specific language are available in literature. There are certain common beliefs about the advantages/disadvantages of these approaches. However, it is hard to be objective and speak in favor of a particular one, since these implementation approaches are normally compared over diverse application domains. The purpose of this paper is to provide empirical results from ten diverse implementation approaches for domain-specific languages, but conducted using the same representative language. Comparison shows that these discussed approaches differ in terms of the effort need to implement them, however, the effort needed by a programmer to implement a domain-specific language should not be the only factor taken into consideration. Another important factor is the effort needed by an end-user to rapidly write correct programs using the produced domain-specific language. Therefore, this paper also provides empirical results on end-user productivity, which is measured as the lines of code needed to express a domain-specific program, similarity to the original notation, and how error-reporting and debugging are supported in a given implementation. &copy; 2007 Elsevier B.V. All rights reserved.},
key = {Query languages},
keywords = {Embedded systems;Error detection;Program compilers;Program debugging;Program interpreters;},
note = {Commercial Off The Shelfs;Extensible compilers;Interpreter generators;Preprocessing;},
URL = {http://dx.doi.org/10.1016/j.infsof.2007.04.002},
} 


@inproceedings{20083011391961 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Leveraging patterns on domain models to improve UML profile definition},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Lagarde, Francois and Espinoza, Huascar and Terrier, Francois and Andre, Charles and Gerard, Sebastien},
volume = {4961 LNCS},
year = {2008},
pages = {116 - 130},
issn = {03029743},
address = {Budapest, Hungary},
abstract = {Building a reliable UML profile is a difficult activity that requires the use of complex mechanisms -stereotypes and their attributes, OCL enforcement- to define a domain-specific modeling language (DSML). Despite the ever increasing number of profiles being built in many domains, there is a little published literature available to help DSML designers. Without a clear design process, most such profiles are inaccurate and jeopardize subsequent model transformations or model analyses. We believe that a suitable approach to building UML based domain specific languages should include systematic transformation of domain representations into profiles. This article therefore proposes a clearly-defined process geared to helping the designer throughout this design activity. Starting from the conceptual domain model, we identify a set of design patterns for which we detail several profile implementations. We illustrate our approach by creating a simplified profile that depicts elements belonging to a real-time system domain. The prototype tool supporting our approach is also described. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Process engineering},
keywords = {Computer simulation languages;Java programming language;Linguistics;Multi agent systems;Process design;Query languages;Real time systems;Software engineering;Unified Modeling Language;},
note = {Complex mechanisms;Conferences (Chemical industry);Design activities;Design patterns;Design processes;Domain modeling;Domain representations;Domain specific language (DSL);Domain specific modeling language(DSML);European;Heidelberg (CO);International (CO);International conferences;Model transformations;Prototype tools;Real-time systems;Systematic (CO);Uml profiles;},
URL = {http://dx.doi.org/10.1007/978-3-540-78743-3_10},
} 


@article{20114014395438 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Design and implementation of domain-specific language easytime},
journal = {Computer Languages, Systems and Structures},
author = {Fister Jr., Iztok and Mernik, Marjan and Brest, Janez},
volume = {37},
number = {4},
year = {2011},
pages = {151 - 167},
issn = {14778424},
address = {Langford Lane, Kidlington, Oxford, OX5 1GB, United Kingdom},
abstract = {Measuring time in mass sporting competitions is, typically, performed with a timing system that consists of a measuring technology and a computer system. The first is dedicated to tracking events that are triggered by competitors and registered by measuring devices (primarily based on RFID technology). The latter enables the processing of these events. In this paper, the processing of events is performed by an agent that is controlled by the domain-specific language, EasyTime. EasyTime improves the flexibility of the timing system because it supports the measuring of time in various sporting competitions, their quick adaptation to the demands of new sporting competitions and a reduction in the number of measuring devices. Essentially, we are focused on the development of a domain specific language. In practice, we made two case studies of using EasyTime by measuring time in two different sporting competitions. The use of EasyTime showed that it can be useful for sports clubs and competition organizers by aiding in the results of smaller sporting competitions, while in larger sporting competitions it could simplify the configuration of the timing system. &copy; 2011 Elsevier Ltd. All rights reserved.},
key = {Problem oriented languages},
keywords = {Cryptography;Radio frequency identification (RFID);},
note = {Domain specific languages;Measuring device;Measuring technology;RFID technology;Sporting competition;Timing systems;},
URL = {http://dx.doi.org/10.1016/j.cl.2011.04.001},
} 


@inproceedings{2005269178113 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Teaching compiler construction using a domain specific language},
journal = {Proceedings of the Thirty-Sixth SIGCSE Technical Symposium on Computer Science Education, SIGCSE 2005},
author = {Henry, Tyson R.},
year = {2005},
pages = {7 - 11},
address = {St. Louis, MO, United states},
abstract = {Building a compiler for a domain specific language (a language designed for a specific problem domain) can engage students more than traditional compiler course projects. Most students feel that compiler courses are irrelevant because they are not likely to get a job writing compilers[2]. However, the technologies used to construct a compiler are widely applicable [2,5]. Using a domain specific language demonstrates to students the wide applicability of compiler construction techniques. This paper presents the results of using a domain specific language in an upper division compiler course. Copyright 2005 ACM.},
key = {Education computing},
keywords = {Animation;Codes (symbols);Computer graphics;Computer programming;Computer programming languages;Game theory;Program compilers;Students;},
note = {Compiler construction;Domain specific languages;Educational projects;Game programming language (GPL);},
} 


@inproceedings{2005519609541 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Developing embedded multi-threaded applications with CATAPULTS, a domain-specific language for generating thread schedulers},
journal = {CASES 2005: International Conference on Compilers, Architecture, and Synthesis for Embedded Systems},
author = {Roper, Matthew D. and Olsson, Ronald A.},
year = {2005},
pages = {295 - 303},
address = {San Francisco, CA, United states},
abstract = {This paper describes CATAPULTS, a domain-specific language for creating and testing application-specific user level thread schedulers. Using a domain-specific language to write thread schedulers provides three advantages. First, it modularizes the thread scheduler, making it easy to plug in and experiment with different schedulers. Second, using a domain-specific language for scheduling code helps prevent several of the common programming mistakes that are easy to make when programming in low-level C or assembly. Finally, the CATAPULTS translator has multiple backends that generate code for different languages and libraries. This makes it easy to prototype an embedded application on a regular PC, and then develop the final version on the embedded hardware; the CATAPULTS translator will take care of generating the appropriate code for both the PC proto-type and the final embedded version of the program. Using our implementation of CATAPULTS for Z-World's embedded Rabbit processors, we obtained a performance gain of about 12.6% at the expense of about 12.7% increase in code size for a fairly typical embedded application. Copyright 2005 ACM.},
key = {Formal languages},
keywords = {C (programming language);Codes (standards);Embedded systems;Program processors;Software prototyping;},
note = {Application-specific schedulers;Domain-specific languages;Thread scheduling;User-level threads;},
} 


@article{1999504871258 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Teapot: A domain-specific language for writing cache coherence protocols},
journal = {IEEE Transactions on Software Engineering},
author = {Chandra, Satish and Richards, Bradley and Larus, James R.},
volume = {25},
number = {3},
year = {1999},
pages = {317 - 333},
issn = {00985589},
abstract = {In this paper, we describe Teapot, a domain-specific language for writing cache coherence protocols. Cache coherence is of concern when parallel and distributed systems make local replicas of shared data to improve scalability and performance. In both distributed shared memory systems and distributed file systems, a coherence protocol maintains agreement among the replicated copies as the underlying data are modified by programs running on the system. Cache coherence protocols are notoriously difficult to implement, debug, and maintain. Moreover, protocols are not off-the-shelf, reusable components, because their details depend on the requirements of the system under consideration. The complexity of engineering coherence protocols can discourage users from experimenting with new, potentially more efficient protocols. We have designed and implemented Teapot, a domain-specific language that attempts to address this complexity. Teapot's language constructs, such as a state-centric control structure and continuations, are better suited to expressing protocol code than those of a typical systems programming language. Teapot also facilitates automatic verification of protocols, so hard to find protocol bugs, such as deadlocks, can be detected and fixed before encountering them on an actual execution. We describe the design rationale of Teapot, present an empirical evaluation of the language using two case studies, and relate the lessons that we learned in building a domain-specific language for systems programming.},
key = {Software engineering},
keywords = {Buffer storage;Computational complexity;Computer programming languages;Network protocols;Parallel processing systems;Program debugging;},
note = {Cache coherence protocols;Software package Teapot;},
URL = {http://dx.doi.org/10.1109/32.798322},
} 


@inproceedings{20093512277600 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific language for HW/SW Co-design for FPGAs},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Agron, Jason},
volume = {5658 LNCS},
year = {2009},
pages = {262 - 284},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {This article describes FSMLanguage, a domain-specific language for HW/SW co-design targeting platform FPGAs. Modern platform FPGAs provide a wealth of configurable logic in addition to embedded processors, distributed RAM blocks, and DSP slices in order to help facilitate building HW/SW co-designed systems. A technical challenge in building such systems is that the practice of designing software and hardware requires different areas of expertise and different description domains, i.e. languages and vocabulary. FSMLanguage attempts to unify these domains by defining a way to describe HW/SW co-designed systems in terms of sets of finite-state machines - a concept that is reasonably familiar to both software programmers and hardware designers. FSMLanguage is a domain-specific language for describing the functionality of a finite-state machine in such a way that its implementation can be re-targeted to software or hardware in an efficient manner. The efficiency is achieved by exploiting the resources found within modern platform FPGAs - namely the distributed RAM blocks, soft-core processors, and the ability to construct dedicated communication channels between FSMs in the reconfigurable fabric. The language and its compiler promote uniformity in the description of a HW/SW co-designed system, which allows a system designer to make partitioning and implementation strategy decisions later in the design cycle. &copy; IFIP International Federation for Information Processing 2009.},
key = {Query languages},
keywords = {Asynchronous machinery;Computer software;Contour followers;Design;DSL;Embedded systems;Field programmable gate arrays (FPGA);Graphical user interfaces;Linguistics;Modems;Program compilers;Random access storage;Telecommunication lines;},
note = {Communication channel;Configurable logic;Description domains;Design cycle;Designing softwares;Domain specific languages;Embedded processors;Finite state machines;Hardware designers;HW/SW Codesign;Implementation strategies;In-buildings;Reconfigurable fabrics;Soft-core processors;System designers;Technical challenges;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_13},
} 


@inproceedings{20091512018464 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Pantaxou: A domain-specific language for developing safe coordination services},
journal = {GPCE'08: Proceedings of the ACM SIGPLAN 7th International Conference on Generative Programming and Component Engineering},
author = {Mercadal, Julien and Palix, Nicolas and Consel, Charles and Lawall, Julia L.},
year = {2008},
pages = {149 - 159},
address = {Nashville, TN, United states},
abstract = {Coordinating entities in a networked environment has always been a significant challenge for software developers. In recent years, however, it has become even more difficult, because devices have increasingly rich capabilities, combining an ever larger range of technologies (networking, multimedia, sensors, etc.). To address this challenge, we propose a language-based approach to covering the life-cycle of applications coordinating networked entities. Our approach covers the characterization of the networked environment, the specification of coordination applications, the verification of a networked environment and its deployment. It is carried out in practice by a domain-specific language, named Pantaxou. This paper presents the domain-specific language Pantaxou, dedicated to the development of applications for networked heterogeneous entities. Pantaxou has been used to specify a number of coordination scenarios in areas ranging from home automation to telecommunications. The language semantics has been formally defined and a compiler has been developed. The compiler verifies the coherence of a coordination scenario and generates coordination code in Java. &copy; 2008 ACM.},
key = {Query languages},
keywords = {Applications;Computer software;Graphical user interfaces;Information theory;Large scale systems;Life cycle;Linguistics;Program compilers;Safety engineering;},
note = {Architecture description languages;Coordination languages;Distributed systems;Domain-specific languages;Safety;},
URL = {http://dx.doi.org/10.1145/1449913.1449936},
} 


@inproceedings{20113914374447 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain specific language and translator for cellular automata models of physico-chemical processes},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Kalgin, Konstantin},
volume = {6873 LNCS},
year = {2011},
pages = {166 - 174},
issn = {03029743},
address = {Kazan, Russia},
abstract = {A new domain specific language CACHE and its translator into C and Processing are presented. The domain is a set of cellular automata models of physico-chemical processes. The language and the translator are intended for using by researchers studying such processes. The translator allows to obtain both serial and parallel programs on C language. Multicores and clusters as target parallel architectures are supported. Additionally, one can easily visualize the process interactively, create a movie, and publish a Java-applet in the Internet using Processing. &copy; 2011 Springer-Verlag Berlin Heidelberg.},
key = {C (programming language)},
keywords = {Cellular automata;Chemical engineering;Parallel architectures;Program translators;Translation (languages);},
note = {C language;Cellular automata models;Domain specific languages;Multi-cores;Parallel program;Physicochemical process;},
URL = {http://dx.doi.org/10.1007/978-3-642-23178-0_14},
} 


@inproceedings{20085011772884 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {WebDSL: A case study in domain-specific language engineering},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Visser, Eelco},
volume = {5235 LNCS},
year = {2008},
pages = {291 - 373},
issn = {03029743},
address = {Braga, Portugal},
abstract = {The goal of domain-specific languages (DSLs) is to increase the productivity of software engineers by abstracting from low-level boilerplate code. Introduction of DSLs in the software development process requires a smooth workflow for the production of DSLs themselves. This requires technology for designing and implementing DSLs, but also a methodology for using that technology. That is, a collection of guidelines, design patterns, and reusable DSL components that show developers how to tackle common language design and implementation issues. This paper presents a case study in domain-specific language engineering. It reports on a project in which the author designed and built WebDSL, a DSL for web applications with a rich data model, using several DSLs for DSL engineering: SDF for syntax definition and Stratego/XT for code generation. The paper follows the stages in the development of the DSL. The contributions of the paper are three-fold. (1) A tutorial in the application of the specific SDF and Stratego/XT technology for building DSLs. (2) A description of an incremental DSL development process. (3) A domain-specific language for web-applications with rich data models. The paper concludes with a survey of related approaches. &copy; 2008 Springer Berlin Heidelberg.},
key = {Engineering},
keywords = {Applications;Codes (symbols);Computer programming languages;Computer software reusability;Data structures;DSL;Graphical user interfaces;Java programming language;Linguistics;Modems;Paper;Query languages;Response time (computer systems);Software engineering;Telecommunication lines;},
note = {Case studies;Code generations;Common languages;Data models;Design patterns;Development processes;Do-mains;Software development processes;Software Engineers;Specific languages;Syntax definitions;WEB applications;},
URL = {http://dx.doi.org/10.1007/978-3-540-88643-3-7},
} 


@inproceedings{20112514080784 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for managing feature models},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Acher, Mathieu and Collet, Philippe and Lahire, Philippe and France, Robert B.},
year = {2011},
pages = {1333 - 1340},
address = {TaiChung, Taiwan},
abstract = {Feature models are a popular formalism for managing variability in software product lines (SPLs). In practice, developing an SPL can involve modeling a large number of features representing different viewpoints, sub-systems or concerns of the software system. To manage complexity, there is a need to separate, relate and compose several feature models while automating the reasoning on their compositions in order to enable rigorous SPL validation and configuration. In this paper, we propose a Domain-Specific Language (DSL) that is dedicated to the management of feature models and that complements existing tool support. Rationale for this language is discussed and its main constructs are presented through examples. We show how the DSL can be used to realize a non trivial scenario in which multiple SPLs are managed. &copy; 2011 ACM.},
key = {Software design},
keywords = {Problem oriented languages;},
note = {Domain specific languages;Feature models;Non-trivial;Product-lines;Software Product Line;Software systems;Sub-systems;Tool support;},
URL = {http://dx.doi.org/10.1145/1982185.1982473},
} 


@inproceedings{20095312586267 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The business choreography language (BCL) - A domain-specific language for global choreographies},
journal = {SERVICES 2009 - 5th 2009 World Congress on Services},
author = {Motal, Thomas and Zapletal, Marco and Werthner, Hannes},
number = {PART 2},
year = {2009},
pages = {150 - 159},
address = {Bangalore, India},
abstract = {UN/CEFACT's Modeling Methodology (UMM) is a modeling approach for describing the choreography of B2B processes. UMM is developed by the United Nations Center for Trade Facilitation and Electronic Business (UN/CEFACT) and currently defined as a UML profile. Thereby, it constrains the UML for the specific needs of B2B. As we learned, using UML as the underlying notation for UMM results in several shortcomings. Furthermore, some workarounds are required to fit the concepts of UMM to the UML meta model. Thus, in this paper we examine an alternative notation for UMM following the concepts of a domain-specific language (DSL). The contribution of this paper is twofold: (i) we identify general concepts for modeling global choreographies by taking UMM as a starting point. (ii) We introduce the Business Choreography Language (BCL), a domain-specific language designed to efficiently support the prior identified concepts. The concepts of the BCL are exemplified by an implementation using the Microsoft DSL Tools for Visual Studio. In fact, the BCL is an approach tailored to support the specific needs of global B2B choreographies. &copy; 2009 IEEE.},
key = {Linguistics},
keywords = {DSL;Electric load management;Electronic commerce;Modems;Problem oriented languages;Semantic Web;Telecommunication lines;},
note = {Domain specific languages;Electronic business;Meta model;MicroSoft;Modeling approach;Modeling methodology;Trade facilitation;UML profiles;UN/CEFACT;United Nations;Visual studios;},
URL = {http://dx.doi.org/10.1109/SERVICES-2.2009.25},
} 


@inproceedings{20113214209186 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Neptune: A domain specific language for deploying HPC software on cloud platforms},
journal = {ScienceCloud'11 - Proceedings of the 2nd International Workshop on Scientific Cloud Computing},
author = {Bunch, Chris and Chohan, Navraj and Krintz, Chandra and Shams, Khawaja},
year = {2011},
pages = {59 - 68},
address = {San Jose, CA, United states},
abstract = {In this paper, we present the design and implementation of Neptune, a domain specific language (DSL) that automates configuration and deployment of existing HPC software via cloud computing platforms. We integrate Neptune into a popular, open-source cloud platform, and extend the platform with support for user-level and automated placement of cloud services and HPC components. Such platform integration of Neptune facilitates hybrid-cloud application execution as well as portability across disparate cloud fabrics. Supporting additional cloud fabrics through a single interface enables high throughput computing (HTC) to be achieved by users who do not necessarily own grid-level resources but do have access to otherwise independent cloud technologies. We evaluate Neptune using different applications that employ a wide range of popular HPC packages for their implementation including MPI, X10, MapReduce, DFSP, and dwSSA. In addition, we show how Neptune can be extended to support other HPC software and application domains, and thus be used as a mechanism for many task computing (MTC). &copy; 2011 ACM.},
key = {Cloud computing},
keywords = {Computer systems;},
note = {Application domains;Application execution;Automated placements;Cloud services;Computing platform;Domain specific languages;High-throughput computing;Map-reduce;Neptune;Open-source;service placement;Task computing;},
URL = {http://dx.doi.org/10.1145/1996109.1996120},
} 


@article{20113914363004 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {SEPL - A domain-specific language and execution environment for protocols of stateful Web services},
journal = {Distributed and Parallel Databases},
author = {Hummer, Waldemar and Leitner, Philipp and Dustdar, Schahram},
volume = {29},
number = {4},
year = {2011},
pages = {277 - 307},
issn = {09268782},
address = {Van Godewijckstraat 30, Dordrecht, 3311 GZ, Netherlands},
abstract = {In order to interact with stateful Web services, clients need to obtain information about the intra-service protocol, which contains valid operation sequences and the expected input-output transformation across invocations. While the community has widely agreed on WSDL as the standard for functional service description (the "static" service interface), there is still an evident lack of languages to describe the dynamic, behavioral interface of services. In this paper we introduce SEPL (SErvice Protocol Language), a domain-specific language (DSL) for defining executable intraservice protocols. Notable features of the DSL include support for WS-Addressing and simple creation of new Web service instances, synchronous and asynchronous service invocation facilities and easy access to WSRF-style service resource properties. Service providers use SEPL to define the procedure that clients must adhere to in order to achieve a certain higher-level functionality. Clients use the combined information of the SEPL document and the WSDL definitions to execute an intra-service protocol. We provide a graphical representation of SEPL the form of UML Activity Diagrams, and tools to generate executable code from these models. We further present a solution to host and execute SEPL protocols in a server application based on Web services technology. &copy; Springer Science+Business Media, LLC 2011.},
key = {Web services},
keywords = {Internet protocols;Problem oriented languages;},
note = {Behavioral interfaces;Combined informations;Domain specific languages;Executable codes;Execution environments;Functional services;Graphical representations;Input-output;Intra-service protocol;Operation sequences;SEPL;Server applications;Service instances;Service interfaces;Service invocation;Service protocols;Service provider;Service resources;UML activity diagrams;Web Services technologies;},
URL = {http://dx.doi.org/10.1007/s10619-011-7079-6},
} 


@inproceedings{20113514280118 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {TEMPLE - A domain specific language for modeling and solving staff scheduling problems},
journal = {IEEE SSCI 2011 - Symposium Series on Computational Intelligence - CISched 2011: 2011 IEEE Symposium on Computational Intelligence in Scheduling},
author = {Gartner, Johannes and Musliu, Nysret and Schafhauser, Werner and Slany, Wolfgang},
year = {2011},
pages = {58 - 64},
address = {Paris, France},
abstract = {We present TEMPLE, a domain specific language for modeling and solving staff scheduling problems. TEMPLE provides a set of intuitive abstractions and notations allowing to formulate the constraints of a particular problem in a very compact and natural way. After modeling a staff scheduling problem in TEMPLE, three generic local search algorithms can immediately be applied to the corresponding optimization problem. We show how real-life staff scheduling problems can be both effectively modeled as well as efficiently solved using our approach. Finally, we report on a practical application of TEMPLE in a commercial staff scheduling software. &copy; 2011 IEEE.},
key = {Artificial intelligence},
note = {Domain specific languages;Local search algorithm;Optimization problems;Staff scheduling;},
URL = {http://dx.doi.org/10.1109/SCIS.2011.5976550},
} 


@inproceedings{20111713937725 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Design of domain specific language for web services QoS constraints definition},
journal = {Communications in Computer and Information Science},
author = {Sikri, Monika},
volume = {147 CCIS},
year = {2011},
pages = {411 - 416},
issn = {18650929},
address = {Nagpur, Maharashtra, India},
abstract = {Semantic Webservices (SWS) has raised interest in mechanisms for Ontological representation of Web Services. A number of mechanisms most notably WSMO and OWL-S are being developed to represent the same. An important area in description of Web Services is the QoS characterization and discovery which is the focus of research for this paper. A Domain Specific language is being proposed for definition of observable QoS characteristics and conditions. The syntax of this proposed language is being kept closer to WSML considering it the standard modeling language. &copy; 2011 Springer-Verlag.},
key = {Web services},
keywords = {Information technology;Mobile telecommunication systems;Semantic Web;Semantics;},
note = {Domain specific languages;Modeling languages;Ontological representation;QoS;QoS constraints;SOA;WSML;},
URL = {http://dx.doi.org/10.1007/978-3-642-20573-6_73},
} 


@inproceedings{20114014406062 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {OptiML: An implicitly parallel domain-specific language for machine learning},
journal = {Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
author = {Sujeeth, Arvind K. and Lee, HyoukJoong and Brown, Kevin J. and Chafi, Hassan and Wu, Michael and Atreya, Anand R. and Olukotun, Kunle and Rompf, Tiark and Odersky, Martin},
year = {2011},
pages = {609 - 616},
address = {Bellevue, WA, United states},
abstract = {As the size of datasets continues to grow, machine learning applications are becoming increasingly limited by the amount of available computational power. Taking advantage of modern hardware requires using multiple parallel programming models targeted at different devices (e.g. CPUs and GPUs). However, programming these devices to run efficiently and correctly is difficult, error-prone, and results in software that is harder to read and maintain. We present OptiML, a domain-specific language (DSL) for machine learning. OptiML is an implicitly parallel, expressive and high performance alternative to MATLAB and C++. OptiML performs domain-specific analyses and optimizations and automatically generates CUDA code for GPUs. We show that OptiML outperforms explicitly parallelized MATLAB code in nearly all cases. Copyright 2011 by the author(s)/owner(s).},
key = {MATLAB},
keywords = {Learning systems;Parallel programming;Problem oriented languages;Program processors;},
note = {Computational power;Data sets;Domain specific;Domain specific languages;Error prones;Machine learning applications;Matlab code;Parallel programming model;},
} 


@inproceedings{20110413614038 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific language for context-aware web applications},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Nebeling, Michael and Grossniklaus, Michael and Leone, Stefania and Norrie, Moira C.},
volume = {6488 LNCS},
year = {2010},
pages = {471 - 479},
issn = {03029743},
address = {Hong Kong, China},
abstract = {Context-awareness is a requirement in many modern web applications. While most model-driven web engineering approaches have been extended with support for adaptivity, state-of-the-art development platforms generally provide only limited means for the specification of adaptation and often completely lack a notion of context. We propose a domain-specific language for context-aware web applications that builds on a simple context model and powerful context matching expressions. &copy; 2010 Springer-Verlag Berlin Heidelberg.},
key = {World Wide Web},
keywords = {Information systems;Problem oriented languages;Systems engineering;},
note = {Context matching;Context models;Context- awareness;Context-Aware;Development platform;Domain specific languages;Model-driven;Support for adaptivity;WEB application;Web engineering;},
URL = {http://dx.doi.org/10.1007/978-3-642-17616-6_42},
} 


@article{20113614291367 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Measuring time in sporting competitions with the domain-specific language EasyTime},
journal = {Elektrotehniski Vestnik/Electrotechnical Review},
author = {Fister, Iztok},
volume = {78},
number = {1-2},
year = {2011},
pages = {36 - 41},
issn = {00135852},
address = {Trzaska 25, Ljubljana, 1001, Slovenia},
abstract = {Measuring time in mass sporting competitions is unthinkable manually today because of their long duration and unreliability. Besides, automatic timing devices based on the RFID technology have become cheaper. However, these devices cannot operate stand-alone. To work efficiently, they need a computer timing system for monitoring results. Such system should be capable of processing the incoming events, encoding and assigning results to a individual competitor, sorting results according to the achieved time and printing them. In this paper, a domain-specific language named EasyTime will be defined. It enables controlling an agent by writing events to a database. Using the agent, the number of measuring devices can be reduced. Also, EasyTime is of a universal type that can be applied to many different sporting competitions.},
key = {Problem oriented languages},
keywords = {Automatic programming;Cryptography;Monitoring;},
note = {BNF notation;Code Generation;Domain specific languages;Parser;RFID technology;Time measuring;},
} 


@inproceedings{20105113504725 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language for contextual design},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Barn, Balbir S. and Clark, Tony},
volume = {6409 LNCS},
year = {2010},
pages = {46 - 61},
issn = {03029743},
address = {Reykjavik, Iceland},
abstract = {This paper examines the role of user-centered design (UCD) approaches to design and implementation of a mobile social software application to support student social workers in their work place. The experience of using a variant of UCD is outlined. The principles and expected norms of UCD raised a number of key lessons. It is proposed that these problems and lessons are a result of the inadequacy of precision of modeling the outcomes of UCD, which prevents model driven approaches to method integration between UCD approaches. Given this, it is proposed that the Contextual Design method is a good candidate for enhancing with model driven principles. A subset of the Work model focussing on Cultural and Flow models are described using a domain specific language and supporting tool built using the MetaEdit+ platform. &copy; 2010 IFIP International Federation for Information Processing.},
key = {Design},
keywords = {Software engineering;},
note = {Contextual design;Domain specific languages;Flow model;Method integration;Model driven approach;Model-driven;Social software;Supporting tool;User centered designs;Work place;},
URL = {http://dx.doi.org/10.1007/978-3-642-16488-0_5},
} 


@inproceedings{20101112762972 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language approach to protocol stack implementation},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Wang, Yan and Gaspes, Veronica},
volume = {5937 LNCS},
year = {2010},
pages = {183 - 185},
issn = {03029743},
address = {Madrid, Spain},
abstract = {This paper describes a domain-specific language embedded in Haskell, IPS, for the implementation of protocol stacks for embedded systems. IPS profits from Haskell's features and generates C implementations by embedded compilation. &copy; 2010 Springer-Verlag.},
key = {Computer programming},
keywords = {Computer software;DSL;Embedded systems;Linguistics;Modems;Problem oriented languages;Profitability;Query languages;Switching systems;Telecommunication lines;Textiles;Uninterruptible power systems;},
note = {Communication software;Domain specific languages;DSL networks;Haskell;Protocol stack;},
URL = {http://dx.doi.org/10.1007/978-3-642-11503-5_16},
} 


@inproceedings{20114014396070 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modelling and prototyping of business applications based on multilevel domain-specific language},
journal = {Lecture Notes in Business Information Processing},
author = {Pergl, Robert},
volume = {88 LNBIP},
year = {2011},
pages = {173 - 191},
issn = {18651348},
address = {London, United kingdom},
abstract = {An effective approach to modelling and prototyping of business applications is presented in this paper. The approach is based on three concepts: The concept of data structure abstraction, the concept of a behavioural model based on the dynamic functional approach and a design approach based on creating multiple levels of a domain-specific language. The characteristics of each concept are presented. A technique how to combine them together to create highly detailed descriptive models that may be easily turned to prototypes is shown and demonstrated. Limitations are formulated and benefits over the object-oriented approach are discussed, as well. &copy; 2011 Springer-Verlag.},
key = {LISP (programming language)},
keywords = {Abstracting;Computer simulation;Data structures;Functional programming;Graphical user interfaces;Industry;Object oriented programming;Problem oriented languages;Software prototyping;},
note = {Abstract data structures;Clojure;Domain specific languages;Functional modelling;Lisp;},
URL = {http://dx.doi.org/10.1007/978-3-642-24175-8_13},
} 


@inproceedings{20113414258635 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic generation and verification of interlocking tables based on Domain Specific Language for Computer Based Interlocking Systems (DSL-CBI)},
journal = {Proceedings - 2011 IEEE International Conference on Computer Science and Automation Engineering, CSAE 2011},
author = {Cao, Yan and Xu, Tianhua and Tang, Tao and Wang, Haifeng and Zhao, Lin},
volume = {2},
year = {2011},
pages = {511 - 515},
address = {Shanghai, China},
abstract = {Interlocking tables, as the function specification of the Computer Based Interlocking System (CBI), play an important role in ensuring safe train movements at a railway station. The development and verification of interlocking tables is entirely manual process currently, which is inefficient and error-prone due to the complexity of the CBI and the human interferences. In order to tackle these problems, we introduce a toolset based on Domain Specific Language for Computer Based Interlocking Systems (DSL-CBI) to automatically generate and verify the interlocking table. In this paper, we address how to use the algorithm to automatically generate the interlocking table by inputting the XML file of the railway station designed by DSL-CBI, and how to use model checking to verify whether there are any conflicting settings in it. We also discuss the advantages of the toolset and the significant contribution in developing CBI based on the proposed toolset. &copy; 2011 IEEE.},
key = {Interlocking signals},
keywords = {Algorithms;Computer science;Model checking;Railroad stations;Railroads;Safety devices;},
note = {Automatic Generation;Computer Based Interlocking;Domain specific languages;Error prones;Function specification;Human interference;interlocking table;Manual process;Railway stations;Route information;Toolsets;Train movement;XML files;},
URL = {http://dx.doi.org/10.1109/CSAE.2011.5952519},
} 


@inproceedings{20110713667525 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MobDSL: A domain specific language for multiple mobile platform deployment},
journal = {2010 IEEE International Conference on Networked Embedded Systems for Enterprise Applications, NESEA 2010},
author = {Kramer, Dean and Clark, Tony and Oussena, Samia},
year = {2010},
address = {Suzhou, China},
abstract = {There is increasing interest in establishing a presence in the mobile application market, with platforms including Apple iPhone, Google Android and Microsoft Windows Mobile. Because of the differences in platform languages, frameworks, and device hardware, development of an application for more than one platform can be a difficult task. In this paper we address this problem by the creation of a mobile Domain Specific Language (DSL). Domain analysis was carried out using two case studies, inferring basic requirements of the language. The paper further introduces the language calculus definition and provides discussion how it fits the domain analysis, and any issues found in our approach. &copy;2010 IEEE.},
key = {Embedded systems},
keywords = {Mobile computing;Trees (mathematics);},
note = {Domain analysis;Domain specific languages;Microsoft windows;Mobile applications;Mobile domains;Mobile platform;Platform-independence;},
URL = {http://dx.doi.org/10.1109/NESEA.2010.5678062},
} 


@inproceedings{20103013102010 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Macml: A domain-specific language for machinery service management},
journal = {Proceedings - 2010 International Conference on Service Science, ICSS 2010},
author = {Yang, Junwei and Hu, Zhongxiang and Zheng, Yujun},
year = {2010},
pages = {293 - 297},
address = {Hangzhou, China},
abstract = {The paper presents Macml, a domain-specific language (DSL) that focuses on the effective specification, implementation, and verification of information systems in the domain of machinery services. As a meta-model of the application domain, the language precisely defining elements including entities, relationships, behaviors, constraints, and workflows, based on which the users, domain experts, and software engineers can effectively communicate with each other and work together to model a variety of machinery service management systems, which are all instances of the meta-model and which can be further transformed into executable systems mechanically. As a case study, a system model of Macml is presented to illustrate the iiriDlementation of our aDDroach. &copy; 2010 IEEE.},
key = {Mathematical models},
keywords = {Intelligent control;Linguistics;Machinery;Management;Model structures;Problem oriented languages;},
note = {Application domains;Domain experts;Domain specific languages;Executable systems;Meta model;Model transformation;Service management;Software engineers;System models;Work-flows;},
URL = {http://dx.doi.org/10.1109/ICSS.2010.12},
} 


@inproceedings{20103813240036 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MONACO - A domain-specific language supporting hierarchical abstraction and verification of reactive control programs},
journal = {IEEE International Conference on Industrial Informatics (INDIN)},
author = {Prahofer, Herbert and Hurnaus, Dominik},
year = {2010},
pages = {908 - 914},
issn = {19354576},
address = {Osaka, Japan},
abstract = {Domain-specific languages aim to present software in the notations of domain experts and allow a straightforward mapping of application concepts to software solutions. In this paper, we present a domain-specific language for programming reactive control programs. The language differs from other approaches mainly by its hierarchical component approach, in which lower-level components provide elementary operations and upper components rely on the operations of their subordinates to implement higher control tasks. Moreover, the hierarchical component approach is leveraged in a hierarchical verification technique in which component implementations are verified against dynamic contracts of their subcomponents. We present the principles of the verification technique and discuss how it can be applied in a multi-stage development process. &copy; 2010 IEEE.},
key = {Computer software selection and evaluation},
keywords = {Graphical user interfaces;Hierarchical systems;Linguistics;Problem oriented languages;},
note = {Control task;Development process;Domain experts;Domain specific languages;Elementary operations;Hierarchical components;Hierarchical verification;Multi-stage;Reactive control;Software solution;Verification techniques;},
URL = {http://dx.doi.org/10.1109/INDIN.2010.5549622},
} 


@inproceedings{20110113552572 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An integrated domain specific language for post-processing and visualizing electrophysiological signals in Java},
journal = {2010 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC'10},
author = {Strasser, T. and Peters, T. and Jagle, H. and Zrenner, E. and Wilke, R.},
year = {2010},
pages = {4687 - 4690},
address = {Buenos Aires, Argentina},
abstract = {Electrophysiology of vision - especially the electroretinogram (ERG) - is used as a non-invasive way for functional testing of the visual system. The ERG is a combined electrical response generated by neural and non-neuronal cells in the retina in response to light stimulation. This response can be recorded and used for diagnosis of numerous disorders. For both clinical practice and clinical trials it is important to process those signals in an accurate and fast way and to provide the results as structured, consistent reports. Therefore, we developed a freely available and open-source framework in Java (http://www.eye.uni-tuebingen.de/projectlidsI4sigproc). The framework is focused on an easy integration with existing applications. By leveraging well-established software patterns like pipes-and-filters and fluent interfaces as well as by designing the application programming interfaces (API) as an integrated domain specific language (DSL) the overall framework provides a smooth learning curve. Additionally, it already contains several processing methods and visualization features and can be extended easily by implementing the provided interfaces. In this way, not only can new processing methods be added but the framework can also be adopted for other areas of signal processing. This article describes in detail the structure and implementation of the framework and demonstrate its application through the software package used in clinical practice and clinical trials at the University Eye Hospital Tuebingen one of the largest departments in the field of visual electrophysiology in Europe. &copy; 2010 IEEE.},
key = {Java programming language},
keywords = {Application programming interfaces (API);Electrophysiology;Experiments;Neurology;Processing;Signal processing;Visualization;},
note = {Clinical practices;Clinical trial;Domain specific languages;Electrical response;Electroretinograms;Functional testing;Learning curves;Light stimulation;Neuronal cell;Non-invasive way;Open source frameworks;Post processing;Processing method;Software patterns;Visual systems;},
URL = {http://dx.doi.org/10.1109/IEMBS.2010.5626417},
} 


@inproceedings{20103513188582 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A C++-embedded domain-specific language for programming the MORA soft processor array},
journal = {Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors},
author = {Vanderbauwhede, W. and Margala, M. and Chalamalasetti, S.R. and Purohit, S.},
year = {2010},
pages = {141 - 148},
issn = {10636862},
address = {Rennes, France},
abstract = {MORA is a novel platform for high-level FPGA programming of streaming vector and matrix operations, aimed at multimedia applications. It consists of soft array of pipelined low-complexity SIMD processors-in-memory (PIM). We present a Domain-Specific Language (DSL) for high-level programming of the MORA soft processor array. The DSL is embedded in C++, providing designers with a familiar language framework and the ability to compile designs using a standard compiler for functional testing before generating the FPGA bitstream using the MORA toolchain. The paper discusses the MORA-C++ DSL and the compilation route into the assembly for the MORA machine and provides examples to illustrate the programming model and performance. &copy; 2010 IEEE.},
key = {Pipeline processing systems},
keywords = {Ability testing;Computer architecture;Field programmable gate arrays (FPGA);Linguistics;Nanotechnology;Problem oriented languages;},
note = {Bit stream;Domain specific languages;Embedded domains;Functional testing;High-level programming;Low-complexity;Matrix operations;Multimedia applications;Multimedia processing;Programming models;Reconfigurable processors;Simd processors;Soft processors;},
URL = {http://dx.doi.org/10.1109/ASAP.2010.5540750},
} 


@inproceedings{20103513191312 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {First step towards a domain specific language for self-adaptive systems},
journal = {NOTERE'10 - 10th Annual International Conference on New Technologies of Distributed Systems},
author = {Ahmad, Manzoor},
year = {2010},
pages = {285 - 290},
address = {Tozeur, Tunisia},
abstract = {Self-adaptive systems are capable of autonomously modifying their behavior at run-time in response to changing environmental conditions. In order to modify the behavior, requirements play an important role, as they tend to change for these systems. For this we need to identify those requirements that are concerned with the adaptability features of the self-adaptive systems. In order to cope with the uncertainty inherent in self-adaptive systems, requirements engineering languages for these systems should include explicit constructs. RELAX is a requirement engineering language for self-adaptive systems that incorporates uncertainty into the specification of these systems. To go one step further, we aim at developing a domain specific language that would bridge the gap between requirements and the overall system model. The first step that is illustrated in this paper is to build a textual editor for RELAX. &copy;2010 IEEE.},
key = {Adaptive systems},
keywords = {Embedded systems;Linguistics;Query languages;},
note = {Domain specific languages;Dynamically Adaptive Systems (DASs);Eclipse modeling framework;Environmental conditions;One step;Requirement engineering;Runtimes;Self-adaptive system;System models;},
URL = {http://dx.doi.org/10.1109/NOTERE.2010.5536629},
} 


@inproceedings{20105013487705 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An exercise in iterative domain-specific language design},
journal = {ACM International Conference Proceeding Series},
author = {Van Amstel, Marcel and Van Den Brand, Mark and Engelen, Luc},
year = {2010},
pages = {48 - 57},
address = {Antwerp, Belgium},
abstract = {We describe our experiences with the process of designing a domain-specific language (DSL) and corresponding model transformations. The simultaneous development of the language and the transformations has lead to an iterative evolution of the DSL. We identified four main influences on the evolution of our DSL: the problem domain, the target platforms, model quality, and model transformation quality. Our DSL is aimed at modeling the structure and behavior of distributed communicating systems. Simultaneously with the development of our DSL, we implemented three model transformations to different formalisms: one for simulation, one for execution, and one for verification. Transformations to each of these formalisms were implemented one at the time, while preserving the validity of the existing ones. The DSL and the formalisms for simulation, execution, and verification have different semantic characteristics. We also implemented a number of model transformations that bridge the semantic gaps between our DSL and each of the three formalisms. In this paper, we describe our development process and how the aforementioned influences have caused our DSL to evolve. &copy; 2010 ACM.},
key = {Computer software selection and evaluation},
keywords = {Computer simulation;Mathematical models;Problem oriented languages;Semantics;Software engineering;Technical presentations;},
note = {Development process;Domain specific languages;Model qualities;Model transformation;Problem domain;Semantic gap;Three models;},
URL = {http://dx.doi.org/10.1145/1862372.1862386},
} 


@inproceedings{20103413171228 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A human readable platform independent domain specific language for BPEL},
journal = {Communications in Computer and Information Science},
author = {Simon, Balazs and Goldschmidt, Balazs and Kondorosi, Karoly},
volume = {87 CCIS},
number = {PART 1},
year = {2010},
pages = {537 - 544},
issn = {18650929},
address = {Prague, Czech republic},
abstract = {The basic building blocks of SOA systems are web services. High-level service orchestration is usually achieved by defining processes in BPEL. The available development environments, however, usually have visual tools for BPEL handling. The problem with this is that they are not satisfactory when efficiency, repeatability, and manageability is necessary. The domain specific language introduced in this paper uses a Java and C#-like language for describing web service interfaces and BPEL processes. It has the same descriptive power as WSDL and BPEL while maintaining simplicity and readability. Examples show how to use the language, and how it can be compiled into BPEL process descriptions. &copy; 2010 Springer-Verlag.},
key = {Java programming language},
keywords = {Linguistics;Web services;},
note = {Basic building block;BPEL;Development environment;Domain specific languages;High-level services;Human-readable;Platform independent;SOA;Visual tools;Web service interface;},
URL = {http://dx.doi.org/10.1007/978-3-642-14292-5_55},
} 


@inproceedings{20103613209748 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Vivisection of a non-executable, domain-specific language: Understanding (the usage of) the P3P language},
journal = {IEEE International Conference on Program Comprehension},
author = {Lammel, Ralf and Pek, Ekaterina},
year = {2010},
pages = {104 - 113},
address = {Braga, Minho, Portugal},
abstract = {P3P is the policy language with which websites declare the intended use of data that is collected about users of the site. We have systematically collected P3P-based privacy policies from websites listed in the Google directory, and analysed the resulting corpus with regard to different levels of validity, size or complexity metrics, different cloning levels, coverage of language constructs, and the use of the language's extension mechanism. In this manner, we have found interesting characteristics of P3P in the wild. For instance, cloning is exceptionally common in this domain, and encountered language extensions exceed the base language in terms of grammar complexity. Overall, this effort helps understanding the de-facto usage of the nonexecutable, domain-specific language P3P. Some elements of our methodology may be useful for other software languages as well. &copy; 2010 IEEE.},
key = {Linguistics},
keywords = {Cloning;Computer programming;Problem oriented languages;Query languages;World Wide Web;},
note = {Base language;Complexity metrics;Domain specific languages;Grammar complexity;Language constructs;Language extensions;Policy language;Privacy policies;Software languages;},
URL = {http://dx.doi.org/10.1109/ICPC.2010.45},
} 


@inproceedings{20103413171227 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A human readable platform independent domain specific language for WSDL},
journal = {Communications in Computer and Information Science},
author = {Simon, Balazs and Goldschmidt, Balazs},
volume = {87 CCIS},
number = {PART 1},
year = {2010},
pages = {529 - 536},
issn = {18650929},
address = {Prague, Czech republic},
abstract = {The basic building blocks of SOA systems are web services. WSDL, the standard language for defining web services, is far too complex and redundant to be efficiently handled by humans. Existing solutions use either graphical representations (UML, etc.), which are again inefficient in large scale projects, or define web services in the implementation's native language, which is a bottom-up approach risking interface stability. Both lack support for concepts like conditions, access-rights, etc. The domain specific language introduced in this paper uses a Java and C#-like language for describing web service interfaces. It has the same descriptive power as WSDL while maintaining simplicity and readability. Examples show how to use the language, and how it can be compiled into WSDL. &copy; 2010 Springer-Verlag.},
key = {Java programming language},
keywords = {Linguistics;Web services;},
note = {Basic building block;Bottom up approach;Domain specific languages;Graphical representations;Human-readable;Interface stabilities;Large-scale projects;Native language;Platform independent;SOA;Web service interface;WSDL;},
URL = {http://dx.doi.org/10.1007/978-3-642-14292-5_54},
} 


@article{20103113111530 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MetaHDL: inference and parameter tracing oriented domain-specific language for hardware description},
journal = {Zhejiang Daxue Xuebao (Gongxue Ban)/Journal of Zhejiang University (Engineering Science)},
author = {Meng, Xin and Shen, Hai-Bin and Yan, Xiao-Lang},
volume = {44},
number = {6},
year = {2010},
pages = {1079 - 1085+1097},
issn = {1008973X},
address = {20 Yugu Road, Hangzhou, 310027, China},
abstract = {Configurable parameterized System-On-a-Chip (SoC) design using industry standard Hardware Description Language (HDL) is complicate and hard to maintain. A Domain-specific Language (DSL) named MetaHDL was presented for synthesizable functional description of configurable digital Very Large Scale Integrated (VLSI) circuits, ranging from logic oriented low-level module design to Intellectual Property (IP) based SoC integration. MetaHDL uses inference and parameter tracing technologies and has specific optimizations for circuit's structure and functional descriptions, so as to improve language expressiveness, code readability and maintainability, and achieved over 65% code reduction. MetaHDL provides a two-level code configuration system consisting comprehensive preprocessor and parameter tracing mechanism to ease the reuse-oriented module design and IP integration. MetaHDL has been used in the Unified Threat Management (UTM) chip development project, addressed various design challenges of complex reuse scenarios, and improved the project efficiency and quality.},
key = {Computer hardware description languages},
keywords = {Application specific integrated circuits;Digital circuits;DSL;Linguistics;Machine design;Maintainability;Microprocessor chips;Modems;Problem oriented languages;Programmable logic controllers;VLSI circuits;},
note = {Code configuration;Code readability;Configurable;Design challenges;Development project;Domain specific languages;Hardware description languages;Hardware descriptions;Industry standards;Module design;Parameterized system;Preprocessors;Project efficiency;Reusable design;SOC integration;Threat management;Very large scale integrated;VLSI design;},
URL = {http://dx.doi.org/10.3785/j.issn.1008-973X.2010.06.005},
} 


@inproceedings{20094812518506 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for manipulation of binary data in dylan},
journal = {Proceedings of the 2007 International Lisp Conference, ILC '07},
author = {Mehnert, Hannes and Bogk, Andreas},
year = {2009},
pages = {Associaton of Lisp Users - },
address = {Cambridge, United kingdom},
abstract = {We present a domain specific language for manipulation of binary data, or structured byte sequences, as they appear in everyday applications such as networking or graphics file manipulation. Our DSL is implemented as an extension of the Dylan language, making use of the macro facility. Dylan macros, unlike Common Lisp macros, are implemented as pattern matches and substitutions on the parse tree, and we will show the strengths and limits of this approach for the given problem.},
key = {LISP (programming language)},
keywords = {Binary sequences;Linguistics;Problem oriented languages;Two term control systems;},
note = {Binary data;Domain specific languages;Graphics files;Parse trees;Pattern match;},
URL = {http://dx.doi.org/10.1145/1622123.1622148},
} 


@inproceedings{20085111784840 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for the model-driven construction of advanced web-based dialogs},
journal = {Proceeding of the 17th International Conference on World Wide Web 2008, WWW'08},
author = {Freudenstei, Patrick and Nussbaumer, Martin and Allerding, Florian and Gaedke, Martin},
year = {2008},
pages = {1069 - 1070},
address = {Beijing, China},
abstract = {Complex dialogs with comprehensive underlying data models are gaining increasing importance in today's Web applications. This in turn accelerates the need for highly dynamic dialogs offering guidance to the users and thus reducing cognitive overload. Beyond that, requirements from the fields of aesthetics, Web accessibility, platform-independence, and Web service integration arise. To this end, we present an evolutionary, extensible approach for the model-driven construction of advanced dialogs. It is based on a Domain-specific Language (DSL) focusing on simplicity and fostering collaboration with stakeholders.},
key = {World Wide Web},
keywords = {DSL;Internet;Linguistics;Modems;Systems analysis;Telecommunication lines;},
note = {Cognitive overloads;Data models;Do-mains;Specific languages;User interaction;Web accessibilities;WEB applications;Web engineering;Web service integrations;},
URL = {http://dx.doi.org/10.1145/1367497.1367660},
} 


@inproceedings{20091311992792 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language for the definition of extended queueing network models},
journal = {Proceedings of the IASTED International Conference on Software Engineering, SE 2008},
author = {Gianni, Daniele and D'Ambrogio, Andrea},
year = {2008},
pages = {118 - 124},
address = {Innsbruck, Austria},
abstract = {The use of design patterns and modular decomposition for the development of component-based software products brings significant improvements in terms of several quality attributes (e.g., reusability, reliability, maintainability). In addition, the modular design of interacting software components allows the foundation of a flexible Domain Specific Language (DSL) that acts as a model description language rather than a coding language, bringing significant savings in terms of development effort. This is particularly true in the field of simulation, in which the use of a common language both to represent and to simulate a given simulation model practically eliminates the need and the effort to fill the gap between the model specification and the simulator implementation. This paper introduces the design features of jEQN, a language for the specification and implementation of simulation models based on extended queueing networks. Details concerning the application of design patterns, modular decomposition and generic type parameters are also presented.},
key = {Computer simulation},
keywords = {Computer simulation languages;Computer software reusability;Design;DSL;Java programming language;Linguistics;Maintainability;Modems;Queueing networks;Reusability;Software engineering;Software reliability;Specifications;Spontaneous emission;Systems analysis;Telecommunication lines;},
note = {Coding languages;Common languages;Component-based softwares;Design features;Design patterns;Domain-specific languages;EQN;Generic types;Interacting softwares;Java;Model description languages;Model specifications;Model-driven design;Modular decompositions;Modular designs;Quality attributes;Queueing network models;Simulation;Simulation models;},
} 


@inproceedings{20095312586268 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language for UN/CEFACT's core components},
journal = {SERVICES 2009 - 5th 2009 World Congress on Services},
author = {Liegl, Philipp and Mayrhofer, Dieter},
number = {PART 2},
year = {2009},
pages = {123 - 131},
address = {Bangalore, India},
abstract = {In order to overcome the heterogeneities of different business document standards the United Nations Center for Trade Facilitation and Electronic Business (UN/CEFACT) has released the Core Components Technical Specification (CCTS). Core components are reusable building blocks for assembling business documents in an implementation neutral manner. However, core components are standardized without considering a specific implementation format and thus no tool integration is possible. Currently a syntax specific solution for core components, based on the Unified Modeling Language (UML), is provided with the UML Profile for Core Components (UPCC). In this paper we circumvent the complex UML meta model and provide a dedicated core component modeling environment based on a Domain Specific Language (DSL). Thereby, core component models are assembled on a conceptual level. In a next step the conceptual document model is used for the generation of domain specific artifacts. Our DSL based solution provides in situ validation of conceptual core component models and the flexible generation of deployment artifacts such as XML Schema definitions, used for the definition of interfaces in a service oriented environment. &copy; 2009 IEEE.},
key = {Unified Modeling Language},
keywords = {DSL;Electronic commerce;Linguistics;Markup languages;Modems;Telecommunication lines;},
note = {Building blockes;Business documents;Conceptual levels;Core components;Dedicated cores;Document model;Domain specific;Domain specific languages;Electronic business;In-situ;Meta model;Service-oriented environment;Technical specifications;Tool integration;Trade facilitation;UML profiles;UN/CEFACT;United Nations;Xml schema definitions;},
URL = {http://dx.doi.org/10.1109/SERVICES-2.2009.24},
} 


@inproceedings{20094812505516 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Measurement-Domain Specific Language for magnetic test specifications at CERN},
journal = {2009 IEEE Intrumentation and Measurement Technology Conference, I2MTC 2009},
author = {Arpaia, Pasquale and Buzio, Marco and Fiscarelli, Lucio and Inglese, Vitaliano and La Commara, Giuseppe and Walckiers, Louis},
year = {2009},
pages = {1716 - 1720},
address = {Singapore, Singapore},
abstract = {A Measurement-Domain Specific Language (MDSL) for test procedure definition, measurement tasks synchronization, and instrument configuration is proposed. MDSL is a formal language specially designed for a specific domain of measurement and test, aimed at specifying complete, easy-to-understand, -reuse, and -maintain applications efficiently and quickly. Owing to MDSL constructs capability of abstracting key concepts of the domain, the test engineer can write more concise and higher level programs in shorter time without being a skilled programmer. The MDSL has been applied to the specifications of superconducting magnet tests of the Large Hadron Collider at CERN. &copy; 2009 IEEE.},
key = {Magnetic domains},
keywords = {Automatic testing;Data compression;Elementary particles;Formal languages;Linguistics;Magnetic variables measurement;Measurement theory;Monitoring;Specifications;Superconducting magnets;},
note = {Automatic test equipment;Component;Component measurement;Domain specific languages;Large Hadron Collider;Test engineers;Test procedures;Test specifications;},
URL = {http://dx.doi.org/10.1109/IMTC.2009.5168733},
} 


@inproceedings{20091812056757 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for parallel and grid computing},
journal = {DSAL'08: Proceedings of the 2008 AOSD Workshop on Domain-specific Aspect Languages},
author = {Sobral, Joao L. and Monteiro, Miguel P.},
year = {2008},
address = {Brussels, Belgium},
abstract = {This paper overviews a Domain-Specific Language (DSL) for parallel and grid computing, layered on top of AspectJ. This DSL aims to bridge the gap between sequential code and parallel/grid applications, by avoiding invasive source code changes in scientific applications. Moreover, it aims to promote the localization of parallelization and gridification issues into well defined modules that can be (un)plugged (from)to existing scientific applications. This paper builds on previous work based on AspectJ and presents the main motivations for implementing a DSL in preference to a pure-AspectJ solution. The paper presents the DSL's design rationale, overviews current implementation and open research issues. &copy; 2008 ACM.},
key = {Grid computing},
keywords = {Applications;DSL;Linguistics;Modems;Parallel processing systems;Query languages;Telecommunication lines;},
note = {Aspect composition;Aspect-j;Design rationales;Domain-specific aspect languages;Domain-specific languages;Parallel computing;Parallelization;Research issues;Scientific applications;Source code changes;},
URL = {http://dx.doi.org/10.1145/1404927.1404929},
} 


@inproceedings{20095012546137 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for programming in the tile assembly model},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Doty, David and Patitz, Matthew J.},
volume = {5877 LNCS},
year = {2009},
pages = {25 - 34},
issn = {03029743},
address = {Fayetteville, AR, United states},
abstract = {We introduce a domain-specific language (DSL) for creating sets of tile types for simulations of the abstract Tile Assembly Model. The language defines objects known as tile templates, which represent related groups of tiles, and a small number of basic operations on tile templates that help to eliminate the error-prone drudgery of enumerating such tile types manually or with low-level constructs of general-purpose programming languages. The language is implemented as a class library in Python (a so-called internal DSL), but is presented independently of Python or object-oriented programming, with emphasis on support for a visual editing tool for creating large sets of complex tile types. &copy; 2009 Springer-Verlag.},
key = {Object oriented programming},
keywords = {Building materials;Calculations;Computer science;DNA;DSL;Fluorine containing polymers;Genes;Genetic programming;Linguistics;Modems;Nucleic acids;Problem oriented languages;Query languages;Simulators;Telecommunication lines;},
note = {Assembly model;Basic operation;Class libraries;Domain specific languages;Editing tools;Error prones;General-purpose programming language;},
URL = {http://dx.doi.org/10.1007/978-3-642-10604-0_3},
} 


@inproceedings{20100412663744 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language for the I* framework},
journal = {ICEIS 2009 - 11th International Conference on Enterprise Information Systems, Proceedings},
author = {Nunes, Carlos and Araujo, Joao and Amaral, Vasco and Silva, Carla},
volume = {DISI},
year = {2009},
pages = {158 - 163},
address = {Milan, Italy},
abstract = {The i* framework proposes a goal-oriented analysis method for requirements engineering. It is a systematic approach to discover and structure requirements at organizational level where functional, non-functional requirements and their relations are specified. A Domain Specific Language (DSL) has the purpose to specify and model concepts in some domain, having several advantages in relation to general purpose languages, such as it allows expressing a solution in the desired language and at the desired abstraction level. In order to create such a DSL, normally it is necessary to start by specifying its syntax by means of a metamodel to be given as input to the language workbenches that generate the corresponding editors for it. With a proper editor for the language we can specify models with the proposed notation. This paper presents a DSL for the i* framework, with the purpose to handle complexity and scalability of its concrete models by introducing some innovations in the i* framework metamodel like mechanisms that will help to manage the models scalability.},
key = {Query languages},
keywords = {DSL;Information systems;Linguistics;Modems;Scalability;Telecommunication lines;},
note = {Abstraction level;CASE tools;Concrete model;Domain specific languages;General purpose languages;Goal-oriented analysis;Language workbenches;Meta model;Metamodeling;Non-functional requirements;Organizational levels;Organizational modeling;},
} 


@inproceedings{20093512277596 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language for composable memory transactions in Java},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Du Bois, Andre Rauber and Echevarria, Marcos},
volume = {5658 LNCS},
year = {2009},
pages = {170 - 186},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {In this paper we present CMTJava, a domain specific language for composable memory transactions [7] in Java. CMTJava provides the abstraction of transactional objects. Transactional objects have their fields accessed only by special get and set methods that are automatically generated by the compiler. These methods return transactional actions as a result. A transactional action is an action that, when executed, will produce the desired effect. Transactional actions can only be executed by the atomic method. Transactional actions are first class values in Java and they are composable: transactions can be combined to generate new transactions. The Java type system guarantees that the fields of transactional objects will never be accessed outside a transaction. CMTJava supports the retry and orElse constructs from STM Haskell. To validate our design we implemented a simple transactional system following the description of the original Haskell system. CMTJava is implemented as a state passing monad using BBGA closures, a Java extension that supports closures in Java. &copy; IFIP International Federation for Information Processing 2009.},
key = {Java programming language},
keywords = {DSL;Linguistics;Modems;Query languages;Telecommunication lines;},
note = {Automatically generated;Domain specific languages;Haskell;Transactional systems;Type systems;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_9},
} 


@article{20093012205026 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Improving domain-specific language reuse with software product line techniques},
journal = {IEEE Software},
author = {White, Jules and Hill, James H. and Gray, Jeff and Tambe, Sumant and Gokhale, Aniruddha S. and Schmidt, Douglas C.},
volume = {26},
number = {4},
year = {2009},
pages = {47 - 53},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {Developing a domain-specific language (DSL) or a composition of DSLs to model a system concern, such as deploying and configuring software components to meet real-time scheduling constraints, is time consuming. Ideally, developers should be able to reuse DSLs and DSL compositions across projects to amortize development effort. Reusing DSLs is hard, however, because they're often designed to precisely describe a single domain or concern. A new approach uses techniques from software product lines (SPLs) to improve the reusability of a DSL, DSL composition, or supporting tool by providing traceability of language concepts to DSL design. A case study of four DSLs demonstrates the need for-and benefits of-applying SPL reuse techniques to DSLs. &copy; 2009 IEEE.},
key = {Computer software reusability},
keywords = {Chemical analysis;DSL;Graphical user interfaces;Interactive computer systems;Linguistics;Mining;Models;Modems;Network architecture;Probability density function;Query languages;Real time systems;Reusability;Software engineering;Telecommunication lines;Time domain analysis;},
note = {Adaptation model;Aerospace electronics;Domain analysis;Domain hierarchy;Domain-specific languages;Feature models;Reuse;Software;Software product lines;},
URL = {http://dx.doi.org/10.1109/MS.2009.95},
} 


@article{20085111792405 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for cryptographic protocols based on streams},
journal = {Journal of Logic and Algebraic Programming},
author = {Jurjens, Jan},
volume = {78},
number = {2},
year = {2009},
pages = {54 - 73},
issn = {15678326},
address = {360 Park Avenue South, New York, NY 10010, United States},
abstract = {Developing security-critical systems is difficult and there are many well-known examples of security weaknesses exploited in practice. Thus a sound methodology supporting secure systems development is urgently needed. In particular, an important missing link in the construction of secure systems is finding a practical way to create reliably secure crypto protocol implementations. We present an approach that aims to address this need by making use of a domain-specific language for crypto protocol implementations. One can use this language to construct a compact and precise yet executable representation of a cryptographic protocol. This high-level program can be verified against the security goals using automated theorem provers for first order logic. One can then use it to provide assurance for legacy implementations of crypto protocols by generating test-cases. &copy; 2008 Elsevier Inc. All rights reserved.},
key = {Computer networks},
keywords = {Computer hardware description languages;Cryptography;Internet protocols;Linguistics;},
note = {Automated theorem provers;Critical systems;Crypto protocols;Cryptographic protocols;Do-mains;First order logics;On streams;Secure systems;Security analysis;Security goals;Security weaknesses;Specific languages;},
URL = {http://dx.doi.org/10.1016/j.jlap.2008.08.006},
} 


@inproceedings{20091612034680 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for ubiquitous healthcare},
journal = {2008 3rd International Conference on Pervasive Computing and Applications, ICPCA08},
author = {Munnelly, Jennifer and Clarke, Siobhan},
volume = {2},
year = {2008},
pages = {757 - 762},
address = {Alexandria, Egypt},
abstract = {The development of ubiquitous healthcare applications has proved to be significantly more complex than traditional healthcare applications. In software engineering research, there are two approaches of interest to us for handling the kind of complexcity that emerges. The first is the use of domain-specific languages, which abstracts the low level domain knowledge required when using general-purpose programming languages into more expressive domain-specific constructs. The second is advanced modularity techniques, such as aspect-oriented programming, that provide for modularization of concerns that complicate code by cutting across a broad code base and tangling with other concerns. In this paper, we identify a set of ubiquitous healthcare concerns that complicate their software development. We use advanced modularity techniques to provide good separation of these concerns and encapsulate their behaviour within a new domain-specific language, ALPH that provides the application developer with a high level of abstraction. The result is a means to develop ubiquitous healthcare applications more easily and in a more timely fashion, while improving software quality by increasing modularity in the code.&copy; 2008 IEEE.},
key = {Query languages},
keywords = {Abstracting;Applications;Computer software selection and evaluation;Computers;Engineering research;Graphical user interfaces;Linguistics;Modular construction;Software engineering;},
note = {Application developers;Aspect-oriented programming;Domain knowledge;Domain specific languages;Domain specifics;General-purpose programming languages;Health care applications;High level of abstractions;Low levels;Modularization;Programming languages;Software development;Software engineering researches;Software qualities;Ubiquitous healthcare;},
URL = {http://dx.doi.org/10.1109/ICPCA.2008.4783710},
} 


@inproceedings{20104613396518 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Scrapping your inefficient engine: Using partial evaluation to improve domain-specific language implementation},
journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
author = {Brady, Edwin C. and Hammond, Kevin},
year = {2010},
pages = {297 - 308},
address = {Baltimore, MD, United states},
abstract = {Partial evaluation aims to improve the efficiency of a program by specialising it with respect to some known inputs. In this paper, we show that partial evaluation can be an effective and, unusually, easy to use technique for the efficient implementation of embedded domain-specific languages. We achieve this by exploiting dependent types and by following some simple rules in the definition of the interpreter for the domain-specific language. We present experimental evidence that partial evaluation of programs in domain-specific languages can yield efficient residual programs whose performance is competitive with their Java and C equivalents and which are also, through the use of dependent types, verifiably resource-safe. Using our technique, it follows that a verifiably correct and resource-safe program can also be an efficient program. &copy; 2010 ACM.},
key = {Java programming language},
keywords = {Computer software;Functional programming;Graphical user interfaces;Problem oriented languages;Query languages;},
note = {Dependent types;Domain specific languages;Efficient implementation;Embedded domains;Experimental evidence;Partial evaluation;Residual programs;Simple rules;},
URL = {http://dx.doi.org/10.1145/1863543.1863587},
} 


@inproceedings{20110613651877 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Scrapping your inefficient engine: Using partial evaluation to improve domain-specific language implementation},
journal = {ACM SIGPLAN Notices},
author = {Brady, Edwin C. and Hammond, Kevin},
volume = {45},
number = {9},
year = {2010},
pages = {297 - 308},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Partial evaluation aims to improve the efficiency of a program by specialising it with respect to some known inputs. In this paper, we show that partial evaluation can be an effective and, unusually, easy to use technique for the efficient implementation of embedded domain-specific languages. We achieve this by exploiting dependent types and by following some simple rules in the definition of the interpreter for the domain-specific language. We present experimental evidence that partial evaluation of programs in domain-specific languages can yield efficient residual programs whose performance is competitive with their Java and C equivalents and which are also, through the use of dependent types, verifiably resource-safe. Using our technique, it follows that a verifiably correct and resource-safe program can also be an efficient program. Copyright &copy; 2010 ACM.},
key = {Java programming language},
keywords = {Computer software;Graphical user interfaces;Problem oriented languages;Query languages;},
note = {Dependent types;Domain specific languages;Efficient implementation;Embedded domains;Experimental evidence;Partial evaluation;Residual programs;Simple rules;},
URL = {http://dx.doi.org/10.1145/1932681.1863587},
} 


@inproceedings{20094012360923 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a domain specific language for a goal-oriented approach based on KAOS},
journal = {Proceedings of the 2009 3rd International Conference on Research Challenges in Information Science, RCIS 2009},
author = {Dias, Ana and Amaral, Vasco and Araujo, Joao},
year = {2009},
pages = {409 - 420},
address = {Fez, Morocco},
abstract = {Requirements Engineering (RE) is the branch of Software Engineering dealing with requirements for software systems. A software requirement is a property which must be exhibited by software developed or adapted to solve a particular problem. Within RE, there are several branches of methodologies for obtaining requirements, among which we have Goal-Oriented Requirements Engineering (GORE), that uses goals to treat requirements. The visual complexity of standard GORE diagrams, when dealing with real cases, can get very high due to the high number of goals to be refined and detailed in the models. This can make them unreadable and difficult to manage and, as a consequence, the models can became harder to validate or update. As this problem has never been tackled before by the current existent tools, this paper proposes an extension to the KAOS language in order to incorporate the notion of Compartment, an encapsulation technique to keep concepts and with collapsing ability at user's request, with the main purpose of improving scalability of models. For the making of the tool it was used the Eclipse framework (with GMF/EMF plugins). We have chosen a specific GORE methodology named KAOS and based on it we designed a new Domain-Specific Language (DSL) by creating its extended metamodel. &copy; 2009 IEEE.},
key = {Requirements engineering},
keywords = {Computer software;Linguistics;},
note = {Domain specific languages;Goal-oriented approach;Goal-oriented requirements engineering;Meta model;Plug-ins;Software requirements;Software systems;Visual complexity;},
URL = {http://dx.doi.org/10.1109/RCIS.2009.5089305},
} 


@inproceedings{20091311984960 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Ronald: A domain-specific language to study the interactions between malaria infections and drug treatments},
journal = {Proceedings of the 2008 International Conference on Bioinformatics and Computational Biology, BIOCOMP 2008},
author = {Antao, T. and Hastings, I. and McBurney, P.},
year = {2008},
pages = {747 - 752},
address = {Las Vegas, NV, United states},
abstract = {Malaria kills more than 1 million people a year, mostly children in sub-Saharan Africa. Antimalarial drug resistance is one of the greatest challenges facing malaria control today. We present Ronald, a Domain-Specific Language to model the fundamental forces driving antimalarial drug resistance including drug pharmacokinetics and pharmacodynamics, drug regimens and parasite genotypes. Example of applications of this language include the study of the consequences of counterfeit or lower quality drugs, the implications of different dosage regimens, the impact of drug half life on the emerging and spread of resistance and the benefits and drawbacks of combination therapies, among many others.},
key = {Drug dosage},
keywords = {Bioinformatics;Drug interactions;Impact resistance;Linguistics;Malaria control;Query languages;},
note = {Antimalarial drugs;Combination therapies;Domain specific languages;Dosage regimens;Half lives;Infectious diseases;Malaria;Parasite-;Pharmacokinetics and pharmacodynamics;Pharmacology;Sub-Saharan Africa;},
} 


@inproceedings{20091412016859 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {WebDSL : A domain-specific language for dynamic web applications},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Groenewegen, Danny M. and Hemel, Zef and Kats, Lennart C.L. and Visser, Eelco},
year = {2008},
pages = {779 - 780},
address = {Nashville, TN, United states},
abstract = {WebDSL is a domain-specific language for the implementation of dynamic web applications with a rich data model. It consists of a core language with constructs to define entities, pages and business logic. Higher-level abstractions, modeling access control and workflow, are defined in a modular fashion as extensions of the core language.},
key = {Object oriented programming},
keywords = {Access control;Applications;Computer systems programming;Linguistics;Query languages;World Wide Web;},
note = {Business-logic;Data models;Domain-specific languages;Dynamic web applications;Higher-level abstractions;Languages;},
URL = {http://dx.doi.org/10.1145/1449814.1449858},
} 


@inproceedings{20095212581423 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {RASCAL: A domain specific language for source code analysis and manipulation},
journal = {9th IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2009},
author = {Klint, Paul and Van Der Storm, Tijs and Vinju, Jurgen},
year = {2009},
pages = {168 - 177},
address = {Edmonton, AB, Canada},
abstract = {Many automated software engineering tools require tight integration of techniques for source code analysis and manipulation. State-of-the-art tools exist for both, but the domains have remained notoriously separate because different computational paradigms fit each domain best. This impedance mismatch hampers the development of new solutions because the desired functionality and scalability can only be achieved by repeated and ad hoc integration of different techniques. RASCAL is a domain-specific language that takes away most of this boilerplate by integrating source code analysis and manipulation at the conceptual, syntactic, semantic and technical level. We give an overview of the language and assess its merits by implementing a complex refactoring. &copy; 2009 IEEE.},
key = {Linguistics},
keywords = {Integration;Problem oriented languages;Software engineering;},
note = {Computational paradigm;Domain specific languages;Impedance mismatch;New solutions;Refactorings;Software engineering tools;Source code analysis;Technical levels;},
URL = {http://dx.doi.org/10.1109/SCAM.2009.28},
} 


@inproceedings{20095212579613 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An interpretive domain specific language workbench},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Hen-Tov, Atzmon and Lorenz, David H. and Schachter, Lior},
year = {2009},
pages = {751 - 752},
address = {Orlando, FL, United states},
abstract = {Domain-specific language (DSL) utilization comes in three sorts: internal, external, and language workbench. An internal DSL is confined to the hosting language. An external DSL is freed from confinement in the hosting language, but surrenders all native tool support in return. A language workbench incorporates external DSLs into the development environment, thus bridging the tool-support gap that exists between external and internal DSLs. DSL workbenches hold the most promise for DSL based development. Yet they are also the least utilized. In this work, we present a concrete example of a language workbench. Our language workbench facilitates DSL based development in Java, where the DSLs are external to Java and yet enjoy Java-like automatic tool support.},
key = {Object oriented programming},
keywords = {Computer systems programming;DSL;Java programming language;Linguistics;Modems;Problem oriented languages;Query languages;Telecommunication lines;},
note = {Automatic tools;Development environment;Domain specific languages;Language workbenches;Tool support;},
URL = {http://dx.doi.org/10.1145/1639950.1639997},
} 


@article{20081411185588 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Implementing a Domain-Specific Language Using Stratego/XT: An Experience Paper},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Hamey, Leonard G.C. and Goldrei, Shirley N.},
volume = {203},
number = {2},
year = {2008},
pages = {37 - 51},
issn = {15710661},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {We describe the experience of implementing a Domain-Specific Language using transformation to a General Purpose Language. The domain of application is image processing and low-level computer vision. The transformation is accomplished using the Stratego/XT language transformation toolset. The implementation presented here is contrasted with the original implementation carried out many years ago using standard compiler implementation tools of the day. We highlight some of the unexpected advantages afforded to us, as language designers and implementers, by the source-to-source transformation technique. We also present some of the practical challenges faced in the implementation and show how these issues were addressed. &copy; 2008 Elsevier B.V. All rights reserved.},
key = {Formal languages},
keywords = {Computer programming languages;Computer vision;Program compilers;},
note = {Compiler implementation;Domain specific languages;Language definition;Language designers;},
URL = {http://dx.doi.org/10.1016/j.entcs.2008.03.043},
} 


@article{20094712485189 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Design of a Domain Specific Language for modelling processes in landscapes},
journal = {Ecological Modelling},
author = {Degenne, P. and Lo Seen, D. and Parigot, D. and Forax, R. and Tran, A. and Ait Lahcen, A. and Cure, O. and Jeansoulin, R.},
volume = {220},
number = {24},
year = {2009},
pages = {3527 - 3535},
issn = {03043800},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {The modelling of processes that occur in landscapes is often confronted to issues related to the representation of space and the difficulty of properly handling time and multiple scales. In order to investigate these issues, a flexible modelling environment is required. We propose to develop such a tool based on a Domain Specific Language (DSL) that capitalises on the service-oriented architecture (SOA) paradigm. The modelling framework around the DSL is composed of a model building environment, a code generator and compiler, and a program execution platform. The DSL introduces five language elements (entity, service, relation, scenario and datafacer) that can be combined to offer a wide range of possibilities for modelling in space and time at different scales. When developing a model, model parts are either built using the DSL or taken from libraries of previously built ones, and adapted to the specific model. The practical usage of the DSL is illustrated first with the Lotka-Volterra model, and then with a landscape modelling experiment on the spread of a mosquito-borne disease in the Sahelian region of West Africa. An interesting characteristic of this approach is the possibility of adding new elements into an existing model, and replacing others with more appropriate ones, thus allowing potentially complex models to be built from simpler parts. &copy; 2009 Elsevier B.V. All rights reserved.},
key = {Model buildings},
keywords = {DSL;Information services;Linguistics;Modems;Program compilers;Service oriented architecture (SOA);Telecommunication lines;Web services;},
note = {Code generators;Complex model;Different scale;Domain specific languages;Handling time;Language elements;Lotka-Volterra models;Modelling environment;Modelling framework;Modelling of process;Modelling process;Multi-scale;Multiple scale;Ocelet;Program execution;SOA;Space and time;Spatial and temporal modelling;West Africa;},
URL = {http://dx.doi.org/10.1016/j.ecolmodel.2009.06.018},
} 


@inproceedings{20104913448106 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {CSP as a domain-specific language embedded in python and jython},
journal = {Concurrent Systems Engineering Series},
author = {Mount, Sarah and Hammoudeh, Mohammad and Wilson, Sam and Newman, Robert},
volume = {67},
year = {2009},
pages = {293 - 309},
issn = {13837575},
address = {Nieuwe Hemweg 6B, Amsterdam, 1013 BG, Netherlands},
abstract = {Recently, much discussion has taken place within the Python programming community on how best to support concurrent programming. This paper describes a new Python library, python-csp, which implements synchronous, message-passing concurrency based on Hoare's Communicating Sequential Processes. Although other CSP libraries have been written for Python, python-csp has a number of novel features. The library is implemented both as an object hierarchy and as a domain-specific language, meaning that programmers can compose processes and guards using infix operators, similar to the original CSP syntax. The language design is intended to be idiomatic Python and is therefore quite different to other CSP libraries. python-csp targets the CPython interpreter and has variants which reify CSP process as Python threads and operating system processes. An equivalent library targets the Jython interpreter, where CSP processes are reified as Java threads. jython-csp also has Java wrappers which allow the library to be used from pure Java programs. We describe these aspects of python-csp, together with performance benchmarks and a formal analysis of channel synchronisation and choice, using the model checker SPIN. Copyright &copy; 2009 The authors and IOS Press.},
key = {Java programming language},
keywords = {Computer operating procedures;Computer operating systems;Computer programming;Graphical user interfaces;Libraries;Message passing;Model checking;Problem oriented languages;},
note = {Communicating sequential process;Concurrent programming;CSP;Domain specific languages;Dynamic languages;Formal analysis;Java program;Java thread;Language design;Message-passing concurrency;Model checker;Object hierarchy;Operating systems;Python;Python programming;Synchronisation;},
URL = {http://dx.doi.org/10.3233/978-1-60750-065-0-293},
} 


@inproceedings{20091311992999 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Semantics for a domain-specific language for the digital forensics domain},
journal = {CSIIRW'08 - 4th Annual Cyber Security and Information Intelligence Research Workshop: Developing Strategies to Meet the Cyber Security and Information Intelligence Challenges Ahead},
author = {Bradford, Phillip G. and Ray, Daniel A.},
year = {2008},
address = {Oak Ridge, TN, United states},
abstract = {This paper reviews details around the motivation for creating a domain-specific language that allows the easy design of software tools that support digital investigation. These tools will enable the specification of security requirements, support the activities of various investigations, certify security properties, and formulate security claims. Additionally, the main purpose of this paper is to introduce a proposed syntax for a language that is appropriate to the specific needs of the digital investigation domain. Copyright 200X ACM.},
key = {Query languages},
keywords = {Computer aided software engineering;Electronic crime countermeasures;Graphical user interfaces;Information theory;Linguistics;Software design;},
note = {Digital forensics;Digital investigations;Domain-specific languages;Security properties;Security requirements;Software tools;},
URL = {http://dx.doi.org/10.1145/1413140.1413153},
} 


@inproceedings{20101612856824 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Semi-supervised learning of domain-specific language models from general domain data},
journal = {2009 International Conference on Asian Language Processing: Recent Advances in Asian Language Processing, IALP 2009},
author = {Bai, Shuanhu and Zhang, Min and Li, Haizhou},
year = {2009},
pages = {273 - 279},
address = {Singapore, Singapore},
abstract = {We present a semi-supervised learning method for building domain-specific language models (LM) from general-domain data. This method is aimed to use small amount of domain-specific data as seeds to tap domain-specific resources residing in larger amount of general-domain data with the help of topic modeling technologies. The proposed algorithm first performs topic decomposition (TD) on the combined dataset of domain-specific and general-domain data using probabilistic latent semantic analysis (PLSA). Then it derives domain-specific word n-gram counts with mixture modeling scheme of PLSA. Finally, it uses traditional n-gram modeling approach to construct domain-specific LMs from the domain-specific word n-gram counts. Experimental results show that this approach can outperform both stat-of-the-art methods and the simulated supervised learning method with our data sets. In particular, the semi-supervised learning method can achieve better performance even with very small amount of domain-specific data. &copy; 2009 IEEE.},
key = {Supervised learning},
keywords = {Algorithms;Computational linguistics;Problem oriented languages;},
note = {Data sets;Domain specific;Domain specific languages;Mixture modeling;Modeling technology;N-gram modeling;Probabilistic latent semantic analysis;Semi-supervised learning;Semi-supervised learning methods;Supervised learning methods;},
URL = {http://dx.doi.org/10.1109/IALP.2009.65},
} 


@inproceedings{20101712889811 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A design flow based on a domain specific language to concurrent development of device drivers and device controller simulation models},
journal = {ACM International Conference Proceeding Series},
author = {Lisboa, Edson and Silva, Luciano and Chaves, Igino and Lima, Thiago and Barros, Edna},
volume = {320},
year = {2009},
pages = {53 - 60},
address = {Nice, France},
abstract = {Nowadays, embedded Systems must communicate with different peripheral devices. The communication structure is implemented by a combined solution of hardware and software. The device controller is the hardware that implements, in general, complex communication protocols. On the other hand, the device driver provides transparent access to the functionalities of the device and depends on the architecture of the device controller. So, the design of the communication structure demands great effort, considerable development time and is very susceptible to errors. To minimize these issues, this paper presents an approach to the concurrent development of device controller simulation models and of the respective device drivers. Also a domain specific language, called DevC, is proposed to describe device controller features in a high level of abstraction. In this paper a brief introduction to this language is presented. From the specifications described in DevC, controller models and device drivers are synthesized. Both the device controller and the driver are first validated using a hardware virtual platform to reduce simulation time, and then they are validated on real hardware. Some controllers, such as a serial, as well as a text and graphic lcd, have been developed to validate the approach proposed. &copy; 2009 by EDAA.},
key = {Embedded systems},
keywords = {Communication;Concurrency control;Controllers;Embedded software;Linguistics;Program compilers;Technical presentations;},
note = {Combined solution;Communication protocols;Communication structures;Concurrent development;Controller models;Design flows;Development time;Device controller;Device Driver;Domain specific languages;Hardware and software;High level of abstraction;Peripheral devices;Simulation model;Simulation time;Transparent access;Virtual platform;},
} 


@article{20092912192399 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Experience report: Playing the DSL card a domain specific language for component configuration},
journal = {ACM SIGPLAN Notices},
author = {Jones, Mark P.},
volume = {43},
number = {9},
year = {2008},
pages = {87 - 90},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {This paper describes our experience using a functional language, Haskell, to build an embedded, domain-specific language (DSL) for component configuration in large-scale, real-time, embedded systems. Prior to the introduction of the DSL, engineers would describe the steps needed to configure a particular system in a handwritten XML document. In this paper, we outline the application domain, give a brief overview of the DSL that we developed, and provide concrete data to demonstrate its effectiveness. In particular, we show that the DSL has several significant benefits over the original, XML-based approach including reduced code size, increased modularity and scalability, and detection and prevention of common defects. For example, using the DSL, we were able to produce clear and intuitive descriptions of component configurations that were sometimes less than 1/30 of the size of the original XML. Copyright &copy; 2008 ACM.},
key = {DSL},
keywords = {Embedded systems;Functional programming;Graphical user interfaces;Linguistics;Logging (forestry);Markup languages;Modems;Query languages;Real time systems;Telecommunication lines;Timber;XML;},
note = {Application domains;Component configuration;Component configurations;Domain-specific languages;Experience report;Functional languages;Haskell;Reduced code;},
} 


@inproceedings{20090611900844 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Experience report: Playing the DSL card - A domain specific language for component configuration},
journal = {Proceedings of the ACM SIGPLAN International Conference on Functional Programming, ICFP},
author = {Jones, Mark P.},
year = {2008},
pages = {87 - 90},
address = {Victoria, BC, Canada},
abstract = {This paper describes our experience using a functional language, Haskell, to build an embedded, domain-specific language (DSL) for component configuration in large-scale, real-time, embedded systems. Prior to the introduction of the DSL, engineers would describe the steps needed to configure a particular system in a hand-written XML document. In this paper, we outline the application domain, give a brief overview of the DSL that we developed, and provide concrete data to demonstrate its effectiveness. In particular, we show that the DSL has several significant benefits over the original, XML-based approach including reduced code size, increased modularity and scalability, and detection and prevention of common defects. For example, using the DSL, we were able to produce clear and intuitive descriptions of component configurations that were sometimes less than 1/30 of the size of the original XML. Copyright &copy; 2008 ACM.},
key = {Functional programming},
keywords = {Computer programming;DSL;Embedded systems;Graphical user interfaces;Integrated circuits;Linguistics;Logging (forestry);Markup languages;Modems;Programming theory;Query languages;Real time systems;Telecommunication lines;Timber;XML;},
note = {Application domains;Component configuration;Domain-specific languages;Experience reports;Functional languages;Haskell;Reduced codes;},
URL = {http://dx.doi.org/10.1145/1411204.1411219},
} 


@article{20064310194549 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A Domain-Specific Language for Generating Dataflow Analyzers},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Zeng, Jia and Mitchell, Chuck and Edwards, Stephen A.},
volume = {164},
number = {2 SPEC. ISS.},
year = {2006},
pages = {103 - 119},
issn = {15710661},
abstract = {Dataflow analysis is a well-understood and very powerful technique for analyzing programs as part of the compilation process. Virtually all compilers use some sort of dataflow analysis as part of their optimization phase. However, despite being well-understood theoretically, such analyses are often difficult to code, making it difficult to quickly experiment with variants. To address this, we developed a domain-specific language, Analyzer Generator (AG), that synthesizes dataflow analysis phases for Microsoft's Phoenix compiler framework. AG hides the fussy details needed to make analyses modular, yet generates code that is as efficient as the hand-coded equivalent. One key construct we introduce allows IR object classes to be extended without recompiling. Experimental results on three analyses show that AG code can be one-tenth the size of the equivalent handwritten C++ code with no loss of performance. It is our hope that AG will make developing new dataflow analyses much easier. &copy; 2006 Elsevier B.V. All rights reserved.},
key = {Data flow analysis},
keywords = {Codes (symbols);Computer program listings;Computer simulation;Optimization;Program compilers;},
note = {Analyzer Generator (AG);Domain-specific languages;Dynamic class extension;Phoenix compiler framework;},
URL = {http://dx.doi.org/10.1016/j.entcs.2006.10.008},
} 


@inproceedings{20094812508225 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic generation of FPGA hardware accelerators using a domain specific language},
journal = {FPL 09: 19th International Conference on Field Programmable Logic and Applications},
author = {Menotti, Ricardo and Cardoso, Joao M. P. and Fernandes, Marcio M. and Marques, Eduardo},
year = {2009},
pages = {457 - 461},
address = {Prague, Czech republic},
abstract = {This paper describes an alternative approach to direct mapping loops described in high-level languages onto FPGAs. Different from other approaches, this technique does not inherit from software pipelining techniques. The control is distributed over operations, thus a finite state machine is not necessary to control the order of operations, allowing efficient hardware implementations. The specification of a hardware block is done by means of LALP, a domain specific language specially designed to help the application of the techniques. While the language syntax resembles C, it contains certain constructs that allow programmer interventions to enforce or relax data dependences as needed, and so optimize the performance of the generated hardware blocks. &copy;2009 IEEE.},
key = {High level languages},
keywords = {Field programmable gate arrays (FPGA);Hardware;Linguistics;Query languages;},
note = {Alternative approach;Automatic Generation;Data dependence;Direct mapping;Domain specific languages;Finite state machines;Hardware accelerators;Hardware blocks;Hardware implementations;Language syntax;Software pipelining;},
URL = {http://dx.doi.org/10.1109/FPL.2009.5272485},
} 


@inproceedings{20083111416933 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language for securing distributed systems},
journal = {Second International Conference on Systems and Networks Communications, ICSNC 2007},
author = {Hamdi, Hedi and Mosbah, Mohamed and Bouhoula, Adel},
year = {2007},
address = {Cap Esterel, France},
abstract = {Distributed applications are becoming increasingly common. However, incorporating security in them remains a major challenge. There are currently few choices to express and enforce security in distributed systems. We can either use a special-purpose language which may be too limited to express security requirements, or use a general purpose language that provides the ability to make complicated security policy but makes us reimplement infrastructure code for authorization, interdiction, obligation and so on with each new security policy. In this paper, we introduce a domain-specific language approach that takes the middle road, giving a way to reuse security infrastructure for new policies while also allowing the expression of complicated security policy easily. We present our DSL approach and and apply it to a real-world scenario: specification and implementation of security policy.<sup>1</sup> &copy; 2007 IEEE.},
key = {Linguistics},
keywords = {Security systems;},
note = {Distributed applications;Distributed systems;Do-mains;Domain specifics;General purpose languages;Infra structures;Security infrastructures;Security policies;Security requirements;Specific languages;},
URL = {http://dx.doi.org/10.1109/ICSNC.2007.2},
} 


@inproceedings{20082811354928 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for model coupling},
journal = {Proceedings - Winter Simulation Conference},
author = {Bulatewicz, Tom and Cuny, Janice},
year = {2006},
pages = {1091 - 1100},
issn = {08917736},
address = {Monterey, CA, United states},
abstract = {There is an increasing need for the comprehensive simulation of complex, dynamic, physical systems. Often such simulations are built by coupling existing, component models so that their concurrent simulations affect each other. The process of model coupling is, however, a non-trivial task that is not adequately supported by existing frameworks. To provide better support, we have developed an approach to model coupling that uses high level model interfaces called Potential Coupling Interfaces. In this work, we present a visual, domain-specific language for model coupling, called the Coupling Description Language, based on these interfaces. We show that it supports the resolution of model incompatibilities and allows for the fast-prototyping of coupled models. &copy; 2006 IEEE.},
URL = {http://dx.doi.org/10.1109/WSC.2006.323199},
} 


@inproceedings{20083111417543 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language and methodology for control systems GUI specification, verification and prototyping},
journal = {Proceedings - IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC 2007},
author = {Risoldi, Matteo and Buchs, Didier},
year = {2007},
pages = {179 - 182},
address = {Coeur d'Alene, ID, United states},
abstract = {A work-in-progress domain-specific language and methodology for modeling complex control systems GUIs is presented. MDA techniques are applied for language design and verification, simulation and prototyping. &copy; 2007 IEEE.},
key = {Control systems},
keywords = {Graphical user interfaces;Linguistics;Query languages;},
note = {And verifications;Complex control systems;Do-mains;Domain specifics;Language designs;Prototyping;Specific languages;},
URL = {http://dx.doi.org/10.1109/VLHCC.2007.2},
} 


@article{20095112562528 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Implementation of an Orchestration Language as a Haskell Domain Specific Language},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Campos, Marco Devesas and Barbosa, L.S.},
volume = {255},
year = {2009},
pages = {45 - 64},
issn = {15710661},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Even though concurrent programming has been a hot topic of discussion in Computer Science for the past 30 years, the community has yet to settle on a, or a few standard approaches to implement concurrent programs. But as more and more cores inhabit our CPUs and more and more services are made available on the web the problem of coordinating different tasks becomes increasingly relevant. The present paper addresses this problem with an implementation of the orchestration language Orc as a domain specific language in Haskell. Orc was, therefore, realized as a combinator library using the lightweight threads and the communication and synchronization primitives of the Concurrent Haskell library. With this implementation it becomes possible to create orchestrations that re-use existing Haskell code and, conversely, re-use orchestrations inside other Haskell programs. The complexity inherent to distributed computation, entails the need for the classification of efficient, reusable, concurrent programming patterns. The paper discusses how the calculus of recursive schemes used in the derivation of functional programs, scales up to a distributed setting. It is shown, in particular, how to parallelize the entire class of binary tree hylomorphisms. &copy; 2009 Elsevier B.V. All rights reserved.},
key = {Query languages},
keywords = {Binary trees;Computational efficiency;Computer software reusability;Concurrency control;Linguistics;Parallel algorithms;Parallel programming;Program processors;},
note = {Combinator library;Concurrent Haskell;Concurrent program;Concurrent programming;Coordination language;Distributed computations;Divide-and-conquer algorithm;Domain specific languages;Functional programs;Haskell;Haskell programs;Recursive scheme;Synchronization primitive;},
URL = {http://dx.doi.org/10.1016/j.entcs.2009.10.024},
} 


@inproceedings{20073110738977 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MDL, A domain-specific language for molecular dynamics},
journal = {Proceedings - Simulation Symposium},
author = {Cickovski, Trevor and Sweet, Chris and Izaguirre, Jesus A.},
year = {2007},
pages = {256 - 264},
issn = {1080241X},
address = {Norfolk, VA, United states},
abstract = {Molecular Dynamics (MD) involves solving Newton's equations of motion for a molecular system and propagating the system by time-dependent updates of atomic positions and velocities. As a severe limitation of molecular dynamics is the size of the timestep used for propagation, a key area of research is the development of efficient propagation algorithms which can maintain accuracy and stability with larger timesteps. We present MDL, an MD domain-specific language with the goals of allowing prototyping, testing and debugging of these algorithms. We illustrate the use of parallelism within MDL to implement the Finite Temperature String Method, and interfacing to visualization and graphical tools. &copy; 2007 IEEE.},
key = {Molecular dynamics},
keywords = {Algorithms;Computer programming languages;Equations of motion;Program debugging;Software prototyping;Velocity measurement;},
note = {Atomic positions;Molecular systems;Propagation algorithms;Time dependence;},
URL = {http://dx.doi.org/10.1109/ANSS.2007.26},
} 


@inproceedings{20092912196033 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Extracting a domain specific language from an example a bottom-up method using the ngrease metalanguage},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Oikarinen, Ville T},
year = {2007},
pages = {850 - 851},
address = {Montreal, QC, Canada},
abstract = {This demonstration shows a lightweight and fast method for a tested and working domain specific language. The is demonstrated using the ngrease metalanguage. creation of a new language is started by writing a example of the final product with a test that the transformation from a stub source to the result. test is made to pass by writing a constant transformer unconditionally outputs the result. each step the language is extended by refactoring: part of the transformer template is converted from a subtree to a reference to data read from the source, thus driving additions to the new language., each refactoring step can be driven by a new that demonstrates the lack of parameterization of some of the final product.},
key = {Object oriented programming},
keywords = {Electric transformer testing;Linguistics;Network components;},
note = {Bottom up methods;Code generation;Domain specific languages;DSL8method;Fast methods;Metaprogramming;Refactoring;Subtree;},
} 


@article{2005159041297 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An embedded domain-specific language for type-safe server-side web scripting},
journal = {ACM Transactions on Internet Technology},
author = {Thiemann, Peter},
volume = {5},
number = {1},
year = {2005},
pages = {1 - 46},
issn = {15335399},
abstract = {WASH/CGI is an embedded domain-specific language for server-side Web scripting. Due to its reliance on the strongly typed, purely functional programming language Haskell as a host language, it is highly flexible and - at the same time - it provides extensive guarantees due to its pervasive use of type information. WASH/CGI can be structured into a number of sublanguages addressing different aspects of the application. The document sublanguage provides tools for the generation of parameterized XHTML documents and forms. Its typing guarantees that almost all generated documents are valid XHTML documents. The session sublanguage provides a session abstraction with a transparent notion of session state and allows the composition of documents and Web forms to entire interactive scripts. Both are integrated with the widget sublanguage which describes the communication (parameter passing) between client and server. It imposes a simple type discipline on the parameters that guarantees that forms posted by the client are always understood by the server. That is, the server never asks for data not submitted by the client and the data submitted by the client has the type requested by the server. In addition, parameters are received in their typed internal representation, not as strings. Finally, the persistence sublanguage deals with managing shared state on the server side as well as individual state on the client side. It presents shared state as an abstract data type, where the script can control whether it wants to observe mutations due to concurrently executing scripts. It guarantees that states from different interaction threads cannot be confused. &copy; 2005 ACM.},
key = {Computer programming languages},
keywords = {Computer programming;Data reduction;Embedded systems;Interactive computer systems;Servers;World Wide Web;},
note = {Domain-specific languages;Interactive Web services;Web forms;Web programming;},
URL = {http://dx.doi.org/10.1145/1052934.1052935},
} 


@inproceedings{20073110742078 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {YABS: A domain-specific language for pervasive computing based on stigmergy},
journal = {Proceedings of the 5th International Conference on Generative Programming and Component Engineering, GPCE'06},
author = {Barron, Peter and Cahill, Vinny},
year = {2006},
pages = {285 - 294},
address = {Portland, OR, United states},
abstract = {This paper presents YABS, a novel domain-specific language for defining entity behavior in pervasive computing environments. The programming model of YABS is inspired by nature and, in particular, the observations made by the French biologist Grasse&acute; on how social insects coordinate their actions using indirect communication via the environment, a phenomenon that has become known as stigmergy. Following this approach yields a simple yet expressive language that abstracts the complexities of dealing with the variety of underlying technologies typical of pervasive computing environments and that facilitates the incremental construction and improvement of solutions while providing high-level constructs for defining the behavior of entities and their coordination. We show how YABS has been used to program a number of pervasive computing applications both deployed and simulated. Copyright &copy; 2006 ACM.},
key = {Ubiquitous computing},
keywords = {Computer simulation;Domain decomposition methods;Formal languages;Mathematical models;Problem solving;},
note = {Domain-specific languages;High-level constructs;Programming models;},
URL = {http://dx.doi.org/10.1145/1173706.1173730},
} 


@inproceedings{20072010600793 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Evolving an embedded domain-specific language in Java},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Freeman, Steve and Pryce, Nat},
volume = {2006},
year = {2006},
pages = {855 - 865},
address = {Portland, OR, United states},
abstract = {This paper describes the experience of evolving a domain-specific language embedded in Java over several generations of a test framework. We describe how the framework changed from a library of classes to an embedded language. We describe the lessons we have learned from this experience for framework developers and language designers.},
key = {Object oriented programming},
keywords = {Digital libraries;Embedded systems;Java programming language;Software design;},
note = {Embedded domain specific languages;Embedded languages;Mock objects;},
URL = {http://dx.doi.org/10.1145/1176617.1176735},
} 


@inproceedings{20094012347175 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The expert system approach in development of loosely coupled software with use of domain specific language},
journal = {Proceedings of the International Multiconference on Computer Science and Information Technology, IMCSIT 2008},
author = {Grobelny, Piotr},
volume = {3},
year = {2008},
pages = {119 - 123},
address = {Wisla, Poland},
abstract = {This paper addresses the problem of supporting the software development process through the artificial intelligence. The expert systems could advise the domain engineer in programming without the detailed experience in programming languages. He will use and integrate, with the help of deductive database and domain knowledge, the previously developed software components to new complex functionalities. The Service Oriented Architecture (SOA) and loosely coupled software allow to fulfill these requirements. The objective of this document is to provide the knowledge representation of atomic Web Services which will be registered as the facts in the deductive database as well as the inferring techniques. Also, the use of Domain Specific Language (DSL) for modeling domain engineer's requests to the expert system will be considered within this document. &copy; 2008 IEEE.},
key = {Computer software},
keywords = {Artificial intelligence;Computer science;Expert systems;Helium;Information services;Information technology;Knowledge representation;Linguistics;Object oriented programming;Query languages;Service oriented architecture (SOA);Software architecture;},
note = {Deductive database;Domain knowledge;Domain specific languages;Programming language;Software component;Software development process;},
URL = {http://dx.doi.org/10.1109/IMCSIT.2008.4747227},
} 


@article{20092912192247 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {WebRB: Evaluating a visual domain-specific language for building relational web-applications},
journal = {ACM SIGPLAN Notices},
author = {Leff, Avraham and Rayfield, James T.},
volume = {42},
number = {10},
year = {2007},
pages = {281 - 300},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Many web-applications can be characterized as "relational". In this paper we introduce and evaluate WebRB, avisual domain-specific language for building such applications. WebRB addresses the limitations of the conventional "imperative-embedding" approach typically used to build relational web-applications. We describe the WebRB language, present extended examples of its use, and discuss the WebRB visual editor, libraries, and runtime. We then evaluate WebRB by comparing it to alternative approaches, and demonstrate its effectiveness in building relational web-applications. Copyright &copy; 2007 ACM.},
key = {Linguistics},
keywords = {Computer programming;Computer software;Query languages;Visualization;},
note = {Data-flow languagesR;Relational web-applications;Visual programming languages;Web relational blocks;Web-application development;Webrb;},
} 


@inproceedings{20092912187321 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {WebRB: Evaluating a visual domain-specific language for building relational web-applications},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Leff, Avraham and Rayfield, James T.},
year = {2007},
pages = {281 - 300},
address = {Montreal, QC, Canada},
abstract = {Many web-applications can be characterized as "relational". In this paper we introduce and evaluate WebRB, a visual domain-specific language for building such applications. WebRB addresses the limitations of the conventional "imperative-embedding" approach typically used to build relational web-applications. We describe the WebRB language, present extended examples of its use, and discuss the WebRB visual editor, libraries, and runtime. We then evaluate WebRB by comparing it to alternative approaches, and demonstrate its effectiveness in building relational webapplications. Copyright&copy; 2007 ACM.},
key = {Object oriented programming},
keywords = {Computer software;Computer systems programming;Linguistics;Query languages;Visualization;},
note = {Data-flow languagesR;Relational webapplications;Visual programming languages;Web relational blocks;Web-application development;webrb;},
} 


@article{20073910835746 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The design and implementation of a domain-specific language for network performance testing},
journal = {IEEE Transactions on Parallel and Distributed Systems},
author = {Pakin, Scott},
volume = {18},
number = {10},
year = {2007},
pages = {1436 - 1449},
issn = {10459219},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {CONCEPTUAL is a toolset designed specifically to help measure the performance of high-speed interconnection networks such as those used in workstation clusters and parallel computers. It centers around a high-level, domain-specific language which makes it easy for a programmer to express, measure, and report the performance of complex communication patterns. The primary challenge in implementing a compiler for such a language is that the generated code must be extremely efficient so as not to misattribute overhead costs to the messaging library. At the same time, the language itself must not sacrifice expressiveness for compiler efficiency or there would be little point in using a high-level language for performance testing.This paper describes the CONCEPTUAL language and the CONCEPTUAL compiler's novel code-generation framework. The language provides primitives for a wide variety of idioms needed for performance testing and emphasizes a readable syntax. The core code-generation technique, based on unrolling CONCEPTUAL programs into sequences of communication events, is simple yet enables the efficient implementation of a variety of high-level constructs. The paper further explains how CONCEPTUAL implements time-bounded loops - even those which comprise blocking communication - in the absence of a timeout mechanism as this is a somewhat unique language/implementation feature. &copy; 2007 IEEE.},
key = {Computer networks},
keywords = {Data communication systems;High level languages;Interconnection networks;Parallel processing systems;Program compilers;},
note = {CONCEPTUAL language;High-speed interconnection network;Interprocessor communications;},
URL = {http://dx.doi.org/10.1109/TPDS.2007.1065},
} 


@article{1999504871262 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific language for regular sets of strings and trees},
journal = {IEEE Transactions on Software Engineering},
author = {Klarlund, Nils and Schwartzbach, Michael I.},
volume = {25},
number = {3},
year = {1999},
pages = {378 - 386},
issn = {00985589},
abstract = {We propose a new high-level programming notation, called FIDO, that we have designed to concisely express regular sets of strings or trees. In particular, it can be viewed as a domain-specific language for the expression of finite-state automata on large alphabets (of sometimes astronomical size). FIDO is based on a combination of mathematical logic and programming language concepts. This combination shares no similarities with usual logic programming languages. FIDO compiles into finite-state string or tree automata, so there is no concept of run-time. It has already been applied to a variety of problems of considerable complexity and practical interest. In the present paper, we motivate the need for a language like FIDO, and discuss our design and its implementation. Also, we briefly discuss design criteria for domain-specific languages that we have learned from the work with FIDO. We show how recursive data types, unification, implicit coercions, and subtyping can be merged with a variation of predicate logic, called the Monadic Second-order Logic (M2L) on trees. FIDO is translated first into pure M2L via suitable encodings, and finally into finite-state automata through the MONA tool.},
key = {Software engineering},
keywords = {Computational complexity;Computer systems programming;Finite automata;Formal logic;High level languages;Response time (computer systems);Trees (mathematics);},
note = {Domain specific languages (DSL);Software package FIDO;},
URL = {http://dx.doi.org/10.1109/32.798326},
} 


@article{1999504871259 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Mawl: A domain-specific language for form-based services},
journal = {IEEE Transactions on Software Engineering},
author = {Atkins, David L. and Ball, Thomas},
volume = {25},
number = {3},
year = {1999},
pages = {334 - 346},
issn = {00985589},
abstract = {A form-based service is one in which the flow of data between service and user is described by a sequence of query/response interactions, or forms. Mawl is a domain-specific language for programming form-based services in a device-independent manner. We focus on Mawl's form abstraction, which is the means for separating service logic from user interface description, and show how this simple abstraction addresses seven issues in service creation, analysis, and maintenance: compile-time guarantees, implementation flexibility, rapid prototyping, testing and validation, support for multiple devices, composition of services, and usage analysis.},
key = {Software engineering},
keywords = {Computer programming languages;Computer systems programming;HTML;Information services;Query languages;User interfaces;World Wide Web;},
note = {Form-based services;},
URL = {http://dx.doi.org/10.1109/32.798323},
} 


@article{2001105497907 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {WebCaL - a domain specific language for web caching},
journal = {Computer Communications},
author = {Gulwani, S. and Tarachandani, A. and Gupta, D. and Sanghi, D. and Barreto, L.P. and Muller, G. and Consel, C. and Compose Group},
volume = {24},
number = {2},
year = {2001},
pages = {191 - 201},
issn = {01403664},
address = {Amsterdam, Netherlands},
abstract = {Web caching aims to improve the performance of the Internet in three ways - by improving client latency, alleviating network traffic and reducing server load. A web cache is basically a limited store of information which helps in presenting a faster web-access environment to the clients. The performance of a cache depends on proper management of this information and effective inter-cache communication. The existing web caches have simple and hard-coded policies which are not best suited for all environments. They offer limited flexibility just in the form of changing some simple parameters such as cache size, peer caches, etc. This drawback motivates the need for a framework for building new web caches tailored to specific environments. In this paper, we describe a domain specific language based on an event-action model using which new local web cache policies and inter-cache protocols can be easily specified. This should make it possible to write a new policy or protocol quickly, evaluate its performance and test it thoroughly using the complete program-execute-debug cycle.},
key = {World Wide Web},
keywords = {Buffer storage;Client server computer systems;Computer hardware description languages;Computer systems programming;Congestion control (communication);Data communication systems;Response time (computer systems);Storage allocation (computer);Telecommunication traffic;},
note = {Domain specific languages;},
URL = {http://dx.doi.org/10.1016/S0140-3664(00)00314-5},
} 


@article{2002226962446 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Panoptis: Intrusion detection using a domain-specific language},
journal = {Journal of Computer Security},
author = {Spinellis, Diomidis and Gritzalis, Dimitris},
volume = {10},
number = {1-2},
year = {2002},
pages = {159 - 176},
issn = {0926227X},
abstract = {We describe the use of a domain-specific language (DSL) for expressing critical design values and constraints in an intrusion detection application. Through the use of this specialised language, information that is critical to the correct operation of the software can be expressed in a form that can be easily drafted, verified, and maintained by domain experts (security officers), thus minimising the risk inherent from the mediation of software engineers. Our application, Panoptis, is a DSL-based low-cost, easy-to-use intrusion detection system using the process accounting records kept by most Unix systems. A set of database tables contain resource usage profiles for processes, terminals, users, and time intervals. Panoptis monitors new process data against the recorded profiles and reports on entities diverging from the established resource usage envelopes implying possible data security threats. We demonstrate the operation of Panoptis by a case study of a real attack and subsequent system compromise that occured on a system under our administrative control.},
key = {Computer programming languages},
keywords = {Computer crime;Computer software;Database systems;Security of data;Software engineering;UNIX;},
note = {Domain-specific languages (DSL);Intrusion detection systems (IDS);},
} 


@article{1977110005817 ,
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {STRUCTURED DEBUGGING USING A DOMAIN SPECIFIC LANGUAGE.},
journal = {Software - Practice and Experience},
author = {Leavenworth, B.M.},
volume = {7},
number = {4},
year = {1977},
pages = {475 - 482},
issn = {00380644},
abstract = {A structured approach to debugging is presented based on restricting the class of programs that can be written. This is achieved by defining a domain specific language, eliminating control flow by using aggregate operations and eliminating side effects by using an applicative language as a base. The debugging strategy consists of setting up a sequence of input/output transformations; this process takes the input to the output in partial stages so that the correctness of each transformation relative to its input and output set can be verified. The approach is illustrated by a simple data processing problem.},
key = {COMPUTER PROGRAMMING LANGUAGES},
keywords = {COMPUTER PROGRAMMING;},
} 


@article{20110813689428 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific language integration with compile-time parser generator library},
journal = {ACM SIGPLAN Notices},
author = {Porkolab, Zoltan and Sinkovics, Abel},
volume = {46},
number = {2},
year = {2011},
pages = {137 - 146},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Smooth integration of domain-specific languages into a general purpose host language requires absorbing of domain code written in arbitrary syntax. The integration should cause minimal syntactical and semantic overhead and introduce minimal dependency on external tools. In this paper we discuss a DSL integration technique for the C++ programming language. The solution is based on compile-time parsing of the DSL code. The parser generator is a C++ template metaprogram reimplementation of a runtime Haskell parser generator library. The full parsing phase is executed when the host program is compiled. The library uses only standard C++ language features, thus our solution is highly portable. As a demonstration of the power of this approach, we present a highly efficient and type-safe version of printf and the way it can be constructed using our library. Despite the well known syntactical difficulties of C++ template metaprograms, building embedded languages using our library leads to self-documenting C++ source code. Copyright &copy; 2010 ACM.},
key = {Integration},
keywords = {Computer aided software engineering;Graphical user interfaces;Problem oriented languages;Semantics;},
note = {C++ language;C++ templates;Compile time;Domain specific languages;Embedded Languages;External tools;General purpose;Haskell;Highly-portable;Integration techniques;Library use;Metaprograms;Parser generator;Parser generators;Runtimes;Source codes;},
URL = {http://dx.doi.org/10.1145/1942788.1868315},
} 


@article{20110813689422 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modular domain-specific language components in scala},
journal = {ACM SIGPLAN Notices},
author = {Hofer, Christian and Ostermann, Klaus},
volume = {46},
number = {2},
year = {2011},
pages = {83 - 92},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Programs in domain-specific embedded languages (DSELs) can be represented in the host language in different ways, for instance implicitly as libraries, or explicitly in the form of abstract syntax trees. Each of these representations has its own strengths and weaknesses. The implicit approach has good composability properties, whereas the explicit approach allows more freedom in making syntactic program transformations. Traditional designs for DSELs fix the form of representation, which means that it is not possible to choose the best representation for a particular interpretation or transformation. We propose a new design for implementing DSELs in Scala which makes it easy to use different program representations at the same time. It enables the DSL implementor to define modular language components and to compose transformations and interpretations for them. Copyright &copy; 2010 ACM.},
key = {XML},
keywords = {Graphical user interfaces;Problem oriented languages;Syntactics;Trees (mathematics);},
note = {Domain specific languages;Embedded Languages;Scala;Term Representation;Visitor patterns;},
URL = {http://dx.doi.org/10.1145/1942788.1868307},
} 


@inproceedings{20104413351524 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific language modelling with UML profiles by decoupling abstract and concrete syntaxes},
journal = {Journal of Systems and Software},
author = {Pardillo, Jesus and Cachero, Cristina},
volume = {83},
number = {12},
year = {2010},
pages = {2591 - 2606},
issn = {01641212},
address = {360 Park Avenue South, New York, NY 10010, United States},
abstract = {UML profiling presents some acknowledged deficiencies, among which the lack of expressiveness of the profiled notations, together with the high coupling between abstract and concrete syntaxes outstand. These deficiencies may cause distress among UML-profile modellers, who are often forced to extend from unsuitable metaclasses for mere notational reasons, or even to model domain-specific languages from scratch just to avoid the UML-profiling limitations. In order to palliate this situation, this article presents an extension of the UML profile metamodel to support arbitrarily-complex notational extensions by decoupling the UML abstract and concrete syntax. Instead of defining yet another metamodel for UML-notational profiling, notational extensions are modelled with DI, i.e., the UML notation metamodel for diagram interchange, keeping in this way the extension within the standard. Profiled UML notations are rendered with DI by defining the graphical properties involved, the domain-specific constraints applied to DI, and the rendering routines associated. Decoupling abstract and concrete syntax in UML profiles increases the notation expressiveness while decreasing the abstract-syntax complexity. &copy; 2010 Elsevier Inc.},
key = {Unified Modeling Language},
keywords = {Abstracting;Graphical user interfaces;Markup languages;Problem oriented languages;Syntactics;},
note = {Diagramming;Modelling;Profiles;Syntax;UML;Visual language;},
URL = {http://dx.doi.org/10.1016/j.jss.2010.08.019},
} 


@inproceedings{20105113498028 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific language integration with compile-time parser generator library},
journal = {GPCE'10 - Proceedings of the 2010 Conference on Generative Programming and Component Engineering},
author = {Porkolab, Zoltan and Sinkovics, Abel},
year = {2010},
pages = {137 - 146},
address = {Eindhoven, Netherlands},
abstract = {Smooth integration of domain-specific languages into a general purpose host language requires absorbing of domain code written in arbitrary syntax. The integration should cause minimal syntactical and semantic overhead and introduce minimal dependency on external tools. In this paper we discuss a DSL integration technique for the C++ programming language. The solution is based on compile-time parsing of the DSL code. The parser generator is a C++ template metaprogram reimplementation of a runtime Haskell parser generator library. The full parsing phase is executed when the host program is compiled. The library uses only standard C++ language features, thus our solution is highly portable. As a demonstration of the power of this approach, we present a highly efficient and type-safe version of printf and the way it can be constructed using our library. Despite the well known syntactical difficulties of C++ template metaprograms, building embedded languages using our library leads to self-documenting C++ source code. &copy; 2010 ACM.},
key = {Integration},
keywords = {Computer aided software engineering;Graphical user interfaces;Problem oriented languages;Semantics;},
note = {C++ language;C++ templates;Compile time;Domain specific languages;Embedded Languages;External tools;General purpose;Haskell;Highly-portable;Integration techniques;Library use;Metaprograms;Parser generators;Runtimes;Source codes;},
URL = {http://dx.doi.org/10.1145/1868294.1868315},
} 


@inproceedings{20105113498022 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modular domain-specific language components in Scala},
journal = {GPCE'10 - Proceedings of the 2010 Conference on Generative Programming and Component Engineering},
author = {Hofer, Christian and Ostermann, Klaus},
year = {2010},
pages = {83 - 92},
address = {Eindhoven, Netherlands},
abstract = {Programs in domain-specific embedded languages (DSELs) can be represented in the host language in different ways, for instance implicitly as libraries, or explicitly in the form of abstract syntax trees. Each of these representations has its own strengths and weaknesses. The implicit approach has good composability properties, whereas the explicit approach allows more freedom in making syntactic program transformations. Traditional designs for DSELs fix the form of representation, which means that it is not possible to choose the best representation for a particular interpretation or transformation. We propose a new design for implementing DSELs in Scala which makes it easy to use different program representations at the same time. It enables the DSL implementor to define modular language components and to compose transformations and interpretations for them. &copy; 2010 ACM.},
key = {XML},
keywords = {Graphical user interfaces;Problem oriented languages;Syntactics;Trees (mathematics);},
note = {Domain specific languages;Embedded Languages;Scala;Term representation;Visitor patterns;},
URL = {http://dx.doi.org/10.1145/1868294.1868307},
} 


@inproceedings{20104913467765 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language for complex natural and artificial systems simulations},
journal = {Proceedings of the 10th Workshop on Language Descriptions, Tools and Applications, LDTA 2010},
author = {Giavitto, Jean-Louis},
year = {2010},
pages = {ACM Special Interest Group on Programming Languages (SIGPLAN); University of Minnesota Software Engineering Center - },
address = {Paphos, Cyprus},
abstract = {A DSL for Systems Biology. Domain specific languages are often designed to incorporate domain-specific knowledge in order to enhance expressiveness (for the programmer) and quality, flexibility, maintenability, ..., of the produced soft-wares. In this talk I introduce a language initially developed to ease the modeling and the simulation of developmental processes in biology. In this application domain, one must face: &bull dynamical processes that are located and move in space, &bull processes that interact locally with their (spatial) neighbors, &bull a spatial neighborhood that is build (computed) and adjusted as a result of the process activities, &bull various style of processes (numerical simulation of ODE and PDE, stochastic processes and discrete deterministic or non-deterministic transition systems). &copy; ACM 2010.},
key = {Computer simulation},
keywords = {Random processes;},
note = {Application domains;Artificial systems;Domain specific languages;Domain-specific knowledge;Dynamical process;Maintenability;Numerical simulation;Process activities;Spatial neighborhoods;Stochastic process;Systems biology;Transition system;},
URL = {http://dx.doi.org/10.1145/1868281.1868282},
} 


@inproceedings{20110813674229 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using domain specific language for modeling and simulation: Scalation as a case study},
journal = {Proceedings - Winter Simulation Conference},
author = {Miller, John A. and Han, Jun and Hybinette, Maria},
year = {2010},
pages = {741 - 752},
issn = {08917736},
address = {Baltimore, MD, United states},
abstract = {Progress in programming paradigms and languages has over time influenced the way that simulation programs are written. Modern object-oriented, functional programming languages are expressive enough to define embedded Domain Specific Languages (DSLs). The Scala programming language is used to implement ScalaTion that supports several popular simulation modeling paradigms. As a case study, ScalaTion is used to consider how language features of object-oriented, functional programming languages and Scala in particular can be used to write simulation programs that are clear, concise and intuitive to simulation modelers. The dichotomy between "model specification" and "simulation program" is also considered both historically and in light of the potential narrowing of the gap afforded by embedded DSLs. &copy;2010 IEEE.},
key = {Object oriented programming},
keywords = {Computer simulation;Functional programming;},
note = {Domain specific languages;Embedded domain specific languages;Functional programming languages;Language features;Model specifications;Modeling and simulation;Object oriented;Programming language;Programming paradigms;Simulation modelers;Simulation modeling;Simulation program;},
URL = {http://dx.doi.org/10.1109/WSC.2010.5679113},
} 


@inproceedings{20104113289871 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Feldspar: A domain specific language for digital signal processing algorithms},
journal = {8th ACM/IEEE International Conference on Formal Methods and Models for Codesign, MEMOCODE 2010},
author = {Axelsson, Emil and Claessen, Koen and Devaiy, Gergely and Horvathy, Zoltan and Keijzer, Karin and Lyckegardz, Bo and Perssonz, Anders and Sheeran, Mary and Svenningsson, Josef and Vajdax, Andras},
year = {2010},
pages = {169 - 178},
address = {Grenoble, France},
abstract = {A new language, Feldspar, is presented, enabling high-level and platform-independent description of digital signal processing (DSP) algorithms. Feldspar is a pure functional language embedded in Haskell. It offers a high-level dataflow style of programming, as well as a more mathematical style based on vector indices. The key to generating efficient code from such descriptions is a high-level optimization technique called vector fusion. Feldspar is based on a low-level, functional core language which has a relatively small semantic gap to machine-oriented languages like C. The core language serves as the interface to the back-end code generator, which produces C. For very small examples, the generated code performs comparably to hand-written C code when run on a DSP target. While initial results are promising, to achieve good performance on larger examples, issues related to memory access patterns and array copying will have to be addressed. &copy; 2010 IEEE.},
key = {High level languages},
keywords = {Digital signal processing;Digital signal processors;Feldspar;Formal methods;Machine oriented languages;Mathematical programming;Signal processing;Silicate minerals;},
note = {C codes;Code generators;Dataflow;Digital signal processing algorithms;Domain specific languages;Functional languages;Haskell;High-level optimizations;Memory access patterns;Semantic gap;Vector index;},
URL = {http://dx.doi.org/10.1109/MEMCOD.2010.5558637},
} 


@inproceedings{20102913090219 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {EriLex: An embedded domain specific language generator},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Xu, Hao},
volume = {6141 LNCS},
year = {2010},
pages = {192 - 212},
issn = {03029743},
address = {Malaga, Spain},
abstract = {EriLex is a software tool for generating support code for embedded domain specific languages (EDSLs). It supports specifying syntax, static semantics, and dynamic semantics of an EDSL, mixing the method chaining style and the functional nesting style in the EDSL embedding, and using native types and values in the EDSL. The EriLex approach to EDSL embedding assumes only basic object-oriented features and generics in the host language and does not require any particular technology in the definition or implementation of host languages and tools. The generated support code allows the EDSLs to reuse not only host language compilers but also host language semantic editors. &copy; 2010 Springer-Verlag.},
key = {Object oriented programming},
keywords = {Embedded software;Linguistics;Query languages;Semantics;},
note = {Dynamic semantic;Embedded domain specific languages;Generating support;Language semantics;Object-oriented features;Software tool;Static semantics;},
URL = {http://dx.doi.org/10.1007/978-3-642-13953-6_11},
} 


@inproceedings{20110413613003 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A Scala-based domain specific language for structured data representation},
journal = {ICSOFT 2010 - Proceedings of the 5th International Conference on Software and Data Technologies},
author = {Maeda, Kazuaki},
volume = {2},
year = {2010},
pages = {296 - 299},
address = {Athens, Greece},
abstract = {This paper describes Sibon, a new representation written in a text-based data format using Scala syntax. The design principle of Sibon is good readability and simplicity of structured data representation. An important feature of Sibon is an executable representation. Once Sibon-related definitions are loaded, the representation can be executed corresponding to the definitions. A program generator was developed to create Scala and Java programs from Sibon definitions. In the author's experience, productivity was improved in the design and implementation of programs that manipulate structured data.},
key = {Java programming language},
keywords = {Computer software;},
note = {Data representations;Domain specific languages;Java;Scala;Structured data;},
} 


@inproceedings{20103713230245 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Ocelet: An ontology-based domain specific language to model complex domains},
journal = {3rd Int. Conf. on Communication Theory, Reliability, and Quality of Service, CTRQ 2010, Includes MOPAS 2010: 1st Int. Conf. on Models and Ontology-Based Design of Protocols, Architecture and Services},
author = {Cure, Olivier and Forax, Remi and Degenne, Pascal and Seen, Danny Lo and Parigot, Didier and Lahcen, Ayoub Ait},
year = {2010},
pages = {255 - 260},
address = {Athens, Glyfada, Greece},
abstract = {In this work, we consider that the modeling of complex domains can be performed using Domain Specific Languages (DSL). The main principle of this approach consists in developing DSL primitives and to assemble them to model a certain domain. The ability to add new primitives into an existing model and to fine-tune it by replacing some of them provides a flexibility that is highly desirable in simulation intense fields. We have designed such a language, named Ocelet, which is tailored for dynamic landscape modeling. We consider that three important components may influence the adoption of this approach: a graphical user interface to build models in an efficient and user-friendly way, a solution to reason, e.g., consistency checking, about model primitives and a tool to facilitate the development of primitives repositories. In this paper, we emphasize that an ontology-based approach is adapted to design all these components. Moreover, a mapping between ontology and Ocelet elements is sufficient for its achievement and supports automatic transformations from one model to the other. &copy; 2010 IEEE.},
key = {Ontology},
keywords = {Computer simulation;Design;Graphical user interfaces;Information theory;Linguistics;Model checking;Network architecture;Quality control;Quality of service;Query languages;Reliability theory;Signal reconstruction;},
note = {Automatic transformations;Complex domains;Consistency checking;Domain specific languages;Intense field;Landscape modeling;Model complexes;Ocelet;Ontology-based;Reasoning;},
URL = {http://dx.doi.org/10.1109/CTRQ.2010.50},
} 


@inproceedings{20104413350102 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A SOA approach for domain-specific language implementation},
journal = {Proceedings - 2010 6th World Congress on Services, Services-1 2010},
author = {Liu, Shih-Hsi and Cardenas, Adam and Xiong, Xang and Mernik, Marjan and Bryant, Barrett R. and Gray, Jeff},
year = {2010},
pages = {535 - 542},
address = {Miami, FL, United states},
abstract = {Although there have been many benefits of Domain-Specific Languages (DSLs) reported from both academia and industry, implementation of DSLs continue to face challenges with respect to frequent evolution of both syntax and semantics. Techniques for implementing DSLs also lack interoperable capabilities among base languages and limited tool support. Such challenges result in increasing DSL development cost and constrain DSL adoption opportunities. This paper introduces a Service-Oriented Architecture (SOA) approach to address such problems. The approach utilizes WSDL to perform lexical and syntax analysis. Web services are used to define the semantics of a DSL, and WS-BPEL is then used to specify a DSL program. We present two case studies representing different DSL categories to show the feasibility of SOA-based DSL implementation. The case studies demonstrate the potential for easing the burden of DSL evolution and offering interoperability and tool support. Improved modularization and removal of tokenization/parsing are two additional advantages. Discussion and comparison among interpreter-based, model-driven and SOA-based DSL implementations are provided, which may raise more research interests in this area. &copy; 2010 IEEE.},
key = {Research},
keywords = {Graphical user interfaces;Information services;Modular construction;Problem oriented languages;Program interpreters;Semantic Web;Syntactics;Web services;},
note = {Base language;Development costs;Domain specific languages;Model-driven;Modularizations;Syntax analysis;Tool support;WS-BPEL;},
URL = {http://dx.doi.org/10.1109/SERVICES.2010.119},
} 


@inproceedings{20104713407579 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Papyrus: A UML2 tool for domain-specific language modeling},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Gerard, Sebastien and Dumoulin, Cedric and Tessier, Patrick and Selic, Bran},
volume = {6100 LNCS},
year = {2010},
pages = {361 - 368},
issn = {03029743},
address = {Dagstuhl Castle, Germany},
abstract = {This chapter outlines Papyrus, a tool for graphical modeling of UML2 applications. It is an open-source project, designed as an Eclipse component, and based on the existing EMF-based realization of the UML2 meta-model. The goal of this open-source project is twofold. First, it is a complete, efficient, robust, and methodologically agnostic implementation of a UML2 tool to both industry and academia. Second, it is an open and flexible facility for defining and utilizing domain-specific modeling languages using a very advanced implementation of the UML profile concept. &copy; 2010 Springer-Verlag.},
key = {Real time systems},
keywords = {Computational linguistics;Embedded systems;Problem oriented languages;},
note = {MDD;MDE;Modeling and Eclipse;UML profiles;UML2;},
URL = {http://dx.doi.org/10.1007/978-3-642-16277-0_19},
} 


@inproceedings{20105113497546 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MDSD for the iPhone: Developing a domain-specific language and IDE tooling to produce real world applications for mobile devices},
journal = {Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion, SPLASH '10},
author = {Behrens, Heiko},
year = {2010},
pages = {123 - 127},
address = {Reno/Tahoe, NV, United states},
abstract = {During the last years, code generators and models have become increasingly popular tools to support software development processes in manyfold ways. At the same time, the emerging pervasiveness of domain-specific languages (DSLs) in this field has complemented the idea of raising the level of abstraction by introducing specialized view points of a certain problem space. In combination with a proper set of idioms at the target platform generation-based approaches allow for weaving generated parts of an application with handwritten enhancements and refinements over the whole application lifecycle. The mobile division of itemis AG has delivered an implementation of such a model-based solution for mobile devices that uses a DSL to completely describe the structure and behavior of data-centric mobile applications. Its tool support reaches from static analysis over code navigation to compiler and simulator integration of the iPhone development platform. &copy; 2010 ACM.},
key = {Object oriented programming},
keywords = {Computer systems programming;Graphical user interfaces;Java programming language;Mobile devices;Mobile telecommunication systems;Portable equipment;Problem oriented languages;Software design;Static analysis;},
note = {Development environment;Domain specific languages;Eclipse;IPhone;Model-driven software development;},
URL = {http://dx.doi.org/10.1145/1869542.1869562},
} 


@inproceedings{20094812500116 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language in dependability analysis},
journal = {Proceedings of 2009 4th International Conference on Dependability of Computer Systems, DepCos-RELCOMEX 2009},
author = {Kowalski, Marcin and Wilkosz, Kazimierz},
year = {2009},
pages = {324 - 331},
address = {Brunow, Poland},
abstract = {Domain Specific Languages gain increasing popularity as they substantially leverage software development by bridging the gap between technical and business area. After a domain framework is produced, experts gain an effective vehicle for assessing quality and performance of a system in the business-specific context. We consider the domain to be dependability of Multi-Agent System (MAS), for which a key requirement is an efficient verification of a topology model of a power system. As a result, we come up with a reliability evaluation solution offering a significant rise in the level of Abstraction towards MAS utilized for purposes of a power system topology verification. By means of the mentioned solution safety engineers are enabled to perform analysis while the design is still incomplete. A new DSL is developed in XText in order to specify a structure of the system together with dependability extensions, which are further translated into Dynamic Fault Trees using Model to Model Transformations. The Eclipse Ecore becomes a common denominator, in which both metamodels' Abstract Syntax Trees are defined. Finally, an expert is offered with two ways of defining a model: through abstract and textual concrete syntax, both of which are checked for consistency using Object Constraint Language.},
key = {Abstracting},
keywords = {Electric power transmission networks;Linguistics;Query languages;Syntactics;Topology;XML;},
note = {Abstract Syntax Trees;Common denominators;Concrete syntax;Dependability analysis;Domain specific languages;Dynamic fault trees;Level of abstraction;Meta model;Model to model transformation;Object Constraint Language;Power system topology;Power systems;Reliability Evaluation;Safety engineer;Software development;Topology model;},
URL = {http://dx.doi.org/10.1109/DepCoS-RELCOMEX.2009.14},
} 


@inproceedings{20091412016883 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Prototyping domain-specific language semantics},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Sadilek, Daniel A.},
year = {2008},
pages = {895 - 896},
address = {Nashville, TN, United states},
abstract = {Domain-specific languages (DSLs) need semantics. For an external, executable, metamodel-based DSL, this can be done in an operational or a translational way. In my dissertation, I develop a framework that allows both. It provides flexibility for semantics description in two axes: on the one axis, operational semantics is fixed and one can choose between different description languages (QVT, Java, Prolog, Abstract State Machines, and Scheme); on the other axis, Scheme is fixed and one can choose between operational and translational semantics. Using operational semantics, DSL program interpretation can be animated and debugged. Equivalence of operational semantics described with different languages can be tested by comparing execution traces.},
key = {Object oriented programming},
keywords = {Computer software;Computer systems programming;DSL;Graphical user interfaces;Information theory;Java programming language;Linguistics;Modems;Program debugging;Program interpreters;PROLOG (programming language);Query languages;Semantics;Telecommunication lines;},
note = {Abstract state machines;Description languages;Domain-specific languages;Execution traces;Language engineering;Meta models;Metamodelling;Operational semantics;Prototyping;},
URL = {http://dx.doi.org/10.1145/1449814.1449896},
} 


@inproceedings{20090111838298 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language for the development of collaborative systems},
journal = {Proceedings - International Conference of the Chilean Computer Science Society, SCCC},
author = {Bibbo, Luis Mariano and Garcia, Diego and Pons, Claudia},
year = {2008},
pages = {3 - 12},
issn = {15224902},
address = {Punta Arenas, Chile},
abstract = {Domain-Specific Languages (DSLs) are high level languages defined for combining expressivity and simplicity by means of constructs which are close to the problem domain and distant from the intricacies of underlying software implementation constraints. This paper presents a language to graphically document the analysis and design decisions embodied in Collaborative System development. The language was designed as a conservative extension of the UML and it enables the application of the MDD approach to the development of such systems. &copy; 2008 IEEE.},
key = {Query languages},
keywords = {C (programming language);Computers;High level languages;Linguistics;Sailing vessels;Unified Modeling Language;},
note = {Analysis and designs;Collaborative systems;Conservative extensions;Domain specifics;Problem domains;Software implementations;System developments;},
URL = {http://dx.doi.org/10.1109/SCCC.2008.12},
} 


@inproceedings{20100912734924 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Executable domain specific language for message-based system integration},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Shtelma, Michael and Cartsburg, Mario and Milanovic, Nikola},
volume = {5795 LNCS},
year = {2009},
pages = {622 - 626},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {Heterogeneous IT-systems rarely rely on a common data format and structure, so in order to integrate them, the corresponding data/message transformations must be developed. Transformations may also be required by the business logic. We present a platform-independent approach for message transformation specification, in form of a system integration DSL, and discuss approaches for making it executable. &copy; 2009 Springer Berlin Heidelberg.},
key = {Linguistics},
keywords = {Models;Query languages;},
note = {Business logic;Data format;Domain specific languages;Execution systems;Message transformation;System integration;},
URL = {http://dx.doi.org/10.1007/978-3-642-04425-0_48},
} 


@inproceedings{20094712483822 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language and workflow execution engine to enable dynamic workflows},
journal = {Proceedings - 2009 IEEE International Symposium on Parallel and Distributed Processing with Applications, ISPA 2009},
author = {Sturmer, G. and Mangler, J. and Schikuta, E.},
year = {2009},
pages = {653 - 658},
address = {Chengdu, Sichuan, China},
abstract = {Abstract-Workflow engines [1][2][3] often being based on WS-BPEL, currently rely on a mix of recovery / modification strategies [4] that are either part of the workflow description, part of the workflow engine, or realized as plugins to the workflow engine. To foster the development of distributed cloud-based workflow engines and novel repair algorithms, workflow engines have to be modularized in order to overcome the static and inflexible APIs provided by these workflow engines. Dynamic features gained by a modularization include the creation of external modules to monitor as well as modify a workflow to provide error handling in conjunction with Service Level Agreement (SLA) constraints. The aim of this paper is to present a flexible Workflow Execution Engine to facilitate the development of a new dynamic infrastructure to realize dynamic workflow engines with a focus on cloud-based environments.},
key = {Management},
keywords = {Distributed parameter networks;Engines;Modular construction;},
note = {Domain specific languages;Dynamic features;Dynamic infrastructure;Dynamic workflow;Error handling;Flexible workflows;Modularizations;Modularized;Plug-ins;Repair algorithms;Service Level Agreements;Work-flows;Workflow engines;Workflow execution;WS-BPEL;},
URL = {http://dx.doi.org/10.1109/ISPA.2009.106},
} 


@inproceedings{20094612440279 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain specific language for extracting models in software modernization},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Canovas Izquierdo, Javier Luis and Molina, Jesus Garcia},
volume = {5562 LNCS},
year = {2009},
pages = {92 - 97},
issn = {03029743},
address = {Enschede, Netherlands},
abstract = {Model-Driven Engineering techniques can be used both to create new software and to modernize existing software systems. Model-Driven Software Modernization requires a first step for the extraction of models. Most modernization scenarios involve dealing with the GPL source code of the existing system. Techniques and tools providing efficient means to extract models from source code are therefore needed. In this paper, we analyze the difficulties encountered when using the existing approaches and we propose a language, called Gra2MoL, which is especially tailored to address the problem of model extraction. This provides a powerful query language for concrete syntax trees, and mappings between source grammar elements and target metamodel elements are expressed by rules similar to those found in model transformation languages. Moreover, the approach also allows reusing existing grammars. &copy; 2009 Springer Berlin Heidelberg.},
key = {Query languages},
keywords = {Computer software;Linguistics;Modernization;},
note = {Concrete syntax;Domain specific languages;Existing systems;Extract models;Meta model;Model extraction;Model transformation;Model-driven;Model-driven Engineering;Software modernization;Software systems;Source codes;},
URL = {http://dx.doi.org/10.1007/978-3-642-02674-4-7},
} 


@inproceedings{20090511881925 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for application-level checkpointing},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Arora, Ritu and Mernik, Marjan and Bangalore, Purushotham and Roychoudhury, Suman and Mukkai, Saraswathi},
volume = {5375 LNCS},
year = {2008},
pages = {26 - 38},
issn = {03029743},
address = {New Delhi, India},
URL = {http://dx.doi.org/10.1007/978-3-540-89737-8_3},
} 


@inproceedings{20094812499856 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Photon: A domain-specific language for testing converged applications},
journal = {Proceedings - International Computer Software and Applications Conference},
author = {Miller, Anne and Kumar, Balaji and Singhal, Anukul},
volume = {2},
year = {2009},
pages = {269 - 274},
issn = {07303157},
address = {Seattle, WA, United states},
abstract = {Automated testing of converged applications can be complex, as it is rare for a single testing tool to provide a single solution for all access points which a given application supports. As such, testing teams often create customized testing frameworks, which integrate several different testing tools, and a myriad of programming languages and scripting tools. When an application's unique set of access points changes, or a new testing tool comes to market which offers a competitive advantage over existing test tools, the cost of updating these customized frameworks can be difficult to justify. This paper provides a solution to this problem by introducing "Photonese," a domainspecific language which testers can use to compose automation scripts which are independent of the test tool used for automation. In this way, the tester creates reusable testing assets in a framework which is reusable across multiple projects. &copy; 2009 IEEE.},
key = {Computer applications},
keywords = {Automation;Competition;Computer software reusability;Linguistics;Problem oriented languages;Query languages;Word processing;},
note = {Access points;Automated testing;Competitive advantage;Domain specific languages;Multiple projects;Programming language;Scripting tools;Test tools;Testing framework;Testing tools;},
URL = {http://dx.doi.org/10.1109/COMPSAC.2009.143},
} 


@article{20093012205024 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Habitation: A domain-specific language for home automation},
journal = {IEEE Software},
author = {Jimenez, Manuel and Rosique, Francisca and Sanchez, Pedro and Alvarez, Barbara and Iborra, Andres},
volume = {26},
number = {4},
year = {2009},
pages = {30 - 38},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {Developers need suitable tools to develop home automation systems while enhancing quality and productivity. One solution is to use domain-specific languages (DSLs) within a model-driven approach. The Habitation DSL provides a powerful visual development environment, including a catalog of reusable functional units and a set of home automation interconnection primitives. The model-driven approach offers mechanisms to automatically generate code to enhance the quality and portability of home automation systems. The result is an Eclipse-based tool whose usability the authors have validated in a case study. &copy; 2009 IEEE.},
key = {Unified Modeling Language},
keywords = {Automation;Computer integrated manufacturing;Computer software;DSL;Graphical user interfaces;Linguistics;Modems;Query languages;Systems analysis;Telecommunication lines;},
note = {Catalogs;Computational modeling;Domain-specific languages;Home automation;Model-driven engineering;Software;Visual languages;},
URL = {http://dx.doi.org/10.1109/MS.2009.93},
} 


@inproceedings{20084811738150 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Coordinated queries: A domain specific language for exploratory development of multiview visualizations},
journal = {Proceedings - 2008 IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC 2008},
author = {Weaver, Chris},
year = {2008},
pages = {197 - 200},
address = {Herrsching am Ammersee, Germany},
abstract = {The development of information visualization user interfaces suffers from a persistent gap between toolkit-based programming and interactive design, between the visualization experts who build tools and the information experts who cultivate analytic utility. Coordinated Queries is a declarative language for live design of information visualization user interfaces. The combination of a visualization specific language with an extensive library of views and queries gives designers flexible, yet precise control over the appearance and behavior of data in response to interaction. Through live, integrated editing of essentially infinite variations on well-known patterns of visual data representation and multiple view coordination, it is practical to iteratively grow and vary visualizations much more quickly than by traditional means, thereby facilitating open-ended visual exploration and analysis in a variety of domains. &copy; 2008 IEEE.},
key = {Data visualization},
keywords = {Information analysis;Information science;Information systems;Linguistics;Query languages;User interfaces;Visualization;},
note = {Coordinated queries;Declarative languages;Do-mains;Domain specifics;Information visualizations;Interactive designs;Multiple views;Multiview visualizations;Precise controls;Specific languages;Visual data representations;Visual explorations;},
URL = {http://dx.doi.org/10.1109/VLHCC.2008.4639085},
} 


@inproceedings{20100912734911 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Anatomy of a visual domain-specific language project in an industrial context},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Wienands, Christoph and Golm, Michael},
volume = {5795 LNCS},
year = {2009},
pages = {453 - 467},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {Domain-specific languages (DSL) are specialized modeling languages targeting a narrow domain. In this paper, we present the results of a research project on visual DSLs set in an industrial context, using the domain of elevator controllers. After domain analysis and inception of new, abstract modeling concepts a language prototype was developed, considering aspects such as usability, combination of visual and textual DSLs, and performance of generated code. We describe the challenges encountered during the project, such as defining a user-friendly concrete syntax or tool limitations, and analyze them in retrospective. The paper concludes with several metrics to support the findings. &copy; 2009 Springer Berlin Heidelberg.},
key = {Linguistics},
keywords = {Graphical user interfaces;Models;Network components;Problem oriented languages;Query languages;},
note = {Abstract modeling;Code Generation;Concrete syntax;Domain analysis;Domain specific languages;Elevator controllers;Industrial context;Modeling languages;},
URL = {http://dx.doi.org/10.1007/978-3-642-04425-0_35},
} 


@article{20093012205025 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model talk: When everything is a domain-specific language},
journal = {IEEE Software},
author = {Hen-Tov, Atzmon and Lorenz, David H. and Pinhasi, Assaf and Schachter, Lior},
volume = {26},
number = {4},
year = {2009},
pages = {39 - 46},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {Many see a great future for domain-specific software development. Yet, the path to fulfilling the potential of domain-specific languages on a large scale remains largely uncharted. This article presents ModelTalk, a model-driven framework for DSL-based development. ModelTalk can be used to produce a product line of commercial business support systems for the telecommunications industry. &copy; 2009 IEEE.},
key = {Probability density function},
keywords = {Computer software;DSL;Graphical user interfaces;Java programming language;Linguistics;Mining;Modems;Query languages;Systems analysis;Telecommunication lines;},
note = {Business;Domain-specific languages;Java;Model-driven development;Software;Software product lines;},
URL = {http://dx.doi.org/10.1109/MS.2009.97},
} 


@article{2005509548402 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific language models and lexicons for tagging},
journal = {Journal of Biomedical Informatics},
author = {Coden, Anni R. and Pakhomov, Serguei V. and Ando, Rie K. and Duffy, Patrick H. and Chute, Christopher G.},
volume = {38},
number = {6},
year = {2005},
pages = {422 - 430},
issn = {15320464},
abstract = {Accurate and reliable part-of-speech tagging is useful for many Natural Language Processing (NLP) tasks that form the foundation of NLP-based approaches to information retrieval and data mining. In general, large annotated corpora are necessary to achieve desired part-of-speech tagger accuracy. We show that a large annotated general-English corpus is not sufficient for building a part-of-speech tagger model adequate for tagging documents from the medical domain. However, adding a quite small domain-specific corpus to a large general-English one boosts performance to over 92% accuracy from 87% in our studies. We also suggest a number of characteristics to quantify the similarities between a training corpus and the test data. These results give guidance for creating an appropriate corpus for building a part-of-speech tagger model that gives satisfactory accuracy results on a new domain at a relatively small cost. &copy; 2005 Elsevier Inc. All rights reserved.},
key = {Natural language processing systems},
keywords = {Biotechnology;Information retrieval;Markov processes;Mathematical models;},
note = {Clinical information system;Clinical report analysis;Corpus linguistics;Domain adaptation;Hidden Markov Model;Part-of speech tagging accuracy;},
URL = {http://dx.doi.org/10.1016/j.jbi.2005.02.009},
} 


@inproceedings{2006109751748 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific language for patchy landscape modelling: The Brittany agricultural mosaic as a case study},
journal = {Ecological Modelling},
author = {Gaucherel, Cedric. and Giboire, Nathalie and Viaud, Valerie and Houet, Thomas and Baudry, Jacques and Burel, Francoise},
volume = {194},
number = {1-3 SPEC. ISS.},
year = {2006},
pages = {233 - 243},
issn = {03043800},
abstract = {Recent developments in landscape ecology have emphasised the functional role of heterogeneity of mosaics such as a "patchworks" of agricultural fields. Explicit (process) landscape models are important tools to study this functional role, although very few model are dedicated to patchy landscape dynamics. We construct such a model (L1) manipulating patches (polygons) instead of pixels by a combination of pure attributive or geometrical modifications. In addition, our aim was to build a perennial and dynamic software platform. Hence, the L1 platform contributes to the design of distinct scenarios, as well as distinct models of (forested, agricultural, suburban...) landscapes. It is designed around a kernel modelling, a generic patchy landscape that could be progressively driven to follow natural (climatic, ecological...) forces and human (sociological, economical...) decisions. We present, here, the first model of the L1 platform with an application on a Brittany agricultural landscape and four simplified scenarios. We focused on human decisions driving the patchy mosaic and demonstrated the importance of taking into account the different decision levels, from the main characteristics of the European Common Agricultural Policies (CAP) to the farmer individual land use allocation. Results are a set of rules that reproduces Brittany landscape evolutions with increasing complexity driving-decisions, and therefore, with increasing realism degree. They illustrate part of the L1 platform flexibility. &copy; 2005 Elsevier B.V. All rights reserved.},
key = {Landslides},
keywords = {Agriculture;Climatology;Mathematical models;},
note = {Categorical landscape;Farm practices;Modelling platform;Spatial pattern;},
URL = {http://dx.doi.org/10.1016/j.ecolmodel.2005.10.026},
} 


@article{2006269963269 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {PADS: A domain-specific language for processing ad hoc data},
journal = {ACM SIGPLAN Notices},
author = {Fisher, Kathleen and Gruber, Robert},
volume = {40},
number = {6},
year = {2005},
pages = {295 - 304},
issn = {03621340},
abstract = {PADS is a declarative data description language that allows data analysts to describe both the physical layout of ad hoc data sources and semantic properties of that data. From such descriptions, the PADS compiler generates libraries and tools for manipulating the data, including parsing routines, statistical profiling tools, translation programs to produce well-behaved formats such as XML or those required for loading relational databases, and tools for running XQueries over raw PADS data sources. The descriptions are concise enough to serve as "living" documentation while flexible enough to describe most of the ASCII, binary, and Cobol formats that we have seen in practice. The generated parsing library provides for robust, application-specific error handling. Copyright 2005 ACM.},
key = {Data description},
keywords = {COBOL (programming language);Computer programming languages;Query languages;Semantics;Standards;XML;},
note = {Domain-specific languages;},
URL = {http://dx.doi.org/10.1145/1064978.1065046},
} 


@inproceedings{2004408388997 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {NDL: A domain-specific language for device drivers},
journal = {Proceedings of the ACM SIGPLAN Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES)},
author = {Conway, Christopher L. and Edwards, Stephen A.},
year = {2004},
pages = {30 - 36},
address = {Washington, DC, United states},
abstract = {Device drivers are difficult to write and error-prone. They are usually written in C, a fairly low-level language with minimal type safety and little support for device semantics. As a result, they have become a major source of instability in operating system code. This paper presents NDL, a language for device drivers. NDL provides high-level abstractions of device resources and constructs tailored to describing common device driver operations. We show that NDL allows for the coding of a semantically correct driver with a code size reduction of more than 50% and a minimal impact on performance.},
key = {Computer systems programming},
keywords = {C (programming language);Computer operating systems;Computer software;Encoding (symbols);Network protocols;Optimization;Program debugging;Semantics;},
note = {Code size reduction;Device drivers;Device programming;Domain-specific languages;},
URL = {http://dx.doi.org/10.1145/997163.997169},
} 


@inproceedings{2004398378225 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {NDL: A domain-specific language for device drivers},
journal = {ACM SIGPLAN Notices},
author = {Conway, Christopher L. and Edwards, Stephen A.},
volume = {39},
number = {7},
year = {2004},
pages = {30 - 36},
issn = {03621340},
abstract = {Device drivers are difficult to write and error-prone. They are usually written in C, a fairly low-level language with minimal type safety and little support for device semantics. As a result, they have become a major source of instability in operating system code. This paper presents NDL, a language for device drivers. NDL provides high-level abstractions of device resources and constructs tailored to describing common device driver operations. We show that NDL allows for the coding of a semantically correct driver with a code size reduction of more than 50% and a minimal impact on performance.},
key = {Computer systems programming},
keywords = {Codes (symbols);Computer hardware;Computer operating systems;Computer programming languages;Program compilers;Software engineering;},
note = {Coding tools;Device drivers;Domain specific languages;},
} 


@inproceedings{20074410893518 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {ALPH: A domain-specific language for crosscutting pervasive healthcare concerns},
journal = {DSAL'07: Second Workshop on Domain-Specific Aspect Languages},
author = {Munnelly, Jennifer and Clarke, Siobhan},
year = {2007},
address = {Vancouver, BC, Canada},
abstract = {Pervasive healthcare is an advancing discipline that applies ubiquitous computing features to applications deployed in the healthcare domain. In these applications, ubiquitous computing concerns and health informatics concerns are entwined with base functionality resulting in significant, complex crosscutting code. Domainspecific languages (DSLs) can reduce development effort by providing higher level programming abstractions for domain-specific functionality. We introduce ALPH (Aspect Language for Pervasive Healthcare); a DSL that provides domain-specific constructs for tasks and entities within the pervasive healthcare domain. The DSL is translated into an aspect language and the crosscutting behaviour is weaved. We describe an example implementation to illustrate the level of abstraction that can be achieved using domain-specific constructs. Copyright &copy; 2007 ACM.},
key = {Ubiquitous computing},
keywords = {Abstracting;Bioinformatics;Codes (symbols);Computer programming languages;Health care;},
note = {Aspect oriented programmings;Domain specific languages;Health informatics;Pervasive healthcares;},
URL = {http://dx.doi.org/10.1145/1255400.1255404},
} 


@article{20065110314135 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {SmPL: A Domain-Specific Language for Specifying Collateral Evolutions in Linux Device Drivers},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Padioleau, Yoann and Lawall, Julia L. and Muller, Gilles},
volume = {166},
number = {SPEC. ISS.},
year = {2007},
pages = {47 - 62},
issn = {15710661},
abstract = {Collateral evolutions are a pervasive problem in large-scale software development. Such evolutions occur when an evolution that affects the interface of a generic library entails modifications, i.e., collateral evolutions, in all library clients. Performing these collateral evolutions requires identifying the affected files and modifying all of the code fragments in these files that in some way depend on the changed interface. We have studied the collateral evolution problem in the context of Linux device drivers. Currently, collateral evolutions in Linux are mostly done manually using a text editor, possibly with the help of tools such as grep. The large number of Linux drivers, however, implies that this approach is time-consuming and unreliable, leading to subtle errors when modifications are not done consistently. In this paper, we propose a transformation language, SmPL, to specify collateral evolutions. Because Linux programmers are accustomed to exchanging, reading, and manipulating program modifications in terms of patches, we build our language around the idea and syntax of a patch, extending patches to semantic patches. &copy; 2006 Elsevier B.V. All rights reserved.},
key = {Computer programming languages},
keywords = {Computer operating systems;Interfaces (computer);Problem solving;Software engineering;Syntactics;},
note = {Collateral evolutions;Device drivers;Domain specific languages;},
URL = {http://dx.doi.org/10.1016/j.entcs.2006.07.022},
} 


@inproceedings{20080411045397 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {CAOS: A domain-specific language for the parallel simulation of cellular automata},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Grelck, Clemens and Penczek, Frank and Trojahner, Kai},
volume = {4671 LNCS},
year = {2007},
pages = {410 - 417},
issn = {03029743},
address = {Pereslavl-Zalessky, Russia},
abstract = {We present the design and implementation of CAOS, a domain-specific high-level programming language for the parallel simulation of extended cellular automata. CAOS allows scientists to specify complex simulations with limited programming skills and effort. Yet the CAOS compiler generates efficiently executable code that automatically harnesses the potential of contemporary multi-core processors, shared memory multiprocessors, workstation clusters and supercomputers. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Cellular automata},
keywords = {Computer programming languages;Computer simulation;Parallel processing systems;Program compilers;Supercomputers;},
note = {Multi core processors;Shared memory multiprocessors;Workstation clusters;},
} 


@inproceedings{20085011773758 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Software design using UML for empowering end-users with an external Domain Specific Language},
journal = {Proceedings - International Conference on Software Engineering},
author = {Shani, Uri and Sela, Aviad},
year = {2008},
pages = {52 - 55},
issn = {02705257},
address = {Leipzig, Germany},
abstract = {Domain Specific Languages (DSL) also known as "small languages" lack the power of a general purpose language (GPL), but are very productive for the purpose they are designed. While "internal" DSLs require and rely on the use of a hosting GPL, "external" DSLs are independent of a GPL and are thus more suitable for the non-programmer - but domain expert - end-user. Empowering this end-user via DSLs is our prime goal as software designers and architects. Our product will be stronger since much of the final tuning of the application can be done by the end-user and will reduce the number of software revisions that require stringent GPL software testing and validations. As software engineers, the design of a DSL as part of our product should fit into the tools of the trade of software development. We adopt UML for this purpose and propose that the design of DSL can be embedded as an extension of the traditional software modeling and design tools. In this paper we present firstly a view of software development process in which DSLs are an integral part, and than how we use UML to design a DSL which, via empowering a domain expert end-user, achieves challenging software delivery requirements with good stability and excellent performance. Copyright 2008 ACM.},
key = {Software design},
keywords = {Cobalt;Computer software selection and evaluation;Design;DSL;Engineering;Linguistics;Modems;Process engineering;Query languages;Software engineering;Software testing;Technical presentations;Telecommunication lines;Unified Modeling Language;},
note = {Domain Specific Languages;Eclipse;EMF;IDE;Software development;},
URL = {http://dx.doi.org/10.1145/1370847.1370859},
} 


@inproceedings{20093712305975 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generating system models for a highly configurable train control system using a domain-specific language: A case study},
journal = {IEEE International Conference on Software Testing, Verification, and Validation Workshops, ICSTW 2009},
author = {Kloos, Johannes and Eschbach, Robert},
year = {2009},
pages = {39 - 47},
address = {Denver, CO, United states},
abstract = {In this work, we present a results from case study on testing a highly configurable, safety-critical system from the railway domain using model-based risk-oriented testing. In the construction of the system and test models, we face the following problems: (i) A domain expert will usually not be knowledgeable in the construction of system models, but has very detailed knowledge which configurations of the system will be especially critical (e.g., prone to head-on collisions). Thus, a method for the construction of system and test models from domain-specific descriptions is necessary. (ii) The system model shall be validatable against the system's requirements. (iii) The verification of the system model against safety requirements should be possible. We will demonstrate an approach based on DSLs, compositional construction of Mealy machines and a proof technique as a solution to these three problems. &copy; 2009 IEEE.},
key = {Safety testing},
keywords = {Computer software selection and evaluation;Model structures;Research;Security systems;Software testing;Technical presentations;Verification;},
note = {Configurable;Domain experts;Domain specific;Domain specific languages;Following problem;Generating system;Head-on collision;Model-based;Safety critical systems;Safety requirements;System models;Test models;Three problems;Train control systems;},
URL = {http://dx.doi.org/10.1109/ICSTW.2009.32},
} 


@inproceedings{20072010600777 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Grammar-driven generation of domain-specific language tools},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Wu, Hui},
volume = {2006},
year = {2006},
pages = {772 - 773},
address = {Portland, OR, United states},
abstract = {Domain-specific languages (DSLs) assist an end-user programmer in writing programs using idioms that are closer to the abstractions found in a specific problem domain. Language testing tool support for DSLs is lacking when compared to the capabilities provided in standard general purpose languages (e.g., Java and C++). For example, support for debugging a program written in a DSL is often nonexistent. This research abstract describes a grammar-driven technique to build a testing tool generation framework through automated transformation of existing DSL grammars. The modified grammars generate the hooks needed to interface with a supporting infrastructure written for an Integrated Development Environment that assists in debugging, testing, and profiling a DSL program.},
key = {Computer programming languages},
keywords = {Conformal mapping;Problem solving;Program debugging;Software testing;},
note = {DSLs;Grammar driven generation;Integrated Development Environment;},
URL = {http://dx.doi.org/10.1145/1176617.1176718},
} 


@inproceedings{2005068829412 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Concrete syntax for objects : Domain-specific language embedding and assimilation without restrictions},
journal = {19th Annual ACM Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA'04},
author = {Bravenboer, Martin and Visser, Eelco},
year = {2004},
pages = {365 - 383},
address = {Vancouver, BC, Canada},
abstract = {Application programmer's interfaces give access to domain knowledge encapsulated in class libraries without providing the appropriate notation for expressing domain composition. Since object-oriented languages are designed for extensibility and reuse, the language constructs are often sufficient for expressing domain abstractions at the semantic level. However, they do not provide the right abstractions at the syntactic level. In this paper we describe METABORG, a method for providing concrete syntax for domain abstractions to application programmers. The method consists of embedding domain-specific languages in a general purpose host language and assimilating the embedded domain code into the surrounding host code. Instead of extending the implementation of the host language, the assimilation phase implements domain abstractions in terms of existing APIs leaving the host language undisturbed. Indeed, META-BORG can be considered a method for promoting APIs to the language level. The method is supported by proven and available technology, i.e. the syntax definition formalism SDF and the program transformation language and toolset Stratego/XT. We illustrate the method with applications in three domains: code generation, XML generation, and user-interface construction.},
key = {Syntactics},
keywords = {Abstracting;Codes (symbols);Computer software reusability;Embedded systems;Graphical user interfaces;Hierarchical systems;Java programming language;Knowledge based systems;Libraries;Metadata;Object oriented programming;},
note = {Concrete object syntax;Domain-specific languages;Embedded languages;Extensible syntax;Meta programming;METABORG;Rewriting;SDF;Stratego;Syntax extension;},
} 


@inproceedings{20114014397024 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Text data acquisition for domain-specific language models},
journal = {COLING/ACL 2006 - EMNLP 2006: 2006 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
author = {Sethy, Abhinav and Georgiou, Panayiotis G. and Narayanan, Shrikanth},
year = {2006},
pages = {382 - 389},
address = {Sydney, NSW, Australia},
abstract = {The language modeling community is showing a growing interest in using large collections of text mined from the World Wide Web (WWW) to supplement sparse in-domain text resources. However, in most cases the style and content of the text harvested from these corpora differs significantly from the specific nature of these domains. In this paper we present a relative entropy (r.e.) based method to select relevant subsets of sentences whose distribution in an n-gram sense matches the domain of interest. Using simulations, we provide an analysis of how the proposed scheme outperforms filtering techniques proposed in recent language modeling literature on mining text from the web. A comparative study is presented using a text collection of over 800M words collected from the WWW. Experimental results show that by using the proposed subset selection scheme we can get performance improvement in both Word Error Rate (WER) and Perplexity (PPL) over the models built from the entire collection by using just 10% of the data. Improvements in data selection also translated to a significant reduction in the vocabulary size as well as the number of estimated parameters in the adapted language model. &copy; 2006 Association for Computational Linguistics.},
key = {Natural language processing systems},
keywords = {Computational linguistics;Data reduction;Problem oriented languages;User interfaces;World Wide Web;},
note = {Community IS;Comparative studies;Data Selection;Domain specific languages;Estimated parameter;Filtering technique;Language model;Language modeling;Performance improvements;Relative entropy;Specific nature;Subset selection;Text collection;Vocabulary size;Word error rate;},
} 


@inproceedings{2005179055063 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Concrete syntax for objects: Domain-specific language embedding and assimilation without restrictions},
journal = {ACM SIGPLAN Notices},
author = {Bravenboer, Martin and Visser, Eelco},
volume = {39},
number = {10},
year = {2004},
pages = {365 - 383},
issn = {03621340},
abstract = {Application programmer's interfaces give access to domain knowledge encapsulated in class libraries without providing the appropriate notation for expressing domain composition. Since object-oriented languages are designed for extensibility and reuse, the language constructs are often sufficient for expressing domain abstractions at the semantic level. However, they do not provide the right abstractions at the syntactic level. In this paper we describe METABORG, a method for providing concrete syntax for domain abstractions to application programmers. The method consists of embedding domain-specific languages in a general purpose host language and assimilating the embedded domain code into the surrounding host code. Instead of extending the implementation of the host language, the assimilation phase implements domain abstractions in terms of existing APIs leaving the host language undisturbed. Indeed, METABORG can be considered a method for promoting APIs to the language level. The method is supported by proven and available technology, i.e. the syntax definition formalism SDF and the program transformation language and toolset Stratego/XT. We illustrate the method with applications in three domains: code generation, XML generation, and user-interface construction.},
key = {Object oriented programming},
keywords = {Embedded systems;Java programming language;Metadata;Semantics;User interfaces;XML;},
note = {Concrete Object Syntax;Domain-Specific Languages;Embedded Languages;Extensible Syntax;Meta Programming;METABORG;Rewriting;SDF;Stratego;Syntax Extension;},
URL = {http://dx.doi.org/10.1145/1035292.1029007},
} 


@inproceedings{20082211278348 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Optimizing packet accesses for a domain specific language on network processors},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Liu, Tao and Li, Xiao-Feng and Liu, Lixia and Wu, Chengyong and Ju, Roy},
volume = {4339 LNCS},
year = {2006},
pages = {47 - 61},
issn = {03029743},
address = {Hawthorne, NY, United states},
abstract = {Programming network processors remains a challenging task since their birth until recently when high-level programming environments for them are emerging. By employing domain specific languages for packet processing, the new environments try to hide hardware details from the programmers and enhance both the programmability of the systems and the portability of the applications. A frequent issue for the new environments to be widely adopted is their relatively low achievable performance compared to low-level, hand-tuned programming. In this paper we present two techniques, Packet Access Combining (PAC) and Compiler-Generated Packet Caching (CGPC), to optimize packet accesses, which are shown as the performance bottleneck in such new environments for packet processing applications. PAC merges multiple packet accesses into a single wider access; CGPC implements an automatic packet data caching mechanism without a hardware cache. Both techniques focus on reducing long memory latency and expensive memory traffic, and they also reduce instruction counts significantly. We have implemented the proposed techniques in a high level programming environment for network processor named Shangri-La. Our evaluation with standard NPF benchmarks shows that for the evaluated applications the two techniques can reduce the memory traffic by 90% and improve the packet throughput by 5.8 times, on average. &copy; 2006 Springer-Verlag Berlin Heidelberg.},
key = {Packet networks},
keywords = {Computer hardware;Computer programming;Optimization;Tuning;},
note = {Memory traffic;Network processors;},
URL = {http://dx.doi.org/10.1007/978-3-540-69330-7_4},
} 


@inproceedings{20064110160639 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Dealing with contract violations: Formalism and domain specific language},
journal = {Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOC},
author = {Governatori, Guido and Milosevic, Zoran},
year = {2005},
pages = {46 - 57},
issn = {15417719},
address = {Enschede, Netherlands},
abstract = {This paper presents a formal system for reasoning about violations of obligations in contracts. The system is based on the formalism for the representation of contrary-to-duty obligations. These are the obligations that take place when other obligations are violated as typically applied to penalties in contracts. The paper shows how this formalism can be mapped onto the key policy concepts of a contract specification language. This language, called Business Contract Language (BCL) was previously developed to express contract conditions of relevance for run time contract monitoring. The aim of this mapping is to establish a formal underpinning for this key subset of BCL. &copy; 2005 IEEE.},
key = {Contracts},
keywords = {Competitive intelligence;Computer hardware description languages;Conformal mapping;Formal languages;Laws and legislation;Public policy;},
note = {Business Contract Languages (BCL);Domain specific languages;Formal systems;Obligations;},
URL = {http://dx.doi.org/10.1109/EDOC.2005.13},
} 


@inproceedings{2006189858282 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Bossa Nova: Introducing modularity into the Bossa domain-specific language},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Lawall, Julia L. and Duchesne, Herve and Muller, Gilles and Le Meur, Anne-Francoise},
volume = {3676 LNCS},
year = {2005},
pages = {78 - 93},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {Domain-specific languages (DSLs) have been proposed as a solution to ease the development of programs within a program family. Sometimes, however, experience with the use of a DSL reveals the presence of subfamilies within the family targeted by the language. We are then faced with the question of how to capture these subfamilies in DSL abstractions. A solution should retain features of the original DSL to leverage existing expertise and support tools. The Bossa DSL is a language targeted towards the development of kernel process scheduling policies. We have encountered the issue of program subfamilies in using this language to implement an encyclopedic, multi-OS library of scheduling policies. In this paper, we propose that introducing certain kinds of modularity into the language can furnish abstractions appropriate for implementing scheduling policy subfamilies. We present the design of our modular language, Bossa Nova, and assess the language quantitatively and qualitatively. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Computer programming languages},
keywords = {Computer programming;Public policy;Scheduling;},
note = {Bossa Nova;Domain-specific languages (DSLs);Kernel process;Scheduling policies;},
URL = {http://dx.doi.org/10.1007/11561347_7},
} 


@inproceedings{2001316601364 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Hycom: A domain specific language for hypermedia application development},
journal = {Proceedings of the Hawaii International Conference on System Sciences},
author = {Risi, W. and Lopez, P. and Marcos, D.},
year = {2001},
pages = {292 - },
issn = {10603425},
address = {Maui, HI, United states},
abstract = {This paper presents HyCom, a DSL for hypermedia authoring embedded in the language Haskell. HyCom prOvides a declarative framework for describing hypermedia designs and also automatic application generation. We propose HyCom as the bridge between engineering models and implementation environments. HyCom is based on the principle of programming by combination. A hypermedia application is constructed by the combination and transformation of components, promoting the reuse of existing assets and the abstraction of common patterns. The resulting framework is flexible and practical - yet rigorous and formal - enabling the effective representation of existing engineering methods primitives without loss of expressiveness. We present a real situation in which HyCom is used in the definition of an application developed following systematic steps. By means of an example, we show the general principles underlying its use for the mapping of design concepts to implementation environments.},
key = {Hypermedia systems},
keywords = {Computer programming languages;Computer software;Computer software reusability;Program compilers;},
note = {Domain specific languages (DSL);},
} 


@article{2001035426578 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {UML as domain specific language for the construction of knowledge-based configuration systems},
journal = {International Journal of Software Engineering and Knowledge Engineering},
author = {Felfernig, Alexander and Friedrich, Gerhard E. and Jannach, Dietmar},
volume = {10},
number = {4},
year = {2000},
pages = {449 - 469},
issn = {02181940},
address = {Kaiserslautern, Ger},
abstract = {In many domains, software development has to meet the challenges of developing highly adaptable software very rapidly. In order to accomplish this task, domain specific, formal description languages and knowledge-based systems are employed. From the viewpoint of the industrial software development process, it is important to integrate the construction and maintenance of these systems into standard software engineering processes. In addition, the descriptions should be comprehensible for the domain experts in order to facilitate the review process. For the realization of product configuration systems, we show how these requirements can be met by using a standard design language (UML-Unified Modeling Language) as notation in order to simplify the construction of a logic-based description of the domain knowledge. We show how classical description concepts for expressing configuration knowledge can be introduced into UML and be translated into logical sentences automatically. These sentences are exploited by a general inference engine solving the configuration task.},
key = {Knowledge based systems},
keywords = {Computer hardware description languages;Computer simulation languages;Computer systems programming;Software engineering;},
note = {Domain specific languages;},
URL = {http://dx.doi.org/10.1016/S0218-1940(00)00024-9},
} 


@article{2004128062527 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {CodeBricks: Code fragments as building blocks},
journal = {ACM SIGPLAN Notices},
author = {Attardi, Giuseppe and Cisternino, Antonio and Kennedy, Andrew},
volume = {38},
number = {10},
year = {2003},
pages = {306 - 314},
issn = {03621340},
abstract = {We present a framework for code generation that allows programs to manipulate and generate code at the source level while the joining and splicing of executable code is carried out automatically at the intermediate code/VM level. The framework introduces a data type Code to represent code fragments: methods/operators from this class are used to reify a method from a class, producing its representation as an object of type Code. Code objects can be combined by partial application to other Code objects. Code combinators, corresponding to higher-order methods, allow splicing the code of a functional actual parameter into the resulting Code object. CodeBricks is a library implementing the framework for the .NET Common Language Runtime. The framework can be exploited by language designers to implement metaprogramming, multistage programming and other language features. We illustrate the use of the technique in the implementation of a fully featured regular expression compiler that generates code emulating a finite state automaton. We present benchmarks comparing the performance of the RE matcher built with CodeBricks with the hand written one present in .NET.},
key = {Programming theory},
keywords = {Algorithms;Codes (symbols);Computer programming languages;Computer systems programming;},
note = {Domain specific language;Generative programming;Metaprogramming;Multistage programming;Program generation;Program transformation;},
} 


@article{IP51142571 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Raising the level of abstraction for developing message passing applications},
journal = {Journal of Supercomputing},
author = {Arora, Ritu and Bangalore, Purushotham and Mernik, Marjan},
year = {2010},
pages = {1 - 22},
issn = {09208542},
abstract = {Message Passing Interface (MPI) is the most popular standard for writing portable and scalable parallel applications for distributed memory architectures. Writing efficient parallel applications using MPI is a complex task, mainly due to the extra burden on programmers to explicitly handle all the complexities of message-passing (viz., inter-process communication, data distribution, load-balancing, and synchronization). The main goal of our research is to raise the level of abstraction of explicit parallelization using MPI such that the effort involved in developing parallel applications is significantly reduced in terms of the reduction in the amount of code written manually while avoiding intrusive changes to existing sequential programs. In this research, generative programming tools and techniques are combined with a domain-specific language, Hi-PaL (High-Level Parallelization Language), for automating the process of generating and inserting the required code for parallelization into the existing sequential applications. The results show that the performance of the generated applications is comparable to the manually written versions of the applications, while requiring no explicit changes to the existing sequential code. &copy; 2010 Springer Science+Business Media, LLC.},
key = {Message passing},
keywords = {Abstracting;Problem oriented languages;},
note = {Complex task;Data distribution;Distributed memory architecture;Domain specific languages;Generative programming;Interprocess communication;Level of abstraction;Load-Balancing;Message Passing Interface;Parallel application;Parallelizations;Sequential applications;Sequential programs;},
URL = {http://dx.doi.org/10.1007/s11227-010-0490-3},
} 


@article{20102613041542 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {GrGen.NET: The expressive, convenient and fast graph rewrite system},
journal = {International Journal on Software Tools for Technology Transfer},
author = {Jakumeit, Edgar and Buchwald, Sebastian and Kroll, Moritz},
volume = {12},
number = {3},
year = {2010},
pages = {263 - 271},
issn = {14332779},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {GrGen. NET is a generative programming system for graph rewriting, transforming intuitive and expressive rewrite rule specifications into highly efficient. NET code. The user is supported by a convenient environment consisting of a graph viewer, an interactive shell with integrated debugging support, and an elegant domain-specific language for the combination of rewrite rules. After rapid prototyping with these tools, the resulting graph transformation programmes can be easily integrated into arbitrary. NET applications to serve as the algorithmic kernel. Expressiveness, convenience, and speed are exemplified by GrGen-solutions to the case studies AntWorld, Refactoring, and Conference Scheduling-besides others. &copy; 2010 Springer-Verlag.},
key = {Computer programming languages},
keywords = {Concurrent engineering;Graph theory;Job analysis;Linguistics;Pattern matching;Problem oriented languages;Rapid prototyping;},
note = {Domain specific languages;General purpose;Generative programming;Graph pattern matching;Graph rewriting;Graph Transformation;},
URL = {http://dx.doi.org/10.1007/s10009-010-0148-8},
} 


@inproceedings{20083711533223 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards reusable automation system components},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Aschauer, Thomas and Dauenhauer, Gerd and Pree, Wolfgang},
volume = {5030 LNCS},
year = {2008},
pages = {217 - 220},
issn = {03029743},
address = {Beijing, China},
abstract = {In this paper we present a domain specific language for describing an automation system, that is, its hardware and software components. These domain components form the basis of large-scale reuse so that specific automation systems can be configured efficiently. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Computer software reusability},
keywords = {Computer networks;Enterprise resource planning;Industrial engineering;},
note = {Automation systems;Component reuse;Domain specific modeling language;},
URL = {http://dx.doi.org/10.1007/978-3-540-68073-4_21},
} 


@article{20113914380369 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven generative development of measurement software},
journal = {Software and Systems Modeling},
author = {Monperrus, Martin and Jezequel, Jean-Marc and Baudry, Benoit and Champeau, Joel and Hoeltzener, Brigitte},
volume = {10},
number = {4},
year = {2011},
pages = {537 - 552},
issn = {16191366},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {Metrics offer a practical approach to evaluate properties of domain-specific models. However, it is costly to develop and maintain measurement software for each domain-specific modeling language. In this paper, we present a model-driven and generative approach to measuring models. The approach is completely domain-independent and operationalized through a prototype that synthesizes a measurement infrastructure for a domain-specific modeling language. This model-driven measurement approach is model-driven from two viewpoints: (1) it measures models of a domain-specific modeling language; (2) it uses models as unique and consistent metric specifications, with respect to a metric specification metamodel which captures all the necessary concepts for model-driven specifications of metrics. The benefit from applying the approach is evaluated by four case studies. They indicate that this approach significantly eases the measurement activities of model-driven development processes. &copy; 2010 Springer-Verlag.},
key = {Specifications},
note = {Domain specific;Domain-specific modeling language;Measurement software;Measuring model;Meta model;Model driven development;Model-driven;},
URL = {http://dx.doi.org/10.1007/s10270-010-0165-9},
} 


@inproceedings{20112414066702 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Ladybird: Debugging support in the sequencer},
journal = {Applications of Mathematics and Computer Engineering - American Conference on Applied Mathematics, AMERICAN-MATH'11, 5th WSEAS International Conference on Computer Engineering and Applications, CEA'11},
author = {Kos, Tomaz and Kosar, Tomaz and Mernik, Marjan and Knez, Jure},
year = {2011},
pages = {135 - 139},
address = {Puerto Morelos, Mexico},
abstract = {Domain-specific modeling language (DSML) allows domain-experts to play a vital role in software development lifecycle, making them programmers/modelers of new systems. Although, there are reports of numerous DSMLs and their advantages, there are some obstacles working against the more widespread adoption of DSMLs in practice. One of them is a lack of supporting tools in most of reported DSMLs, which would assist modelers and make them more efficient. This paper presents DSML called Sequencer, where debugging facilities were integrated in the development environment. Debugging support, such as different execution modes, steps, breakpoints, animations, variable views, stack traces and others have been developed for the Sequencer.},
key = {Computer debugging},
keywords = {Computer music;Mathematical techniques;Program debugging;Software design;},
note = {Break-points;Debugging support;Development environment;Domain-specific modeling language;Measurement systems;Programming language;Software development life cycle;Supporting tool;Vehicle testing;},
} 


@article{20111913961989 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A modeling language based on UML for modeling simulation testing system of avionic software},
journal = {Chinese Journal of Aeronautics},
author = {Wang, Lize and Liu, Bin and Lu, Minyan},
volume = {24},
number = {2},
year = {2011},
pages = {181 - 194},
issn = {10009361},
address = {37 Xueyuan Road, Beijing, 100191, China},
abstract = {With direct expression of individual application domain patterns and ideas, domain-specific modeling language (DSML) is more and more frequently used to build models instead of using a combination of one or more general constructs. Based on the profile mechanism of unified modeling language (UML) 2.2, a kind of DSML is presented to model simulation testing systems of avionic software (STSAS). To define the syntax, semantics and notions of the DSML, the domain model of the STSAS from which we generalize the domain concepts and relationships among these concepts is given, and then, the domain model is mapped into a UML meta-model, named UML-STSAS profile. Assuming a flight control system (FCS) as system under test (SUT), we design the relevant STSAS. The results indicate that extending UML to the simulation testing domain can effectively and precisely model STSAS. &copy; 2011 Chinese Journal of Aeronautics. All rights reserved.},
key = {Unified Modeling Language},
keywords = {Abstracting;Avionics;Computer simulation;Computer software;Contour followers;Flight control systems;Instruments;Mathematical models;Semantics;Synthetic apertures;Test facilities;},
note = {Abstract state machines;domain-specific modeling language;hardware-in-the-loop;Meta model;UML profiles;},
URL = {http://dx.doi.org/10.1016/S1000-9361(11)60022-8},
} 


@inproceedings{20104913453993 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An approach of code generation based on Model Integrated Computing},
journal = {ICCASM 2010 - 2010 International Conference on Computer Application and System Modeling, Proceedings},
author = {Wang, Yujuan and Zhou, Li and Zheng, QiuHua and Zhang, Zhen and Wu, Guohua},
volume = {15},
year = {2010},
pages = {v15114 - v15117},
address = {Shanxi, Taiyuan, China},
abstract = {Model Integrated Computing (MIC) is a theory of domain-specific modeling, using meta-model as a domain-specific modeling language (DSML), and constructing a component library for domain model. DSML abstracts the commonness and individuality in a domain, the developer employs it to construct domain model to represent the system. The final cross-platform code is automatically generated by code interpreter. In this paper, we propose an approach for designing code interpreter, it can transform domain model into a Platform Independent Model (PIM), and parsing PIM through code template, finally generating the code. This approach can shorten development time, promote reusability of code, improve work efficiency, and accomplish system rapidly. &copy; 2010 IEEE.},
key = {Computer applications},
keywords = {Network components;Reusability;},
note = {Automatically generated;Code Generation;Code interpreter;Component libraries;Cross-platform;Development time;Domain model;Domain specific modeling;Domain-specific modeling language;Meta model;MIC;Model integrated computing;Model interpreter;Platform independent model;Transform domain;Work efficiency;},
URL = {http://dx.doi.org/10.1109/ICCASM.2010.5622538},
} 


@inproceedings{20104413337729 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Object modeling language for C4ISR capability requirement analysis},
journal = {Proceedings - 2010 3rd IEEE International Conference on Computer Science and Information Technology, ICCSIT 2010},
author = {Wang, Cong and Wang, Xiao-Guo and Liu, Jun and Tian, Ming and Wang, Zhi-Xue},
volume = {3},
year = {2010},
pages = {609 - 613},
address = {Chengdu, China},
abstract = {the paper suggests a meta-ontology for C4ISR capability conceptualization. Under which, by taking advantage of the UML profile mechanism, the paper defines a domain-specific modeling language for C4ISR capability requirement. The abstract syntax, concrete syntax and formal semantic of the modeling language have been discussed in the paper. A case study of C4ISR architectural simulation modeling is provided to demonstrate the availability and applicability of the language. &copy; 2010 IEEE.},
key = {Computer simulation languages},
keywords = {Computer simulation;Information technology;Ontology;Syntactics;},
note = {Abstract syntax;Architectural modeling;Architectural simulation;C4ISR capability;Concrete syntax;Domain specific modeling;Domain-specific modeling language;Formal Semantics;Meta-ontology;Modeling languages;Object modeling;Requirement analysis;UML;UML profiles;},
URL = {http://dx.doi.org/10.1109/ICCSIT.2010.5565130},
} 


@inproceedings{20102613042125 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Improving UML profile design practices by leveraging conceptual domain models},
journal = {ASE'07 - 2007 ACM/IEEE International Conference on Automated Software Engineering},
author = {Lagarde, Francois and Espinoza, Huascar and Terrier, Francois and Gerard, Sebastien},
year = {2007},
pages = {445 - 448},
address = {Atlanta, GA, United states},
abstract = {The profile extension mechanism has permitted a rapid growth of the use of UML as a domain-specific modeling language. However, designing profiles typically falls into ad-hoc processes that often rely on domain-inappropriate primitives. One of the fundamental reasons is that profiles are specified on the same level of abstraction as the UML abstract syntax and consequently they narrow down the design space to an implementation level. In order to improvethis situation, some profile designers start from a "conceptual domain model" that states the domain ontology, and only then deal with finding out the profile extensions to support it. In spite of this, building truthfulness conceptual domain models and maintaining traceable mapping with the profile view is a bit of an art. In this paper, we propose to systematize the design of UML profiles built-upon conceptual domain models, by adopting a minimal setof framing rules. As these rules are defined on the basis of regularly occurring design patterns, domain models can be afterward checked for self-consistency and interactively transformed in stereotypes, tags and constraints. Copyright 2007 ACM.},
key = {Query languages},
keywords = {Abstracting;Computer software;Design;Markup languages;Ontology;},
note = {Abstract syntax;Ad hoc process;Design Patterns;Design practice;Design spaces;Domain model;Domain ontologies;Domain-specific modeling language;Level of abstraction;Rapid growth;Self-consistency;UML profiles;},
URL = {http://dx.doi.org/10.1145/1321631.1321705},
} 


@inproceedings{20110813675346 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MetaEdit+: Defining and using domain-specific modeling languages and code generators},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Tolvanen, Juha-Pekka and Rossi, Matti},
year = {2003},
pages = {92 - 93},
address = {Anaheim, CA, United states},
abstract = {MetaEdit+ is an environment that allows building modeling tools and generators fitting to application domains, without having to write a single line of code. The capability to define modeling tools and generators is relevant as it provides the ability to raise the abstraction of design work from code to domain concepts, and a raise in abstraction leads to an imminent raise in productivity, as illustrated by the past years' experiences. In domain-specific modeling and MetaEdit+, one expert defines a domain-specific language as a metamodel containing the domain concepts and rules, and specifies the mapping from that to code in a domain-specific code generator. For the method implementation, MetaEdit+ provides a metamodeling language and tool suite for defining the method concepts, their properties, associated rules, symbols, checking reports, and generators. Once the expert defines a modeling method, or even a partial prototype, the rest of the team can start to use it in MetaEdit+ to make models with the modeling language and the required code is automatically generated from those models. Based on the metamodel, MetaEdit+ automatically provides CASE tool functionality: diagramming editors, browsers, generators, multiuser/project/platform support, etc. The MetaEdit+ demo will focus on showing how the domainspecific languages and generators are made; complete with several examples of domain-specific methods and related code generators.},
key = {Object oriented programming},
keywords = {Abstracting;Computer aided software engineering;Computer systems programming;Problem oriented languages;},
note = {Application domains;Automatically generated;CASE tools;Code generators;Design work;Domain concepts;Domain specific;Domain specific languages;Domain-specific codes;Domain-specific modeling;Domain-specific modeling language;Line of codes;Meta model;Metamodeling;Modeling languages;Modeling method;Modeling tool;Toolsuite;},
URL = {http://dx.doi.org/10.1145/949344.949365},
} 


@inproceedings{20113914359237 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automated transformation of component-based software architecture models to queueing petri nets},
journal = {IEEE International Workshop on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems - Proceedings},
author = {Meier, Philipp and Kounev, Samuel and Koziolek, Heiko},
year = {2011},
pages = {339 - 348},
address = {Singapore, Singapore},
abstract = {Performance predictions early in the software development process can help to detect problems before resources have been spent on implementation. The Palladio Component Model (PCM) is an example of a mature domain-specific modeling language for component-based systems enabling performance predictions at design time. PCM provides several alternative model solution methods based on analytical and simulation techniques. However, existing solution methods suffer from scalability issues and provide limited flexibility in trading-off between results accuracy and analysis overhead. Queueing Petri Nets (QPNs) are a general-purpose modeling formalism, at a lower level of abstraction, for which efficient and mature simulation-based solution techniques are available. This paper contributes a formal mapping from PCM to QPN models, implemented by means of an automated model-to-model transformation as part of a new PCM solution method based on simulation of QPNs. The limitations of the mapping and the accuracy and overhead of the new solution method compared to existing methods are evaluated in detail in the context of five case studies of different size and complexity. The new solution method proved to provide good accuracy with solution overhead up to 20 times lower compared to PCM's reference solver. &copy; 2011 IEEE.},
key = {Software architecture},
keywords = {Computer simulation;Computer software;Forecasting;Petri nets;Software design;Telecommunication systems;},
note = {Automated transformations;Component based systems;Component model;Component-based software architecture;Design time;Different sizes;Domain-specific modeling language;Formal mapping;Level of abstraction;Model solution;Model to model transformation;Modeling formalisms;Non-functional;Performance prediction;Scalability issue;Simulation technique;Simulation-based;software architecture models;Software development process;Solution methods;Solution techniques;},
URL = {http://dx.doi.org/10.1109/MASCOTS.2011.23},
} 


@inproceedings{20073110742005 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a formal foundation for domain specific modeling languages},
journal = {IEEE International Conference on Embedded Software, EMSOFT 2006},
author = {Jackson, Ethan K. and Sztipanovits, Janos},
year = {2006},
pages = {53 - 62},
address = {Seoul, Korea, Republic of},
abstract = {Embedded system design is inherently domain specific and typically model driven.As a result, design methodologies like OMG's model driven architecture (MDA)and model integrated computing (MIC)evolved to support domain specific modeling language(DSMLs). The success of the DSML approach has encouraged work on the heterogeneous composition of DSMLs, model transformations between DSMLs, approximations of formal properties within DSMLs, and reuse of DSML semantics. However, in the effort to produce a mature design approach that can handle both the structural and behavioral semantics of embedded system design,many foundational issues concerning DSMLs have been overlooked. In this paper we present a formal foundation for DSMLs and for their construction within metamodeling frameworks. This foundation allows us to algorithmically decide if two DSMLs or metamodels are equivalent, if model transformations preserve properties, and if metamodeling frameworks have metametamodels. These results are key to building correct embedded systems with DSMLs. Copyright 2006 ACM.},
key = {Embedded systems},
keywords = {Computer architecture;Domain decomposition methods;Formal logic;Mathematical models;Metadata;Semantics;},
note = {Domain specific modeling language(DSML);Horn logic;Metamodeling;Model driven architecture (MDA);},
URL = {http://dx.doi.org/10.1145/1176887.1176896},
} 


@inproceedings{20112314027468 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Imprecise domain-specific modeling for C4ISR capability requirements analysis},
journal = {2011 International Conference on Information Science and Technology, ICIST 2011},
author = {Wang, Zhixue and Dong, Qingchao and He, Hongyue and Fu, Fengke},
year = {2011},
pages = {33 - 38},
address = {Nanjing, China},
abstract = {The paper proposes an approach to model the uncertain and vague requirements information of the C4ISR capability requirements. It suggests that C4ISR requirements elicitation be initiated with capability meta concept framework (CMCF) construction according to the Meta-Model of DoDAF. With the semantic confinement of CMCF, the approach extends the Fuzzy-UML and declares a C4ISR domain-specific modeling language (C4ISR DSL). Compared with classic UML and Fuzzy-UML, the C4ISR DSL is more specialized in C4ISR domain knowledge elicitation and reuse. The experiment shows the modeling language can better express both precise and vague concepts of the C4ISR capability model. &copy; 2011 IEEE.},
key = {Requirements engineering},
keywords = {Information science;Semantics;},
note = {Capability model;Domain knowledge;Domain specific modeling;Domain-specific modeling language;Meta model;Modeling languages;Requirements analysis;Requirements elicitation;},
URL = {http://dx.doi.org/10.1109/ICIST.2011.5765205},
} 


@inproceedings{20110913704348 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A formal definition of the structural semantics of Domain-Specific Modeling languages},
journal = {2nd International Conference on Information Science and Engineering, ICISE2010 - Proceedings},
author = {Jiang, Tao and Wang, Xin and Yu, Yong},
year = {2010},
pages = {1696 - 1699},
address = {Hangzhou, China},
abstract = {As a Model-Driven Development methodology (MDD) for the specific domain, Domain-Specific Modeling (DSM) has been widely and successfully used in system design and analysis of specific areas. In spite of its general important, due to informal definition of Domain-Specific Modeling Language (DSMLs), the structural semantics of DSMLs cannot be strictly described and the properties based on it also cannot be analyzed and validated. In response, the paper proposes a formal definition method of the structural semantics of DSMLs. Firstly, a formal definition of domain indicating structural semantics of DSMLs based on algebra is presented to unify DSMLs and its models in the domain, secondly, a mapping mechanism from domain to the corresponding first-order logic system is established to finish analysis and validation of properties of domain such as consistency based on first-order logical inference, based on this, the method of formalization and consistency analysis and validation of structural semantics of DSMLs based on first-order logic is presented, finally, the formalization automatic mapping engine for model and metamodel is introduced to show the application of formalization of structural semantics in analysis and validation of properties of models. &copy; 2010 IEEE.},
key = {Structural analysis},
keywords = {Formal logic;High level languages;Information science;Mapping;Semantics;Systems analysis;},
note = {Consistency;Domain;Domain mapping;Domain-specific modeling language (dsmls);First-order logic;Structural semantics;},
URL = {http://dx.doi.org/10.1109/ICISE.2010.5689083},
} 


@inproceedings{20113514267968 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Simplification of semantically-rich model transformations through generated transformation blocks},
journal = {Proceedings - 18th IEEE International Conference and Workshops on Engineering of Computer-Based Systems, ECBS 2011},
author = {Hudson, Maribel and Sprinkle, Jonathan},
year = {2011},
pages = {260 - 268},
address = {Las Vegas, NV, United states},
abstract = {This paper demonstrates a novel concept for the simplification of model transformations in which composite or complex objects are inserted into an existing model through a well-defined interface. The technique utilizes a model transformation from the domain of the modeling language into the domain of model transformation languages. The user specifies these semantically rich blocks using the original domain-specific modeling language. Then, a transformation generates the necessary model transformation graph to create an instance of the semantically rich, user-defined pattern. Users insert these generated patterns into their customized transformations. The approach is helpful for endogenous transformations in which existing objects may be refactored. It will also serve as a teaching tool for users who are unfamiliar with model transformations: specifically how to represent a newly-created model in the transformation domain. Finally, the approach is designed to reduce specification errors of model transformations in which new (semantically rich) blocks are inserted at key points, as the correctness of the semantically rich blocks is guaranteed, based on their construction in the original domain. &copy; 2011 IEEE.},
key = {Technical presentations},
keywords = {Interfaces (computer);},
note = {Complex objects;Domain specific modeling;Domain-specific modeling language;Generative transformations;Keypoints;Model transformation;Modeling languages;Novel concept;Teaching tools;Transformation domain;Transformation simplification;},
URL = {http://dx.doi.org/10.1109/ECBS.2011.28},
} 


@inproceedings{20105213530543 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven engineering of industrial process control applications},
journal = {Proceedings of the 15th IEEE International Conference on Emerging Technologies and Factory Automation, ETFA 2010},
author = {Lukman, Tomaz and Godena, Giovanni and Gray, Jeff and Strmcnik, Stanko},
year = {2010},
pages = {IEEE Industrial Electronics Society - },
address = {Bilbao, Spain},
abstract = {Software is an important part of industrial process control systems. However, the state-of-the-practice for developing industrial process control software still has several key challenges that need to be addressed (e.g., migration to platforms of different vendors, lack of automation). This paper introduces a model-driven engineering approach to the development of industrial process control software, which is based on the ProcGraph domain-specific modeling language. The paper discusses and offers solutions to several of the development challenges that have not been addressed by existing techniques in the process controls domain. The contributions of the paper are a model-driven engineering approach for the industrial process control domain and a supporting tool infrastructure. The approach is demonstrated by a case study focused on the development of a control system for a TiO<inf>2</inf> (titanium dioxide) pigment production subprocess. &copy;2010 IEEE.},
key = {Process control},
keywords = {Control systems;Factory automation;Industry;Remote control;Systems analysis;Titanium;Titanium dioxide;},
note = {Domain-specific modeling language;Industrial process control;Model-driven Engineering;Pigment production;Supporting tool;TiO;},
URL = {http://dx.doi.org/10.1109/ETFA.2010.5641224},
} 


@article{20094012362337 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain specific software modeling by using FODA},
journal = {Huazhong Keji Daxue Xuebao (Ziran Kexue Ban)/Journal of Huazhong University of Science and Technology (Natural Science Edition)},
author = {Quan, Wei and Xing, Zhongbao and Wang, Bidou and Wei, Chunjie},
volume = {37},
number = {8},
year = {2009},
pages = {35 - 38},
issn = {16714512},
address = {Wuhan, Hubei, 430074, China},
abstract = {A domain-specific modeling method based on feature-oriented domain analysis (FODA) is presented to improve the efficiency of software development in specific domain. FODA method was used to analyze the specific domain, and a feature model is obtained. According to the feature model the domain meta-model can be built, from which the domain-specific modeling language (DSML) can be generated by the meta-model interpreter. When developing a new system in this domain, one can thus follow these two steps: firstly, constructing the user model of the system using DSML; secondly, generating the source code by model interpreter and an application system can be complied. This method is applied to the domain of clinical analyzer. The result indicates that the efficiency of developing a new system of the domain has been improved, thus it will be a reference for other domains.},
key = {Model buildings},
keywords = {Computer software reusability;Electric load management;Reusability;Software engineering;},
note = {Application systems;Domain analysis;Domain specific;Domain specific modeling;Domain-specific modeling (DSM);Domain-specific modeling language;Feature model;Feature models;Feature-oriented;Generic modeling environment (GME);Meta-model;Model interpreter;New system;Software development;Software modeling;Source codes;User models;},
} 


@inproceedings{20104813445700 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Workflow-driven tool integration using model transformations},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Balogh, Andras and Bergmann, Gabor and Csertan, Gyorgy and Gonczy, Laszlo and Horvath, Akos and Majzik, Istvan and Pataricza, Andras and Polgar, Balazs and Rath, Istvan and Varro, Daniel and Varro, Gergely},
volume = {5765 LNCS},
year = {2010},
pages = {224 - 248},
issn = {03029743},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {The design of safety-critical systems and business-critical services necessitates to coordinate between a large variety of tools used in different phases of the development process. As certification frequently prescribes to achieve justified compliance with regulations of authorities, integrated tool chain should strictly adhere to the development process itself. In order to manage complexity, we follow a model-driven approach where the development process is captured using a precise domain-specific modeling language. Each individual step within this process is represented transparently as a service. Moreover, to carry out individual tasks, systems engineers are guided by semi-automated transformation steps and well-formedness constraint checking. Both of them are formalized by graph patterns and graph transformation rules as provided by the Viatra2 framework. In our prototype implementation, we use the popular JBPM workflow engine as orchestration means between different design and verification tools. We also give some insights how this tool integration approach was applied in recent projects. &copy; 2010 Springer-Verlag Berlin Heidelberg.},
key = {Systems analysis},
keywords = {Graph theory;Laws and legislation;Management;},
note = {Critical service;Development process;Domain-specific modeling language;Graph patterns;Graph transformation rules;Integrated tools;Model driven approach;Model transformation;Prototype implementations;Safety critical systems;Semi-automated;Systems engineers;Tool integration;Verification tools;Workflow engines;},
URL = {http://dx.doi.org/10.1007/978-3-642-17322-6_11},
} 


@inproceedings{20094012360920 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using UML profiles to interchange DSML and UML models: A proposal for MDD approaches},
journal = {Proceedings of the 2009 3rd International Conference on Research Challenges in Information Science, RCIS 2009},
author = {Giachetti, Giovanni and Marin, Beatriz and Pastor, Oscar},
year = {2009},
pages = {385 - 394},
address = {Fez, Morocco},
abstract = {A key requirement for MDD solutions is to have a modeling language that allows the correct representation of conceptual models. Nowadays, there are two options that are the most widely used for the definition of these modeling languages: 1) the specification of a domain-specific modeling language (DSML) or 2) the customization of UML. In practice, these two modeling alternatives are viewed as opposite solutions. However, since both alternatives provide benefits for the application of MDD solutions, in this paper, we present a proposal that uses UML profile extension mechanisms to interchange modeling information between DSML-based models and UML models. This proposal shows how these two modeling alternatives can be integrated in a unique MDD solution. &copy; 2009 IEEE.},
key = {Markup languages},
keywords = {Interchanges;Linguistics;Query languages;},
note = {Conceptual model;Domain-specific modeling language;DSML;MDD;Modeling languages;UML;UML Model;UML profile;UML profiles;},
URL = {http://dx.doi.org/10.1109/RCIS.2009.5089302},
} 


@inproceedings{20083911595310 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automated middleware QoS configuration techniques using model transformations},
journal = {Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOC},
author = {Kavimandan, Amogh and Gokhale, Aniruddha},
year = {2007},
issn = {15417719},
address = {Annapolis, MD, United states},
abstract = {This paper provides following three contributions to the study of developing and applying model driven engineering (MDE) techniques to Quality of Service (QoS) configuration of distributed real-time and embedded (DRE) systems. First, we describe the challenges associated with mapping domain-level QoS policies of DRE systems to middleware configuration space. Second, we discuss a domain specific modeling language (DSML) to capture QoS requirements of DRE system at a higher level of abstraction, simplifying the system QoS specification process. Third, we describe model transformations to automate the mapping of domain-specific QoS requirements.Our results indicate that our approach provides significant benefits in terms of productivity, scalability, reusability and automation of middleware QoS mapping compared to traditional QoS configuration techniques for publish/subscribe-based DRE systems. &copy;2008 IEEE.},
key = {Quality of service},
keywords = {Computer software;Conformal mapping;Embedded systems;Middleware;Real time systems;Technology;Wave functions;},
note = {Configuration spaces;Distributed Real-time and Embedded Systems;Domain specific modeling language;Domain-specific;DRE systems;Enterprise distributed object computing;Level of abstraction;Model transformations;Model-driven engineering;Publish/subscribe;QoS mapping;QOS requirements;QoS specifications;},
URL = {http://dx.doi.org/10.1109/EDOCW.2007.5},
} 


@inproceedings{20092912200714 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Raising the abstraction of domain-specific model translator development},
journal = {Proceedings of the International Symposium and Workshop on Engineering of Computer Based Systems},
author = {Vajk, Tamas and Kereskenyi, Robert and Levendovszky, Tihamer and Ledeczi, Akos},
year = {2009},
pages = {31 - 37},
address = {San Francisco, CA, United states},
abstract = {Model-based development methodologies are gaining ground as software applications are getting more and more complex while the pressure to decrease time-to-market continually increase. Domain-specific modeling tools that support system analysis, simulation, and automatic code generation can increase productivity. However, most domain-specific model translators are still manually written. This paper presents a technique that automatically generates a domain-specific application programming interface from the same metamodels that are used to define the domain-specific modeling language itself. This facilitates the creation of domain-specific model translators by providing a high-level abstraction hiding all the cumbersome modeling tool-specific implementation details from the developer. The approach is illustrated using the Generic Modeling Environment and the Microsoft .NET C# language. &copy; 2009 IEEE.},
key = {Automatic programming},
keywords = {Abstracting;Application programming interfaces (API);Linguistics;Network components;Systems analysis;},
note = {Automatic code generations;Code generation;Domain specific;Domain-specific application;Domain-specific modeling;Domain-specific modeling language;Generic modeling;High-level abstraction;Meta model;Metamodeling;Microsoft .NET;Model based development;Model translators;Modeling tool;Software applications;Support systems;Time-to-market;Translator;},
URL = {http://dx.doi.org/10.1109/ECBS.2009.30},
} 


@inproceedings{20100412653449 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Poster abstract: Prototyping a software factory for wireless sensor networks},
journal = {Proceedings of the 7th ACM Conference on Embedded Networked Sensor Systems, SenSys 2009},
author = {Naumowicz, Tomasz and Schroter, Benjamin and Schiller, Jochen},
year = {2009},
pages = {369 - 370},
address = {Berkeley, CA, United states},
abstract = {Wireless sensor networks (WSNs) are often advertised with high sensing accuracy, long lifetime, and easy deployment. However, they are still not widely used in environmental research due to of poor tool support and high complexity. A wider use of WSNs in field science would enable researchers to address scientific questions that are infeasible today. To address this issue, we designed and prototyped a Software Factory for WSNs that hides the complexity of software development for embedded systems. It exposes a visual domain-specific modeling language and supports code generation for resource constrained devices. The proposed Software Factory simplifies the integration of domain experts into the development process, making WSNs more attractive as a tool for researchers from outside of the computer science field. This could lead to a wider adoption of WSNs in field sciences.},
key = {Wireless sensor networks},
keywords = {Embedded software;Embedded systems;Linguistics;Problem oriented languages;Query languages;Research;Sensor networks;Software prototyping;Wireless telecommunication systems;},
note = {Code Generation;Development process;Domain experts;Domain specific languages;Domain-specific modeling language;Environmental researches;In-field;Long lifetime;Prototyping;Resourceconstrained devices;Sensing accuracy;Software development;Software factories;Software factory;Tool support;},
URL = {http://dx.doi.org/10.1145/1644038.1644106},
} 


@inproceedings{20073110738080 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a model-based application integration framework for smart oilfields},
journal = {Proceedings of the 2006 IEEE International Conference on Information Reuse and Integration, IRI-2006},
author = {Zhang, Cong and Bakshi, Amol and Prasanna, Viktor and Da Sie, Will},
year = {2006},
pages = {545 - 550},
address = {Waikoloa Village, HI, United states},
abstract = {The increasing demand for cost-effective oil and gas production has led to an industry-wide push to develop smart oilfields for the future. Applications for smart oilfields are characterized with heterogeneous data and resources, complicated business processes, and changing business requirements from users. Existing software development process and techniques have become increasingly incapable of managing such complex software systems. Model-based integration frameworks are based on a domain-specific modeling language and a common model database. They offer the benefits of extensibility, modularity, and resuability of both code and design to the applications. In this paper, we describe a prototype integration framework for a class of oilfield applications. To demonstrate the advantages of the integration framework, we will show how applications are developed and integrated in the framework in a systematic manner. &copy; 2006 IEEE.},
key = {Software engineering},
keywords = {Database systems;Industrial applications;Integration;Mathematical models;Oil field development;},
note = {Domain specific modeling language;Integration frameworks;Software development process;},
URL = {http://dx.doi.org/10.1109/IRI.2006.252472},
} 


@article{20111013723773 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Time-triggered buffers for event-based middleware systems},
journal = {Innovations in Systems and Software Engineering},
author = {Sprinkle, Jonathan and Eames, Brandon},
volume = {7},
number = {1},
year = {2011},
pages = {9 - 22},
issn = {16145046},
address = {The Guildway, Old Portsmouth Road, Artington, Guildford, GU3 1LP, United Kingdom},
abstract = {Application developers utilizing event-based middleware have sought to leverage domain-specific modeling for the advantages of intuitive specification, code synthesis, and support for design evolution. For legacy and cysber-physical systems, the use of event-based middleware may mean that changes in computational platform can result anomalous system behavior, due to the presence of implicit temporal dependencies. These anomalies are a function not of the component implementation, but of the model of computation employed for supporting system composition. In order to address these behavioral anomalies, the paper presents an approach where time-based blocks are inserted into the system to account for the temporal dependencies. An advantage of capturing the system composition in a domain-specific modeling language is the ability to efficiently re factor an application to include time-triggered, event-based schedulers. This paper describes how an existing event-based component topology can be modified to permit a time-triggered model of computation, with no changes to the existing component software. Further, the time-triggered components can be deployed alongside standard publish/subscribe methodologies. This strategy is beneficial to the maintenance of existing legacy systems upon upgrade, since the current operational mode could be maintained with minimal changes to the legacy software even under changes to the target platform which alter execution speed. These time-triggered layers are discussed in three permutations: fully triggered, start triggered, and release triggered. A discussion is provided regarding the limitations of each approach, and a brief example is given. The example shows how to apply these triggering approaches without the modification of existing components, but instead through the insertion of triggered buffers between legacy components. &copy; Springer-Verlag London Limited 2010.},
key = {Real time systems},
keywords = {Behavioral research;Computer software maintenance;Embedded systems;Legacy systems;Middleware;Topology;},
note = {Application developers;Code synthesis;Component software;Computational platforms;Design evolution;Distributed real time system;Domain specific modeling;Domain-specific modeling language;Event-based;Event-based middleware;Execution speed;Giotto;Legacy component;Legacy software;Logical execution time;Model of computation;Model transformations;Operational modes;Physical systems;Publish/subscribe;Supporting systems;System behaviors;System composition;Time triggered;Time-triggered model;},
URL = {http://dx.doi.org/10.1007/s11334-010-0139-7},
} 


@article{IP51405294 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain-specific modeling approach to realizing user-centric communication},
journal = {Software - Practice and Experience},
author = {Wu, Yali and Allen, Andrew A. and Hernandez, Frank and France, Robert and Clarke, Peter J.},
year = {2011},
issn = {00380644},
abstract = {Advances in communication devices and technologies are dramatically expanding our communication capabilities and enabling a wide range of multimedia communication applications. The current approach to develop communication-intensive applications results in products that are fragmented, inflexible, and incapable of responding to changing end-users' communication needs. These limitations have resulted in the need for a new development approach of building communication applications that are driven by end-users and that support the dynamic nature of communication-based collaboration. To address this need, the Communication Virtual Machine (CVM) technology has been developed to support rapid specification and automatic realization of user-centric communication applications based on a domain-specific modeling approach. The CVM technology consists of a domain-specific modeling language (DSML), the Communication Modeling Language (CML), that is used to create communication models, and a semantic rich platform, the CVM, that realized the created communication models. In this paper, we report on our experiences of applying a systematic approach to engineering CML and the synthesis of CML models in CVM. Based on a feature model describing the taxonomy of the user-centric communication domain in a network independent manner, we develop the meta-model of CML and its different concrete syntaxes. We also present a behavioral specification (dynamic semantics) of CML that enables the dynamic synthesis of user-centric communication models into an executable form called communication control script. We validated the CML semantics using Kermeta, a meta-programming environment for engineering DSMLs, and evaluated the practicality of our approach using a CVM prototype and a set of experiments. Copyright &copy; 2011 John Wiley &amp; Sons, Ltd.},
key = {Communication},
keywords = {Information theory;Models;Multimedia systems;Semantics;Specifications;},
note = {Behavioral specification;Communication application;Communication capabilities;Communication control;Communication device;Communication domain;Communication models;Communication virtual machine;Concrete syntax;Development approach;Domain specific modeling;Domain-specific modeling language;Dynamic nature;Dynamic semantic;Dynamic synthesis;End-users;Feature models;Meta model;Meta Programming;Modeling languages;Multimedia communication;User-centric;},
URL = {http://dx.doi.org/10.1002/spe.1081},
} 


@inproceedings{20113214218285 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven performance analysis of reconfigurable conveyor systems used in material handling applications},
journal = {Proceedings - 2011 IEEE/ACM 2nd International Conference on Cyber-Physical Systems, ICCPS 2011},
author = {An, Kyoungho and Trewyn, Adam and Gokhale, Aniruddha and Sastry, Shivakumar},
year = {2011},
pages = {141 - 150},
address = {Chicago, IL, United states},
abstract = {Reconfigurable conveyors are increasingly being adopted in multiple industrial sectors for their immense flexibility in adapting to new products and product lines. Before modifying the layout of the conveyor system for the new product line, however, engineers and layout planners must be able to answer many questions about the system, such as maximum sustainable rate of flow of goods, prioritization among goods, and tolerances of failures. Any analysis capability that provides answers to these questions must account for both the physical and cyber artifacts of the reconfigurable system all at once. Moreover, the same system should enable the stakeholders to seamlessly change the layouts and be able to analyze the pros and cons of the layouts. This paper addresses these challenges by presenting a model-driven analysis tool that provides three important capabilities. First, a domain-specific modeling language provides the stakeholders with intuitive artifacts to model conveyor layouts. Second, an analysis engine embedded within the model-driven tool provides an accurate simulation of the modeled conveyor system accounting for both the physical and cyber issues. Third, generative capabilities within the tool help to automate the analysis process. The merits of our model-driven analysis tool are evaluated in the context of an example conveyor topology. &copy; 2011 IEEE.},
key = {Computer simulation},
keywords = {Conveyors;Embedded systems;Materials handling;Structural design;Topology;},
note = {All-at-once;Analysis capabilities;Analysis process;Analysis tools;Conveyor systems;design-time analysis;Domain-specific modeling language;Industrial sector;Material handling;Model-based simulations;Model-driven;New product;Performance analysis;Prioritization;Product-lines;Re-configurable;Reconfigurable conveyors;Reconfigurable systems;},
URL = {http://dx.doi.org/10.1109/ICCPS.2011.12},
} 


@inproceedings{20105013474380 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Integration of multiagent systems and service oriented architectures in the steel industry},
journal = {Proceedings - 2010 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, IAT 2010},
author = {Jacobi, Sven and Hahn, Christian and Raber, David},
volume = {2},
year = {2010},
pages = {479 - 482},
address = {Toronto, ON, Canada},
abstract = {In the course of globalization competitive pressure is rising in most industrial sectors. High quality products are basic prerequisites for companies of high wage countries to be present on the global market. Improved adherence to delivery date, increased flexibility despite to decreased production costs are some examples of the challenges to be managed just to keep current positions. In general, these requirements are mostly requirements on the processes-not on the actual products. Economic efficiency is not any longer just a property of products and quality, but more and more a property of processes. Thus, process capability is getting more important beside production capability. This paper shows how service-oriented architectures (SOA) and multi-agent systems (MAS) can be integrated using a model-driven approach. In fact, a model transformation from SoaML - a metamodel for SOA - to DSML4MAS - a domain-specific modeling language for MAS - is utilized for the integration. The relevance of this approach is proven by applying it to a real-world industry scenario. This includes modeling a segment of a production chain of Saarstahl AG - a global respected steel manufacturer. The presented approach helps to increase flexibility of mid and short term planning and scheduling along the chosen segment and thus improve processes. &copy; 2010 IEEE.},
key = {Service oriented architecture (SOA)},
keywords = {Industry;Information services;International trade;Iron and steel plants;Multi agent systems;Steelmaking;},
note = {Competitive pressure;Delivery dates;Domain-specific modeling language;Economic efficiency;Global market;High-quality products;Increased flexibility;Industrial sector;Meta model;Model driven approach;Model transformation;Process capabilities;Production capabilities;Production chain;Production cost;Products and quality;Real-world;Short term planning;Steel industry;},
URL = {http://dx.doi.org/10.1109/WI-IAT.2010.218},
} 


@inproceedings{20111313881205 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Flexible sketch-based requirements modeling},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Wuest, Dustin and Glinz, Martin},
volume = {6606 LNCS},
year = {2011},
pages = {100 - 105},
issn = {03029743},
address = {Essen, Germany},
abstract = {[Context and motivation] Requirements engineers and stakeholders like to create informal, sketchy models in order to communicate ideas and to make them persistent. They prefer pen and paper over current software modeling tools, because the former allow for any kind of sketches and do not break the creative flow. [Question/problem] To facilitate requirements management, engineers then need to manually transform the sketches into more formal models of requirements. This is a tedious, time-consuming task. Furthermore, there is a risk that the original intentions of the sketched models and informal annotations get lost in the transition. [Principal ideas/results] We present the idea for a seamless, tool-supported transition from informal, sketchy drafts to more formal models such as UML diagrams. Our approach uses an existing sketch recognizer together with a dynamic library of modeling symbols. This library can be augmented and modified by the user anytime during the sketching/modeling process. Thus, an engineer can start sketching without any restrictions, and can add both syntax and semantics later. Or the engineer can define a domain-specific modeling language with any degree of formality and adapt it on the fly. [Contribution] In this paper we describe how our approach combines the advantages of modeling with the freedom and ease of sketching in a way other modeling tools cannot provide. &copy; 2011 Springer-Verlag Berlin Heidelberg.},
key = {Engineering},
keywords = {Computer software selection and evaluation;Engineers;Requirements engineering;Semantics;},
note = {adaptable formalization;Domain-specific modeling language;Formal model;Modeling tool;On the flies;Over current;Requirements engineers;Requirements management;requirements modeling;Requirements sketching;Software modeling tools;Time-consuming tasks;UML diagrams;},
URL = {http://dx.doi.org/10.1007/978-3-642-19858-8_12},
} 


@article{IP51146247 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Reusable model transformations},
journal = {Software and Systems Modeling},
author = {Sen, Sagar and Moha, Naouel and Mahe, Vincent and Barais, Olivier and Baudry, Benoit and Jezequel, Jean-Marc},
year = {2010},
pages = {1 - 15},
issn = {16191366},
abstract = {Model transformations written for an input metamodel may often apply to other metamodels that share similar concepts. For example, a transformation written to refactor Java models can be applicable to refactoring UML class diagrams as both languages share concepts such as classes, methods, attributes, and inheritance. Deriving motivation from this example, we present an approach to make model transformations reusable such that they function correctly across several similar metamodels. Our approach relies on these principal steps: (1) We analyze a transformation to obtain an effective subset of used concepts. We prune the input metamodel of the transformation to obtain an effective input metamodel containing the effective subset. The effective input metamodel represents the true input domain of transformation. (2) We adapt a target input metamodel by weaving it with aspects such as properties derived from the effective input metamodel. This adaptation makes the target metamodel a subtype of the effective input metamodel. The subtype property ensures that the transformation can process models conforming to the target input metamodel without any change in the transformation itself. We validate our approach by adapting well known refactoring transformations (Encapsulate Field, Move Method, and Pull Up Method) written for an in-house domain-specific modeling language (DSML) to three different industry standard metamodels (Java, MOF, and UML). &copy; 2010 Springer-Verlag.},
key = {Java programming language},
note = {Domain-specific modeling language;Industry standards;Java models;Meta model;Model transformation;Process model;Pull up;Refactorings;UML class diagrams;},
URL = {http://dx.doi.org/10.1007/s10270-010-0181-9},
} 


@article{20100212621898 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A flexible infrastructure for multilevel language engineering},
journal = {IEEE Transactions on Software Engineering},
author = {Atkinson, Colin and Gutheil, Matthias and Kennel, Bastian},
volume = {35},
number = {6},
year = {2009},
pages = {742 - 755},
issn = {00985589},
address = {445 Hoes Lane / P.O. Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {Although domain-specific modeling tools have come a long way since the modern era of model-driven development started in the early 1990s and now offer an impressive range of features, there is still significant room for enhancing the flexibility they offer to end users and for combining the advantages of domain-specific and general-purpose languages. To do this, however, it is necessary to enhance the way in which the current generation of tools view metamodeling and support the representation of the multiple, ontological classification levels that often exist in subject domains. State-of-the-art tools essentially allow users to describe the abstract and concrete syntaxes of a language in the form of metamodels and to make statements in that language in the form of models. These statements typically convey information in terms of types and instances in the domain (e.g., the classes and objects of UML), but not in terms of types of types (i.e., domain metaclasses), and types of types of types, and so on, across multiple classification levels. In essence, therefore, while they provide rich support for linguistic metamodeling, the current generation of tools provides little if any built-in support for modeling ontological classification across more than one type/instance level in the subject domain. In this paper, we describe a prototype implementation of a new kind of modeling infrastructure that, by providing built-in support for multiple ontological as well as linguistic classification levels, offers various advantages over existing language engineering approaches and tools. These include the ability to view a single model from the perspective of both a general-purpose and a domain-specific modeling language, the ability to define constraints across multiple ontological classification levels, and the ability to tie the rendering of model elements to ontological as well as linguistic types over multiple classification levels. After first outlining the key conceptual ingredients of this new infrastructure and presenting the main elements of our current realization, we show these benefits through two small examples. &copy; 2009 IEEE.},
key = {Query languages},
keywords = {Computational linguistics;Ontology;Software prototyping;},
note = {Concrete syntax;Current generation;Domain specific;Domain specific modeling;Domain-specific modeling language;End users;Language engineering;Linguistic classification;Meta model;Metamodeling;Model driven development;Model elements;Modeling infrastructures;Multi-level languages;Multilevel modeling;Multiple Classification;Prototype implementations;},
URL = {http://dx.doi.org/10.1109/TSE.2009.31},
} 


@inproceedings{20110813686656 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An aspect-oriented generative approach},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Kulesza, Uira and Garcia, Alessandro and Lucena, Carlos},
year = {2004},
pages = {166 - 167},
address = {Vancouver, BC, Canada},
abstract = {The integration of generative and aspect-oriented techniques is not a trivial task. This paper describes our experience in the definition of an aspect-oriented generative approach for the context of multi-agent systems. Our generative approach is composed of: (i) a domain-specific language called Agent-DSL, which allows to model crosscutting and non-crosscuting agent features; (ii) an aspect-oriented architecture that models a family of software agents; and (iii) a code generator that maps abstractions of the Agent-DSL to specific compositions of objects and aspects in specific implementations of agent architectures. The use of aspect-oriented techniques in the definition of our generative approach brought benefits to the modeling and code generation of crosscutting features since early design stages.},
key = {Object oriented programming},
keywords = {Aspect oriented programming;Automatic programming;Computer systems programming;Intelligent agents;Multi agent systems;Network components;Problem oriented languages;Program compilers;Software agents;Software design;},
note = {Agent architectures;Aspect oriented software development;Aspect-oriented;Aspect-oriented architecture;Code Generation;Code generators;Crosscutting features;Domain specific languages;Early design stages;Generative programming;},
URL = {http://dx.doi.org/10.1145/1028664.1028732},
} 


@inproceedings{20104113278010 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generating safe template languages},
journal = {ACM SIGPLAN Notices},
author = {Heidenreich, Florian and Johannes, Jendrik and Seifert, Mirko and Wende, Christian and Bohme, Marcel},
volume = {45},
number = {2},
year = {2010},
pages = {99 - 108},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Template languages are widely used within generative programming, because they provide intuitive means to generate software artefacts expressed in a specific object language. However, most template languages perform template instantiation on the level of string literals, which allows neither syntax checks nor semantics analysis. To make sure that generated artefacts always conform to the object language, we propose to perform static analysis at template design time. In addition, the increasing popularity of domainspecific languages (DSLs) demands an approach that allows to reuse both the concepts of template languages and the corresponding tools. In this paper we address the issues mentioned above by presenting how existing languages can be automatically extended with generic template concepts (e.g., placeholders, loops, conditions) to obtain safe template languages. These languages provide means for syntax checking and static semantic analysis w.r.t. the object language at template design time.We discuss the prerequisites for this extension, analyse the types of correctness properties that can be assured at template design time, and exemplify the key benefits of this approach on a textual DSL and Java. Copyright &copy; 2009 ACM.},
key = {Java programming language},
keywords = {Design;Syntactics;},
note = {Correctness properties;Domain specific languages;Generative programming;Generic templates;Language extensions;Literals;Placeholders;Safe authoring;Semantics analysis;Software artefacts;Static-semantic analysis;Template designs;Template language;},
URL = {http://dx.doi.org/10.1145/1837852.1621624},
} 


@inproceedings{20110513635337 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {C++ metastring library and its applications},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Szugyi, Zalan and Sinkovics, Abel and Pataki, Norbert and Porkolab, Zoltan},
volume = {6491 LNCS},
year = {2011},
pages = {461 - 480},
issn = {03029743},
address = {Braga, Portugal},
abstract = {C++ template metaprogramming is an emerging direction of generative programming: with proper template definitions we can enforce the C++ compiler to execute algorithms at compilation time. Template metaprograms have become essential part of today's C++ programs of industrial size; they provide code adoptions, various optimizations, DSL embedding, etc. Besides the compilation time algorithms, template metaprogram data-structures are particularly important. From simple typelists to more advanced STL-like data types there are a variety of such constructs. Interesting enough, until recently string, as one of the most widely used data type of programming, has not been supported. Although, boost::mpl::string is an advance in this area, it still lacks the most fundamental string operations. In this paper, we analysed the possibilities of handling string objects at compilation time with a metastring library. We created a C++ template metaprogram library that provides the common string operations, like creating sub-strings, concatenation, replace, and similar. To provide real-life use-cases we implemented two applications on top of our Metastring library. One use case utilizes compilation time inspection of input in the domain of pattern matching algorithms, thus we are able to select the more optimal search method at compilation time. The other use-case implements safePrint, a type-safe version of printf - a widely investigated problem. We present both the performance improvements and extended functionality we have achieved in the applications of our Metastring library. &copy; 2011 Springer-Verlag.},
key = {Time domain analysis},
keywords = {Algorithms;Computer programming;Computer software;Optimization;Pattern matching;},
note = {C++ templates;Data type;Generative programming;Industrial size;Metaprograms;Optimal search;Pattern matching algorithms;Performance improvements;Sub-strings;Time algorithms;},
URL = {http://dx.doi.org/10.1007/978-3-642-18023-1_15},
} 


@inproceedings{20111113739591 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A study of automatic code generation},
journal = {Proceedings - 2010 International Conference on Computational and Information Sciences, ICCIS 2010},
author = {Liao, Haode and Jiang, Jun and Zhang, Yuxin},
year = {2010},
pages = {689 - 691},
address = {Chengdu, Sichuan, China},
abstract = {Automatic code generation is the study of generative programming in the sense that the source code is generated automatically. In this paper, an approach based on component techniques that can produce in a systematic way correct, compatible and efficient database structures and manipulation function modules from abstract models is proposed. In contrast to some conventional software engineering methods, this approach has certain merits of improving software quality and shortening the software development cycle. &copy; 2010 IEEE.},
key = {Automatic programming},
keywords = {Computer software selection and evaluation;Information science;Network components;Software design;},
note = {Abstract models;Automatic code generations;Component techniques;Database structures;Generative programming;Manipulation functions;Software development cycles;Software engineering methods;Software Quality;Source codes;},
URL = {http://dx.doi.org/10.1109/ICCIS.2010.171},
} 


@inproceedings{20094812518485 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generating safe template languages},
journal = {GPCE'09 - Proceedings of the 8th International ACM SIGPLAN Conference on Generative Programming and Component Engineering},
author = {Heidenreich, Florian and Johannes, Jendrik and Seifert, Mirko and Wende, Christian and Bohme, Marcel},
year = {2009},
pages = {99 - 108},
address = {Denver, CO, United states},
abstract = {Template languages are widely used within generative programming, because they provide intuitive means to generate software artefacts expressed in a specific object language. However, most template languages perform template instantiation on the level of string literals, which allows neither syntax checks nor semantics analysis. To make sure that generated artefacts always conform to the object language, we propose to perform static analysis at template design time. In addition, the increasing popularity of domain-specific languages (DSLs) demands an approach that allows to reuse both the concepts of template languages and the corresponding tools. In this paper we address the issues mentioned above by presenting how existing languages can be automatically extended with generic template concepts (e.g., placeholders, loops, conditions) to obtain safe template languages. These languages provide means for syntax checking and static semantic analysis w.r.t. the object language at template design time. We discuss the prerequisites for this extension, analyse the types of correctness properties that can be assured at template design time, and exemplify the key benefits of this approach on a textual DSL and Java. Copyright &copy; 2009 ACM.},
key = {Query languages},
keywords = {Linguistics;Problem oriented languages;Semantics;Syntactics;},
note = {Correctness properties;Domain specific languages;Generative programming;Generic templates;Literals;Placeholders;Semantics analysis;Software artefacts;Static-semantic analysis;Template designs;},
URL = {http://dx.doi.org/10.1145/1621607.1621624},
} 


@inproceedings{20110213563847 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Functional programming with C++ template metaprograms},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Porkolab, Zoltan},
volume = {6299 LNCS},
year = {2010},
pages = {306 - 353},
issn = {03029743},
address = {Komarno, Slovakia},
abstract = {Template metaprogramming is an emerging new direction of generative programming. With the clever definitions of templates we can force the C++ compiler to execute algorithms at compilation time. Among the application areas of template metaprograms are the expression templates, static interface checking, code optimization with adaption, language embedding and active libraries. However, as template metaprogramming was not an original design goal, the C++ language is not capable of elegant expression of metaprograms. The complicated syntax leads to the creation of code that is hard to write, understand and maintain. Although template metaprogramming has a strong relationship with functional programming, this is not reflected in the language syntax and existing libraries. In this paper we give a short and incomplete introduction to C++ templates and the basics of template metaprogramming. We will enlight the role of template metaprograms, and some important and widely used idioms. We give an overview of the possible application areas as well as debugging and profiling techniques. We suggest a pure functional style programming interface for C++ template metaprograms in the form of embedded Haskell code which is transformed to standard compliant C++ source. &copy; 2010 Springer-Verlag.},
key = {Functional programming},
keywords = {Libraries;Syntactics;},
note = {Application area;C++ language;C++ templates;Code optimization;Expression templates;Generative programming;Haskell;Language syntax;Metaprograms;New directions;Original design;Programming interface;Template metaprogramming;},
URL = {http://dx.doi.org/10.1007/978-3-642-17685-2_9},
} 


@article{20110813689427 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Lightweight modular staging: A pragmatic approach to runtime code generation and compiled DSLs},
journal = {ACM SIGPLAN Notices},
author = {Rompf, Tiark and Odersky, Martin},
volume = {46},
number = {2},
year = {2011},
pages = {127 - 136},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Software engineering demands generality and abstraction, performance demands specialization and concretization. Generative programming can provide both, but developing high-quality program generators takes a large effort, even if a multi-stage programming language is used. We present lightweight modular staging, a library-based multistage programming approach that breaks with the tradition of syntactic quasi-quotation and instead uses only types to distinguish between binding times. Through extensive use of component technology, lightweight modular staging makes an optimizing compiler framework available at the library level, allowing programmers to tightly integrate domain-specific abstractions and optimizations into the generation process. We argue that lightweight modular staging enables a form of language virtualization, i.e. allows to go from a pure-library embedded language to one that is practically equivalent to a standalone implementation with only modest effort. Copyright &copy; 2010 ACM.},
key = {Automatic programming},
keywords = {Abstracting;Network components;Optimization;Program compilers;Software engineering;},
note = {Code Generation;Component technologies;Domain specific;Domain specific languages;Embedded Languages;Generation process;Generative programming;High-quality programs;Multi-stage programming;Optimizing compilers;Run-time code generation;Virtualizations;},
URL = {http://dx.doi.org/10.1145/1942788.1868314},
} 


@inproceedings{20100412658040 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A lightweight MDSD process applied in small projects},
journal = {Conference Proceedings of the EUROMICRO},
author = {Guta, Gabor and Schreiner, Wolfgang and Draheim, Dirk},
year = {2009},
pages = {255 - 258},
issn = {10896503},
address = {Patras, Greece},
abstract = {Model driven software development, domain specific languages and other generative programming approaches have gained much attention. There is a large number of tools available, starting from simple code generators to full-blown tool suites. There are several success stories and process frameworks about applying full scale MDSD approaches, but there is no or little help for small-size projects. To fill this gap, we designed a new development process which targets small and middle size projects with limited resources. According to our experience the process is working efficiently in small projects even if they cannot afford bigger initial resource investment. In this experince report we document an industrial project in which the process was used. We present this process in the form which is applied in the first project and also discuss our experience and the limitations of the process. &copy; 2009 IEEE.},
key = {Computer software},
note = {Agile development;Code generators;Development process;Domain specific languages;Full scale;Generative programming;Industrial projects;Initial resources;Model-Driven Software Development;Process framework;Software process;Toolsuite;},
URL = {http://dx.doi.org/10.1109/SEAA.2009.63},
} 


@inproceedings{20081711212391 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {CASE-FX: Feature modeling support in an OO CASE tool},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Forget, Alain and Arnold, Dave and Chiasson, Sonia},
year = {2007},
pages = {803 - 804},
address = {Montreal, QC, Canada},
abstract = {Generative Programming advocates developing a family of systems rather than a set of single systems. Feature modeling can assist in supporting the development of such software product lines through software reuse. To our knowledge, CASE-FX is the first implementation of state-level feature modeling support within a CASE tool.},
key = {Object oriented programming},
keywords = {Computer software reusability;Computer systems programming;Linguistics;Neodymium;Product development;},
note = {CASE tools;Feature modelling;Generative programming (GP);international conferences;Languages (traditional);Object-oriented programming;Software product line (SPL);Software Re-use;},
URL = {http://dx.doi.org/10.1145/1297846.1297896},
} 


@inproceedings{20092912196010 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {CASE-FX: Feature modeling support in an OO CASE tool},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Forget, Alain and Arnold, Dave and Chiasson, Sonia},
year = {2007},
pages = {803 - 804},
address = {Montreal, QC, Canada},
abstract = {Generative Programming advocates developing a family of systems rather than a set of single systems. Featuremodeling can assist in supporting the development of such software product lines through software reuse. To our knowledge, CASE-FX is the first implementation of state-level feature modeling support within a CASE tool.},
key = {Computer systems programming},
keywords = {Computer software reusability;Object oriented programming;},
note = {CASE;CASE tools;Feature modeling;Generative programming;Rational rose-RT;Software Product Line;Software Re-use;},
} 


@inproceedings{20081711212401 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Structured co-evolution of models and Web application platforms},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Pingel, Adam},
year = {2007},
pages = {823 - 824},
address = {Montreal, QC, Canada},
abstract = {Web applications exemplify the need for generative programming techniques in part due to the many languages, artifacts, and groups of developers involved. Some problems remain, including those that that arise from the interplay with versioning. This paper proposes addressing these problems with structured program transformations, and explores a framework for the co-evolution of platform artifacts and the models that generate them.},
key = {Object oriented programming},
keywords = {Cobalt;Computer systems programming;Linguistics;Neodymium;World Wide Web;},
note = {Co evolution;Generative programming (GP);international conferences;Languages (traditional);Object-oriented programming;Program Transformations;versioning;WEB applications;},
URL = {http://dx.doi.org/10.1145/1297846.1297906},
} 


@inproceedings{20100412658027 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Constructing domain-specific component frameworks through architecture refinement},
journal = {Conference Proceedings of the EUROMICRO},
author = {Loiret, Frederic and Plek, Ale and Merle, Philippe and Seinturier, Lionel and Malohlava, Michal},
year = {2009},
pages = {375 - 382},
issn = {10896503},
address = {Patras, Greece},
abstract = {Recently, a plethora of domain-specific component frameworks (DSCF) emerges. Although the current trend emphasizes generative programming methods as cornerstones of software development, they are commonly applied in a costly, ad-hoc fashion. However, we believe that DSCFs share the same subset of concepts and patterns. In this paper we propose two contributions to DSCF development. First, we propose DomainComponents - a high-level abstraction to capture semantics of domain concepts provided by containers, and we identify patterns facilitating their implementation. Second, we develop a generic framework that automatically generates implementation of DomainComponents semantics, thus addressing domain-specific services with one unified approach. To evaluate benefits of our approach we have conducted several case studies that span different domain-specific challenges. &copy; 2009 IEEE.},
key = {Computer software},
keywords = {Semantics;},
note = {Component framework;Component model;Current trends;Different domains;Domain concepts;Domain specific;Generative programming;Generic frameworks;High-level abstraction;Software development;Unified approach;},
URL = {http://dx.doi.org/10.1109/SEAA.2009.24},
} 


@inproceedings{20105113498027 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Lightweight modular staging: A pragmatic approach to runtime code generation and compiled DSLs},
journal = {GPCE'10 - Proceedings of the 2010 Conference on Generative Programming and Component Engineering},
author = {Rompf, Tiark and Odersky, Martin},
year = {2010},
pages = {127 - 136},
address = {Eindhoven, Netherlands},
abstract = {Software engineering demands generality and abstraction, performance demands specialization and concretization. Generative programming can provide both, but developing high-quality program generators takes a large effort, even if a multi-stage programming language is used. We present lightweight modular staging, a library-based multistage programming approach that breaks with the tradition of syntactic quasi-quotation and instead uses only types to distinguish between binding times. Through extensive use of component technology, lightweight modular staging makes an optimizing compiler framework available at the library level, allowing programmers to tightly integrate domain-specific abstractions and optimizations into the generation process. We argue that lightweight modular staging enables a form of language virtualization, i.e. allows to go from a pure-library embedded language to one that is practically equivalent to a standalone implementation with only modest effort. &copy; 2010 ACM.},
key = {Automatic programming},
keywords = {Abstracting;Network components;Optimization;Problem oriented languages;Program compilers;Software engineering;XML;},
note = {Code Generation;Component technologies;Domain specific;Domain specific languages;Embedded Languages;Generation process;Generative programming;High-quality programs;Multi-stage programming;Optimizing compilers;Run-time code generation;Virtualizations;},
URL = {http://dx.doi.org/10.1145/1868294.1868314},
} 


@article{20103213127174 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Experience of building an architecture-based generator using GenVoca for distributed systems},
journal = {Science of Computer Programming},
author = {Lung, Chung-Horng and Rajeswaran, Pragash and Sivadas, Sathyanarayanan and Sivabalasingam, Theleepan},
volume = {75},
number = {8},
year = {2010},
pages = {672 - 688},
issn = {01676423},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Selecting the architecture that meets the requirements, both functional and non-functional, is a challenging task, especially at the early stage when more uncertainties exist. Architectural prototyping is a useful approach in supporting the evaluation of alternative architectures and balancing different architectural qualities. Generative programming has gained increasing attention, but it mostly deals with lower-level artifacts; hence, it usually supports lower degrees of software automation. This paper proposes an architecture-centric generative approach in facilitating architectural prototyping and evaluation. We also present our empirical experience in raising the level of abstraction to the architecture layer for distributed and concurrent systems using GenVoca. GenVoca is a generative programming approach that is used here to support the generation or instantiation of a particular architectural pattern in distributed computing based on user's selection. As a result, it can support rapid architectural prototyping and evaluation of both functional and non-functional requirements and encourage greater degrees of software automation and reuse. Lessons learned from the empirical study are also reported and could be applied to other areas. &copy; 2009 Elsevier B.V. All rights reserved.},
key = {Software prototyping},
keywords = {Computer software reusability;Computer software selection and evaluation;Software architecture;},
note = {Distributed systems;Generative programming;GenVoca;Prototyping;Software patterns;},
URL = {http://dx.doi.org/10.1016/j.scico.2009.05.003},
} 


@inproceedings{2004037822148 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {European Space Agency (Special Publication) ESA SP},
journal = {European Space Agency, (Special Publication) ESA SP},
number = {532},
year = {2003},
issn = {03796566},
address = {Prague, Czech republic},
abstract = {The proceedings contain 90 papers from the conference of European Space Agency, (special publication) ESA SP. The topics discussed include: generative programming for space applications; reusable infrastructure elements for spacecraft simulators; grid technology and neural networks for the analysis of atmospheric ozone from satellite data; high performances space processors simulators based on virtualization technologies; standard test equipment approach for space electronics verification; and architecture of next generation highly integrated data handling systems.},
key = {Space research},
keywords = {Astronomy;Computer aided software engineering;Computer architecture;Computer operating systems;Computer programming languages;Computer simulation;Control systems;Flight dynamics;Geostationary satellites;Large scale systems;Mathematical models;Program documentation;Project management;Real time systems;Space applications;Spacecraft;},
note = {Celestial mechanics;Domain-specific languages (DSL);EiRev;Generative programming environment;Object-oriented software development;Project life cycles;Software development cycles;Wave frequency;},
} 


@article{2001226519884 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Engineering components for ease of customisation and evolution},
journal = {IEE Proceedings: Software},
author = {Jarzabek, S. and Seviora, R.},
volume = {147},
number = {6},
year = {2000},
pages = {237 - 248},
issn = {14625970},
abstract = {Building software systems out of prefabricated components is a very attractive vision. Distributed component platforms (DCP) and their visual-development environments bring this vision closer to reality than ever. At the same time, some experiences with component libraries warn us about potential problems that arise when software-system families or systems evolve over many years of changes. Indeed, implementation-level components, when affected by many independent changes, tend to grow in both size and number, impeding reuse. This unwanted effect is analysed in detail. It is argued that components affected by frequent unexpected changes require higher levels of flexibility than the 'plug-and-play' paradigm is able to provide. A program-construction environment is proposed, based on generative programming techniques, to help in customisation and evolution of components that require much flexibility. This solution allows the benefits of DCPs to be reaped during runtime and, at the same time, keeps components under control during system construction and evolution. Salient features of a construction environment for component-based systems are discussed. Its implementation with commercial reuse technology Fusion&trade; is described, illustrating with examples from domain-engineering projects. The main lesson learnt from the project is that generative-programming techniques can extend the strengths of the component-based approach in two important ways. First, generative-programming techniques automate routine component customisation and composition tasks and allow developers work more productively, at a higher abstraction level. Secondly, as custom components with required properties are generated on demand, it is not necessary to store and manage multiple versions of components; components do not overly grow in size, helping developers keep the complexity of an evolving system under control.},
key = {Software engineering},
keywords = {Computational complexity;Computer programming;Computer software reusability;Distributed computer systems;Information technology;Systems analysis;},
note = {Component based systems;Distributed component platforms;Generative programming techniques;Software systems;},
URL = {http://dx.doi.org/10.1049/ip-sen:20000914},
} 


@inproceedings{2006229905632 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Integrating code generators into the C# language},
journal = {Proceedings - 3rd International Conference on Information Technology and Applications, ICITA 2005},
author = {Draheim, Dirk and Lutteroth, Christof and Weber, Gerald},
volume = {I},
year = {2005},
pages = {107 - 110},
address = {Sydney, Australia},
abstract = {In this paper we show how the concept of code generators can be safely implemented into an object oriented language. Modern languages like Java and C# begin to offer advanced features for generative programming, like generic types. Our own extension of C# generalizes the concept of generic types by combining it with reflection. With reflection many code generation tasks can be accomplished for which generic types are insufficient. By balancing the availability of code generation features with their safety, we are able to detect potential generation errors statically. &copy; 2005 IEEE.},
key = {Computer programming languages},
keywords = {Code converters;Error detection;Integrating circuits;Java programming language;Object oriented programming;},
note = {Generative programming;Integrating code generators;Potential generation errors;},
URL = {http://dx.doi.org/10.1109/ICITA.2005.161},
} 


@inproceedings{20080711094940 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Realizing the automated design of building automation systems},
journal = {2006 IEEE International Conference on Industrial Informatics, INDIN'06},
author = {Dibowski, H. and Oezluek, C. and Ploennigs, J. and Kabitzsch, K.},
year = {2007},
pages = {251 - 256},
address = {Singapore, Singapore},
abstract = {The future design of large and complex building automation systems (BAS) needs to be increasingly efficient. The usage of prefabricated devices and design patterns alone is insufficient to face complex demands. New automated design approaches not only need to take over recurrent tasks, they also have to integrate more direct and smoother methods into the overall design process. This paper addresses that broad scope by introducing an automated functional design concept for BAS. Following a continuous top-down design starting at a platform-independent functional level, a semiautomatic composition over different levels of abstraction towards a full-developed and industry-spanning BAS network is accomplished. Here, devices from different manufacturers are integrated into a properly operating system by incorporating formal interoperability checks. The predominant technologies of the proposed automated design approach are ontologies, generative programming and evolutionary algorithms. &copy; 2006 IEEE.},
key = {Intelligent systems},
keywords = {Automation;Computer operating systems;Evolutionary algorithms;Interoperability;},
note = {Functional design;Generative programming;Prefabricated devices;},
URL = {http://dx.doi.org/10.1109/INDIN.2006.275789},
} 


@inproceedings{2005209099591 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model engineering for software modernization},
journal = {Proceedings - Working Conference on Reverse Engineering, WCRE},
author = {Bezivin, Jean},
year = {2004},
pages = {4 - },
issn = {10951350},
address = {Delft, Netherlands},
abstract = {In November 2000 the OMG proposed a new approach to interoperability named MDA<sup>a</sup> (Model-Driven Architecture). MDA is one example of the broader Model Driven Engineering (MDE) vision, encompassing many popular research trends like generative programming, domain specific languages, model-integrated computing, model-driven software development, model management and much more. Considering models as first class entities and any software artifact as a model or a model element constitute the core principle of MDE. The original motivation for this paradigm change in software engineering was the separation of aspects, mainly between platform dependent and platform independent parts of software systems. Progressively the operation of model transformation appeared as the key technology to map neutral and relatively stable business models to rapidly evolving technological platforms of the present and the future. In this approach any model including transformation models conforms to a metamodel. More recently it became obvious that the techniques used to generate executable systems on these platforms of the present and the future (like Corba, EJB, DotNet, Grid computing, P2P computing, etc.) could also be applied to extract business models from the platform of the past (RPG, COBOL, PL/1, ADA, 4GLs, etc.). The combination of backward and forward engineering is thus taking, in the context of MDE, an increasing importance. The present transition to model engineering will have probably a much deeper impact on software practices than the move from procedural to object technology that took place in the 80's. Areas like software modernization will have much to gain from this rise in abstraction. The presentation intends to show how the basic principles of MDE may help to unify and integrate good reengineering practices.},
key = {Software engineering},
keywords = {Computer programming languages;Computer simulation;Interfaces (computer);Interoperability;Reengineering;Reverse engineering;},
note = {Generative programming;Model driven engineering (MDE);Model integrated computing;Software modernization;},
} 


@inproceedings{20073110742051 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Creating custom containers with generative techniques},
journal = {Proceedings of the 5th International Conference on Generative Programming and Component Engineering, GPCE'06},
author = {Moreno, Gabriel A.},
year = {2006},
pages = {29 - 38},
address = {Portland, OR, United states},
abstract = {Component containers are a key part of mainstream component technologies, and play an important role in separating non-functional concerns from the core component logic. This paper addresses two different aspects of containers. First, it shows how generative programming techniques, using AspectC++ and meta-programming, can be used to generate stubs and skeletons without the need for special compilers or interface description languages. Second, the paper describes an approach to create custom containers by composing different non-functional features. Unlike component technologies such as EJB, which only support a predefined set of container types, this approach allows different combinations of non-functional features to be composed in a container to meet the application needs. Copyright &copy; 2006 ACM.},
key = {Computer hardware description languages},
keywords = {Formal logic;Interfaces (computer);Object oriented programming;Program compilers;},
note = {Aspect oriented programming;AspectC++;Custom containers;Generative programming;Meta-programming;Non-functional concern;},
URL = {http://dx.doi.org/10.1145/1173706.1173712},
} 


@article{20110813689416 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic variation-point identification in function-block-based models},
journal = {ACM SIGPLAN Notices},
author = {Ryssel, Uwe and Ploennigs, Joern and Kabitzsch, Klaus},
volume = {46},
number = {2},
year = {2011},
pages = {23 - 32},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Function-block-based modeling is often used to develop embedded systems, particularly as system variants can be developed rapidly from existing modules. Generative approaches can simplify the handling and development of the resulting high variety of functionblock- based models. But they often require the development of new generic models that do not utilize existing ones. Reusing existing models will significantly decrease the effort to apply generative programming. This work introduces an automatic approach to recognize variants in a set of models and identify the variation points and their dependencies within variants. As result it offers automatically generated feature models and ICCL content to regenerate the given variants. Copyright &copy; 2010 ACM.},
key = {Embedded systems},
keywords = {Information analysis;},
note = {Automatically generated;Feature models;Formal Concept Analysis;Generative programming;Generic models;System variants;Variation-Point Identification;},
URL = {http://dx.doi.org/10.1145/1942788.1868299},
} 


@inproceedings{20064010147327 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {WISBuilder: A framework for facilitating development of web-based information systems},
journal = {Proceedings of the 16th IEEE International Conference on Electronics, Communications and Computers, CONIELECOMP 2006},
author = {Ortiz-Cornejo, Angel Israel and Cuayahuitl, Heriberto and Perez-Corona, Carlos},
volume = {2006},
year = {2006},
pages = {46 - },
address = {Puebla, Mexico},
abstract = {This paper presents WISBuilder, a framework that investigates an approach for facilitating the development of Web-based Information Systems. The approach is based on the Model-View-Controller and Generative Programming paradigms. Firstly, the WISBuilder framework applies the following separation of tasks: structure, business-logic and visual style. The system specification is performed with two high-level XML-based languages: WSML and WAML. Secondly, WISBuilder proposes the creation of reusable code templates for each high-level language. Thirdly, WIS-Builder uses predefined code templates for expanding the system specification in high-level annotations. The goals of this framework are twofold: to speed-up development by writing less code and development in parallel; and to promote software reusability by reusing generic code templates. Experimental results with three small-scale Webbased information systems show an important reduction of programming effort, using the proposed framework in comparison with an equivalent manual coding. These results show initial evidence that software development based on both paradigms is a good practice. &copy; 2006 IEEE.},
key = {Information management},
keywords = {Computer software reusability;High level languages;Software engineering;World Wide Web;XML;},
note = {Business logic;Code templates;Generative Programming paradigms;Web-based information systems;},
URL = {http://dx.doi.org/10.1109/CONIELECOMP.2006.65},
} 


@inproceedings{20064310192384 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A tutorial on feature oriented programming and the AHEAD tool suite},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Batory, Don},
volume = {4143 LNCS},
year = {2006},
pages = {3 - 35},
issn = {03029743},
address = {Braga, Portugal},
abstract = {Feature oriented programming (FOP) is the study of feature modularity and its use in program synthesis. AHEAD is a theory of FOP that is based on a fundamental concept of generative programming that functions map programs. This enables the design of programs to be expressed compositionally as algebraic expressions, which are suited for automated analysis, manipulation, and program synthesis. This paper is a tutorial on FOP and AHEAD. We review AHEAD's theory and the tool set that implements it. &copy; Springer-Verlag Berlin Heidelberg 2006.},
key = {Computer programming},
keywords = {Algebra;Computation theory;Set theory;},
note = {Automated analysis;Feature oriented programming;Generative programming;Program synthesis;},
} 


@inproceedings{20105113498016 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic variation-point identification in function-block-based models},
journal = {GPCE'10 - Proceedings of the 2010 Conference on Generative Programming and Component Engineering},
author = {Ryssel, Uwe and Ploennigs, Joern and Kabitzsch, Klaus},
year = {2010},
pages = {23 - 32},
address = {Eindhoven, Netherlands},
abstract = {Function-block-based modeling is often used to develop embedded systems, particularly as system variants can be developed rapidly from existing modules. Generative approaches can simplify the handling and development of the resulting high variety of function-block-based models. But they often require the development of new generic models that do not utilize existing ones. Reusing existing models will significantly decrease the effort to apply generative programming. This work introduces an automatic approach to recognize variants in a set of models and identify the variation points and their dependencies within variants. As result it offers automatically generated feature models and ICCL content to regenerate the given variants. &copy; 2010 ACM.},
key = {Embedded systems},
keywords = {Information analysis;},
note = {Automatically generated;Feature models;Formal Concept Analysis;Generative programming;Generic models;System variants;Variation-point identification;},
URL = {http://dx.doi.org/10.1145/1868294.1868299},
} 


@article{2005269176657 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {FISIM: An integrated model for simulation of industrial fibre and film processes},
journal = {Plastics, Rubber and Composites},
author = {Cox, C.L. and Duffy, E. and Von Oehsen, J.B.},
volume = {33},
number = {9-10},
year = {2004},
pages = {426 - 437},
issn = {14658011},
abstract = {The present study covers the structure and some applications of FISIM (Fiber and film SIMulation), a versatile polymer process modelling package which is being developed by the Center for Advanced Engineering Fibers and Films. Generative programming techniques are used to overcome degradation in performance and storage which is often associated with the C++ language. The process stages are integrated using a component-based design so that configurations representing all or part of a process stage can be easily swapped in and out. The prototype code incorporates filtration, forming, external flow under quench conditions, and drawing, applied to fibre melt-spinning. Visualisation is playing a prominent role, providing a user-friendly means for initialising, monitoring, and post-processing simulation output. Process models, solution strategies, and software tools which are implemented in FISIM are presented, along with comparisons between simulation results and experimental measurements. These ingredients comprise a unique modelling environment which will substantially reduce the need for trial-and-error experiments in the development of new fibre and film processes. &copy; 2004 Institute of Materials, Minerals and Mining.},
key = {Thin films},
keywords = {C (programming language);Computer aided design;Computer simulation;Degradation;Finite element method;Polymers;Quenching;Software engineering;Synthetic fibers;Viscoelasticity;Visualization;},
note = {Component-based design;Generative programming;Polymer process simulation;Post-processing;},
URL = {http://dx.doi.org/10.1179/174328904X29939},
} 


@inproceedings{20094712464083 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MDAI: Model based design in automobile industry},
journal = {IEEE International Conference on Industrial Informatics (INDIN)},
author = {Ferreira, Joao Carlos Amaro},
year = {2009},
pages = {434 - 439},
issn = {19354576},
address = {Cardiff, United kingdom},
abstract = {It is proposed a new approach based on a methodology, assisted by a tool, to create new products in the automobile industry based on previous defined processes and experiences inspired on a set of best practices or principles: it is based on high-level models or specifications; it is componentbased architecture centric; it is based on generative programming techniques. This approach follows in essence the MDA (Model Driven Architecture) philosophy with some specific characteristics. We propose a repository that keeps related information, such as models, applications, design information, generated artifacts and even information concerning the development process itself (e.g., generation steps, tests and integration milestones). Generically, this methodology receives the users' requirements to a new product (e.g., functional, non-functional, product specification) as its main inputs and produces a set of artifacts (e.g., design parts, process validation output) as its main output, that will be integrated in the engineer design tool (e.g. CAD system) facilitating the work. &copy; 2009 IEEE.},
key = {Computer aided design},
keywords = {Automobile parts and equipment;Embedded systems;Philosophical aspects;Specifications;},
note = {Automobile industry;Best practice;CAD system;Component-based architecture;Design information;Design tool;Development process;Generative programming;High-level models;Information concerning;MDA(model driven architecture);Model-based design;New approaches;New product;Non-functional;Process validation;Product specifications;},
URL = {http://dx.doi.org/10.1109/INDIN.2009.5195843},
} 


@inproceedings{20094212373744 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A framework for raising the level of abstraction of explicit parallelization},
journal = {2009 31st International Conference on Software Engineering - Companion Volume, ICSE 2009},
author = {Arora, Ritu and Bangalore, Purushotham},
year = {2009},
pages = {339 - 342},
address = {Vancouver, BC, Canada},
abstract = {In this research, a Framework for Synthesizing Parallel Applications (FraSPA) in a user-guided manner is being developed. The FraSPA would facilitate the synthesis of parallel applications from existing sequential applications and middleware components for multiple-platforms and diverse domains. The framework design is based upon design patterns and generative programming techniques. The main goal of this research is to raise the level of abstraction of the widely used low-level parallel programming approaches. A technique to separate parallel and sequential concerns will be demonstrated through this work. Other contributions will be in the area of design patterns and Domain-Specific Languages (DSLs) for parallel computing. The design patterns, along with the DSLs, will promote code reuse and code correctness. There would be a reduction in code complexity and code maintenance would become easy. The productivity of the end-users will increase. This research can be broadly classified as Software Engineering for High Performance Computing. &copy; 2009 IEEE.},
key = {Parallel programming},
keywords = {Abstracting;Computer software maintenance;Design;Middleware;Parallel architectures;Research;Software engineering;Synthesis (chemical);},
note = {Code complexity;Code reuse;Design Patterns;Diverse domains;Domain specific languages;End-users;Generative programming;High performance computing;Level of abstraction;Middleware components;Parallel application;Parallel Computing;Parallelizations;Sequential applications;},
URL = {http://dx.doi.org/10.1109/ICSE-COMPANION.2009.5071016},
} 


@inproceedings{20102613042221 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Enforcing the use of API functions in Linux code},
journal = {Proceedings of the 8th Workshop on Aspects, Components, and Patterns for Infrastructure Software, ACP4IS '09, Co-located with the 8th Int. Conf. Aspect-Oriented Software Development, AOSD.09},
author = {Lawall, Julia L. and Muller, Gilles and Palix, Nicolas},
year = {2009},
pages = {7 - 11},
address = {Charlottesville, VA, United states},
abstract = {In the Linux kernel source tree, header files typically define many small functions that have a simple behavior but are critical to ensure readability, correctness, and maintainability. We have observed, however, that some Linux code does not use these functions systematically. In this paper, we propose an approach combining rule-based program matching and transformation with generative programming to generate rules for finding and fixing code fragments that should use the functions defined in header files. We illustrate our approach using an in-depth study based on four typical functions defined in the header file include/linux/usb.h. Copyright 2009 ACM.},
key = {Software design},
keywords = {Computer operating systems;Computer systems programming;Maintainability;Open systems;},
note = {API functions;Bug-fixing;Code fragments;Combining rules;Generative programming;Header files;In-depth study;Linux kernel;Source tree;},
URL = {http://dx.doi.org/10.1145/1509276.1509279},
} 


@inproceedings{20083511481051 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {ezRealtime: A Domain-Specific Modeling tool for Embedded Hard Real-Time software synthesis},
journal = {Proceedings -Design, Automation and Test in Europe, DATE},
author = {Cruz, Fabiano and Barreto, Raimundo and Cordeiro, Lucas and Maciel, Paulo},
year = {2008},
pages = {1510 - 1515},
issn = {15301591},
address = {Munich, Germany},
abstract = {In this paper, we introduce the ezRealtime project, which relies on the Time Petri Net (TPN) formalism and defines a Domain-Specific Modeling (DSM) tool to provide an easy-to-use environment for specifying Embedded Hard Real-Time (EHRT) systems and for synthesizing timely and predictable scheduled C code. Therefore, this paper presents a generative programming method in order to boost code quality and improve substantially developer productivity by making use of automated software synthesis. The ezReal-time tool reads and automatically translates the system's specification to a time Petri net model through composition of building blocks with the purpose of providing a complete model of all tasks in the system. Hence, this model is used to find a feasible schedule by applying a depth-first search algorithm. Finally, the scheduled code is generated by traversing the feasible schedule, and replacing transition's instances by the respective code segments. We also present the application of the proposed method in an expressive case study. &copy; 2008 EDAA.},
key = {Real time systems},
keywords = {Automation;Codes (standards);Codes (symbols);Embedded systems;Graph theory;Industrial engineering;Learning algorithms;Petri nets;Testing;},
note = {Building Blocks;Case studies;Code quality;Code segments;Depth first search algorithms;Domain-specific modeling;Feasible schedule;Generative programming;Hard real-time;Software synthesis;Time Petri Nets;},
URL = {http://dx.doi.org/10.1109/DATE.2008.4484888},
} 


@inproceedings{20074910958426 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Research on pattern language for agent-based application},
journal = {Fourth International Conference on Information Technology and Applications, ICITA 2007},
author = {Wang, Jiafang and Feng, Zhiyong and Zhao, Fei},
year = {2007},
pages = {329 - 334},
address = {Harbin, China},
abstract = {Agent-based computing has received more and more attention in the development of distribute systems for dynamic and open network, and it has also become a promising paradigm for software engineering. To develop robust, maintainable Multi-agent System, an Agent Pattern Language named APL has been proposed in the light of Generative Programming and engineering disciplines for grammarware, in accompany with a single agent architecture based on blackboard. With a Business Process Management application scenario, the paper describes how the APL language is used to describe the data type and components like knowledge Sources and so on, then a parser for APL parses APL files and generate executable code for Agent which run on JADE. By this way, systems based on agent can be developed fast and Multi-agent system can be constructed in a top-down manner. Then not only the productivity for the development agent-base system is improved, but flexibility and reusability of the system are also enhanced.},
key = {Computation theory},
keywords = {Computer programming languages;Distributed computer systems;Intelligent agents;Multi agent systems;},
note = {Agent Pattern Language;Agent-based computing;Generative programming;Grammarware;},
} 


@inproceedings{20093512278194 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {LEESA: Embedding strategic and xpath-like object structure traversals in C++},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Tambe, Sumant and Gokhale, Aniruddha},
volume = {5658 LNCS},
year = {2009},
pages = {100 - 124},
issn = {03029743},
address = {Oxford, United kingdom},
abstract = {Traversals of heterogeneous object structures are the most common operations in schema-first applications where the three key issues are (1) separation of traversal specifications from type-specific actions, (2) expressiveness and reusability of traversal specifications, and (3) supporting structure-shy traversal specifications that require minimal adaptation in the face of schema evolution. This paper presents Language for Embedded quEry and traverSAl (LEESA), which provides a generative programming approach to address the above issues. LEESA is an object structure traversal language embedded in C++. Using C++ templates, LEESA combines the expressiveness of XPath's axes-oriented traversal notation with the genericity and programmability of Strategic Programming. LEESA uses the object structure meta-information to statically optimize the traversals and check their compatibility against the schema. Moreover, a key usability issue of domain-specific error reporting in embedded DSL languages has been addressed in LEESA through a novel application of Concepts, which is an upcoming C++ standard (C++0x) feature. We present a quantitative evaluation of LEESA illustrating how it can significantly reduce the development efforts of schema-first applications. &copy; IFIP International Federation for Information Processing 2009.},
key = {Query languages},
keywords = {DSL;Linguistics;Modems;Reusability;Specifications;Telecommunication lines;},
note = {C++ templates;Common operations;Domain specific;Generative programming;Genericity;Heterogeneous object;Key issues;Meta information;Novel applications;Object structure;Programmability;Quantitative evaluation;Schema evolution;Strategic programming;Supporting structure;},
URL = {http://dx.doi.org/10.1007/978-3-642-03034-5_6},
} 


@inproceedings{20113614299920 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Information modeling of business processes in X-ray fluorescent analysis},
journal = {MIPRO 2011 - 34th International Convention on Information and Communication Technology, Electronics and Microelectronics - Proceedings},
author = {Vorobyeva, O.P. and Cherkashin, E.A. and Ipatov, S.A. and Paramonov, V.V.},
year = {2011},
pages = {941 - 944},
address = {Opatija, Croatia},
abstract = {The article is devoted to the formalization of investigation processes of substances by means of the X-ray fluorescence analysis (XRF). The research is aimed at solving the problem of automation of the analytical investigations in the XRF, which suppose to increases the productivity of the analyst and the accuracy of determining the concentration of elements in samples. Decomposition of information processes has been represented in the IDEF0 standard as a hierarchy of the core activities. Based on the decomposition the information model of the domain is developed. The model is represented as UML-diagrams adapted to MDA (Model Driven Architecture) based generative programming tools. These tools allow one to transform the model automatically into a skeleton of information system for XRF techniques automation. &copy; 2011 MIPRO.},
key = {Information theory},
keywords = {Fluorescence;Information technology;Microelectronics;Software architecture;},
note = {Analytical investigations;Business Process;Core activity;Decomposition of information;Generative programming;Information Modeling;Information models;Investigation process;MDA(model driven architecture);X ray fluorescence analysis;X-ray fluorescent analysis;},
} 


@inproceedings{20094512436258 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Fault-tolerance for component-based systems - An automated middleware specialization approach},
journal = {Proceedings of the 2009 IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing, ISORC 2009},
author = {Tambe, Sumant and Dabholkar, Akshay and Gokhale, Aniruddha},
year = {2009},
pages = {47 - 54},
address = {Tokyo, Japan},
abstract = {General-purpose middleware, by definition, cannot readily support domain-specific semantics without significant manual efforts in specializing the middleware. This paper presents GRAFT (GeneRative Aspects for Fault Tolerance), which is a model-driven, automated, and aspects-based approach for specializing general-purpose middleware with failure handling and recovery semantics imposed by a domain. Model-driven techniques are used to specify the special fault tolerance requirements, which are then transformed into middleware-level code artifacts using generative programming. Since the resulting fault tolerance semantics often crosscut the middleware architecture, GRAFT uses aspect-oriented programming to weave them into the original fabric of the general-purpose middleware. We evaluate the capabilities of GRAFT using a representative case study. &copy; 2009 IEEE.},
key = {Fault tolerance},
keywords = {Computer science;Computer systems programming;Grafting (chemical);Middleware;Quality assurance;Semantics;},
note = {Aspect-Oriented Programming;Aspects;Component based systems;Domain specific;Failure handling;Generative programming;Middleware architecture;Model-based;Model-driven;Model-driven techniques;Representative case;},
URL = {http://dx.doi.org/10.1109/ISORC.2009.50},
} 


@inproceedings{20072410651802 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The Feature-Architecture Mapping (FArM) method for feature-oriented development of software product lines},
journal = {Proceedings of the International Symposium and Workshop on Engineering of Computer Based Systems},
author = {Sochos, Periklis and Riebisch, Matthias and Philippow, Ilka},
year = {2006},
pages = {308 - 316},
address = {Potsdam, Germany},
abstract = {Software product lines (PLs) are large, complex systems, demanding high maintainability and enhanced flexibility. Nonetheless, in the state of the art PL methods, features are scattered and tangled throughout the system components, leading to poor maintainability. Additionally, the majority of PL methods support manual product composition, while the implementation of feature-level variability in PL products influences the system's conceptual integrity. Generative programming techniques do enhance flexibility, but on the cost of maintainability. The Feature-Architecture Mapping (FArM) method provides a stronger mapping between features and the architecture. It is based on a series of transformations on the initial PL feature model. During these transformations architectural components are derived, encapsulating the business logic of each transformed feature and having interfaces reflecting the feature interactions. The flexibility of FArM architectures is supported through the explicit integration of plug-in mechanisms. The methodology is evaluated in the context of a wireless handheld-device PL. &copy; 2006 IEEE.},
key = {Software packages},
keywords = {Computer programming;Computer software maintenance;Conformal mapping;Formal logic;Interfaces (computer);Software architecture;},
note = {Feature Architecture Mapping (FArM);Feature interactions;Generative programming;},
URL = {http://dx.doi.org/10.1109/ECBS.2006.69},
} 


@article{IP50978538 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic library migration for the generation of hardware-in-the-loop models},
journal = {Science of Computer Programming},
author = {Ryssel, Uwe and Ploennigs, Joern and Kabitzsch, Klaus},
year = {2010},
issn = {01676423},
abstract = {Embedded systems are widely used in several applications nowadays. As they integrate hard- and software elements, their functionality and reliability are often tested by hardware-in-the-loop methods, in which the system under test runs in a simulated environment. Due to the rising complexity of the embedded functions, performance limitations and practicability reasons, the simulations are often specialized to test specific aspects of the embedded system and develop a high diversity by themselves. This diversity is difficult to manage for a user and results in erroneously selected test components and compatibility problems in the test configuration. This paper presents a generative programming approach that handles the diversity of test libraries. Compatibility issues are explicitly evaluated by a new interface concept. Furthermore, a novel model analyzer facilitates the efficient application in practice by migrating existing libraries. The approach is evaluated for an example from the automotive domain using MATLAB/Simulink. &copy; 2010 Elsevier B.V. All rights reserved.},
key = {Embedded systems},
keywords = {Libraries;Software reliability;Synthetic apertures;Testing;},
note = {Automotive domains;Embedded function;Generative programming;Hard-ware-in-the-loop;MATLAB /simulink;Performance limitations;Simulated environment;Software elements;System under test;Test components;Test configurations;},
URL = {http://dx.doi.org/10.1016/j.scico.2010.06.005},
} 


@inproceedings{20110813674162 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Systems engineering for distributed live, virtual, and constructive (LVC) simulation},
journal = {Proceedings - Winter Simulation Conference},
author = {Gallant, Scott and Gaughan, Chris},
year = {2010},
pages = {1501 - 1511},
issn = {08917736},
address = {Baltimore, MD, United states},
abstract = {Designing a distributed simulation environment across multiple domains that typically have disparate middleware transport protocols, data exchange formats and applications increases the difficulty of capturing and linking system design decisions to the resultant implementation. Systems engineering efforts for distributed simulation environments are typically based on the middleware transport used, the applications available and the constraints placed on the technical team including network, computer and personnel limitations. To facilitate community re-use, systems engineering should focus on integrated operational function decomposition. This links data elements produced within the simulation to the functional capabilities required by the user. The system design should be captured at a functional level and subsequently linked to the technical design. Doing this within a data-driven systems engineering infrastructure allows generative programming techniques to assist accurate, flexible and rapid architecture development. This paper describes the MATREX program systems engineering process, infrastructure and path forward. &copy;2010 IEEE.},
key = {Distributed computer systems},
keywords = {Circuit simulation;Design;Middleware;Systems analysis;Systems engineering;},
note = {Data elements;Data exchange format;Data-driven;Distributed simulation environments;Engineering infrastructure;Functional capabilities;Functional levels;Generative programming;Multiple domains;Operational functions;Program systems;System design;Technical design;Transport protocols;},
URL = {http://dx.doi.org/10.1109/WSC.2010.5679044},
} 


@inproceedings{20112614088833 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {BlockLib: A skeleton library for Cell Broadband Engine},
journal = {Proceedings - International Conference on Software Engineering},
author = {Alind, Markus and Eriksson, Mattias V. and Kessler, Christoph W.},
year = {2008},
pages = {7 - 14},
issn = {02705257},
address = {Leipzig, Germany},
abstract = {Cell Broadband Engine is a heterogeneous multicore processor for high-performance computing and gaming. Its architecture allows for an impressive peak performance but, at the same time, makes it very hard to write efficient code. The need to simultaneously exploit SIMD instructions, coordinate parallel execution of the slave processors, overlap DMA memory traffic with computation, keep data properly aligned in memory, and explicitly manage the very small onchip memory buffers of the slave processors, leads to very complex code. In this work, we adopt the skeleton programming approach to abstract from much of the complexity of Cell programming while maintaining high performance. The abstraction is achieved through a library of parallel generic building blocks, called BlockLib. Macro-based generative programming is used to reduce the overhead of genericity in skeleton functions and control code size expansion. We demonstrate the library usage with a parallel ODE solver application. Our experimental results show that BlockLib code achieves performance close to hand-written code and even outperforms the native IBM BLAS library in cases where several slave processors are used. Copyright 2008 ACM.},
key = {Multicore programming},
keywords = {Abstracting;Computer software selection and evaluation;Parallel processing systems;Software engineering;},
note = {BLAS library;Building blockes;Cell Broadband Engine;Complex codes;Control codes;Generative programming;Genericity;Heterogeneous multicore;High-performance computing;ITS architecture;ODE Solver;On chip memory;Parallel executions;Peak performance;Performance;SIMD instructions;Skeleton function;Slave processors;},
} 


@inproceedings{2006189858292 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Applying a generative technique for enhanced genericity and maintainability on the J2EE platform},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Jun, Yang and Jarzabek, Stan},
volume = {3676 LNCS},
year = {2005},
pages = {237 - 255},
issn = {03029743},
address = {Tallinn, Estonia},
abstract = {One of the themes in building reusable and maintainable software is identifying similarities and designing generic solutions to unify similarity patterns. In this paper, we analyze capabilities of J2EE to effectively unify similarity patterns found in Web Portals (WP). Our experimentation involved a family of WPs to support information sharing and team collaboration, built by our industry partner. While J2EE provides useful mechanisms for reuse of common services across components, we found its limitations in systematic across-the-board reuse in application domain-specific areas. To solve these problems, we applied a generative programming (GP) technique of XVCL on top of J2EE. By unifying similarity patterns, we increased the clarity of portal's conceptual structure as perceived by developers, reducing also the size of the original J2EE WP by 61%. Our solution enhanced traceability of information that mattered during changes. Based on that we hypothesized that XVCL-enhanced J2EE WP would be easier to maintain than the original J2EE WP. In the paper, we describe our solution and evaluate its engineering merits in both quantitative and qualitative ways. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Computer software},
keywords = {Chemical analysis;Information use;Problem solving;Reusability;World Wide Web;},
note = {Generative programming (GP);J2EE platform;Web Portals (WP);},
URL = {http://dx.doi.org/10.1007/11561347_17},
} 


@inproceedings{20102913087585 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {General constant expressions for system programming languages},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Dos Reis, Gabriel and Stroustrup, Bjarne},
year = {2010},
pages = {2131 - 2136},
address = {Sierre, Switzerland},
abstract = {Most mainstream system programming languages provide support for builtin types, and extension mechanisms through userdefined types. They also come with a notion of constant expressions whereby some expressions (such as array bounds) can be evaluated at compile time. However, they require constant expressions to be written in an impoverished language with minimal support from the type system; this is tedious and error-prone. This paper presents a framework for generalizing the notion of constant expressions in modern system programming languages. It extends compile time evaluation to functions and variables of user-defined types, thereby including formerly ad hoc notions of Read Only Memory (ROM) objects into a general and type safe framework. It allows a programmer to specify that an operation must be evaluated at compile time. Furthermore, it provides more direct support for key meta programming and generative programming techniques. The framework is formalized as an extension of underlying type system with a binding time analysis. It was designed to meet real-world requirements. In particular, key design decisions relate to balancing expressive power to implementability in industrial compilers and teachability. It has been implemented for C++ in the GNU Compiler Collection, and is part of the next ISO C++ standard. &copy; 2010 ACM.},
key = {Computer software selection and evaluation},
keywords = {Computer systems programming;Linguistics;Object oriented programming;Program compilers;Query languages;Standardization;},
note = {Binding time analysis;Compile time;compile time evaluation;Design decisions;Error prones;Expressive power;General constants;Generative programming;GNU compiler collection;Implementability;Meta Programming;Minimal supports;Programming language;Read-only memories;Real-world;Type systems;User-defined types;},
URL = {http://dx.doi.org/10.1145/1774088.1774537},
} 


@inproceedings{20110513635345 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Code transformations for embedded reconfigurable computing architectures},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Diniz, Pedro C. and Cardoso, Joao M. P.},
volume = {6491 LNCS},
year = {2011},
pages = {322 - 344},
issn = {03029743},
address = {Braga, Portugal},
abstract = {Embedded Systems permeate all aspects of our daily life, from the ubiquitous mobile devices (e.g., PDAs and smart-phones) to play-stations, set-top boxes, household appliances, and in every electronic system, be it large or small (e.g., in cars, wrist-watches). Most embedded systems are characterized by stringent design constraints such as reduced memory and computing capacity, severe power and energy restrictions, weight and space limitations, most importantly, very short life spans and thus strict design cycles. Reconfiguration has emerged as a key technology for embedded systems as it offers the promise of increased system performance and component number reduction. Reconfigurable components can be customized or specialized (even dynamically) to the task at hand, thereby executing specific tasks more efficiently leading to possible reductions of the weight and power. In this article, we introduce and discuss compilation techniques for reconfigurable embedded systems. We present specific compiler techniques focusing on source-level code transformations highlighting their potential and the applicability of generative programming techniques to this compilation domain. &copy; 2011 Springer-Verlag.},
key = {Embedded systems},
keywords = {Automobile electronic equipment;Cosine transforms;Domestic appliances;Mobile devices;Software engineering;},
note = {Code transformation;Compilation techniques;Compiler techniques;Computing capacity;Daily lives;Design constraints;Design cycle;Electronic systems;Generative programming;Household appliances;Key technologies;Life span;Reconfigurable components;Reconfigurable computing architecture;Reconfigurable embedded systems;Reduced memory;Set top box;Smart-phones;Space limitations;Specific tasks;},
URL = {http://dx.doi.org/10.1007/978-3-642-18023-1_8},
} 


@inproceedings{20083711535573 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven specification of component-based distributed real-time and embedded systems for verification of systemic QoS properties},
journal = {IPDPS Miami 2008 - Proceedings of the 22nd IEEE International Parallel and Distributed Processing Symposium, Program and CD-ROM},
author = {Hill, James H. and Gokhale, Aniruddha},
year = {2008},
pages = {IEEE Computer Society Technical Committee on Parallel Processing - },
address = {Miami, FL, United states},
abstract = {The adage "the whole is not equal to the sum of its parts" is very appropriate in the context of verifying a range of systemic properties, such as deadlocks, correctness, and conformance to quality of service (QoS) requirements, for component-based distributed real-time and embedded (DRE) systems. For example, end-to-end worst case response time (WCRT) in component-based DRE systems is not as simple as accumulating WCRT for each individual component in the system because of inherent complexities introduced by the large solution space of possible deployment and configurations. This paper describes a novel process and tool-based artifacts that simplify the formal specification of component-based DRE systems for verification of systemic QoS properties. Our approach is based on the mathematical formalism of Timed Input/Output Automata and uses generative programming techniques for automating the verification of systemic QoS properties for component-based DRE systems. &copy;2008 IEEE.},
key = {Quality of service},
keywords = {Chlorine compounds;Computer networks;Distributed parameter networks;Embedded systems;Integrated circuits;Specifications;},
note = {Component-based distributed real-time and embedded systems;Formal specification;Generative programming;Model-driven engineering;System verification;Timed I/O automata;},
URL = {http://dx.doi.org/10.1109/IPDPS.2008.4536573},
} 


@article{20110513641332 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Efficient run-time dispatching in generic programming with minimal code bloat},
journal = {Science of Computer Programming},
author = {Bourdev, Lubomir and Jrvi, Jaakko},
volume = {76},
number = {4},
year = {2011},
pages = {243 - 257},
issn = {01676423},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Generic programming with C++ templates results in efficient but inflexible code: efficient, because the exact types of inputs to generic functions are known at compile time; inflexible because they must be known at compile time. We show how to achieve run-time polymorphism without compromising performance by instantiating the generic algorithm with a comprehensive set of possible parameter types, and choosing the appropriate instantiation at run time. Applying this approach navely can result in excessive template bloat: a large number of template instantiations, many of which are identical at the assembly level. We show practical examples of this approach quickly approaching the limits of the compiler. Consequently, we combine this method of run-time polymorphism for generic programming, with a strategy for reducing the number of necessary template instantiations. We report on using our approach in GIL, Adobe's open source Generic Image Library. We observed a notable reduction, up to 70% at times, in executable sizes of our test programs. This was the case even with compilers that perform aggressive template hoisting at the compiler level, due to significantly smaller dispatching code. The framework draws from both the generic and generative programming paradigms, using static metaprogramming to fine tune the compilation of a generic library. Our test bed, GIL, is deployed in a real world industrial setting, where code size is often an important factor. &copy; 2010 Elsevier B.V. All rights reserved.},
key = {Program compilers},
keywords = {Computer programming;Equipment testing;Polymorphism;},
note = {Assembly levels;C++ templates;Code size;Compile time;Generative programming;Generic algorithm;Generic functions;Generic images;Generic libraries;Generic programming;Industrial settings;Meta Programming;Open sources;Runtimes;Template bloat;Template metaprogramming;Test program;},
URL = {http://dx.doi.org/10.1016/j.scico.2008.06.003},
} 


@inproceedings{20104713416222 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Dynamically mapping screen real estate optimality},
journal = {PICMET '10 - Portland International Center for Management of Engineering and Technology, Proceedings - Technology Management for Global Economic Growth},
author = {Benedicenti, Luigi and Petty, Sheila},
year = {2010},
pages = {1378 - 1383},
address = {Phuket, Thailand},
abstract = {This research paper brings together the fields of systems engineering and media studies to investigate the cinema/television/computer/mobile device screen as a dynamic interface through which points of engagement or how the aesthetics and narrative structures presented on the screen engage the user and create meaning. The co-authors work towards the development of a "screen real estate grammar" or ontology by considering the following set of questions: 1. How can the specific structures (ie/ uses of time, space, text, screen resolution, window size, etc.) of user interfaces (ie/ iTunes and QuickTime X Windows) be mapped? 2. Will such mapping expose levels of convergence (ie/ where old forms meet/influence/contribute to new developments and new content? 3. Is it possible to work towards a language of conventions similar to that of other disciplines? Ie/ film language 4. Can interface elements be prioritized on a contextual basis? The framework is presented in the context of a decision support system for user interface optimization, which allows interfaces to be dynamically adapted to different formats given a set of rules that create a semantic mapping between interface elements. Generative programming is then used to create the optimized interface. &copy; 2010 IEEE.},
key = {User interfaces},
keywords = {Artificial intelligence;Decision support systems;Decision theory;Economics;Industrial management;Mapping;Ontology;Optimization;Technology;},
note = {CAN interface;Dynamic interface;Generative programming;Interface elements;Narrative structures;Optimality;Real estate;Research papers;Screen resolution;Semantic mapping;Set of rules;Window Size;X-window;},
} 


@inproceedings{20080311036793 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Let's modularize the data model specifications of the ObjectLens in VisualWorks/smalltalk},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Prasse, Michael},
volume = {4406 LNCS},
year = {2007},
pages = {111 - 133},
issn = {03029743},
address = {Prague, Czech republic},
abstract = {The ObjectLens framework of VisualWorks maps objects to tables. This mapping is described in a data mapping model, which itself is specified in one dataModelSpec method. This method is monolithic and defines the whole data model of an application. This is a suitable approach to start with. However, when the business area extends to a set of similar applications, like a software product family, each of these applications needs its own data model specification. All specifications of the product family would be quite similar but there is no appropriate reuse-mechanism, which could be used. Consequently, the monolithic design specifications lead to a high degree of redundancy, which complicates software development and maintenance. Therefore, this paper describes an approach, which leads to a separation of the monolithic data model specifications. The main idea is to define the mappings of each class in the class itself using inheritance and generate the whole specification from a list of single class data models. In this way, declarative and generative programming techniques are combined. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Data structures},
keywords = {Computer software reusability;Problem solving;Software design;Specification languages;Three dimensional computer graphics;},
note = {Design patterns;Generative programming;ObjectLens;Smalltalk;Software product families;VisualWorks;},
} 


@inproceedings{20104013271219 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Apto: A MDD-based generic framework for context-aware deeply adaptive service-based processes},
journal = {ICWS 2010 - 2010 IEEE 8th International Conference on Web Services},
author = {Jaroucheh, Zakwan and Liu, Xiaodong and Smith, Sally},
year = {2010},
pages = {219 - 226},
address = {Miami, FL, United states},
abstract = {Context-awareness and adaptability are important and desirable properties of service-based processes designed to provide personalized services. Most of the existing approaches focus on the adaptation at the process instance level [1] which involves extending the standard Business Process Execution Language (BPEL) and its engine or creating their own process languages (e.g. [2]). However, the approach proposed here aims to apply an adaptation to processes modeled or developed without any adaptation possibility in mind and independently of specific usage contexts. In addition, most of the existing approaches tackle the adaptation on the process instance or definition levels by explicitly specifying some form of variation points. This, however, leads to a contradiction between how the architect logically views and interprets differences in the process family and the actual modeling constructs through which the logical differences must be expressed. We introduce the notion of an evolution fragment and evolution primitive to capture the variability in a more logical and independent way. Finally, the proposed approach intends to support the viewpoint of context-aware adaptation as a crosscutting concern with respect to the core "business logic" of the process. In this way, the design of the process core can be decoupled from the design of the adaptation logic. To this end, we leverage ideas from the domain of model-driven development (MDD) and generative programming. &copy; 2010 IEEE.},
key = {Web services},
keywords = {Linguistics;},
note = {Adaptive services;BPEL;Business logic;Business process execution language;Context- awareness;Context-Aware;Context-aware adaptation;Crosscutting concern;Generative programming;Generic frameworks;MDD;Model-driven development;Modeling construct;Personalized service;Process instances;Process languages;Process-instance level;Service-based;Usage context;},
URL = {http://dx.doi.org/10.1109/ICWS.2010.16},
} 


@inproceedings{20113714332209 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MetaEdit+: Domain-specific modeling environment for product lines},
journal = {ACM International Conference Proceeding Series},
author = {Tolvanen, Juha-Pekka},
year = {2011},
pages = {Siemens; Hitachi - Inspire the Next; Pure-Systems; Biglever Software Inc.; Software Engineering Institute - Carnegie Mellon - },
address = {Munich, Germany},
abstract = {This demonstration shows how Domain-Specific Modeling languages and related generators are used in product line development. First with practical examples we describe how languages and generators are defined with MetaEdit+ tool. We also describe how modern tools support evolution of the product line by updating the languages and models once the product line evolves. Demonstration ends with discussion on industry experiences from various product line companies. Copyright &copy; 2011 ACM.},
key = {Problem oriented languages},
note = {Code Generation;Domain specific languages;Domain specific modeling;Domain-specific modeling language;Industry experience;Language workbenches;Modern tools;Product line development;Product-lines;},
URL = {http://dx.doi.org/10.1145/2019136.2019195},
} 


@inproceedings{20095212579646 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MetaEdit+: Defining and using integrated domain-specific modeling languages},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Tolvanen, Juha-Pekka and Kelly, Steven},
year = {2009},
pages = {819 - 820},
address = {Orlando, FL, United states},
abstract = {With MetaEdit+ you can build Domain-Specific Modeling languages and tools - without having to write a single line of code. This demonstration shows how different domain-specific languages (DSLs) can be integrated with high-level metamodels, how languages can be created iteratively while automatically updating existing models, and how multiple modelers can work together seamlessly.},
key = {Object oriented programming},
keywords = {Computer systems programming;Linguistics;Network components;Problem oriented languages;Query languages;},
note = {Code Generation;Different domains;Domain specific languages;Domain-specific modeling language;Line of codes;Meta model;Metamodeling;},
URL = {http://dx.doi.org/10.1145/1639950.1640031},
} 


@inproceedings{20100912734933 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic domain model migration to manage metamodel evolution},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Narayanan, Anantha and Levendovszky, Tihamer and Balasubramanian, Daniel and Karsai, Gabor},
volume = {5795 LNCS},
year = {2009},
pages = {706 - 711},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {Metamodel evolution is a significant problem in domain specific software development for several reasons. Domain-specific modeling languages (DSMLs) are likely to evolve much more frequently than programming languages and commonly used software formalisms, often resulting in a large number of valuable instance models that are no longer compliant with the metamodel. In this paper, we present the Model Change Language (MCL), aimed at satisfying these requirements. &copy; 2009 Springer Berlin Heidelberg.},
key = {Query languages},
keywords = {Computer software;Linguistics;Models;},
note = {Domain model;Domain specific software development;Domain-specific modeling language;Meta model;Model change;Programming language;},
URL = {http://dx.doi.org/10.1007/978-3-642-04425-0_57},
} 


@inproceedings{20104713407583 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Metamodelling: State of the art and research challenges},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Sprinkle, Jonathan and Rumpe, Bernhard and Vangheluwe, Hans and Karsai, Gabor},
volume = {6100 LNCS},
year = {2010},
pages = {57 - 76},
issn = {03029743},
address = {Dagstuhl Castle, Germany},
abstract = {This chapter discusses the current state of the art, and emerging research challenges, for metamodelling. In the state-of-the-art review on metamodelling, we review approaches, abstractions, and tools for metamodelling, evaluate them with respect to their expressivity, investigate what role(s) metamodels may play at run-time and how semantics can be assigned to metamodels and the domain-specific modeling languages they could define. In the emerging challenges section on metamodelling we highlight research issues regarding the management of complexity, consistency, and evolution of metamodels, and how the semantics of metamodels impacts each of these. &copy; 2010 Springer-Verlag.},
key = {Real time systems},
keywords = {Embedded systems;Research;},
note = {Domain-specific modeling language;Meta model;Meta-modelling;Research challenges;Research issues;Runtimes;State of the art;State-of-the-art reviews;},
URL = {http://dx.doi.org/10.1007/978-3-642-16277-0_3},
} 


@inproceedings{20112814146051 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {From UML profiles to EMF profiles and beyond},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Langer, Philip and Wieland, Konrad and Wimmer, Manuel and Cabot, Jordi},
volume = {6705 LNCS},
year = {2011},
pages = {52 - 67},
issn = {03029743},
address = {Zurich, Switzerland},
abstract = {Domain-Specific Modeling Languages (DSMLs) are getting more and more attention as a key element of Model Driven Engineering. As any other software artefact, DSMLs should continuously evolve to adapt to the changing needs of the domain they represent. Unfortunately, right now evolution of DSMLs is a costly process that requires changing its metamodel and re-creating the complete modeling environment. In this paper we advocate for the use of EMF Profiles, an adaptation of the UML profile concept to DSMLs. Profiles have been a key enabler for the success of UML by providing a lightweight language-inherent extension mechanism which is expressive enough to cover an important subset of adaptation scenarios. We believe a similar concept for DSMLs would provide an easier extension mechanism which has been so far neglected by current metamodeling tools. Apart from direct metamodel profiles, we also propose reusable profile definition mechanisms whereby profiles are defined independently of any DSML and, later on, coupled with all DSMLs that can benefit from these profiles. Our approach has been implemented in a prototype integrated in the EMF environment. &copy; 2011 Springer-Verlag Berlin Heidelberg.},
key = {Unified Modeling Language},
keywords = {Markup languages;Models;},
note = {Domain-specific modeling language;Key elements;Language engineering;Language extensions;Meta model;Metamodeling;Model-driven Engineering;Modeling environments;Software artefacts;UML profiles;},
URL = {http://dx.doi.org/10.1007/978-3-642-21952-8_6},
} 


@inproceedings{20113514267953 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Measuring and reducing modeling effort in domain-specific modeling languages with examples},
journal = {Proceedings - 18th IEEE International Conference and Workshops on Engineering of Computer-Based Systems, ECBS 2011},
author = {Hill, James H.},
year = {2011},
pages = {120 - 129},
address = {Las Vegas, NV, United states},
abstract = {Domain-specific modeling languages (DSMLs) facilitate rapid and "correct-by-construction" realization of concepts for the target domain. Although DSMLs provide such benefits, there is implied (or hidden) modeling effort - in terms of user actions - associated with using a DSML that can negatively impact its effectiveness. It is therefore critical that DSML developers understand the meaning of modeling effort and how to reduce it so their DSML is of high quality. This paper provides two contributions to research on developing DSMLs. First, the paper defines a metric for measuring model effort. Secondly, this paper discusses several techniques, with examples, reducing (or improving) modeling effort. The techniques discussed in the paper have been applied to an open-source DSML called the Platform Independent Component Modeling Language (PICML), which is currently used in both academic and industry settings for designing and implementing large-scale distributed systems. Finally, results show that it is possible to reduce modeling effort without requiring user studies to analyze such concerns. &copy; 2011 IEEE.},
key = {Technical presentations},
note = {Correct-by-construction;Domain-specific modeling language;High quality;Large-scale distributed system;Measuring model;Open-source;Platform-independent component modeling languages;Target domain;User action;User study;},
URL = {http://dx.doi.org/10.1109/ECBS.2011.22},
} 


@inproceedings{20112314038771 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling Interface Definition Language Extensions (IDL3+) using domain-specific modeling languages},
journal = {Proceedings - 2011 14th IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing, ISORC 2011},
author = {Hill, James H.},
year = {2011},
pages = {75 - 82},
address = {Newport Beach, CA, United states},
abstract = {Model-driven engineering (MDE) of distributed real-time and embedded (DRE) systems built using distributed middleware technologies typically rely on interface definition language (IDL) to define interfaces and attributes of the system under development. Recent needs for using IDL to design and implement systems composed of heterogeneous communication architectures, however, has realized the limitations of IDL. To address these limitations, vendors have proposed several non-trivial extensions to IDL also known as IDL3+. In order to leverage such extensions in the modeling domain, it is necessary to update existing tools, e.g., domain-specific modeling languages) to support such extensions. This paper provides two contributions to MDE of DRE systems using domain-specific modeling languages (DSMLs). First, this paper highlights the technical challenges associated with modeling IDL3+. Secondly, this paper discusses how to overcome such challenges in the context of a representative DSML for modeling DRE systems designed and implemented using IDL3+. Experience gained from using DSMLs to model IDL3+ shows that DSML environments as is do not suffice and need improved application frameworks to support complex DSMLs, such as IDL3+. &copy; 2011 IEEE.},
key = {Distributed computer systems},
keywords = {Embedded systems;Middleware;Real time systems;Systems analysis;},
note = {Application frameworks;Distributed middleware;Distributed real-time and embedded systems;Domain specific;Domain-specific modeling language;DRE systems;Heterogeneous communication;Heterogenous system;IDL3+;Interface definition languages;Model-driven engineering;Non-trivial;Technical challenges;},
URL = {http://dx.doi.org/10.1109/ISORC.2011.19},
} 


@inproceedings{20103713226561 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Library concepts for model reuse},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Herrmannsdorfer, Markus and Hummel, Benjamin},
volume = {253},
number = {7},
year = {2010},
pages = {121 - 134},
issn = {15710661},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Reuse and the composition of libraries of partial system descriptions is a fundamental and well-understood practice in software engineering, as long as we talk about source code. For models and modeling languages, the concepts of reuse often are limited to copy &amp; paste, especially when it comes to domain-specific modeling languages (DSLs). This paper attempts to give an overview of techniques for including support for reuse and library concepts both in the meta-model and the modeling tool, and presents a novel generative approach for this task. The technical consequences for each of the approaches presented are discussed and compared to each other. &copy; 2010 Elsevier B.V. All rights reserved.},
key = {Computer software reusability},
keywords = {Linguistics;Software engineering;},
note = {Domain-specific modeling language;Meta model;Model library;Model re-use;model-based development;Modeling languages;Modeling tool;Partial systems;reuse;Source codes;},
URL = {http://dx.doi.org/10.1016/j.entcs.2010.08.036},
} 


@inproceedings{20104713407586 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling languages for real-time and embedded systems: Requirements and standards-based solutions},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Gerard, Sebastien and Espinoza, Huascar and Terrier, Francois and Selic, Bran},
volume = {6100 LNCS},
year = {2010},
pages = {129 - 154},
issn = {03029743},
address = {Dagstuhl Castle, Germany},
abstract = {Development of increasingly more sophisticated dependable real-time and embedded systems requires new paradigms since contemporary code-centric approaches are reaching their limits. Experience has shown that model-based engineering using domain-specific modeling languages is an approach that can overcome many of these limitations. This chapter first identifies the requirements for a modeling language to be used in the real-time and embedded systems domain. Second, it describes how the MARTE profile of the industry-standard UML language meets these requirements. MARTE enables precise modeling of phenomena such as time, concurrency, software and hardware platforms, as well as their quantitative characteristics. &copy; 2010 Springer-Verlag.},
key = {Real time systems},
keywords = {Embedded systems;Frequency standards;},
note = {Domain-specific modeling language;Hardware platform;Model-based engineering;Modeling languages;Precise modeling;Quantitative characteristics;Real-time and embedded systems;UML language;},
URL = {http://dx.doi.org/10.1007/978-3-642-16277-0_6},
} 


@inproceedings{20110913701953 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Comparing state- and operation-based change tracking on models},
journal = {Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOC},
author = {Koegel, Maximilian and Herrmannsdoerfery, Markus and Liz, Yang and Helmingx, Jonas and David, Joern},
year = {2010},
pages = {163 - 172},
issn = {15417719},
address = {Vitoria, Brazil},
abstract = {In recent years, models are increasingly used throughout the entire lifecycle in software development projects. In effect, the need for collaborating on these models emerged, requiring change tracking and versioning. However, many researchers have shown that existing methods and tools for Version Control (VC) do not work well on graph-like models, such as UML, SysML or domain-specific modeling languages. To alleviate this, alternative techniques and methods have been proposed which can be classified into state-based and operation-based approaches. Existing research shows advantages of operation-based over state-based approaches in selected use cases, such as conflict detection or merging. However, there are only few results available on the advantages of operation-based approaches in the most common use case of a VC system: review and understand change. In this paper, we present and discuss both approaches and their use cases. Moreover, we present the results of an empirical study to compare a state-based with an operation-based approach for the use case of reviewing and understanding change. For this study, we have mined an operation-based model repository and interviewed users to assess their understanding of randomly selected changes. Our results indicate that users better understand complex changes in the operation-based representation. &copy; 2010 IEEE.},
key = {Software design},
note = {Change tracking;Conflict detection;Domain-specific modeling language;Empirical studies;Existing method;Model repositories;Software development projects;State-based;Version control;Versioning;},
URL = {http://dx.doi.org/10.1109/EDOC.2010.15},
} 


@inproceedings{20105113510259 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling heterogeneous points of view with ModHel'X},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Boulanger, Frederic and Jacquet, Christophe and Hardebolle, Cecile and Rouis, Elyes},
volume = {6002 LNCS},
year = {2010},
pages = {310 - 324},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {Non-functional properties (NFPs) concern various characteristics of a system (cost, power, QoS). These characteristics belong to different models of the system, built by different design teams, using different formalisms. Therefore, the design of a system includes a number of domain-specific modeling languages, used to express various NFPs. This paper focuses on the heterogeneity of the points of view on the system. We show that "multi-view" approaches which do not rely on a unique underlying model appear better-suited to express NFPs than model weaving or annotations. However, existing approaches in this category do not yet support model execution. We introduce a multi-view extension to Mod- Hel'X, a framework for executing heterogeneous models, and we show how it can be used for modeling non-functional characteristics of a system and expressing NFPs. A key point of this approach is that it relies only on the core concepts of ModHel'X, but uses them in new ways. &copy; Springer-Verlag Berlin Heidelberg 2010.},
key = {Models},
keywords = {Software engineering;},
note = {Belong to;Design team;Domain-specific modeling language;Heterogeneous models;Keypoints;Model executions;Model weaving;Multi-views;Non functional properties;Non-functional;},
URL = {http://dx.doi.org/10.1007/978-3-642-12261-3_29},
} 


@article{20102513023194 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Tools for continuously evaluating distributed system qualities},
journal = {IEEE Software},
author = {Hill, James and Schmidt, D. and Edmondson, James and Gokhale, Aniruddha},
volume = {27},
number = {4},
year = {2010},
pages = {65 - 71},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {The end-to-end evaluation of distributed systems' quality-of-service (QoS) properties such as performance, reliability, and security has historically occurred late in the software life cycle. As a result, many design flaws that affect QoS aren't found and fixed in a timely and cost-effective manner. Model-driven engineeringparticularly, domain-specific modeling languages (DSMLs) coupled with system execution modeling toolscan enable agile development of distributed systems and facilitate continuous system integration testing to improve quality assurance of QoS properties throughout the software life cycle. For example, the authors have realized such agile techniques in an open-source DSML-based system execution modeling tool called CUTS (Component Workload Emulator [Coworker] Utilization Test Suite). They've used CUTS as a case study to qualitatively and quantitatively evaluate how DSML-based system execution modeling tools can support lightweight and adaptable software development and QoS assurance processes. &copy; 2006 IEEE.},
key = {Agile manufacturing systems},
keywords = {Computer software selection and evaluation;Life cycle;Linguistics;Network security;Quality assurance;Quality control;Quality of service;Software design;Software reliability;Total quality management;},
note = {Continuous system;Distributed systems;Domain-specific modeling language;Model-driven Engineering;Modeling tool;},
URL = {http://dx.doi.org/10.1109/MS.2009.197},
} 


@article{20103613216363 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Synchronization of abstract and concrete syntax in domain-specific modeling languages: By mapping models and live transformations},
journal = {Software and Systems Modeling},
author = {Rath, Istvan and Okros, Andras and Varro, Daniel},
volume = {9},
number = {4},
year = {2010},
pages = {453 - 471},
issn = {16191366},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {Modern domain-specific modeling (DSM) frameworks provide refined techniques for developing new languages based on the clear separation of conceptual elements of the language (called abstract syntax) and their graphical visual representation (called concrete syntax). This separation is usually achieved by recording traceability information between the abstract and concrete syntax using mapping models. However, state-of-the-art DSM frameworks impose severe restrictions on traceability links between elements of the abstract syntax and the concrete syntax. In the current paper, we propose a mapping model which allows to define arbitrarily complex mappings between elements of the abstract and concrete syntax. Moreover, we demonstrate how live model transformations can complement mapping models in providing bidirectional synchronization and implicit traceability between models of the abstract and the concrete syntax. In addition, we introduce a novel architecture for DSM environments which enables these concepts, and provide an overview of the tool support. &copy; 2009 Springer-Verlag.},
key = {Syntactics},
keywords = {Abstracting;Linguistics;Mapping;Query languages;Synchronization;},
note = {Abstract syntax;Complex mapping;Conceptual elements;Concrete syntax;Domain specific modeling;Domain-specific modeling language;Live model transformations;Mapping model;Model synchronization;Model transformation;Novel architecture;Refined techniques;Tool support;Traceability;Traceability information;Traceability links;Visual representations;},
URL = {http://dx.doi.org/10.1007/s10270-009-0122-7},
} 


@article{20102312994136 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automating the construction of domain-specific modeling languages for object-oriented frameworks},
journal = {Journal of Systems and Software},
author = {Santos, Andre L. and Koskimies, Kai and Lopes, Antonia},
volume = {83},
number = {7},
year = {2010},
pages = {1078 - 1093},
issn = {01641212},
address = {360 Park Avenue South, New York, NY 10010, United States},
abstract = {The extension of frameworks with domain-specific modeling languages (DSML) has proved to be an effective way of improving the productivity in software product-line engineering. However, developing and evolving a DSML is typically a difficult and time-consuming task because it requires to develop and maintain a code generator, which transforms application models into framework-based code. In this paper, we propose a new approach for extending object-oriented frameworks that aims to alleviate this problem. The approach is based on developing an additional aspect-oriented layer that encodes a DSML for building framework-based applications, eliminating the need of implementing a code generator. We further show how a language workbench is capable of automating the construction of DSMLs using the proposed layer. &copy; 2010 Elsevier Inc. All rights reserved.},
key = {Object oriented programming},
keywords = {Computer software;Computer systems programming;Linguistics;Network components;Query languages;Wavelet transforms;},
note = {Application models;Aspect-oriented;Aspect-Oriented Programming;Code generators;Domain specific modeling;Domain-specific modeling language;Language workbenches;New approaches;Object-oriented frameworks;Software products;Time-consuming tasks;},
URL = {http://dx.doi.org/10.1016/j.jss.2010.01.047},
} 


@article{20100712708655 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards domain-specific model editors with automatic model completion},
journal = {Simulation},
author = {Sen, Sagar and Baudry, Benoit and Vangheluwe, Hans},
volume = {86},
number = {2},
year = {2010},
pages = {109 - 126},
issn = {00375497},
address = {55 City Road, London, EC1Y 1SP, United Kingdom},
abstract = {Integrated development environments such as Eclipse allow users to write programs quickly by presenting a set of recommendations for code completion. Similarly, word processing tools such as Microsoft Word present corrections for grammatical errors in sentences. Both of these existing structure editors use a set of constraints expressed in the form of a natural language grammar to restrict/correct the user ( syntax-directed editing) or formal grammar (language-directed editing ) to aid document completion. Taking this idea further, in this paper we present an integrated software system capable of generating recommendations for model completion of partial models built in editors for domain-specific modeling languages. We present a methodology to synthesize model editors equipped with automatic completion from a modeling languages declarative specification consisting of a meta-model with a visual syntax. This meta-model directed completion feature is powered by a first-order relational logic engine implemented in ALLOY. We incorporate automatic completion in the generative tool AToM<sup>3</sup>. We use the finite state machines modeling language as a concise running example. Our approach leverages a correct by construction philosophy that renders subsequent simulation of models considerably less error-prone. &copy; 2010 The Society for Modeling and Simulation International.},
key = {Query languages},
keywords = {Alloys;Atoms;Cerium alloys;Computational linguistics;Computer simulation languages;Computer software;Object oriented programming;Philosophical aspects;Syntactics;Word processing;},
note = {Domain-specific modeling language;Meta model;Model completion;Model completions;Partial model;},
URL = {http://dx.doi.org/10.1177/0037549709340530},
} 


@inproceedings{20110813694015 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven engineering: Raising the abstraction level through domain-specific modeling},
journal = {Proceedings of the Annual Southeast Conference},
author = {Gray, Jeff and White, Jules and Gokhale, Aniruddha},
year = {2010},
address = {Oxford, MS, United states},
abstract = {Model-Driven Engineering (MDE) has emerged as a promising paradigm in software engineering by emphasizing the use of models not just for documentation and communication purposes, but as first-class artifacts to be transformed into other work products (e.g., other models, source code, and test scripts). MDE supports full-scale round-trip engineering, from idea inception to operationalization. Historically, models have been developed using general-purpose modeling languages, such as the Unified Modeling Language (UML). A more recent trend is to use domain-specific modeling languages (DSMLs), which assist domain experts in working within their own problem space without being concerned about technical details of the solution space (e.g., programming languages and middleware). DSMLs also provide an accessible way to communicate with stakeholders who are not familiar with the fast changing technologies. This introductory tutorial will present a summary of the areas represented by MDE and offer some insight into the benefits of using DSMLs in both research and teaching. Copyright &copy; 2010 ACM.},
key = {Unified Modeling Language},
keywords = {Middleware;Models;Software engineering;Teaching;},
note = {Abstraction level;Domain experts;Domain specific modeling;Domain-specific modeling language;Model-driven engineering;Modeling languages;Problem space;Programming language;Recent trends;Solution space;Source codes;Technical details;Test scripts;Work products;},
URL = {http://dx.doi.org/10.1145/1900008.1900010},
} 


@article{IP51194110 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Weaving variability into domain metamodels},
journal = {Software and Systems Modeling},
author = {Perrouin, Gilles and Vanwormhoudt, Gilles and Morin, Brice and Lahire, Philippe and Barais, Olivier and Jezequel, Jean-Marc},
year = {2010},
pages = {1 - 23},
issn = {16191366},
abstract = {Domain-specific modeling languages (DSMLs) are the essence of MDE. A DSML describes the concepts of a particular domain in a metamodel, as well as their relationships. Using a DSML, it is possible to describe a wide range of different models that often share a common base and vary on some parts. On the one hand, some current approaches tend to distinguish the variability language from the DSMLs themselves, implying greater learning curve for DSMLs stakeholders and a significant overhead in product line engineering. On the other hand, approaches integrating variability in DSMLs lack generality and tool support. We argue that aspect-oriented modeling techniques enabling flexible metamodel composition and results obtained by the software product line community to manage and resolve variability form the pillars for a solution for integrating variability into DSMLs. In this article, we consider variability as an independent and generic aspect to be woven into the DSML. In particular, we detail how variability is woven and how to perform product line derivation. We validate our approach through the weaving of variability into two different metamodels: Ecore-widely used for DSML definition-and S martA dapters, our aspect model weaver. These results emphasize how new abilities of the language can be provided by this means. &copy; 2010 Springer-Verlag.},
key = {Weaving},
keywords = {Production engineering;},
note = {Aspect model;Aspect oriented modeling;Common-base;Domain metamodels;Domain-specific modeling language;Learning curves;Meta model;Product line engineering;Product-lines;Software Product Line;Tool support;},
URL = {http://dx.doi.org/10.1007/s10270-010-0186-4},
} 


@inproceedings{20104713402124 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MDE-based approach for generalizing design space exploration},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Saxena, Tripti and Karsai, Gabor},
volume = {6394 LNCS},
number = {PART 1},
year = {2010},
pages = {46 - 60},
issn = {03029743},
address = {Oslo, Norway},
abstract = {Design Space Exploration (DSE) is the exploration of design alternatives before the implementation. Existing DSE frameworks are domain-specific where the representation, evaluation method as well as exploration algorithm are tightly coupled with domain-dependent assumptions. Although the tasks involved in DSE are similar, the inflexibility of the existing frameworks restricts their reuse for solving DSE problems from other domains. This paper presents an MDE-based approach for generalizing DSE techniques. The framework supports a reconfigurable representation of a design space, which is decoupled from exploration algorithm. The framework can be configured to solve DSE problems from different domains and enables the designer to experiment with different approaches to solve the same problem with minimum effort. The main contributions of this framework are: (1) rapid modeling of DSE problems, (2) reuse of previously defined artifacts, (3) multiple solver support and (4) a tool for scalability study. &copy; 2010 Springer-Verlag.},
key = {Problem solving},
keywords = {Design;Models;Space research;},
note = {Design alternatives;Design space exploration;Design spaces;Different domains;Domain specific;Domain-specific modeling language;Evaluation Method;Re-configurable;Tightly-coupled;},
URL = {http://dx.doi.org/10.1007/978-3-642-16145-2_4},
} 


@inproceedings{20105113510252 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Deriving correspondence relationships to guide a multi-view heterogeneous composition},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Yie, Andres and Casallas, Rubby and Deridder, Dirk and Wagelaar, Dennis},
volume = {6002 LNCS},
year = {2010},
pages = {225 - 239},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {The use of several view models is a common practice to specify diverse concerns of a complex system. It is advantageous to use appropriate Domain-Specific Modeling Languages, at high-level of abstraction, to specify each concern. To actually produce the running application, it is necessary not only to transform the view-models into code, but also to compose them. We can establish at the high-level correspondence relationships between the concepts in the different concerns, but it is a complex task to compose the models at this level because we face a heterogeneous composition problem. Therefore, our strategy is to independently transform each view model into a common low-level language to perform a homogeneous composition. We create a mechanism to automatically derive correspondence relationships between the generated low-level models. These new correspondences contain the information to guide a homogeneous composition. &copy; Springer-Verlag Berlin Heidelberg 2010.},
key = {Models},
keywords = {High level languages;Software engineering;},
note = {Complex systems;Complex task;Domain-specific modeling language;Heterogeneous composition;Homogeneous composition;Level model;Level of abstraction;Low-level language;Model composition;Model driven engineering;Model transformation;Multi paradigm modeling;Multi-views;Running applications;},
URL = {http://dx.doi.org/10.1007/978-3-642-12261-3_22},
} 


@inproceedings{20111013724836 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Evaluation of development tools for domain-specific modeling languages},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Amyot, Daniel and Farah, Hanna and Roy, Jean-Francois},
volume = {4320 LNCS},
year = {2006},
pages = {183 - 197},
issn = {03029743},
address = {Kaiserslautern, Germany},
abstract = {Creating and maintaining tools for domain-specific modeling languages (DSML) demands time and efforts that often discourage potential developers. However, several tools are now available that promise to accelerate the development of DSML environments. In this paper, we evaluate five such tools (GME, Tau G2, RSA, XMF-Mosaic, and Eclipse with GEF and EMF) by observing how well they can be used to create graphical editors for the Goal-oriented Requirement Language (GRL), for which a simplified metamodel is provided. We discuss the evaluation criteria, results, and lessons learned during the creation of GRL editors with these technologies. &copy; Springer-Verlag 2006.},
key = {Systems analysis},
note = {Development tools;Domain-specific modeling language;Evaluation criteria;Goal-oriented requirement language;Graphical editors;Meta model;},
URL = {http://dx.doi.org/10.1007/11951148_12},
} 


@article{20093612288849 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Supporting domain-specific model patterns with metamodeling},
journal = {Software and Systems Modeling},
author = {Levendovszky, Tihamer and Lengyel, Laszlo and Meszaros, Tamas},
volume = {8},
number = {4},
year = {2009},
pages = {501 - 520},
issn = {16191366},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {Metamodeling is a widely applied technique in the field of graphical languages to create highly configurable modeling environments. These environments support the rapid development of domain-specific modeling languages (DSMLs). Design patterns are efficient solutions for recurring problems. With the proliferation of DSMLs, there is a need for domain-specific design patterns to offer solutions to problems recurring in different domains. The aim of this paper is to provide theoretical and practical foundations to support domain-specific model patterns in metamodeling environments. In order to support the treatment of premature model parts, we weaken the instantiation relationship. We provide constructs relaxing the instantiation rules, and we show that these constructs are appropriate and sufficient to express patterns. We provide the necessary modifications in metamodeling tools for supporting patterns. With the contributed results, a well-founded domain-specific model pattern support can be realized in metamodeling tools. &copy; Springer-Verlag 2009.},
key = {Linguistics},
note = {Configurable;Design Patterns;Different domains;Domain specific;Domain-specific modeling language;Graphical languages;Metamodeling;Metamodeling environment;Modeling environments;Practical foundations;Rapid development;},
URL = {http://dx.doi.org/10.1007/s10270-009-0118-3},
} 


@inproceedings{20093512270444 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Specifying and composing concerns expressed in domain-specific modeling languages},
journal = {Lecture Notes in Business Information Processing},
author = {Hovsepyan, Aram and Van Baelen, Stefan and Berbers, Yolande and Joosen, Wouter},
volume = {33 LNBIP},
year = {2009},
pages = {116 - 135},
issn = {18651348},
address = {Zurich, Switzerland},
abstract = {Separation of concerns and levels of abstraction are key software engineering principles that can help master the increasing complexity of software applications. Aspect-oriented modeling (AOM) and domain-specific modeling languages (DSML) are two important and promising approaches in this context. However, little research is done to investigate the synergy between AOM and DSMLs. In this paper we present an asymmetric approach to compose modularized concerns expressed in different DSMLs with an application base model expressed in a general-purpose modeling language (GPML). This allows to specify each concern in the most appropriate modeling language. We introduce the concept of a concern interface, expressed in a GPML, that serves as a common language between a specific concern and the application base. In addition, we use an explicit composition model to specify the syntactic and the semantic links between entities from the different concerns. We explore these concepts using an application where we modularize the user interface modeled in WebML and the access control specified in XACML. The modularized concerns are then composed with an application base that has been specified in UML. &copy; 2009 Springer Berlin Heidelberg.},
key = {Query languages},
keywords = {Access control;Computer software;Linguistics;User interfaces;},
note = {Aspect-Oriented Modeling;Base models;Common languages;Composition model;Domain-specific modeling language;Levels of abstraction;Little research;Modeling languages;Modularized;Semantic link;Separation of concerns;Software applications;Software engineering principles;},
URL = {http://dx.doi.org/10.1007/978-3-642-02571-6_8},
} 


@inproceedings{20100412658058 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A lightweight approach for domain-specific modeling languages design},
journal = {Conference Proceedings of the EUROMICRO},
author = {Robert, Sylvain and Gerard, Sebastien and Terrier, Francois and Lagarde, Francois},
year = {2009},
pages = {155 - 161},
issn = {10896503},
address = {Patras, Greece},
abstract = {Off-the-shelves general purpose modeling languages cannot obviously cover the whole range of needs that can be encountered in current systems design. Therefore, putting efficiently Model-Driven Engineering into practice involves designing specific modeling languages. The goal is to cover in a more suitable manner a particular application domain (e.g. automotive) or specific concerns (e.g. hardware modeling) or even to focus on a given class of practitioners. In this respect, two design approaches are generally opposed which respectively propose to define domain-specific modeling languages from scratch or to customize an existing general-purpose language. This paper focuses on the latter approach and claims that UML profiles do provide handy and powerful mechanisms to design domain-specific modeling languages but are penalized by lacks of methodological guidelines and tool support. To cope with these lacks, a profile design approach is introduced, which includes a methodological framework to structure profiles design process and tool support to partly automate this process. &copy; 2009 IEEE.},
key = {Linguistics},
keywords = {Computer software;Engineering;High level languages;Knowledge based systems;Machine design;Query languages;Systems analysis;},
note = {Application domains;Current system;Design approaches;Design domains;Design process;Domain-specific modeling language;General purpose modeling languages;Methodological frameworks;Methodological guidelines;Model-driven Engineering;Modeling languages;Tool support;UML profiles;},
URL = {http://dx.doi.org/10.1109/SEAA.2009.81},
} 


@inproceedings{20093512270443 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Algebraic semantics of ocl-constrained metamodel specifications},
journal = {Lecture Notes in Business Information Processing},
author = {Boronat, Artur and Meseguer, Jose},
volume = {33 LNBIP},
year = {2009},
pages = {96 - 115},
issn = {18651348},
address = {Zurich, Switzerland},
abstract = {In the definition of domain-specific modeling languages a MOF metamodel is used to define the main types of its abstract syntax, and OCL invariants are used to add static semantic constraints. The semantics of a metamodel definition can be given as a model type whose values are well-formed models. A model is said to conform to its metamodel when it is a value of the corresponding model type. However, when OCL invariants are involved, the concept of model conformance has not yet been formally defined in the MOF standard. In this work, the concept of OCL-constrained metamodel conformance is formally defined and used for defining style-preserving software architecture configurations. This concept is supported in MOMENT2, an algebraic framework for MOF metamodeling, where OCL constraints can be used for both static and dynamic analysis. &copy; 2009 Springer Berlin Heidelberg.},
key = {Dynamic analysis},
keywords = {Algebra;Electric load shedding;Formal logic;Semantics;Software architecture;},
note = {Abstract syntax;Algebraic framework;Algebraic semantic;Domain-specific modeling language;Membership equational logic;Meta model;Metamodeling;MOF metamodel;OCL invariants;Static and dynamic analysis;Static and dynamic analysis of models;Static semantics;},
URL = {http://dx.doi.org/10.1007/978-3-642-02571-6_7},
} 


@inproceedings{20100912734932 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Weaving variability into domain metamodels},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Morin, Brice and Perrouin, Gilles and Lahire, Philippe and Barais, Olivier and Vanwormhoudt, Gilles and Jezequel, Jean-Marc},
volume = {5795 LNCS},
year = {2009},
pages = {690 - 705},
issn = {03029743},
address = {Denver, CO, United states},
abstract = {Domain-Specific Modeling Languages (DSMLs) describe the concepts of a particular domain and their relationships, in a metamodel. From a given DSML, it is possible to describe a wide range of different models. These models often share a common base and vary on some parts. Current approaches tend to distinguish the variability language from the DSMLs themselves, implying greater learning curve for DSMLs stakeholders and a significant overhead in product line engineering of DSMLs. We propose to consider variability as an independent aspect to be woven into the DSML to introduce variability capabilities. In particular we detail how variability is woven and how to perform product line derivation. We validate our approach through the weaving of variability into two very different metamodels: Ecore and SmartAdapter, our Aspect-Oriented modeling weaver, thus adding flexibility in the weaving process itself. These results emphasize how new abilities of the language can be provided by this means. &copy; 2009 Springer Berlin Heidelberg.},
key = {Models},
keywords = {Linguistics;Production engineering;Query languages;Weaving;},
note = {Aspect oriented modeling;Common-base;Domain metamodels;Domain-specific modeling language;Learning curves;Meta model;Product line engineering;Product-lines;},
URL = {http://dx.doi.org/10.1007/978-3-642-04425-0_56},
} 


@article{20101412822514 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A technique for defining metamodel translations},
journal = {IEICE Transactions on Information and Systems},
author = {Garcia-Magarino, Ivan and Fuentes-Fernandez, Ruben},
volume = {E92-D},
number = {10},
year = {2009},
pages = {2043 - 2052},
issn = {09168532},
address = {P.O. Box 247, Nihonbashi, Tokyo, 103-8691, Japan},
abstract = {Model-Driven Engineering and Domain-Specific Modeling Languages are encouraging an increased used of metamodels for the definition of languages and tools. Although the Meta Object Facility language is the standard for metamodeling, there are alternative metamodeling languages that are aimed at satisfying specific requirements. In this context, sharing information throughout different domains and tools requires not only being able to translate models between modeling languages de-fined with the same metamodeling language, but also between different metamodeling languages. This paper addresses this latter need describing a general technique to define transformations that perform this translation. In this work, two case studies illustrate the application of this process. Copyright &copy; 2009 The Institute of Electronics, Information and Communication Engineers.},
key = {Translation (languages)},
keywords = {Linguistics;Query languages;},
note = {Different domains;Domain-specific modeling language;Meta model;Meta object facility;Metamodeling;Model-driven Engineering;Modeling languages;Sharing information;Translation models;},
URL = {http://dx.doi.org/10.1587/transinf.E92.D.2043},
} 


@inproceedings{20100412654361 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven development in industrial automation: Automating the development of industrial automation systems using model transformations},
journal = {ICINCO 2009 - 6th International Conference on Informatics in Control, Automation and Robotics, Proceedings},
author = {Maurmaier, Mathias and Gohner, Peter},
volume = {2 RA},
year = {2009},
pages = {244 - 249},
address = {Milan, Italy},
abstract = {The complexity of modern automation systems is growing steadily. In software engineering, model-driven development proved that it contributes significantly to cope with this complexity in development, while increasing efficiency and the quality of the development results. However, hardware-software dependencies, different types of requirements that must be considered in development and the large number of modeling languages are specific challenges for a model-driven approach in automation technology. In this paper a concept of model-driven system development is presented that takes into account these challenges, and thus provides the possibility to leverage model-driven development in industrial automation technology.},
key = {Query languages},
keywords = {Computer software;Linguistics;Robotics;},
note = {Automation systems;Automation technology;Development results;Domain-specific modeling language;Industrial automation;Industrial automation system;Model driven approach;Model driven development;Model transformation;Model-driven;Modeling languages;},
} 


@inproceedings{20100412671185 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Verification of DSMLs using graph transformation: A case study with alloy},
journal = {ACM International Conference Proceeding Series},
author = {Demirezen, Zekai and Mernik, Marjan and Gray, Jeff and Bryant, Barrett},
volume = {413},
year = {2009},
address = {Denver, CO, United states},
abstract = {Domain-Specific Modeling Languages (DSMLs) enable domain experts to participate in software development tasks and to specify their own programs using domain abstractions. Many Model-Driven Engineering (MDE) platforms primarily concentrate on structural aspects of DSMLs and only provide techniques to define abstract and concrete syntax. Only a few platforms provide built-in support for specification of behavioral semantics and verification tasks. In this paper, we focus on how to specify the behavioral semantics of a DSML by a sequence of graph transformation rules. We also discuss how to transform a DSML specification into Alloy, a model checking tool. These transformations demonstrate that DSML models specified in a visual notation can be verified by means of existing model checking tools. Copyright &copy; 2009 ACM.},
key = {Model checking},
keywords = {Abstracting;Cerium alloys;Computer simulation languages;Linguistics;Semantics;Software engineering;Specifications;Systems analysis;},
note = {Activity diagram;Behavioral semantics;Concrete syntax;Domain abstraction;Domain experts;Domain-specific modeling language;Graph Transformation;Graph transformation rules;Graph transformation system;Model checking tools;Model-driven engineering;Operational semantics;Software development;Structural aspects;Verification task;Visual notations;},
URL = {http://dx.doi.org/10.1145/1656485.1656488},
} 


@article{20093612281681 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Cross-abstraction functional verification and performance analysis of chip multiprocessor designs},
journal = {IEEE Transactions on Industrial Informatics},
author = {Madl, Gabor and Pasricha, Sudeep and Dutt, Nikil and Abdelwahed, Sherif},
volume = {5},
number = {3},
year = {2009},
pages = {241 - 256},
issn = {15513203},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {This paper introduces the cross-abstraction real-time analysis (Carta) framework for the model-based functional verification and performance estimation of chip multiprocessors (CMPs) utilizing bus matrix (crossbar switch) interconnection networks. We argue that the inherent complexity in CMP designs requires the synergistic use of various models of computation to efficiently manage the tradeoffs between accuracy and complexity. Our approach builds on domain-specific modeling languages (DSMLs) driving an open-source tool-chain that provides a cross-abstraction bridge between the finite-state machine (FSM), discrete-event (DE), and timed automata (TA) models of computation, and utilizes multiple model checkers to analyze formal properties at the cycle-accurate and transaction-level abstractions. The cross-abstraction analysis exploits accuracy for functional verification, and achieves significant speedups for performance estimation with marginal accuracy loss. We demonstrate results on an industrial strength networking CMP design utilizing a bus matrix interconnection network. To the best of our knowledge, the Carta framework is the first model-based tool-chain that utilizes multiple abstractions and model checkers for the comprehensive and formal functional verification, performance estimation, and real-time verification of bus matrix-based CMP designs. &copy; 2006 IEEE.},
key = {Model checking},
keywords = {Abstracting;Buses;Design;Estimation;Interconnection networks;Matrix algebra;Microprocessor chips;Multiprocessing systems;Nanotechnology;Switching circuits;Systems analysis;Telecommunication networks;},
note = {Accuracy loss;Chip Multiprocessor;Chip multiprocessor (CMP);Crossbar switch;Cycle accurate;Discrete events;Domain-specific modeling language;Finite state machines;Formal properties;Functional verification;Industrial strength;Inherent complexity;matrix;Model checker;Model-based;Model-based tools;Models of computation;Multiple models;Open source tools;Performance analysis;Performance estimation;Real time analysis;Real-time;Timed automata models;},
URL = {http://dx.doi.org/10.1109/TII.2009.2026896},
} 


@article{2006029637325 ,
language = {Chinese},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling method for embedded equipment control system},
journal = {Huanan Ligong Daxue Xuebao/Journal of South China University of  Technology (Natural Science)},
author = {Song, Zhu-Mei and Li, Di},
volume = {33},
number = {10},
year = {2005},
pages = {29 - 33},
issn = {1000565X},
abstract = {With the aim of investigating domain-extending technologies for the embedded control of equipment, the model-integrated computing theory is applied to construct the modeling language of the embedded system. For the signal-processing subsystem, a meta-model is established in terms of four aspects, that is, class diagram, visualization, attributes and constraints. The associated model interpreter is modified according to the proposed meta-model. Then, by means of the meta-model interpreter, a graphical modeling language is driven from the meta-model. Based on the associated modeling language, two signal-processing models are built and transferred into two applications respectively. The results indicate that the proposed method is feasible for the rapid development of domain-specific applications.},
key = {Control systems},
keywords = {Applications;Calculations;Computer programming languages;Constraint theory;Embedded systems;Equipment;Mathematical models;Signal processing;Visualization;},
note = {Domain specific modeling language;Embedded equipment control system;Meta model;Model integrated computing;},
} 


@inproceedings{20102413012023 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A modeling language for vehicle motion control behavioral specification},
journal = {Proceedings - International Conference on Software Engineering},
author = {Wang, Shige and Birla, Sushil K. and Neema, Sandeep},
year = {2006},
pages = {53 - 59},
issn = {02705257},
address = {Shanghai, China},
abstract = {Error-free engineering of high integrity applications such as vehicle motion control (VMC) requires unambiguous behavioral specification. As system engineering progresses from requirements modeling to functional design, to system implementation on a distributed platform, the specifications of the system artifacts and work products must be transferred across different engineering environments and stages in models without loss of semantics. Modeling environments currently available for industrial use, with their native modeling languages, do not provide the capability of unambiguous behavior modeling across tools and engineering stages. In this paper, we identify certain fundamental requirements for high integrity systems and show that these requirements are not satisfied in current and proposed international standards, and two commercial modeling tools. A modeling language for VMC behavioral specification, eFSM, is proposed as a candidate for standardization and for adoption by the community in this domain. The language is based on a general mathematical modeling framework and an extended finite state machine paradigm. It adds unambiguous semantics essential to the VMC behavioral specification. An experimental prototype of the eFSM has been developed and evaluated relative to the requirements for modeling high integrity systems. Copyright 2006 ACM.},
key = {Mathematical models},
keywords = {Computer software;Industrial applications;Linguistics;Models;Motion control;Motion planning;Query languages;Semantics;Specifications;Vehicles;},
note = {Behavior modeling;Behavioral specification;Distributed platforms;Domain-specific modeling language;Engineering environment;Experimental prototype;Extended finite state machine;Functional design;High-integrity systems;Industrial use;International standards;Mathematical modeling;Modeling environments;Modeling languages;Modeling tool;Requirements modeling;System engineering;System implementation;Vehicle motion;Work products;},
URL = {http://dx.doi.org/10.1145/1138474.1138484},
} 


@inproceedings{20084711724766 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards the development of a rigorous model-driven domain-specific software engineering environment},
journal = {Proceedings of the 3rd IASTED International Conference on Advances in Computer Science and Technology, ACST 2007},
author = {Grant, Emanuel S. and Reza, Hassan},
year = {2007},
pages = {102 - 107},
address = {Phuket, Thailand},
abstract = {Over the past decades, the software development community has increasingly embraced the principles of a model-driven approach, resulting in the definition of many such methodologies. It is now an appropriate time to consolidate the many software model-driven approaches into a set of well-defined and related techniques, and processes. This set of techniques and processes, would be the building block for subsequent model-driven development methodologies. Such an accomplishment would provide a framework from which rigorously defined domain-specific methodologies are crafted. It would also provide a platform from which the next significant advancement in software development may be launched. The objective of this research is the definition and implementation of a platform independent environment for model-driven software development that incorporates formal specification techniques with informal graphical modeling notations. The methodologies of the environment will amalgamate some of the best practices in model-driven development from academia and industry. The success and viability of this defined environment will be manifested in its adaptation by industrial partners.},
key = {Formal methods},
keywords = {Computer science;Computer software;Computers;Linguistics;Software design;Software engineering;Systems analysis;},
note = {Architectural description language;Best practices;Building Blocks;Development methodologies;Do-mains;Domain-specific modeling language <sup>1</sup>;Formal specification techniques;Industrial partners;Model-driven software developments;Modeling notations;Platform independents;Rigorous models;Software developments;Software Engineering environments;Software models;},
} 


@inproceedings{2005529621802 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Toward a semantic anchoring infrastructure for domain-specific modeling languages},
journal = {Proceedings of the 5th ACM International Conference on Embedded Software, EMSOFT 2005},
author = {Chen, Kai and Sztipanovits, Janos and Neema, Sandeep},
year = {2005},
pages = {35 - 43},
address = {Jersey City, NJ, United states},
abstract = {Metamodeling facilitates the rapid, inexpensive development of domain-specific modeling languages (DSML-s). However, there are still challenges hindering the wide-scale industrial application of model-based design. One of these unsolved problems is the lack of a practical, effective method for the formal specification of DSML semantics. This problem has negative impact on reusability of DSML-s and analysis tools in domain specific tool chains. To address these issues, we propose a formal well founded methodology with supporting tools to anchor the semantics of DSML-s to precisely defined and validated "semantic units". In our methodology, each of the syntactic and semantic DSML components is defined precisely and completely. The main contribution of our approach is that it moves toward an infrastructure for DSML design that integrates formal methods with practical engineering tools. In this paper we use a mathematical model, Abstract State Machines, a common semantic framework to define the semantic domains of DSML-s. Copyright 2005 ACM.},
key = {Computer programming languages},
keywords = {Computer programming;Computer simulation;Computer software;Industrial applications;Semantics;Syntactics;},
note = {Abstract syntax;Domain-specific modeling language;Model-Integrated Computing;Semantic anchoring;},
} 


@inproceedings{20091412016831 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Axiom-based testing for C++},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Bagge, Anya Helene and David, Valentin and Haveraaen, Magne},
year = {2008},
pages = {721 - 722},
address = {Nashville, TN, United states},
abstract = {Axioms, known from program specification, allow program functionality to be described as rules or equations. The draft C++0x standard introduces axioms as part of the new concept feature. We will demonstrate a tool that uses these features for automated unit testing.},
key = {Object oriented programming},
keywords = {Computer software;Computer systems programming;Linguistics;Specifications;Systems analysis;},
note = {Axioms;C++;C++0x;Concepts;Generative programming;Mouldable programming;Program transformation;Test generation;Unit testing;},
URL = {http://dx.doi.org/10.1145/1449814.1449829},
} 


@inproceedings{20110813686685 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Reflective composition: The declarative composition of roles to unify objects, roles, and aspects},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Holland, Simon},
year = {2004},
pages = {224 - 225},
address = {Vancouver, BC, Canada},
abstract = {As bases for object-orientation, both class-based and prototype-based organization have limitations. We argue that roles have significant benefits as a foundation for organizing objects. We further argue that these benefits can be realised most flexibly using logic meta-programming. Additional benefits from this approach are to reduce redundancy and subsume aspects.},
key = {Object oriented programming},
keywords = {Computer systems programming;},
note = {Aspects;Composition;Generative programming;Logic meta programming;Role models;Roles;},
URL = {http://dx.doi.org/10.1145/1028664.1028761},
} 


@inproceedings{20092912190719 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A pattern for static reflection on fields sharing internal representations in indexed family containers},
journal = {ICSOFT 2007 - 2nd International Conference on Software and Data Technologies, Proceedings},
author = {Priesnitz, Andreas P. and Schupp, Sibylle},
volume = {PL},
number = {DPS/KE//-},
year = {2007},
pages = {30 - 37},
address = {Barcelona, Spain},
abstract = {Reflection allows defining generic operations in terms of the constituents of objects. These definitions incur overhead if reflection takes place at run time, which is the common case in popular languages. If performance matters, some compile-time means of reflection is desired to obviate that penalty. Furthermore, the information provided by static reflection can be utilised for class generation, e.g., to optimize internal representation. We demonstrate how to provide static reflection on class field properties by means of generic components in an OO language with static meta-programming facilities. Surprisingly, a major part of the solution is not specific to the particular task of providing reflection. We define the internal representation of classes by a reworked implementation of a generic container that models the concept of a statically indexed family. The proposed features of this implementation are also beneficial to its use as a common container.},
key = {Reflection},
keywords = {Computer software;Containers;Linguistics;Query languages;},
note = {Class generation;Compile time;Generative programming;Generic components;Generic containers;High performance;Indexed families;Internal representation;Meta Programming;Runtime;Serialization;Static reflection;},
} 


@inproceedings{20091412016856 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Testing with concepts and axioms in C++},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Bagge, Anya Helene and David, Valentin and Haveraaen, Magne},
year = {2008},
pages = {773 - 774},
address = {Nashville, TN, United states},
abstract = {Unit testing is a popular way of increasing software reliability. Axioms, known from program specification, allow functionality to be described as rules or equations. We show a method and prototype tool for using the proposed concept and axiom features of the upcoming C++0x standard for automated unit testing.},
key = {Object oriented programming},
keywords = {Computer software selection and evaluation;Computer systems programming;Linguistics;Software reliability;Software testing;Specifications;Systems analysis;},
note = {Axioms;C++;C++0x;Concepts;Generative programming;Mouldable programming;Program transformation;Test generation;Unit testing;},
URL = {http://dx.doi.org/10.1145/1449814.1449855},
} 


@inproceedings{2002387095789 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Maya: Multiple-dispatch syntax extension in Java},
journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
author = {Baker, Jason and Hsieh, Wilson C.},
year = {2002},
pages = {270 - 281},
address = {Berlin, Germany},
abstract = {We have designed and implemented Maya, a vers ion of Java that allows programmers to extend and reinterpret its syntax. Maya generalizes macro systems by treating grammar productions as generic functions, and semantic actions on productions as multimethods on the corresponding generic functions. Programmers can write new generic functions (i.e., grammar productions) and new multimethods (i.e., semantic actions), through which they can extend the grammar of the language and change the semantics of its syntactic constructs, respectively. Maya's multimethods are compile-time metaprograms that transform abstract syntax: they execute at program compile-time, because they are semantic actions executed by the parser. Maya's multimethods can be dispatched on the syntactic structure of the input, as well as the static, source-level types of expressions in the input. In this paper we describe what Maya can do and how it works. We describe how its novel parsing techniques work and how Maya can statically detect certain kinds of errors, such as code that generates references to free variables. Finally, to demonstrate Maya's expressiveness, we describe how Maya can be used to implement the Multi Java language, which was described by Clifton et al. at OOPSLA 2000.},
key = {Java programming language},
keywords = {Error analysis;Functions;Program compilers;},
note = {Generative programming;},
URL = {http://dx.doi.org/10.1145/512529.512562},
} 


@article{20080911115392 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Rational metaprogramming},
journal = {IEEE Software},
author = {Spinellis, Diomidis},
volume = {25},
number = {1},
year = {2008},
pages = {78 - 79},
issn = {07407459},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {Metaprogramming takes place when programs manipulate other programs. It is a powerful but tricky technique that can lead to unmaintainable code and bugs. None of the many current approaches to metaprogramming is mature. An ideal solution would use the same language for programming and metaprogramming. The language would be based on a small set of familiar programming constructs, and its compile-time objects would be first class citizens guaranteed to be syntactically correct and valid. &copy; 2008 IEEE.},
key = {Functional programming},
keywords = {Automatic programming;Codes (symbols);Computer programming languages;Program compilers;Syntactics;},
note = {Generative programming;Metaprogramming;},
URL = {http://dx.doi.org/10.1109/MS.2008.15},
} 


@inproceedings{20093912329797 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using Sysml to describe a new methodology for semiautomatic software generation from inferred behavioral and data models},
journal = {Proceedings of the 4th International Conference on Systems, ICONS 2009},
author = {Gonzalez Alonso, Ignacio and Garcia Fuente, M. P. Almudena and Brugos, J.A.L.},
year = {2009},
pages = {210 - 215},
address = {Gosier, Guadeloupe},
abstract = {This article describes a new methodology designed for semiautomatic generation of software applications using the new standard of OMG consortium: SYSML. The methodology has behavior and data model inference steps. Both data and behavior are inferred, the first by XSD-Schema inference and the latter by Business Process Mining inferences. The paper describes how by using SYSML a better description of the methodology is given, a description that allows making a better design than using UML standard tools. &copy; 2009 IEEE.},
key = {Computer software},
keywords = {Models;},
note = {Behaviour model;Data model;Generative programming;MDSD;Software methogology;SYSML;},
URL = {http://dx.doi.org/10.1109/ICONS.2009.50},
} 


@article{2004268235886 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative and incremental implementation for a scripting interface},
journal = {Journal of Systems Architecture},
author = {Savikko, Vespe},
volume = {50},
number = {7},
year = {2004},
pages = {427 - 439},
issn = {13837621},
address = {Las Vegas, NV, United states},
abstract = {Many systems may benefit from scripting support, but the implementation of it is seldom trivial, especially if the system has not originally been developed with scripting support in mind. In this paper we describe a generative, incremental process for creating an intuitive Python interface to a large, hierarchic COM library. The approach is illuminated with the original, real-life case study. &copy; 2003 Elsevier B.V. All rights reserved.},
key = {Interfaces (computer)},
keywords = {Abstracting;C (programming language);Codes (symbols);Computer programming;Hierarchical systems;Software engineering;Systems analysis;},
note = {Generative programming;Hierarchic COM library;Incremental development;Scripting;},
URL = {http://dx.doi.org/10.1016/j.sysarc.2003.09.007},
} 


@article{20113414248940 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A model-driven framework for aspect weaver construction},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Roychoudhury, Suman and Gray, Jeff and Jouault, Frederic},
volume = {6580},
year = {2011},
pages = {1 - 45},
issn = {03029743},
address = {Tiergartenstrasse 17, Heidelberg, D-69121, Germany},
abstract = {Aspect orientation has been used to improve the modularization of crosscutting concerns that emerge at different levels of software abstraction. Although initial research was focused on imparting aspect-oriented (AO) capabilities to programming languages, the paradigm was later on extended to software artifacts that appear at higher levels of abstraction (e.g., models). In particular, the Model-Driven Engineering (MDE) paradigm has largely benefitted from the inclusion of aspect-oriented techniques. In a converse way, we believe it may also be productive to investigate how MDE techniques can be adopted to benefit the development of aspect-oriented tools. The main objective of this paper is to show how MDE techniques can be used to improve the construction of aspect weavers for General-Purpose Languages (GPLs) through reusable models and transformations. The approach described in the paper uses models to capture the concepts of various Aspect-Oriented Programming (AOP) language constructs at a metamodeling level. These models are then mapped to concrete weavers for GPLs through a combination of higher-order model transformation and program transformation rules. A generic extension to the framework further supports reusability of artifacts among weavers during the construction process. Aspect weavers for FORTRAN and Object Pascal have been constructed using the framework, and their features evaluated against several case study applications. &copy; 2011 Springer-Verlag Berlin Heidelberg.},
key = {Aspect oriented programming},
keywords = {Abstracting;Computer systems programming;Modular construction;Object oriented programming;Reusability;Software design;Systems analysis;},
note = {Aspect oriented software development;Generative programming;Model engineering;model transformation;Program transformations;},
URL = {http://dx.doi.org/10.1007/978-3-642-22031-9_1},
} 


@inproceedings{20111413887100 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A step-wise approach for integrating QoS throughout software development},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Gatti, Stephanie and Balland, Emilie and Consel, Charles},
volume = {6603 LNCS},
year = {2011},
pages = {217 - 231},
issn = {03029743},
address = {Saarbrucken, Germany},
abstract = {When developing real-time systems such as avionics software, it is critical to ensure the performance of these systems. In general, deterministic Quality of Service (QoS) is guaranteed by the execution platform, independently of a particular application. For example, in the avionics domain, the ARINC 664 standard defines a data network that provides deterministic QoS guarantees. However, this strategy falls short of addressing how the QoS requirements of an application get transformed through all development phases and artifacts. Existing approaches provide support for QoS concerns that only cover part of the development process, preventing traceability. In this paper, we propose a declarative approach for specifying QoS requirements that covers the complete software development process, from the requirements analysis to the deployment. This step-wise approach is dedicated to control-loop systems such as avionics software. The domain-specific trait of this approach enables the stakeholders to be guided and ensures QoS requirements traceability via a tool-based methodology. &copy; 2011 Springer-Verlag.},
key = {Software design},
keywords = {Avionics;Quality control;Quality of service;Real time systems;Requirements engineering;},
note = {Data network;Development phasis;Development process;Domain specific;Generative Programming;Loop systems;QoS guarantee;QoS requirements;Requirements analysis;Software development;Software development process;},
URL = {http://dx.doi.org/10.1007/978-3-642-19811-3_16},
} 


@inproceedings{20112714122844 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Leveraging software architectures to guide and verify the development of sense/compute/control applications},
journal = {Proceedings - International Conference on Software Engineering},
author = {Cassou, Damien and Balland, Emilie and Consel, Charles and Lawall, Julia},
year = {2011},
pages = {431 - 440},
issn = {02705257},
address = {Waikiki, Honolulu, HI, United states},
abstract = {A software architecture describes the structure of a computing system by specifying software components and their interactions. Mapping a software architecture to an implementation is a well known challenge. A key element of this mapping is the architecture's description of the data and control-flow interactions between components. The characterization of these interactions can be rather abstract or very concrete, providing more or less implementation guidance, programming support, and static verification. In this paper, we explore one point in the design space between abstract and concrete component interaction specifications. We introduce a notion of interaction contract that expresses allowed interactions between components, describing both data and control-flow constraints. This declaration is part of the architecture description, allows generation of extensive programming support, and enables various verifications. We instantiate our approach in an architecture description language for Sense/Compute/Control applications, and describe associated compilation and verification strategies &copy; 2011 ACM.},
key = {Software architecture},
keywords = {Abstracting;},
note = {architectural conformance;Architecture description;Architecture description languages;Computing system;Concrete components;Control-flow;Design spaces;Generative programming;Implementation guidance;Interaction contracts;Key elements;Programming support;Software component;Static verification;Verification Strategy;},
URL = {http://dx.doi.org/10.1145/1985793.1985852},
} 


@inproceedings{20112914149702 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Optimization of visitor performance by reflection-based analysis},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Lepper, Markus and Trancon Y Widemann, Baltasar},
volume = {6707 LNCS},
year = {2011},
pages = {15 - 30},
issn = {03029743},
address = {Zurich, Switzerland},
abstract = {Visitors are a well-known and powerful design pattern for processing regular data structures and for combining declarative and imperative coding styles. The authors' umod model generator creates Java data models from a concise and algebraic notation. It is primarily used to model intermediate representations of computer languages. The user defines visitor code by extending skeleton classes, which are generated according to traversal annotations in the model. Since the generated code on its own executes the pure traversal and no semantic side-effects, traversals are redundant unless some user-overridden method is eventually invoked. We present a reflection-based control flow analysis to detect this situation and prune the traversal transparently. With a well-stratified model, this may lead to substantial increase in performance. &copy; 2011 Springer-Verlag.},
key = {Data handling},
keywords = {Data structures;Semantics;},
note = {Control flow analysis;Design Patterns;Generative Programming;Intermediate representations;Model generator;Side effect;Visitor patterns;},
URL = {http://dx.doi.org/10.1007/978-3-642-21732-6_2},
} 


@inproceedings{20104113278001 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The axioms strike back: Testing with concepts and axioms in C++},
journal = {ACM SIGPLAN Notices},
author = {Bagge, Anya Helene and David, Valentin and Haveraaen, Magne},
volume = {45},
number = {2},
year = {2010},
pages = {15 - 24},
issn = {15232867},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Modern development practises encourage extensive testing of code while it is still under development, using unit tests to check individual code units in isolation. Such tests are typically case-based, checking a likely error scenario or an error that has previously been identified and fixed. Coming up with good test cases is challenging, and focusing on individual tests can distract from creating tests that cover the full functionality. Axioms, known from program specification, allow for an alternative way of generating test cases, where the intended functionality is described as rules or equations that can be checked automatically. Axioms are proposed as part of the concept feature of the upcoming C++0x standard. In this paper, we describe how tests may be generated automatically from axioms in C++ concepts, and supplied with appropriate test data to form exctive automated unit tests. Copyright &copy; 2009 ACM.},
key = {Automatic test pattern generation},
keywords = {Algebra;Computer software;Specifications;Testing;},
note = {Algebraic specifications;Axiom-Based Testing Axioms;C++;C++0x Concepts;Generative programming;Mouldable Programming;Program transformations;Test generations;Unit testing;},
URL = {http://dx.doi.org/10.1145/1837852.1621612},
} 


@inproceedings{20105113497577 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a tool-based development methodology for sense/compute/control applications},
journal = {Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion, SPLASH '10},
author = {Cassou, Damien and Bruneau, Julien and Mercadal, Julien and Enard, Quentin and Balland, Emilie and Loriant, Nicolas and Consel, Charles},
year = {2010},
pages = {247 - 248},
address = {Reno/Tahoe, NV, United states},
abstract = {This poster presents a design language and a tool suite covering the development life-cycle of a Sense/Compute/Control (SCC) application. This language makes it possible to define the architecture of an application, following an architectural pattern commonly used in SCC applications. Our underlying methodology assigns roles to the stakeholders, providing separation of concerns. Our tool suite includes a compiler that takes design artifacts written in our language as input. The compiler generates customized support for subsequent development stages, namely implementation and test. In doing so, it ensures the conformance between the architecture and the code. Our tool suite also includes a simulator for testing SCC applications, without requiring code modification. Our methodology has been applied to a wide spectrum of areas, such as building automation, advanced telecommunications, and health-care.},
key = {Object oriented programming},
keywords = {Architecture;Computer systems programming;Intelligent buildings;Problem oriented languages;Program compilers;},
note = {Architectural pattern;Architecture description languages;Building automation;Code modifications;Commonly used;Design artifacts;Design languages;Development methodology;Development stages;Domain specific languages;Generative programming;Methodology;Separation of concerns;Toolsuite;Wide spectrum;},
URL = {http://dx.doi.org/10.1145/1869542.1869597},
} 


@inproceedings{2004158109893 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative and Incremental Approach to Scripting Support Implementation},
journal = {Proceedings of the International Conference on Software Engineering Research and Practise},
author = {Savikko, Vespe},
volume = {1},
year = {2003},
pages = {105 - 111},
address = {Las Vegas, NV, United states},
abstract = {Many systems may benefit from scripting support, but the implementation of it is seldom trivial, especially if the system has not originally been developed with scripting support in mind. In this paper we describe a generative, incremental process for creating an intuitive Python interface to a large, hierarchic COM library. The approach is illuminated with the original, real-life case study.},
key = {Information retrieval systems},
keywords = {C (programming language);Codes (symbols);Computer programming languages;Computer software;Digital libraries;Hierarchical systems;Legacy systems;Mathematical models;User interfaces;},
note = {Generative programming;Hierarchic COM library;Incremental development;Python language;Scripting;},
} 


@inproceedings{20091812056759 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modularizing invasive aspect languages},
journal = {DSAL'08: Proceedings of the 2008 AOSD Workshop on Domain-specific Aspect Languages},
author = {Cleenewerck, Thomas and D'Hondt, Theo},
year = {2008},
address = {Brussels, Belgium},
abstract = {In domain-specific aspect languages we observe that aspects are translated to base code and subsequently require a complex integration into base code while guaranteeing the correctness of the aspect and the base code in the woven code. We call this phenomenon invasively composed aspects. Weavers for invasive aspect languages operate on the base language level and offer dedicated support for crosscutting code. Unfortunately, current implementations poorly modularize the implementation of invasive aspect languages. This hampers their (unanticipated) evolution and severely reduces the reusability of their constructs. We suggest an approach where the specification of the crosscutting behavior is expressed on a higher semantic level. To this end, we raise the abstraction level of base languages towards the specific domain of the aspect languages. As such, we enable a modular, declarative approach. We illustrate our approach with KALA, a domain-specific aspect language. &copy; 2008 ACM.},
key = {Linguistics},
keywords = {Information theory;Query languages;Reusability;XML;},
note = {Aspect-oriented programming;Domain-specific languages;Generative programming;KALA;Language engineering;Linglets;Modularity;},
URL = {http://dx.doi.org/10.1145/1404927.1404931},
} 


@inproceedings{20094812518476 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {The axioms strike back: Testing with concepts and axioms in C++},
journal = {GPCE'09 - Proceedings of the 8th International ACM SIGPLAN Conference on Generative Programming and Component Engineering},
author = {Helene, Anya and Valentin, Bagge and Haveraaen, David Magne},
year = {2009},
pages = {15 - 24},
address = {Denver, CO, United states},
abstract = {Modern development practises encourage extensive testing of code while it is still under development, using unit tests to check individual code units in isolation. Such tests are typically case-based, checking a likely error scenario or an error that has previously been identified and fixed. Coming up with good test cases is challenging, and focusing on individual tests can distract from creating tests that cover the full functionality. Axioms, known from program specification, allow for an alternative way of generating test cases, where the intended functionality is described as rules or equations that can be checked automatically. Axioms are proposed as part of the concept feature of the upcoming C++0x standard. In this paper, we describe how tests may be generated automatically from axioms in C++ concepts, and supplied with appropriate test data to form effective automated unit tests. Copyright &copy; 2009 ACM.},
key = {Automatic test pattern generation},
keywords = {Algebra;Computer software;Molds;Specifications;Testing;},
note = {Algebraic specification;Algebraic specifications;Generative programming;Program transformations;Test generations;},
URL = {http://dx.doi.org/10.1145/1621607.1621612},
} 


@inproceedings{20101212784372 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A generative approach to improve the abstraction level to build applications based on the notification of changes in databases},
journal = {ICEIS 2008 - Proceedings of the 10th International Conference on Enterprise Information Systems},
author = {Coz, J.R. and Heradio Gil, R. and Cerrada Somolinos, J.A. and Lopez Ruiz, J.C.},
volume = {DISI},
year = {2008},
pages = {421 - 424},
address = {Barcelona, Spain},
abstract = {This paper highlights the benefits, in terms of quality, productivity and time-to-market, of applying a generative approach to increase the abstraction level to build applications based on the notification of changes in databases. Most of the databases maintain meta-tables with information about all stored tables; this information is used in an automatic process to define the software product line (SPL) variability. The remaining variability can be specified by means of domain specific languages. Code generators can automatically query the meta-tables, analyze the input specifications and configure the current product. The paper also introduces the Exemplar Driven Development process to incrementally develop code generators and the Exemplar Flexibilization Language that supports the process implementation.},
key = {Information systems},
keywords = {Abstracting;Computer software;Linguistics;Query languages;},
note = {Abstraction level;Code generators;Development process;Domain specific languages;Extension languages;Generative programming;Process implementation;Software product lines;Time-to-market;},
} 


@inproceedings{20100112605419 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using a product line for creating component systems},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Bure, Toma and Hnetynka, Petr and Malohlava, Michal},
year = {2009},
pages = {501 - 508},
address = {Honolulu, HI, United states},
abstract = {Component systems have become a wide-spread technology and found their place in several application domains. Each component system has its specifics and particularities that reflect its focus and the application domain it is intended for. Although important, the diversity of component systems leads to a number of problems including having different tools for each systems, unnecessary duplication of functionality and problems with integration when several domains are to be targeted. Based on categorization of component application domains, we propose a "meta-component system", which provides a software product line for creating custom component systems. We focus especially on the deployment and execution environment, which is where most diversities are found. We demonstrate the usage of the "meta-component system" and propose how it is to be realized by two core concepts of SOFA 2, namely connector generator and microcomponents. Copyright 2009 ACM.},
key = {Computer science},
keywords = {Production engineering;},
note = {Application domains;Component application;Component systems;Execution environments;Generative programming;Micro-components;Product line engineering;Product-lines;Runtime environments;Software Product Line;},
URL = {http://dx.doi.org/10.1145/1529282.1529388},
} 


@inproceedings{20091512018467 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An abstraction for reusable MDD components Model-based Generation of -model-based code generators},
journal = {GPCE'08: Proceedings of the ACM SIGPLAN 7th International Conference on Generative Programming and Component Engineering},
author = {Kulkarni, Vinay and Reddy, Sreedhar},
year = {2008},
pages = {181 - 184},
address = {Nashville, TN, United states},
abstract = {We discuss our experience of using model-based techniques to generate model-based code generators. The central idea behind model-driven development (MDD) is to use suitable models to specify various concerns and transform these models to a variety of text artifacts. A business product needs to deliver a given business functionality on a wide variety of implementation platforms and architectures thus necessitating multiple sets of code generators. However, there is a considerable commonality across these code generators. In absence of a suitable abstraction for capturing this commonality, there is little or no reuse across these code generators. We present an abstraction for organizing model-base code generators as a hierarchical composition of reusable building blocks. A building block is a localized specification of a concern in terms of a concern-specific meta model, model to model transformation, and model to text transformation. Model-based code generation is a 3-step walk over the composition tree wherein the first step transforms individual concern-specific models into a unified model, the second step transforms the unified model into individual concern-specific text artifacts, and the third step composes these text artifacts. &copy; 2008 ACM.},
key = {Automatic programming},
keywords = {Abstracting;Fourier transforms;Mathematical transformations;Systems analysis;},
note = {Building blocks;Business products;Code generations;Code generators;Generative programming;Hierarchical compositions;Implementation platforms;Meta models;Model-based;Model-driven development;Model-to-model transformations;Multiple sets;Reuse;Unified models;},
URL = {http://dx.doi.org/10.1145/1449913.1449940},
} 


@inproceedings{20083911592545 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {SmartModels - An MDE platform for the management of software product lines},
journal = {2008 IEEE International Conference on Automation, Quality and Testing, Robotics, AQTR 2008 - THETA 16th Edition - Proceedings},
author = {Tundrea, E.},
volume = {3},
year = {2008},
pages = {193 - 199},
address = {Cluj-Napoca, Romania},
abstract = {In software engineering everything evolves very fast: user requirements, technologies, methodologies and applications. Can we foresight and strengthen our approaches to build software to confront these more and more complex challenges? While there are key issues to solve, it is also noteworthy to know that we are very close to exciting innovations. Software Product Lines (SPL) - modeling technology together with source-code generative tools seem to make it easier to manage diverse environments with complex, constantly changing relationships. In the context of SPL, this paper presents an approach - SmartModels [1] [2], validated by a prototype - SmartFactory. It reviews the state-of-the-art of SmartModels briefly introducing its principles, basic entities and main elements when defining a business-model. It also addresses the Meta-Object Protocol (MOP) which lays the foundation of SmartModels' mechanism to fill the gap between the semantics and the reification of a model entity. &copy;2008 IEEE.},
key = {Computer software selection and evaluation},
keywords = {Automation;Chlorine compounds;Industrial engineering;Information theory;Robotics;Software engineering;Technology;},
note = {Applications.;Generative programming;International conferences;Model;Modeling technology;Prototype;Software factory;Software product lines;User requirements;},
URL = {http://dx.doi.org/10.1109/AQTR.2008.4588910},
} 


@inproceedings{20094812499732 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {ProtoTalk: A generative software engineering framework for prototyping protocols in smalltalk},
journal = {Proceedings - International Computer Software and Applications Conference},
author = {Razavi, Ali and Kontogiannis, Kostas},
volume = {1},
year = {2009},
pages = {435 - 442},
issn = {07303157},
address = {Seattle, WA, United states},
abstract = {Network protocols are complex systems implemented by collections of equally complex software components. In many cases, the realization of such protocols requires extensive prototyping and experimentation with different alternative implementations. In this paper, we present ProtoTalk, a generative, domain-specific software framework that utilizes model driven software engineering principles for prototyping state and message driven protocols with emphasis on telecommunication and network protocols. The framework allows first, for modeling a variety of common protocol features by using mappings from state machines, sequence diagrams and packet encodings to ProtoTalk models, and second, for the consequent automatic generation of prototype Smalltalk code from the aforementioned ProtoTalk models. In this respect, the paper attempts to shed light on the use of generative model driven programming techniques within reflective object oriented programming languages and environments. As a proof of concept, we have specified in ProtoTalk and consequently generated in Smalltalk, several core features of the Session Initiation Protocol. &copy; 2009 IEEE.},
key = {Object oriented programming},
keywords = {Automatic programming;Computer applications;Computer software;Internet;Network protocols;Software prototyping;Word processing;},
note = {Automatic Generation;Complex software;Complex systems;Core features;Domain specific;Encodings;Generative model;Generative programming;Model driven software engineering;Programming technique;Proof of concept;Protocol development;Prototyping;Reflective objects;Sequence diagrams;Session Initiation Protocols;Smalltalk;Software frameworks;State machine;},
URL = {http://dx.doi.org/10.1109/COMPSAC.2009.197},
} 


@article{2005058814784 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A component assembly approach based on aspect-oriented generative domain modeling},
journal = {Electronic Notes in Theoretical Computer Science},
author = {Cao, Fei and Bryant, Barrett R. and Burt, Carol C. and Raje, Rajeev R. and Olson, Andrew M. and Auguston, Mikhail},
volume = {114},
number = {SPEC. ISS.},
year = {2005},
pages = {119 - 136},
issn = {15710661},
abstract = {We present an approach towards automatic component assembly based on aspect-oriented generative domain modeling. It involves the lifecycle covering the component specification generation, and subsequent assembly of implementation components to produce the final software system. Aspect-oriented techniques are applied to capture the crosscutting concerns that emerge during the assembly process. Subsequently, those concerns are woven to generate glue/wrapper code for assembling heterogeneous components to construct a single integrated system. &copy; 2004 Elsevier B.V.},
key = {Software engineering},
keywords = {Computer programming;Computer programming languages;Computer science;Computer software;Distributed computer systems;Reliability;Specifications;},
note = {Aspect orientation;Component assembly;Component specification;Generative domain model;Generative programming;Two-level grammar;UniFrame;},
URL = {http://dx.doi.org/10.1016/j.entcs.2004.02.070},
} 


@inproceedings{20073510783657 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {MDDPro: Model-driven dependability provisioning in enterprise distributed real-time and embedded systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Tambe, Sumant and Balasubramanian, Jaiganesh and Gokhale, Aniruddha and Damiano, Thomas},
volume = {4526 LNCS},
year = {2007},
pages = {127 - 144},
issn = {03029743},
address = {Durham, NH, United states},
abstract = {Service oriented architecture (SOA) design principles are increasingly being adopted to develop distributed real-time and embedded (DRE) systems, such as avionics mission computing, due to the availability of real-time component middleware platforms. Traditional approaches to fault tolerance that rely on replication and recovery of a single server or a single host do not work in this paradigm since the fault management schemes must now account for the timely and simultaneous failover of groups of entities while improving system availability by minimizing the risk of simultaneous failures of replicated entities. This paper describes MDDPro, a model-driven dependability provisioning tool for DRE systems. MDDPro provides intuitive modeling abstractions to specify failover requirements of DRE systems at different granularities. MDDPro enables plugging in different replica placement algorithms to improve system availability. Finally, its generative capabilities automate the deployment and configuration of the DRE system on the underlying platforms. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Distributed computer systems},
keywords = {Embedded systems;Fault tolerance;Middleware;Real time control;Risk management;Software architecture;},
note = {Dependability design tools;Generative programming;Model-driven engineering;Real-time SOA systems;},
} 


@inproceedings{20070910440672 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Model-driven generative techniques for scalable performabality analysis of distributed systems},
journal = {20th International Parallel and Distributed Processing Symposium, IPDPS 2006},
author = {Kogekar, Arundhati and Kaul, Dimple and Gokhale, Aniruddha and Vandal, Paul and Praphamontripong, Upsorn and Gokhale, Swapna and Zhang, Jing and Lin, Yuehua and Gray, Jeff},
volume = {2006},
year = {2006},
address = {445 Hoes Lane - P.O.Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {The ever increasing societal demand for the timely availability of newer and feature-rich but highly dependable network-centric applications imposes the need for these applications to be constructed by the composition, assembly and deployment of off-the-shelf infrastructure and domain-specific services building blocks. Service Oriented Architecture (SOA) is an emerging paradigm, to build applications in this manner by defining a choreography of loosely coupled building blocks. However, current research in SOA does not yet address theperformability (i.e., performance and dependability) challenges of these modern applications. Our research is developing novel mechanisms to address these challenges. We initially focus on the composition and configuration of the infrastructure hosting the individual services. We illustrate the use of domain-specific modeling languages and model weavers to model infrastructure composition using middleware building blocks, and to enhance these models with the desired performability attributes. We also demonstrate the use of generative tools that synthesize metadata from these models for performability validation using analytical, simulation and empirical benchmarking tools. &copy; 2006 IEEE.},
key = {Distributed computer systems},
keywords = {Computer architecture;Computer networks;Computer programming languages;Mathematical models;Response time (computer systems);Telecommunication services;},
note = {Generative programming;Model driven development;Performabality analysis;Service Oriented Architecture (SOA);},
URL = {http://dx.doi.org/10.1109/IPDPS.2006.1639593},
} 


@inproceedings{20080711091773 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Generative metaprogramming},
journal = {GPCE'07 - Proceedings of the Sixth International Conference on Generative Programming and Component Engineering},
author = {Trujillo, Salvador and Azanza, Maider and Diaz, Oscar},
year = {2007},
pages = {105 - 114},
address = {Salzburg, Australia},
abstract = {Recent advances in Software Engineering have reduced the cost of coding programs at the expense of increasing the complexity of program synthesis, i.e. metaprograms, which when executed, will synthesize a target program. The traditional cycle of configuring-linking-compiling, now needs to be supplemented with additional transformation steps that refine and enhance an initial specification until the target program is obtained. So far, these synthesis processes are based on error-prone, hand-crafted scripting. To depart from this situation, this paper addresses generative metaprogramming, i.e. the generation of program-synthesis metaprograms from declarative specifications. To this end, we explore (i) the (meta) primitives for program synthesis, (ii) the architecture that dictates how these primitives can be intertwined, and (iii) the declarative specification of the metaprogram from which the code counterpart is generated. Copyright &copy; 2007 ACM.},
key = {Computer programming},
keywords = {Computational complexity;Computer architecture;Problem solving;Software engineering;},
note = {Generative programming;Metaprogramming;Software product lines;},
URL = {http://dx.doi.org/10.1145/1289971.1289990},
} 


@inproceedings{2004518731795 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings - 12th IEEE International Workshop on Program Comprehension, IWPC 2004},
journal = {Program Comprehension, Workshop Proceedings},
volume = {12},
year = {2004},
pages = {ABACO Software and Consulting; CERIT; EDS; ORACLE; SAP - },
issn = {10928138},
address = {Bari, Italy},
abstract = {The proceedings contain 33 papers from the 12th IEEE International Workshop on Program Comprehension, IWPC 2004. The topics discussed include: tool-supported customization of UML class diagrams for learning complex system models; building executable union slices using conditioned slicing; understanding web applications through dynamic analysis; using development history sticky notes to understand software architecture; empirical assessment of UML static object diagrams and program comprehension strategies for web service and service-oriented architectures.},
key = {Computer programming},
keywords = {Algorithms;Codes (symbols);Computer architecture;Computer programming languages;Computer software;Data acquisition;Database systems;Graphical user interfaces;Information retrieval;Knowledge engineering;Mathematical models;Problem solving;Program debugging;Program documentation;Reverse engineering;Semantics;},
note = {Comprehension patterns;Domain-specific languages (DSL);EiRev;Generative Programming (GP);Model elements;Object-oriented design (OOD);Software platforms;Software systems;System-design qualities;Unified modeling language (UML);},
} 


@inproceedings{20073110742077 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Reflective program generation with patterns},
journal = {Proceedings of the 5th International Conference on Generative Programming and Component Engineering, GPCE'06},
author = {Fahndrich, Manuel and Carbin, Michael and Larus, James R.},
year = {2006},
pages = {275 - 284},
address = {Portland, OR, United states},
abstract = {Runtime reflection facilities, as present in Java and .NET, are powerful mechanisms for inspecting existing code and metadata, as well as generating new code and metadata on the fly. Such power does come at a high price though. The runtime reflection support in Java and .NET imposes a cost on all programs, whether they use reflection or not, simply by the necessity of keeping all metadata around and the inability to optimize code because of future possible code changes. A second - -often overlooked - -cost is the difficulty of writing correct reflection code to inspect or emit new metadata and code and the risk that the emitted code is not well-formed.In this paper we examine a subclass of problems that can be addressed using a simpler mechanism than runtime reflection, which we call compile-time reflection. We argue for a high-level construct called a transform that allows programmers to write inspection and generation code in a pattern matching and template style, avoiding at the same time the complexities of reflection APIs and providing the benefits of staged compilation in that the generated code and metadata is known to be well-formed and type safe ahead of time. Copyright &copy; 2006 ACM.},
key = {Automatic programming},
keywords = {Java programming language;Metadata;Pattern recognition;Program compilers;Template matching;},
note = {.NET;Code change;Compile-time reflection;Generative programming;},
URL = {http://dx.doi.org/10.1145/1173706.1173748},
} 


@inproceedings{20112314038423 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic code generation for actuator interfacing from a declarative specification},
journal = {2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS},
author = {Jung, Ed and Kapoor, Chetan and Batory, Don},
year = {2005},
pages = {3207 - 3212},
address = {Edmonton, AB, Canada},
abstract = {Common software design practices use object- oriented (OO) frameworks that structure software in terms of objects, classes, and packages; designers then create programs by inheritance and composition of classes and objects. Operational Software Components for Advanced Robotics (OSCAR) is one such framework for robot control software with abstractions for generalized kinematics, dynamics, performance criteria, decision making, and hardware interfacing. Even with OSCAR, writing new programs still requires a significant amount of manual labor. Feature-Oriented Programming (FOP) is method for software design that models and specifies programs in terms of features, where a feature encapsulates the common design decisions that occur in a domain. A set of features then forms a domain model for a Product Line Architecture. Product variants in this product line can then be generated from a declarative specification. FOP and related technologies are emerging software engineering techniques for automatically generating programs. Our research applies FOP to robot controller software. As an example, the domain of hardware interfacing is analyzed and 41 features identified. A GUI for specifying and generating programs is presented as well. Analysis of features shows 200 possible different programs could be generated. &copy; 2005 IEEE.},
key = {Software design},
keywords = {Automatic programming;Decision making;Intelligent robots;Object oriented programming;Robotics;Specifications;},
note = {Automatic code generations;Common software;Design decisions;Design practice;Domain model;Engineering techniques;Feature-oriented programming;Generative programming;Manual labors;Operational software;Performance criterion;Product line;Product line architecture;Product variants;Product-lines;Robot control software;Robot controller;},
URL = {http://dx.doi.org/10.1109/IROS.2005.1545465},
} 


@inproceedings{20072010600129 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Intentional software},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Simonyi, Charles and Christerson, Magnus and Clifford, Shane},
volume = {2006},
year = {2006},
pages = {451 - 464},
address = {Portland, OR, United states},
abstract = {Wysiwyg editors simplified document creation by separating the document contents from the looks and by automating the re-application of the looks to changing contents. In the same way Intentional Software simplifies software creation by separating the software contents in terms of their various domains from the implementation of the software and by enabling automatic re-generation of the software as the contents change. This way, domain experts can work in parallel with programmers in their respective areas of expertise; and the repeated intermingling can be automated. Intentional Software is supported by a Domain Workbench tool where multiple domains can be defined, created, edited, transformed and integrated during software creation. Key features include a uniform representation of multiple interrelated domains, the ability to project the domains in multiple editable notations, and simple access for a program generator. Copyright &copy; 2006 ACM.},
key = {Computer software},
keywords = {Computer aided software engineering;Computer systems programming;Data structures;Project management;},
note = {Automatic re-generation;Generative programming;Intentional software;Software contents;},
URL = {http://dx.doi.org/10.1145/1167473.1167511},
} 


@inproceedings{20102613042132 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modular and generic programming with InterpreterLib},
journal = {ASE'07 - 2007 ACM/IEEE International Conference on Automated Software Engineering},
author = {Weaver, Philip and Kimmell, Garrin and Frisby, Nicolas and Alexander, Perry},
year = {2007},
pages = {473 - 476},
address = {Atlanta, GA, United states},
abstract = {Modular monadic semantics (MMS) is a well-known technique for structuring modular denotational semantic definitions. Families of language constructs are independently defined using syntactic functors and semantic algebras that can be combined in a mix-and-match fashion to create complete language definitions. We introduce InterpreterLib, a Haskell library that implements and extends MMS techniques for writing composable analyses. In addition to modular analyses composition, InterpreterLib provides algebra combinators, explicit algebra semantics, preprocessors for boiler plate generation and generic programming techniques adapted to language analysis. The key benefits of these features are reliability, increased code reuse via modularity and the ability to rapidly retarget component analyses. Copyright 2007 ACM.},
key = {Semantics},
keywords = {Algebra;Computer software;Linguistics;},
note = {Algebra semantics;Code reuse;Combinators;Component analysis;Denotational semantics;Functors;Generative programming;Generic programming;Haskell;Language analysis;Language constructs;Mix-and-match;Modular analysis;Modular monadic semantics;Preprocessors;},
URL = {http://dx.doi.org/10.1145/1321631.1321712},
} 


@inproceedings{20102312989089 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A model-driven approach for generating embedded robot navigation control software},
journal = {Proceedings of the Annual Southeast Conference},
author = {Shah, Bina and Dennison, Rachael and Gray, Jeff},
year = {2004},
pages = {332 - 335},
address = {Huntsville, AL, United states},
abstract = {Real-time embedded systems are time-critical systems that are hard to implement as compared to traditional commercial software, due to the large number of conflicting requirements. This paper describes undergraduate research into the use of advanced modeling techniques to improve the development of embedded systems. In particular, we have developed domain-specific models that describe the configuration and layout of a hazardous environment, which is symbolically represented as an area contaminated with hazardous materials (e.g., land mines), as well as objects to be rescued (e.g., babies). The motivation is to model a disaster site that is too dangerous for humans to search for survivors. From the visual model specifications, model interpreters will generate the embedded code that will control two LEGO Mindstorms robots. The mission of the robots is to traverse the hostile terrain and rescue the surviving babies. The modeling environment and generative techniques are described. Copyright 2004 ACM.},
key = {Embedded systems},
keywords = {Embedded software;Mining;Program interpreters;Real time systems;Robots;},
note = {Advanced modeling techniques;Commercial software;Domain specific;Generative programming;Hazardous environment;Land mine;LEGO mindstorms;Model driven approach;Model integrated computing;Model interpreter;Modeling environments;Real-time embedded systems;Robot navigation;Time-critical systems;Undergraduate research;Visual model;},
URL = {http://dx.doi.org/10.1145/986537.986618},
} 


@inproceedings{2004348317751 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Performance modeling from software components},
journal = {Proceedings of the Fourth International Workshop on Software and Performance, WOSP'04},
author = {Wu, Xiuping and Woodside, Murray},
year = {2004},
pages = {290 - 301},
address = {Redwood Shores, CA, United states},
abstract = {When software products are assembled from pre-defined components, performance prediction should be based on the components also. This supports rapid model-building, using previously calibrated sub-models or "performance components", in sync with the construction of the product. The specification of a performance component must be tied closely to the software component specification, but it also includes performance related parameters (describing workload characteristics and demands), and it abstracts the behaviour of the component in various ways (for reasons related to practical factors in performance analysis). A useful set of abstractions and parameters are already defined for layered performance modeling. This work extends them to accommodate software components, using a new XML-based language called Component-Based Modeling Language (CBML). With CBML, compatible components can be inserted into slots provided in a hierarchical component specification based on the UML component model.},
key = {Software engineering},
keywords = {Computer architecture;Computer programming;Computer programming languages;Computer simulation;Constraint theory;Digital libraries;Mathematical models;Queueing theory;},
note = {CBML;Generative programming;Layered queue models;LQN;Performance prediction;Software components;Software performance;Submodels;},
} 


@inproceedings{20092612149217 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Static and metaprogramming patterns and static frameworks: A catalog. an application},
journal = {PLoP 2006 - PLoP Pattern Languages of Programs 2006 Conference Proceedings},
author = {Bachmann, Philipp},
year = {2006},
address = {Portland, OR, United states},
abstract = {The classic UNIX principle to write code that generates code instead of writing this code yourself [48, Chapters 1,9] is experiencing a revival. Much research was done, the techniques are better understood now, and the generation tools were refined. This pattern catalog consists of adaptations of the Gang of Four design patterns [27] Abstract Factory, Adapter, Strategy, and Visitor to the metaprogramming level. It shows that replacing runtime polymorphism by static polymorphism helps to lift variation from the code level up to the meta level, where it might more naturally belong to. Some of the patterns proposed are especially useful for facilitating portable code. The patterns shown can be used to build static Frameworks [50]. A simple example is also presented. For all patterns proposed we identified usage examples in popular existing applications or libraries. Each pattern presentation is accompanied with an example. These examples show sample code in C++. The template metaprogramming capabilities of C++ [2, 17, 65] allow us to express both the program and the meta program in the same programming language. Copyright 2006 ACM.},
key = {Computer programming},
keywords = {Computer software portability;Linguistics;Polymorphism;Query languages;},
note = {Design pattern;Generative programming;Generic programming;Metaprogramming;Portability;Software product lines;Static polymorphism;Template;Template specialization;},
URL = {http://dx.doi.org/10.1145/1415472.1415492},
} 


@article{20064410216035 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Intentional software},
journal = {ACM SIGPLAN Notices},
author = {Simonyi, Charles and Christerson, Magnus and Clifford, Shane},
volume = {41},
number = {10},
year = {2006},
pages = {451 - 463},
issn = {03621340},
abstract = {Wysiwyg editors simplified document creation by separating the document contents from the looks and by automating the reapplication of the looks to changing contents. In the same way Intentional Software simplifies software creation by separating the software contents in terms of their various domains from the implementation of the software and by enabling automatic regeneration of the software as the contents change. This way, domain experts can work in parallel with programmers in their respective areas of expertise; and the repeated intermingling can be automated. Intentional Software is supported by a Domain Workbench tool where multiple domains can be defined, created, edited, transformed and integrated during software creation. Key features include a uniform representation of multiple interrelated domains, the ability to project the domains in multiple editable notations, and simple access for a program generator. Copyright &copy; 2006 ACM.},
key = {Computer software},
keywords = {Automatic programming;Computer programming;File editors;Program documentation;},
note = {Domain Workbench tools;Generative programming;Intentional software;Wysiwyg editors;},
URL = {http://dx.doi.org/10.1145/1167515.1167511},
} 


@article{2005299219732 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Effort reducing in software modeling on MDA approach},
journal = {WSEAS Transactions on Computers},
author = {Belix, Jose Eduardo and Fernandes, Sergio Martins and Shimizu Melnikoff, Selma Shin and Spina, Edison},
volume = {4},
number = {6},
year = {2005},
pages = {621 - 626},
issn = {11092750},
abstract = {The MDA (Model Driven Architecture) is an approach for software development that has the ability to produce applications for virtually every middleware platform from the same base model. All the MDA development projects start with the creation of a Platform Independent Model (PIM), which expresses only business functionality and behavior, abstracting away platform-specific details. This paper focuses on defin ing recommendations to help reducing the necessary effort to represent the PIM model, by the adoption of predefined solutions for the software to be generated. The paper also presents a taxonomy for these predefined solutions and the consequences of their use, pertaining to modeling effort.},
key = {Computer aided software engineering},
keywords = {Automatic programming;Computer architecture;Mathematical models;Middleware;},
note = {Abstractions;Generative programming;Model driven architecture;Platform independent model;Software architecture;},
} 


@article{20064010144233 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {BOTS: A constraint-based component system for synthesizing scalable software systems},
journal = {ACM SIGPLAN Notices},
author = {Pandey, Raju and Wu, Jeffrey},
volume = {41},
number = {7},
year = {2006},
pages = {189 - 198},
issn = {03621340},
abstract = {Embedded application developers create applications for a wide range of devices with different resource constraints. Developers want to maximize the use of the limited resources available on the device while still not exceeding the capabilities of the device. To do this, the developer must be able to scale his software for different platforms. In this paper, we present a software engineering methodology that automatically scales software to different platforms. We intend to have the application developer write high level functional specifications of his software and have tools that automatically scale the underlying runtime. These tools will use the functional and non-functional constraints of both the hardware and client application to produce an appropriate runtime. Our initial results show that the proposed approach can scale operating systems and virtual machines that satisfy the constraints of varying hardware/application combinations. Copyright &copy; 2006 ACM.},
key = {Computer software},
keywords = {Computer aided software engineering;Computer hardware description languages;Constraint theory;Embedded systems;Resource allocation;},
note = {Generative Programming;Runtime Systems;Wireless Sensor Networks;},
URL = {http://dx.doi.org/10.1145/1159974.1134678},
} 


@inproceedings{20071410531381 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A visual tool for generating extensible mobile application skeletons to reduce failures in Java MIDP applications},
journal = {Proceedings of the IASTED International Conference on Software Engineering, as part of the 24th IASTED International Multi-Conference on APPLIED INFORMATICS},
author = {Palviainen, Marko and Yliaho, Jussi and Soininen, Jarno},
volume = {2006},
year = {2006},
pages = {177 - 187},
address = {Innsbruck, Austria},
abstract = {The mobile environment sets hard and partially conflicting requirements for programming and software architectures. Applications should have high quality and adaptability to various kinds of environments, while the memory and energy consumption should be minimized. Mobile users are not accustomed to crashing devices and bugs are not acceptable. In relation to the Nokia OK certification testing program, we have made 98 primary tests and 161 retests of Java Mobile Information Device Profile (MIDP) applications. In 94 of the performed 98 primary tests appeared failures, which were required to be corrected. We classified the failures found in the tested applications. Classification shows that failures are often related to the user interface and navigation inside the application. In order to facilitate the application construction and to minimize the amount of these failures, we developed a visual WYSIWYG tool, called J2MEDesigner, enabling non-programmers to draw the navigation logic and the user interface for a Java MIDP application. J2MEDesigner generates an executable application skeleton, which can be tested in the target mobile devices without manual coding and bugs. The application functionality can be added later with plugins capable to communicate via common data storage. As a result, manually implemented and generated codes are in separate files and so, the application design can be changed and the application skeleton can be regenerated without fear of loss of the manually implemented code. In addition, the behaviour of the application can be changed dynamically by replacing action handler plugins at run-time.},
key = {Computer system recovery},
keywords = {Codes (symbols);Computer architecture;Computer viruses;Java programming language;Optimization;Software testing;},
note = {Data storage;Generative programming;Java Mobile Information Device Profile (MIDP);Mobile application development tools;Third party testing;},
} 


@inproceedings{20063010020365 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {BOTS: A constraint-based component system for synthesizing scalable software systems},
journal = {Proceedings of the ACM SIGPLAN Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES)},
author = {Pandey, Raju and Wu, Jeffrey},
volume = {2006},
year = {2006},
pages = {189 - 198},
address = {Ottawa, ON, Canada},
abstract = {Embedded application developers create applications for a wide range of devices with different resource constraints. Developers want to maximize the use of the limited resources available on the device while still not exceeding the capabilities of the device. To do this, the developer must be able to scale his software for different platforms. In this paper, we present a software engineering methodology that automatically scales software to different platforms. We intend to have the application developer write high level functional specifications of his software and have tools that automatically scale the underlying runtime. These tools will use the functional and non-functional constraints of both the hardware and client application to produce an appropriate runtime. Our initial results show that the proposed approach can scale operating systems and virtual machines that satisfy the constraints of varying hardware/application combinations. Copyright &copy; 2006 ACM.},
key = {Computer software},
keywords = {Computer hardware;Computer operating systems;Constraint theory;Embedded systems;Software engineering;},
note = {Generative Programming;Runtime Systems;Virtual machines;Wireless Sensor Networks;},
} 


@inproceedings{20102813074498 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Eliminating redundancies with a "composition with adaptation" meta-programming technique},
journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
author = {Jarzabek, Stan and Shubiao, Li},
year = {2003},
pages = {237 - 246},
address = {Helsinki, Finland},
abstract = {Redundant code obstructs program understanding and contributes to high maintenance costs. While most experts agree on that, opinions - on how serious the problem of redundancies really is and how to tackle it - differ. In this paper, we present the study of redundancies in the Java Buffer library, JDK 1.4.1, which was recently released by Sun. We found that at least 68% of code in the Buffer library is redundant in the sense that it recurs in many classes in the same or slightly modified form. We effectively eliminated that 68% of code at the meta-level using a technique based on "composition with adaptation" called XVCL. We argue that such a program solution is easier to maintain than buffer classes with redundant code. In this experiment, we have designed our meta-representation so that we could produce buffer classes in exactly the same form as they appear in the original Buffer library. While we have been tempted to re-design the buffer classes, we chose not to do so, in order to allow for the seamless integration of the XVCL solution into contemporary programming methodologies and systems. This decision has not affected the essential results reported in this paper. &copy; 2003 ACM.},
key = {Object oriented programming},
keywords = {Computer software;Computer software maintenance;Libraries;Quality assurance;Redundancy;},
note = {Class libraries;Generative programming;Maintenance cost;Meta Programming;Object oriented method;Program understanding;Programming methodology;Redundant codes;Seamless integration;},
URL = {http://dx.doi.org/10.1145/940071.940104},
} 


@inproceedings{2004138080856 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Eliminating Redundancies with a "Composition with Adaptation" Meta-programming Technique},
journal = {Proceedings of the Joint European Software Engineering Conference (ESEC) and SIGSOFT Symposium on the Foundations of Software Engineering (FSE-11)},
author = {Jarzabek, Stan and Shubiao, Li},
year = {2003},
pages = {237 - 246},
address = {Helsinki, Iceland},
abstract = {Redundant code obstructs program understanding and contributes to high maintenance costs. While most experts agree on that, opinions - on how serious the problem of redundancies really is and how to tackle it - differ. In this paper, we present the study of redundancies in the Java Buffer library, JDK 1.4.1, which was recently released by Sun. We found that at least 68% of code in the Buffer library is redundant in the sense that it recurs in many classes in the same or slightly modified form. We effectively eliminated that 68% of code at the meta-level using a technique based on "composition with adaptation" called XVCL. We argue that such a program solution is easier to maintain than buffer classes with redundant code. In this experiment, we have designed our meta-representation so that we could produce buffer classes in exactly the same form as they appear in the original Buffer library. While we have been tempted to re-design the buffer classes, we chose not to do so, in order to allow for the seamless integration of the XVCL solution into contemporary programming methodologies and systems. This decision has not affected the essential results reported in this paper.},
key = {Software engineering},
keywords = {Codes (symbols);Data structures;Java programming language;Object oriented programming;Problem solving;},
note = {Class libraries;Generative programming;Meta-programming;Object-oriented methods;},
URL = {http://dx.doi.org/10.1145/940071.940104},
} 


@inproceedings{20110813675333 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain driven web development with WebJinn},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Kojarski, Sergei and Lorenz, David H.},
year = {2003},
pages = {53 - 65},
address = {Anaheim, CA, United states},
abstract = {Web application development cuts across the HTTP protocol, the client-side presentation language (HTML, XML), the server-side technology (Servlets, JSP, ASP, PHP), and the underlying resource (files, database, information system). Consequently, web development concerns including functionality, presentation, control, and structure cross-cut, leading to tangled and scattered code that is hard to develop, maintain, and reuse. In this paper we analyze the cause, consequence, and remedy for this crosscutting. We distinguish between intra-crosscutting that results in code tangling and inter-crosscutting that results in code scattering. To resolve inter-crosscutting, we present a new web application development model named XP that introduces extension points as place-holders for structure-dependent code. We present another model named DDD that incorporates XP into the Model-View-Controller (MVC) model to resolve both intra- and inter-crosscutting. WebJinn is a novel domain-driven web development framework that implements the DDD model. WebJinn has been used to develop web applications at several web sites. Domain driven web development with WebJinn benefits from a significant improvement in code reuse, adaptability, and maintainability.},
key = {Object oriented programming},
keywords = {Aspect oriented programming;Computer systems programming;Controllers;HTTP;Hypertext systems;Internet protocols;Maintainability;Program processors;Reusability;Scattering;Struts;World Wide Web;},
note = {Adaptability;Aspect-oriented programming (AOP);Crosscutting concerns;Dynamic pages;Generative programming;Inter-crosscutting;Intra-crosscutting;JSP;Model-view-controller (MVC);Tangling;WEB application;Web development;Web programming;},
URL = {http://dx.doi.org/10.1145/949344.949351},
} 


@inproceedings{20110813675331 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {XAspects: An extensible system for domain-specific aspect languages},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
author = {Shonle, MacNeil and Lieberherr, Karl and Shah, Ankit},
year = {2003},
pages = {28 - 37},
address = {Anaheim, CA, United states},
abstract = {Current general aspect-oriented programming solutions fall short of helping the problem of separation of concerns for several concern domains. Because of this limitation good solutions for these concern domains do not get used and the opportunity to benefit from separation of these concerns is missed. By using XAspects, a plug-in mechanism for domain-specific aspect languages, separation of concerns can be achieved at a level beyond what is possible for objectoriented programming languages. As a result, XAspects allows for certain domain-specific solutions to be used as easily as a new language feature.},
key = {Object oriented programming},
keywords = {Aspect oriented programming;Computer systems programming;Problem oriented languages;},
note = {Aspect-oriented;Domain specific;Domain-specific languages;Extensible systems;General aspects;Generative programming;Language extensions;Language features;Object-oriented programming languages;Plug-ins;Programming solutions;Separation of concerns;},
URL = {http://dx.doi.org/10.1145/949344.949349},
} 


@inproceedings{20102513029151 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Formal specification of generative component assembly using two-level grammar},
journal = {ACM International Conference Proceeding Series},
author = {Bryant, Barrett R. and Burt, Carol C. and Auguston, Mikhail and Raje, Rajeev R. and Olson, Andrew M.},
volume = {27},
year = {2002},
pages = {209 - 212},
address = {Ischia, Italy},
abstract = {Two-Level Grammar (TLG) is proposed as a formal specification language for generative assembly of components. Both generative domain models and generative rules may be expressed in TLG and these specifications may be automatically translated into an implementation which realizes an integration of components according to the principles of the Unified Meta-component Model (UMM) and Unified Approach (UA) to component integration. Furthermore, this implementation realizes Quality of Service (QoS) guarantees by means of static QoS verification at the time of system assembly, and dynamic QoS validation on a set of test cases. Copyright 2002 ACM.},
key = {Knowledge engineering},
keywords = {Computer software selection and evaluation;Quality of service;Query languages;Software engineering;Specification languages;Specifications;},
note = {Component assembly;Component based software;Component integration;Component model;Formal Specification;Formal specification language;Generative domain model;Generative programming;Quality of service guarantees;System assembly;Test case;Two-level grammar;Unified approach;},
URL = {http://dx.doi.org/10.1145/568760.568796},
} 


@article{2001095477655 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Synthesizing objects},
journal = {Concurrency Practice and Experience},
author = {Czarnecki, Krzysztof and Eisenecker, Ulrich W.},
volume = {12},
number = {14},
year = {2000},
pages = {1347 - 1377},
issn = {10403108},
address = {Lisbon, Portugal},
abstract = {This paper argues that the current OO technology does not support reuse and configurability in an effective way. This problem can be addressed by augmenting OO Analysis and Design with feature modeling and by applying generative implementation techniques. Feature modeling allows capturing the variability of domain concepts. Concrete concept instances can then be synthesized from abstract specifications. Using a simple example of a configurable list component, we demonstrate the application of feature modeling and how to implement a feature model as a generator. We introduce the concepts of configuration repositories and configuration generators and show how to implement them using object-oriented, generic, and generative language mechanisms. Interestingly, a configuration repository represents an effective approach for typing synthesized recursive classes. The configuration generator utilizes C++ template metaprogramming, which enables its execution at compile-time.},
key = {Object oriented programming},
keywords = {C (programming language);Computer simulation;Computer software reusability;Program compilers;Program diagnostics;Recursive functions;Response time (computer systems);Software engineering;},
note = {Feature modeling;Feature oriented domain analysis;Generative programming;Template metaprogramming;},
URL = {http://dx.doi.org/10.1002/1096-9128(20001210)12:14<1347::AID-CPE513>3.0.CO;2-N},
} 


@inproceedings{2002507268097 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Recent advances in the design of distributed embedded systems},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Bay, John S.},
volume = {4741},
year = {2002},
pages = {36 - 45},
issn = {0277786X},
address = {Orlando, FL, United states},
abstract = {The network-centric "system-of-systems" concept popular in current defense programs has been viewed from a very functional perspective. However, the heart of such a system is going to be an embedded software infrastructure of unprecedented complexity, and the technology for developing and testing this software needs as much if not more immediate attention than the concept of operations for the envisioned applications. Such an embedded software system will need to be infinitely scalable, modular, verifiable, and distributed, yet satisfy the myriad hard real-time performance constraints imposed by each of perhaps many different device types and service demands. It is suggested here that the only path to a robust design methodology for such systems is with model-based design. Model-based embedded system design is the focus of the Model-Based Integration of Embedded Software (MoBIES) program, currently underway at the Defense Advanced Research Projects Agency (DARPA), managed by the author. This paper will motivate the model-based approach to large-scale embedded software design and explain how projects funded under MoBIES are contributing to the development of interoperable model-based design tool components. An application for such technology is provided in the context of digital flight control systems for aggressive aircraft maneuvers, which is the subject of another DARPA sponsored program, Software-Enabled Control (SEC).},
key = {Digital communication systems},
keywords = {Computer aided design;Computer aided software engineering;Computer software selection and evaluation;Distributed computer systems;Embedded systems;Mathematical models;},
note = {Generative programming;Meta modeling;Software enabled control;},
URL = {http://dx.doi.org/10.1117/12.478733},
} 


@article{20084711727158 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain-specific languages and program generation with meta-AspectJ},
journal = {ACM Transactions on Software Engineering and Methodology},
author = {Huang, Shan Shan and Zook, David and Smaragdakis, Yannis},
volume = {18},
number = {2},
year = {2008},
issn = {1049331X},
address = {1515 Broadway, 17th Floor, New York, NY 10036-5701, United States},
abstract = {Meta-AspectJ (MAJ) is a language for generating AspectJ programs using code templates. MAJ itself is an extension of Java, so users can interleave arbitrary Java code with AspectJ code templates. MAJ is a structured metaprogramming tool: a well-typed generator implies a syntactically correct generated program. MAJ promotes a methodology that combines aspect-oriented and generative programming. A valuable application is in implementing small domain-specific language extensions as generators using unobtrusive annotations for syntax extension and AspectJ as a back-end. The advantages of this approach are twofold. First, the generator integrates into an existing software application much as a regular API or library, instead of as a language extension. Second, a mature language implementation is easy to achieve with little effort since AspectJ takes care of the low-level issues of interfacing with the base Java language. In addition to its practical value, MAJ offers valuable insights to metaprogramming tool designers. It is a mature metaprogramming tool for AspectJ (and, by extension, Java): a lot of emphasis has been placed on context-sensitive parsing and error reporting. As a result, MAJ minimizes the number of metaprogramming (quote/unquote) operators and uses type inference to reduce the need to remember type names for syntactic entities. &copy; 2008 ACM.},
key = {Java programming language},
keywords = {Application programming interfaces (API);Codes (symbols);Computer programming;Computer programming languages;Computer software;Graphical user interfaces;Linguistics;Query languages;Syntactics;XML;},
note = {Domain-specific languages;Language extensions;Metaprogramming;Program synthesis;Program transformation;Program verification;},
URL = {http://dx.doi.org/10.1145/1416563.1416566},
} 


@article{20102413005222 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Domain specific model-based development of software for programmable logic controllers},
journal = {Computers in Industry},
author = {Kandare, Gregor and Strmcnik, Stanislav and Godena, Giovanni},
volume = {61},
number = {5},
year = {2010},
pages = {419 - 431},
issn = {01663615},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {Procedural process control is responsible for coordination of control units that perform basic control in a typical industrial control system. Basic control, in turn, performs actions necessary for maintaining a desired state of process variables and equipment. Software in the domain of procedural process control consists of modules responsible for management of startup and shutdown sequences, exception handling and module communication. In this work we present the domain specific modeling language (DSL) ProcGraph together with its corresponding code generation tool that was designed for the development of software in the domain of procedural process control systems. The advantage of using a domain specific language is that not only the programmers, but also domain experts are able to understand and modify the code. The DSL code is self-documenting, as it is expressed in the idiom of the problem domain. In the article we present a formal description of the ProcGraph language. Furthermore, we describe how the formal model is used in the implementation of the automatic IEC 1131-3 code generator. &copy; 2009 Elsevier B.V. All rights reserved.},
key = {Computer control},
keywords = {Automatic programming;Computer software;Controllers;Linguistics;Network components;Predictive control systems;Program compilers;Programmable logic controllers;Quality control;Query languages;Software design;},
note = {Code generation tools;Code generators;Coordination of controls;Domain experts;Domain specific;Domain specific languages;Domain specific modeling languages;Exception handling;Formal Description;Formal model;Industrial control systems;Logic controller;Model based development;Problem domain;Process Variables;Programable logic controllers;},
URL = {http://dx.doi.org/10.1016/j.compind.2009.10.001},
} 


@inproceedings{2006269962089 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Extending open compilers},
journal = {Proceedings of the International Conference on Information Technology Interfaces, ITI},
author = {Krmpotic, David and Kosar, Tomaz and Mernik, Marjan and Zumer, Viljem},
year = {2005},
pages = {645 - 650},
issn = {13301012},
address = {Cavtat, Croatia},
abstract = {Implementation of a domain-specific language can be demanding, but also very rewarding. Once the hard work is done, we can profit a lot from the effort invested. The purpose of this paper is to present a domain specific language construction with extending the open compilers. Paper presented here gives language designers guidelines on how to incorporate domain specific language into the general-purpose language. Addition-ally information on preserving language tools, like debuggers, with the domain-aware information is given. For that purpose, extension of Mono C# compiler with representative domain-specific language is used.},
key = {Program compilers},
keywords = {Computer aided software engineering;Computer programming languages;Information analysis;},
note = {Compiler/interpreter generators;Domain-specific language;Extensible compiler/interpreter approach;},
URL = {http://dx.doi.org/10.1109/ITI.2005.1491198},
} 


@article{1997483853204 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Effects of corpus size and homogeneity on language model quality},
journal = {HP Laboratories Technical Report},
author = {Rose, Tony G. and Haddock, Nicholas J.},
number = {97-70},
year = {1997},
pages = {1 - 11},
address = {Palo Alto, CA, United States},
abstract = {There are two techniques for augmenting domain-specific language model with data from a more general source. The first is concerned on acquiring a suitable sample of the domain-specific language data from which the models are trained. The data can display different characteristics that affect the quality of the language model since not all domain-specific corpora are equal. The second investigates the empirical development and evaluation of a set of language models for the task of email speech-to-context dictation. The quality issue is that effective language models can be built from modestly sized corpora, providing the training data to match the target application.},
key = {Computational linguistics},
keywords = {Computer simulation;Data acquisition;Data structures;Electronic mail;},
note = {Domain specific language model;},
} 


@inproceedings{20083111410037 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Functional meta-programming for parallel skeletons},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Serot, Jocelyn and Falcou, Joel},
volume = {5101 LNCS},
number = {PART 1},
year = {2008},
pages = {154 - 163},
issn = {03029743},
address = {Krakow, Poland},
abstract = {We describe the implementation in MetaOcaml of a small domain specific language for skeleton-based parallel programming. We show how the meta-programming facilities offered by this language make it possible to virtually eliminate the run-time overhead for the resulting programs, compared to a hand-crafted, low-level implementation. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Parallel programming},
keywords = {Computer programming languages;Functional programming;Linguistics;},
note = {Computational sciences;Domain specific language (DSL);Heidelberg (CO);International conferences;Meta Programming;Run time;},
URL = {http://dx.doi.org/10.1007/978-3-540-69384-0_21},
} 


@inproceedings{20080311018992 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards user-level extensibility of an Ada library: An experiment with Cheddar},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Singhoff, Frank and Plantee, Alain},
volume = {4498 LNCS},
year = {2007},
pages = {180 - 191},
issn = {03029743},
address = {Geneva, Switzerland},
abstract = {In this article, we experiment a way to extend an Ada library called Cheddar. Cheddar provides a domain specific language. Programs written with this domain specific language can be interpreted in order to perform real time scheduling analysis of real time systems. By the past, different projects showed that the Cheddar programming language is useful for the modeling of real time schedulers. But these experiments also showed that the interpreter is lacking of efficiency in case of large scheduling simulations. In this article, by designing a Cheddar metamodel, we investigate on how to compile such Cheddar programs in order to extend the Cheddar library. For such a purpose, we use Platypus, a meta CASE Tool based on EXPRESS. For a given Cheddar program and with a metarmodel of Cheddar handled by Platypus, we can generate a set of Ada packages. Such Ada packages can be compiled and integrated as builtin schedulers into Cheddar. Then, the efficiency of scheduling simulations can be increased. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {User interfaces},
keywords = {Ada (programming language);Computer programming languages;Computer simulation;Digital libraries;Real time systems;},
note = {Ada code generating;Ada library;Cheddar programming language;Domain specific language;Meta-modeling;},
} 


@inproceedings{20082511325763 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Efficient image processing with the apply language},
journal = {Proceedings - Digital Image Computing Techniques and Applications: 9th Biennial Conference of the Australian Pattern Recognition Society, DICTA 2007},
author = {Hamey, Leonard G.C.},
year = {2007},
pages = {533 - 540},
address = {Glenelg, SA, Australia},
abstract = {Apply is a Domain-Specific Language for image processing and low-level computer vision. Apply allows programmers to write kernel operations that focus on the computation for a single pixel location. The compiler generates code to perform the kernel computation over entire images. The original Apply implementation was developed 20 years ago for efficient processing on parallel architectures. The current-generation Apply compiler targets efficient code generation for general-purpose computers, typically outperforming handwritten code, while maintaining the simplicity of the original language. The use of modem compiler writing tools, specifically Stratego/XT, has facilitated improvements in the language design and made it easy to target the compiler to different environments. A large number of computer vision and image processing operations can be expressed in Apply. However, some algorithms require additional features. To motivate future language development, we analyse the requirements of the algorithms provided in a commercial machine vision library. &copy; 2007 IEEE.},
key = {Program compilers},
keywords = {Algorithms;Architectural design;Artificial intelligence;Codes (standards);Codes (symbols);Computational methods;Computer graphics;Computer networks;Computer vision;Computers;Digital image storage;Evolutionary algorithms;Feature extraction;Image processing;Imaging systems;Imaging techniques;Integer programming;Linguistics;Optical data processing;Pattern recognition;Targets;},
note = {Code generations;Compiler writing tools;Digital image computing;Domain specific language (DSL);General-purpose computers;Image processing operations;language designs;language development;Machine vision;Parallel architectures;Single pixel;},
URL = {http://dx.doi.org/10.1109/DICTA.2007.4426843},
} 


@inproceedings{20063010026903 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {KM3: A DSL for metamodel specification},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Jouault, Frederic and Bezivin, Jean},
volume = {4037 LNCS},
year = {2006},
pages = {171 - 185},
issn = {03029743},
address = {Bologna, Italy},
abstract = {We consider in this paper that a DSL (Domain Specific Language) may be defined by a set of models. A typical DSL is the ATLAS Transformation Language (ATL). An ATL program transforms a source model (conforming to a source metamodel) into a target model (conforming to a target metamodel). Being itself a model, the transformation program conforms to the ATL metamodel. The notion of metamodel is thus used to define the source DSL, the target DSL and the transformation DSL itself. As a consequence we can see that agility to define metamodels and precision of these definitions is of paramount importance in any model engineering activity. In order to fullfill the goals of agility and precision in the definition of our metamodels, we have been using a notation called KM3 (Kernel MetaMetaModel). KM3 may itself be considered as a DSL for describing metamodels. This paper presents the rationale for using KM3, some examples of its use and a precise definition of the language. &copy; IFIP International Federation for Information Processing 2006.},
key = {Computer programming languages},
keywords = {Artificial intelligence;Computer science;Data processing;Distributed computer systems;},
note = {Domain Specific Language (DSL);Metamodel;Transformation program;},
URL = {http://dx.doi.org/10.1007/11768869_14},
} 


@inproceedings{20083111409884 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Designing syntax embeddings and assimilations for language libraries},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Bravenboer, Martin and Visser, Eelco},
volume = {5002 LNCS},
year = {2008},
pages = {34 - 46},
issn = {03029743},
address = {Nashville, TN, United states},
abstract = {Language libraries extend regular libraries with domain-specific notation. More precisely, a language library is a combination of a domain-specific language embedded in the general-purpose host language, a regular library implementing the underlying functionality, and an assimilation transformation that maps embedded DSL fragments to host language code. While the basic architecture for realizing language libraries is the same for all applications, there are many design choices to be made in the design of a particular combination of library, guest language syntax, host language, and assimilation. In this paper, we give an overview of the design space for syntax embeddings and assimilations for the realization of language libraries. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Linguistics},
keywords = {Artificial intelligence;Bioinformatics;Computer aided software engineering;Computer science;Libraries;Maps;Models;Software engineering;Syntactics;},
note = {Design spaces;Domain specific;Domain specific language (DSL);Embeddings;Heidelberg (CO);Language syntax;Lecture Notes;},
URL = {http://dx.doi.org/10.1007/978-3-540-69073-3_5},
} 


@inproceedings{2001065457403 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Towards a paradigm for activity modeling},
journal = {Proceedings of the IEEE International Conference on Systems, Man and Cybernetics},
author = {Garrett, J.T. and Ledeczi, A. and DeCaria, F.},
volume = {4},
year = {2000},
pages = {2425 - 2430},
issn = {08843627},
address = {Nashville, TN, USA},
abstract = {Model Integrated Computing involves defining a domain-specific language that allows for someone to effectively program an environment at whatever level the modeling-environment-creator deems appropriate. We've taken several complex, heterogeneous systems that posed problems of needing integration and requiring frequent reconfiguration at very high levels. This paper discusses gathering the specifications for these systems, how the systems can be represented at these high levels in a paradigm also capturing the specifications, and then how reconfiguring this group can proceed. All of the activities constituting monitoring functionality and the resulting decision making exposed by the information system will be shown to have been solved through utilization of Model Integrated Computing techniques.},
key = {Data processing},
keywords = {Computer programming languages;Decision theory;Mathematical models;},
note = {Domain-specific language;Model integrated computing methods;},
} 


@inproceedings{20083011394962 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {AmbientTalk: Object-oriented event-driven programming in mobile ad hoc networks},
journal = {Proceedings - International Conference of the Chilean Computer Science Society, SCCC},
author = {Van Cutsem, Tom and Mostinckx, Stijn and Boix, Elisa Gonzalez and Dedecker, Jessie and De Meuter, Wolfgang},
year = {2007},
pages = {3 - 12},
issn = {15224902},
address = {Iquique, Chile},
abstract = {In this paper, we describe AmbientTalk: a domain-specific language for orchestrating service discovery and composition in mobile ad hoc networks. AmbientTalk is a distributed object-oriented language whose actor-based, event-driven concurrency model makes it highly suitable for composing service objects across a mobile network. The language is a so-called ambient-oriented programming language which treats network partitions as a normal mode of operation. We describe AmbientTalk's object model, concurrency model and distributed communication model in detail. We also highlight influences from other languages and middleware that have shaped AmbientTalk's design. &copy; 2007 IEEE.},
key = {Object oriented programming},
keywords = {Ad hoc networks;BASIC (programming language);Computer aided software engineering;Computer programming languages;Computer science;Computer software;Computers;Information theory;Linguistics;Middleware;Query languages;Telecommunication networks;Wireless networks;Wireless telecommunication systems;},
note = {Ambient oriented programming;Distributed communications;Domain specific language (DSL);International conferences;Languages (traditional);Mobile Ad-hoc NETwork (MANET);Mobile networks;Network partitioning;Normal modes;Object modelling;Object oriented (OO);Object-oriented languages;Service discovery;},
URL = {http://dx.doi.org/10.1109/SCCC.2007.4396972},
} 


@article{20083111412535 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Composing software services in the pervasive computing environment: Languages or APIs?},
journal = {Pervasive and Mobile Computing},
author = {Robinson, Jon and Wakeman, Ian and Chalmers, Dan},
volume = {4},
number = {4},
year = {2008},
pages = {481 - 505},
issn = {15741192},
address = {P.O. Box 211, Amsterdam, 1000 AE, Netherlands},
abstract = {The pervasive computing environment will be composed of heterogeneous services. In this work, we have explored how a domain specific language for service composition can be implemented to capture the common design patterns for service composition, yet still retain a comparable performance to other systems written in mainstream languages such as Java. In particular, we have proposed the use of the method delegation design pattern, the resolution of service bindings through the use of dynamically adjustable characteristics and the late binding of services as key features in simplifying the service composition task. These are realised through the Scooby language, and the approach is compared to the use of APIs to define adaptable services. &copy; 2008 Elsevier B.V. All rights reserved.},
key = {Ubiquitous computing},
keywords = {Computer systems;Java programming language;Linguistics;Query languages;Structure (composition);},
note = {design patterns;Domain specific language (DSL);Elsevier (CO);Heterogeneous services;Languages (traditional);Mainstream (MS);Pervasive computing environments;Service compositions;software services;},
URL = {http://dx.doi.org/10.1016/j.pmcj.2008.01.001},
} 


@article{2006239927082 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {VSTS: In the wild},
journal = {Dr. Dobb's Journal},
author = {Swigart, Scott},
volume = {31},
number = {6},
year = {2006},
pages = {56 - 61},
issn = {1044789X},
abstract = {An interview with Visual Studio Team System (VSTS) expert Richard Hundhausen, regarding extensive consulting and training to companies to implement Team System, is presented. VSTS is a domain specific language for doing precise.NET development. It is the combination of Windows Workflow Foundation, which is already in late beta and process modeling solutions built using DSL tools. The class designer is technically not part of Team System. There are four distributed system designers in a Team Systems, such as logical datacenter designer, application designer (AD), distributed system designer, and deployment designer. Team system can do very sophisticated branching, and shelving, and they need better protection of their code.},
key = {Professional aspects},
keywords = {Codes (standards);Computer programming languages;Computer simulation;Distributed computer systems;Personnel training;Problem solving;},
note = {Domain specific language;Sophisticated branching;Visual Studio Team System (VSTS);Windows Workflow Foundation;},
} 


@inproceedings{20083911589398 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Meta-programming applied to automatic SMP parallelization of linear algebra code},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Falcou, Joel and Serot, Jocelyn and Pech, Lucien and Lapreste, Jean-Thierry},
volume = {5168 LNCS},
year = {2008},
pages = {729 - 738},
issn = {03029743},
address = {Las Palmas de Gran Canaria, Spain},
abstract = {We describe a software solution to the problem of automatic parallelization of linear algebra code on multi-processor and multi-core architectures. This solution relies on the definition of a domain specific language for matrix computations, a performance model for multi-processor architectures and its implementation using C++ template meta-programming. Experimental results asses this model and its implementation on sample computation kernels. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Linear algebra},
keywords = {Algebra;Automatic programming;Boolean algebra;Codes (standards);Codes (symbols);Computer programming;Computer programming languages;Matrix algebra;Multiprocessing systems;Shape memory effect;},
note = {Automatic parallelization;Domain-Specific Language;Matrix computations;Meta-programming;Multi cores;Multi processors;Multi-processor architectures;Parallel processing;Parallelization;Performance modelling;Software solutions;},
URL = {http://dx.doi.org/10.1007/978-3-540-85451-7_78},
} 


@inproceedings{20080411056094 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Compiler assisted elliptic curve cryptography},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Barbosa, M. and Moss, A. and Page, D.},
volume = {4804 LNCS},
number = {PART 2},
year = {2007},
pages = {1785 - 1802},
issn = {03029743},
address = {Vilamoura, Portugal},
abstract = {Although cryptographic software implementation is often performed by expert programmers, the range of performance and security driven options, as well as more mundane software engineering issues, still make it a challenge. The use of domain specific language and compiler techniques to assist in description and optimisation of cryptographic software is an interesting research challenge. Our results, which focus on Elliptic Curve Cryptography (ECC), show that a suitable language allows description of ECC based software in a manner close to the original mathematics; the corresponding compiler allows automatic production of an executable whose performance is competitive with that of a hand-optimised implementation. Our work are set within the context of CACE, an ongoing EU funded project on this general topic. &copy; Springer-Verlag Berlin Heidelberg 2007.},
key = {Cryptography},
keywords = {Computer software;Optimization;Program compilers;},
note = {Domain specific language;Elliptic Curve Cryptography (ECC);},
} 


@inproceedings{2005429417772 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Agile development with Domain Specific Languages scaling up Agile - Is Domain-Specific Modeling the key?},
journal = {Lecture Notes in Computer Science},
author = {Wills, Alan Cameron and Kelly, Steven},
volume = {3556},
year = {2005},
pages = {311 - 314},
issn = {03029743},
address = {Sheffield, United kingdom},
abstract = {This workshop will investigate the application of Domain Specific Languages within Agile development. A Domain Specific Language (DSL) is designed to express the requirements and solutions of a particular business or architectural domain. SQL, GUI designers, workflow languages and regular expressions are familiar examples. In recent years, Domain-Specific Modeling has yielded spectacular productivity improvements in domains such as telephony and embedded systems. By creating graphical or textual languages specific to the needs of an individual project or product line within one company, DSM offers maximum agility. With current tools, creating a language and related tool support is fast enough to make DSM a realistic possibility for projects of all sizes. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Computer software},
keywords = {Codes (standards);Computer architecture;Computer programming;Embedded systems;Industry;Mathematical models;Software engineering;Technical presentations;},
note = {Architectural domain;Doamin specific modeling;Domain specific language (DSL);Workflow languages;},
} 


@inproceedings{20093912332171 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Using activity descriptions to generate user interfaces for ERP software},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {O'Hear, Timothy and Boudjenane, Yassin},
volume = {5613 LNCS},
number = {PART 4},
year = {2009},
pages = {577 - 586},
issn = {03029743},
address = {San Diego, CA, United states},
abstract = {Delivering tailor-made ERP software requires automation of screen and printed report creation to be cost effective. Screens generated directly from data structures tend to have poor usability. An approach is considered using a domain specific language to describe use cases. Paper-prototyping and usability testing results define the usability characteristics the DSL portrays. The DSL is capable of defining a variety of screen types and user interface elements including forms, lists, pivot tables, Gantt charts, calendars and graphs. This approach is currently used in production to generate an interactive "AJAX" web user interface as well as HTML, PDF and Excel reports from descriptions stored in XML files. We believe that further research could extend our results to include non-ERP type software. &copy; 2009 Springer Berlin Heidelberg.},
key = {Computer software},
keywords = {Data structures;DSL;Enterprise resource planning;HTML;Human computer interaction;Knowledge management;Linguistics;Markup languages;Modems;Spreadsheets;Telecommunication lines;User interfaces;},
note = {AJAX;Domain specific language;ERP software;Interaction design;Usability;},
URL = {http://dx.doi.org/10.1007/978-3-642-02583-9_63},
} 


@inproceedings{20083211434949 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Experiences on DSL tools for visual studio},
journal = {Proceedings of the International Conference on Information Technology Interfaces, ITI},
author = {Kosar, Tomaz and Mernik, Marjan and Martinez Lopez, Pablo E.},
year = {2007},
pages = {753 - 758},
issn = {13301012},
address = {Dubrovnik, Croatia},
abstract = {Within their application domains, domain-specific languages offer substantial gains in expressiveness, productivity, and ease of use, compared with general-purpose programming languages. Despite the many advantages of domain-specific languages, their use has been unduly limited, by a lack of support in developmental environments. Recently, Microsoft introduced some support by constructing domain-specific languages with a plug-in 'DSL Tools for Visual Studio'. This paper gives language designers tips on developing a domain-specific language using this tool and describes the experiences of an end-user of constructing a language. Another contribution of this paper is a comparison of tools with the traditional approach by the implementation of a domain-specific language, done on the same representative language.},
key = {Linguistics},
keywords = {Computer programming languages;Computer software;DSL;Graphical user interfaces;Information technology;Modems;Query languages;Studios;Technology;Telecommunication lines;},
note = {Application domains;Domain-specific laiguage;Domain-Specific Language;Domain-Specific Languages;Domain-specific visual language;Ease-of-use;End users;General-purpose programming languages;International conferences;Language workbenches;MicroSoft;Plug ins;Source-to-source transformation;Visual studios;},
URL = {http://dx.doi.org/10.1109/ITI.2007.4283866},
} 


@article{20090311858811 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A DSL for enterprise application integration},
journal = {International Journal of Computer Applications in Technology},
author = {Frantz, Rafael Z.},
volume = {33},
number = {4},
year = {2008},
pages = {257 - 263},
issn = {09528091},
address = {P.O. Box 896, Geneve 15, CH-1215, Switzerland},
abstract = {Enterprise Application Integration (EAI) is one of the big challenges for software engineering. According to a recent report published by IBM, for each US dollar spent on developing an application, companies usually spend from 5 up to 20 times more to integrate it. In this paper we propose a Domain Specific Language (DSL) for designing application integration solutions. Contrarily to Apache Camel, our DSL proposal allows to design an integration solution visually, by working with building blocks at a higher level of abstraction, to create a reusable, well documented and independent of technology/platform solutions. Copyright &copy; 2008 Inderscience Enterprises Ltd.},
key = {Integration},
keywords = {Applications;Buildings;Computer software reusability;DSL;Industrial management;Linguistics;Modems;Software engineering;Telecommunication lines;},
note = {Building blocks;Domain specific language;EAI;EIP;Enterprise application integration;Enterprise integration patterns;},
URL = {http://dx.doi.org/10.1504/IJCAT.2008.022420},
} 


@inproceedings{2005399391481 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Rapid development of application-specific network performance tests},
journal = {Lecture Notes in Computer Science},
author = {Pakin, Scott},
volume = {3515},
number = {II},
year = {2005},
pages = {149 - 157},
issn = {03029743},
address = {Atlanta, GA, United states},
abstract = {Analyzing the performance of networks and messaging layers is important for diagnosing anomalous performance in parallel applications. However, general-purpose benchmarks rarely provide sufficient insight into any particular application's behavior. What is needed is a facility for rapidly developing customized network performance tests that mimic an application's use of the network but allow for easier experimentation to help determine performance bottlenecks. In this paper, we contrast four approaches to developing customized network performance tests: straight C, C with a helper library, Python with a helper library, and a domain-specific language. We show that while a special-purpose library can result in significant improvements in functionality without sacrificing language familiarity, the key to facilitating rapid development of network performances tests is to use a domain-specific language designed expressly for that purpose. &copy; Springer-Verlag Berlin Heidelberg 2005.},
key = {Computer networks},
keywords = {Benchmarking;Computer programming languages;Parallel processing systems;},
note = {Application-specific network;Domain-specific language;General-purpose benchmarks;Network performance;},
} 


@inproceedings{2006269958355 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An error-corrective language-model adaptation for automatic speech recognition},
journal = {9th European Conference on Speech Communication and Technology},
author = {Jeong, Minwoo and Eun, Jihyun and Jung, Sangkeun and Lee, Gary Geunbae},
year = {2005},
pages = {729 - 732},
address = {Lisbon, Portugal},
abstract = {We present a new language model adaptation framework integrated with error handling method to improve accuracy of speech recognition and performance of spoken language applications. The proposed error corrective language model adaptation approach exploits domain-specific language variations and recognition environment characteristics to provide robustness and adaptability for a spoken language system. We demonstrate some experiments of spoken dialogue tasks and empirical results which show an improvement of the accuracy for both speech recognition and spoken language understanding.},
key = {Speech recognition},
keywords = {Computer programming languages;Error correction;Mathematical models;Speech analysis;Stereophonic receivers;},
note = {Domain-specific language variations;Error handling;Spoken language applications;Spoken language system;},
} 


@inproceedings{20073910826315 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {SoftGUESS: Visualization and exploration of code clones in context},
journal = {Proceedings - International Conference on Software Engineering},
author = {Adar, E. and Kim, M.},
year = {2007},
pages = {762 - 765},
issn = {02705257},
address = {Minneapolis, MN, United states},
abstract = {We introduce SoftGUESS, a code clone exploration system. SoftGUESS is built on the more general GUESS system which provides users with a mechanism to interactively explore graph structures both through direct manipulation as well as a domain-specific language. We demonstrate SoftGUESS through a number of mini-applications to analyze evolutionary code-clone behavior in software systems. The miniapplications of SoftGUESS represent a novel way of looking at code-clones in the context of many system features. It is our hope that SoftGUESS will form the basis for other analysis tools in the softwareengineering domain. &copy; 2007 IEEE.},
key = {Codes (symbols)},
keywords = {Computer software;Graph theory;User interfaces;},
note = {Analysis tools;Domain-specific language;Graph structures;},
URL = {http://dx.doi.org/10.1109/ICSE.2007.76},
} 


@inproceedings{20102913080701 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A method for reasoning about complex services within geographic information systems},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Grobelny, Piotr},
volume = {6070 LNAI},
number = {PART 1},
year = {2010},
pages = {132 - 141},
issn = {03029743},
address = {Gdynia, Poland},
abstract = {This paper addresses the problem of intelligent discovery and matchmaking of services within geographic information systems (GIS) domain. Expert system could advise the domain engineer in adaptively building of new functionalities with the help of deductive database and domain knowledge. The Services Oriented Architecture (SOA) allows one to fulfill these requirements. The objective of this document is to provide a method for arranging complex services with use of object-oriented expert system, domain specific language and domain ontology in the area of Internet GIS. &copy; 2010 Springer-Verlag.},
key = {Multi agent systems},
keywords = {Expert systems;Geographic information systems;Information systems;Linguistics;Object oriented programming;Ontology;Semantic Web;Semantics;Web services;},
note = {Complex services;Deductive database;Domain knowledge;Domain ontologies;Domain Specific Language;Domain specific languages;Internet GIS;Object oriented;Services oriented architecture;},
URL = {http://dx.doi.org/10.1007/978-3-642-13480-7_15},
} 


@inproceedings{20093812315163 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Designing a DSL solution for the domain of augmented reality software applications specification},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Rosa, Andre and Amaral, Vasco and Barroca, Bruno},
volume = {5670 LNCS},
year = {2009},
pages = {423 - 434},
issn = {03029743},
address = {Banff, AB, Canada},
abstract = {Code repetition, lack of reuse and basic errors are typical problems in the industry that decrease the productivity during the software development process, and this is no exception in the domain of interactive applications with focus on Augmented Reality (AR). In this paper, we describe a new Domain-Specific Language (DSL), based on an existing AR software framework that tackles this problem by adding a new abstraction layer for product specification. The proposed language's abstract syntax covers the definition of application logic's organization, its configuration, objects construction and behaviour definition. The language's concrete syntax was implemented using a metamodeling language workbench. A real case study within the context of an AR software house was used for validation purposes. &copy; 2009 Springer Berlin Heidelberg.},
key = {Linguistics},
keywords = {Abstracting;Augmented reality;Computer software reusability;DSL;E-learning;Education;Game theory;Interactive devices;Modems;Multimedia systems;Specifications;Syntactics;Telecommunication lines;Virtual reality;},
note = {Abstract syntax;Abstraction layer;Application logic;Concrete syntax;Domain specific languages;Domain-Specific Language;Interactive Applications;Language workbenches;Metamodeling;Model Driven Development;Modeling Language;Product specifications;Software applications;Software development process;Software frameworks;Software house;},
URL = {http://dx.doi.org/10.1007/978-3-642-03364-3_51},
} 


@inproceedings{20084111628030 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {On practical information flow policies for java-enabled multiapplication smart cards},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Ghindici, Dorina and Simplot-Ryl, Isabelle},
volume = {5189 LNCS},
year = {2008},
pages = {32 - 47},
issn = {03029743},
address = {London, United kingdom},
abstract = {In the multiapplicative context of smart cards, a strict control of underlying information flow between applications is highly desired. In this paper we propose a model to improve information flow usability in such systems by limiting the overhead for adding information flow security to a Java Virtual Machine. We define a domain specific language for defining security policies describing the allowed information flow inside the card. The applications are certified at loading time with respect to information flow security policies. We illustrate our approach on the LoyaltyCard, a multiapplicative smart card involving four loyalty applications sharing fidelity points. &copy; IFIP International Federation for Information Processing 2008.},
key = {Smart cards},
keywords = {Computer programming languages;Security systems;},
note = {Advanced applications;Domain-Specific Language;Information flow policies;Information flow security;Information flows;International conferences;Java Virtual Machine;Loading time;Multi-application smart cards;Security policies;Smart card;},
URL = {http://dx.doi.org/10.1007/978-3-540-85893-5_3},
} 


@inproceedings{20083311451135 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {29th International Conference on Software Engineering, Early Aspects},
journal = {Proceedings - International Conference on Software Engineering},
year = {2007},
pages = {IEEE Computer Society Technical Council on Software Engineering; ACM Special Interest Group on Software Engineering (SIGSOFT) - },
issn = {02705257},
address = {Minneapolis, United states},
abstract = {The proceedings contain 8 papers. The topics discussed include: a clustering technique for early detection of dominant and recessive cross-cutting concerns; aspectual support for specifying requirements in software product lines; modeling and evolving crosscutting concerns in ADORA; AGOL: an aspect-oriented domain-specific language for MAS; towards the architectural definition of the health watcher system with ao-adl; revisiting a formal framework for modeling aspects in the design phase; a traceability method for crosscutting concerns with transformation rules; and on the contributions of an end-to-end AOSD testbed.},
key = {Architectural design},
keywords = {Engineering;Requirements engineering;Software design;Software engineering;},
note = {Architecture designs;Aspect-oriented;Clustering techniques;Cross cutting;Crosscutting concerns;Design phase;Domain specific language (DSL);Early aspects;Early detection;End to end (ETE);Formal framework;International conferences;Modeling aspects;Software product line (SPL);Test beds;Transformation rules;},
} 


@article{20083911603938 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An online platform for web APIs and service mashups},
journal = {IEEE Internet Computing},
author = {Maximilien, E. Michael and Ranabahu, Ajith and Gomadam, Karthik},
volume = {12},
number = {5},
year = {2008},
pages = {32 - 43},
issn = {10897801},
address = {445 Hoes Lane / P.O. Box 1331, Piscataway, NJ 08855-1331, United States},
abstract = {On the newly programmable Web, mashups are flourishing. Designers create mashups by combining components of existing Web sites and applications. Although rapid mashup proliferation offers many opportunities, a lack of standarization and compatibility offers considerable challenges. IBM Sharable Code is an online service platform for developing and sharing situational Web 2.0 applications and mashups. The platform is based on an innovative domain-specific language that streamlines and standardizes the development and deployment of applications consuming and exposing Web APIs. Parts of the DSL and the resulting applications and mashups can be shared and reused by members of the IBM Sharable Code community. In this article, the authors offer an overview of the platform's architecture and the DSL language at its core. &copy; 2008 IEEE.},
key = {Codes (standards)},
keywords = {Codes (symbols);DSL;Internet;Linguistics;Modems;Telecommunication lines;},
note = {Applications.;Availability;Communities;Domain-Specific Language;Domain-specific languages;Engines;Feeds;Mashups;On-line services;Rails;Ruby on rails;Service mashups;User interfaces;Web 2.0;},
URL = {http://dx.doi.org/10.1109/MIC.2008.92},
} 


@inproceedings{20102513027609 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Functional programming way to interact with software attacks and vulnerabilities},
journal = {ICSTW 2010 - 3rd International Conference on Software Testing, Verification, and Validation Workshops},
author = {Damjanovic, Violeta and Djuric, Dragan},
year = {2010},
pages = {388 - 393},
address = {Paris, France},
abstract = {This paper proposes using functional programming style in a way to respond to detection of and interaction with the software attacks and vulnerabilities. Additionally, our approach considers involving Description Logics, as a basis for the use of the Semantic Web and meta-programming to produce executable ontologies and to enable semantic reasoning over behavior and interaction with software attacks and vulnerabilities. Accordingly, we introduce Magic Potion, a recently defined Domain Specific meta-Language that uses Modeling Spaces framework to study heterogeneous modeling and meta-modeling problems inspired by Model Driven Architecture. As an example of formalism for modeling software attacks and vulnerabilities, we explore Attack Tree, which provides a formal methodology for analyzing the security of the system. Based on Attack Tree, which is herein specified for a particular problem of dealing with known attacks and vulnerabilities of the security layer of the Wireless Application Protocol, and which is particularly built on top of Magic Potion specification, we define our specific Domain Specific Language that we call Attack Tree Domain Specific Language. It is envisioned as a tool for modeling and interacting with software attacks and vulnerabilities. &copy; 2010 IEEE.},
key = {Computer software selection and evaluation},
keywords = {Cellular telephone systems;Data description;Formal logic;Functional programming;Internet protocols;Linguistics;Network security;Ontology;Semantic Web;Semantics;Software architecture;Software testing;Verification;},
note = {Attack tree;Description logic;Domain specific language;Domain specific languages;Model driven architecture;Software vulnerabilities;},
URL = {http://dx.doi.org/10.1109/ICSTW.2010.53},
} 


@article{20080611080299 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Computer games software factory and edutainment platform for Microsoft.NET},
journal = {IET Software},
author = {Furtado, A.W.B. and Santos, A.L.M. and Ramalho, G.L.},
volume = {1},
number = {6},
year = {2007},
pages = {280 - 293},
issn = {17518806},
address = {Six Hills Way, Stevenage, SG1 2AY, United Kingdom},
abstract = {An environment targeted at computer games development industrialisation in the.NET platform is presented. A computer game product line definition and its architecture are specified and implemented by means of software factory assets, such as a visual designer based on a domain-specific language, semantic validators and code generators. The proposed approach is then illustrated and empirically validated by the creation of real world case studies. Finally, it is investigated how the proposed factory can be used as an edutainment platform for Computer Science 1 and 2 courses. The final intention is to empower game developers and designers to work more productively, with a higher level of abstraction and closer to their application domain. &copy; The Institution of Engineering and Technology 2007.},
key = {Computer software},
keywords = {Animation;Semantics;Software architecture;Specification languages;Three dimensional computer graphics;},
note = {Computer games software;Domain-specific language;Microsoft.NET;Software factory assets;},
URL = {http://dx.doi.org/10.1049/iet-sen:20070023},
} 


@inproceedings{20083111409894 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Modeling and enforcing advanced access control policies in healthcare systems with SECTET},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Hafner, Michael and Memon, Mukhtiar and Alam, Muhammad},
volume = {5002 LNCS},
year = {2008},
pages = {132 - 144},
issn = {03029743},
address = {Nashville, TN, United states},
abstract = {This contribution gives an overview of various access control strategies in use in healthcare scenarios and shows how a variety of policies can be modeled based on a single security policy model for usage control, UCON. The core of this contribution consists of the specialization of the Sectet-Framework for Model Driven Security for complex healthcare scenarios based on UCON. The resulting Domain Architecture comprises a Domain Specific Language for the modeling of policies with advanced security requirements, a target architecture for the enforcement of these policies and model-to-code transformations. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Access control},
keywords = {Artificial intelligence;Bioinformatics;Computer science;Control systems;Cosine transforms;Health;Models;Public policy;Security of data;Security systems;Software engineering;},
note = {Access control policies;Code transformations;Control strategies;Domain architectures;Domain specific language (DSL);Health care systems;Heidelberg (CO);Lecture Notes;Model-driven;Security Policy Model (SPM);Security requirements;Specialization (order);Target architectures;Usage control;},
URL = {http://dx.doi.org/10.1007/978-3-540-69073-3_15},
} 


@inproceedings{20083011389568 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A language-based approach for improving the robustness of network application protocol implementations},
journal = {Proceedings of the IEEE Symposium on Reliable Distributed Systems},
author = {Burgy, Laurent and Reveillere, Laurent and Lawall, Julia L. and Muller, Gilles},
year = {2007},
pages = {149 - 158},
issn = {10609857},
address = {Beijing, China},
abstract = {The secure and robust functioning of a network relies on the defect-free implementation of network applications. As network protocols have become increasingly complex, however, hand- writing network message processing code has become increasingly error-prone. In this paper, we present a domain-specific language, Zebu, for generating robust and efficient message processing layers. A Zebu specification, based on the notation used in RFCs, describes protocol message formats and related processing constraints. Zebu-based applications are efficient, since message fragments can be specified to be processed on demand. Zebu-based applications are also robust, as the Zebu compiler automatically checks specification consistency and generates parsing stubs that include validation of the message structure. Using a message torture suite in the context of SIP and RTSP, we show that Zebu-generated code is both complete and defect-free. &copy; 2007 IEEE.},
key = {Network protocols},
keywords = {Arsenic compounds;Codes (standards);Codes (symbols);Internet protocols;Linguistics;Technical presentations;},
note = {Defect free;Domain specific language (DSL);Error prone;International symposium;Message processing;Message structures;Network applications;On-Demand;Protocol messages;Reliable Distributed Systems;Specification consistency;},
URL = {http://dx.doi.org/10.1109/SRDS.2007.4365692},
} 


@inproceedings{20092812186475 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {An approach to concurrent development of device drivers and device controller},
journal = {International Conference on Advanced Communication Technology, ICACT},
author = {Lisboa, Edson B. and Silva, Luciano and Lima, Thiago and Chaves, Igino and Barros, Edna},
volume = {1},
year = {2009},
pages = {571 - 575},
issn = {17389445},
address = {Phoenix Park, Korea, Republic of},
abstract = {Embedded Systems must communicate with different peripheral devices to provide easy interactivity and mobility. The communication structure combines hardware and software solutions. The design of a communication structure demands great effort, long time, tends to cause many errors and has relevant impact in system performance. To minimize these questions, this paper presents an approach to concurrent development of device controller simulation models and its respective device drivers. The approach is based on a domain specific language, named DevC, that allows to specify several aspects of both: device controller and driver. From this specification, the hardware simulation model and the device driver are synthesized. The device controller and the driver are validated using a hardware virtual platform to reduce development time and, then, are validated in real hardware.},
key = {Embedded systems},
keywords = {Automobile drivers;Communication;Computer operating systems;Concurrency control;Controllers;Embedded software;Linguistics;Simulators;Systems analysis;},
note = {Device Controller;Device Driver;Domain specific language;Embedded system design;Operating System;},
} 


@article{20082711347978 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Aspect-oriented Prolog in a language processing context},
journal = {IET Software},
author = {Lohmann, W. and Riedewald, G. and Wachsmuth, G.},
volume = {2},
number = {3},
year = {2008},
pages = {241 - 259},
issn = {17518806},
address = {Six Hills Way, Stevenage, SG1 2AY, United Kingdom},
abstract = {Language processors can be derived from logic grammars. That several concerns in the processor such as parsing, several kinds of analysis or transformations, can be specified as aspects of the logic grammar is demonstred. For that purpose, the authors bring the concepts of aspect-oriented programming to Prolog in a systematic way, based on established Prolog technology. The authors illustrate that typical Prolog programming techniques can be described as generic aspects and provided in a library to support reusable concerns. A domain-specific language (DSL) is developed to improve readability of aspect-oriented specifications. &copy; 2008 The Institution of Engineering and Technology.},
key = {Artificial intelligence},
keywords = {Computational linguistics;Formal languages;Fuzzy logic;Linguistics;PROLOG (programming language);Specifications;},
note = {(OTDR) technology;Aspect Oriented Programming (AOP);Aspect-oriented;Domain specific language (DSL);language processing;Language processors;logic grammars;Prolog programming;Systematic (CO);},
URL = {http://dx.doi.org/10.1049/iet-sen:20070064},
} 


@inproceedings{2004298269653 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {Architectural description of QoS provisioning for multimedia application support},
journal = {Proceedings - 10th International Multimedia Modelling Conference, MMM 2004},
author = {Neto, Carlos S. Soares and Rodrigues, Rogerio F. and Soares, Luiz Fernando G.},
year = {2004},
pages = {161 - 166},
address = {Brisbana, Australia},
abstract = {The increasing number of multimedia applications has motivated the construction of platforms with end-to-end Quality of Service (QoS) support. This work proposes the use of Wright architecture description language (ADL) in the QoS provisioning domain, as the basis for the formal verification of QoS system properties. To smooth this task, the LindaQoS domain-specific language was designed as a high-level notation for the specification of resource (QoS) orchestration. As a result of this approach, we expect that designers can define clear and unambiguous instantiated platforms, with support to multimedia application implementations, in a reduced development time.},
key = {Multimedia systems},
keywords = {Computational methods;Computer architecture;Data storage equipment;Parameter estimation;Quality of service;Reliability;Resource allocation;Specifications;Synchronization;},
note = {Domain-specific language (DSL);QoS mappers;QoS negotiators;Resource management;UML (Unified Modeling Language);},
URL = {http://dx.doi.org/10.1109/MULMM.2004.1264981},
} 


@inproceedings{20083011391971 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2011 Elsevier Inc.},
copyright = {Compendex},
title = {A domain analysis to specify design defects and generate detection algorithms},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Moha, Naouel and Gueheneuc, Yann-Gael and Le Meur, Anne-Francoise and Duchien, Laurence},
volume = {4961 LNCS},
year = {2008},
pages = {276 - 291},
issn = {03029743},
address = {Budapest, Hungary},
abstract = {Quality experts often need to identify in software systems design defects, which are recurring design problems, that hinder development and maintenance. Consequently, several defect detection approaches and tools have been proposed in the literature. However, we are not aware of any approach that defines and reifies the process of generating detection algorithms from the existing textual descriptions of defects. In this paper, we introduce an approach to automate the generation of detection algorithms from specifications written using a domain-specific language. The domain-specific is defined from a thorough domain analysis. We specify several design defects, generate automatically detection algorithms using templates, and validate the generated detection algorithms in terms of precision and recall on Xerces v2.7.0, an open-source object-oriented system. &copy; 2008 Springer-Verlag Berlin Heidelberg.},
key = {Algorithms},
keywords = {Computer software;Computer software maintenance;Defects;Signal detection;Software design;Software engineering;Specifications;Systems analysis;},
note = {Conferences (Chemical industry);Defect detection;Design defects;Design problems;Detection algorithms;Domain analysis (DA);Domain specific;Domain specific language (DSL);European;Heidelberg (CO);International (CO);International conferences;Object-oriented systems;Open sources;Precision and recall;Software systems design (SSD);Textual descriptions;},
URL = {http://dx.doi.org/10.1007/978-3-540-78743-3_20},
} 


